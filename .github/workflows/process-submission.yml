# Process Skill Submission - Parallel Processing Workflow
#
# Architecture:
#   Job 1: discover-and-plan   - Clone repo, discover skills, create matrix
#   Job 2: process (matrix)    - Process skills in parallel shards
#   Job 3: merge-and-create-pr - Combine results, create single PR
#
# Dynamic Sharding:
#   - < 30 skills: Single job (simple mode)
#   - >= 30 skills: Split evenly across 6 parallel shards
#
# Retry Logic:
#   - Each shard retries failed skills once before giving up

name: Process Skill Submission

on:
  repository_dispatch:
    types: [process-submission]
  workflow_dispatch:
    inputs:
      github_url:
        description: 'GitHub URL of the skill to process'
        required: true
        type: string
      model:
        description: 'Model to use (e.g., gpt-5.2-codex:high, claude-sonnet-4.5). Auto-detects agent.'
        required: false
        type: string
        default: ''
      cli_version:
        description: 'CLI version (default: latest)'
        required: false
        type: string
        default: 'latest'
      max_parallel:
        description: 'Max parallel shards (default: 6)'
        type: string
        default: '6'

env:
  SUBMISSION_ID: ${{ github.event.client_payload.submission_id || github.run_id }}
  GITHUB_URL: ${{ github.event.client_payload.github_url || inputs.github_url }}
  CLI_VERSION: ${{ inputs.cli_version || 'latest' }}
  SHARD_THRESHOLD: 30
  MAX_SHARDS: 6

concurrency:
  group: process-submission-${{ github.event.client_payload.submission_id || github.run_id }}
  cancel-in-progress: false

jobs:
  # ============================================================
  # JOB 1: DISCOVER AND PLAN
  # Clone repo, discover skills, create matrix for parallel processing
  # ============================================================
  discover-and-plan:
    runs-on: self-hosted
    outputs:
      matrix: ${{ steps.plan.outputs.matrix }}
      skill_count: ${{ steps.discover.outputs.skill_count }}
      skills_json: ${{ steps.discover.outputs.skills_json }}
      is_sharded: ${{ steps.plan.outputs.is_sharded }}
      shard_count: ${{ steps.plan.outputs.shard_count }}
      owner: ${{ steps.clone.outputs.owner }}
      repo: ${{ steps.clone.outputs.repo }}
      branch: ${{ steps.clone.outputs.branch }}
    steps:
      - name: Checkout marketplace
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Configure Git identity
        run: |
          git config --global user.name "ai-skill-store[bot]"
          git config --global user.email "2628292+ai-skill-store[bot]@users.noreply.github.com"

      - name: Notify skillstore - Processing started
        if: github.event_name == 'repository_dispatch'
        run: |
          curl -sS -X POST "${{ secrets.SKILLSTORE_API_URL }}/api/submit/callback" \
            -H "Authorization: Bearer ${{ secrets.SKILLSTORE_CALLBACK_TOKEN }}" \
            -H "Content-Type: application/json" \
            -H "User-Agent: GitHub-Actions/SkillstoreBot" \
            -H "X-Skillstore-Callback: true" \
            -d '{
              "submission_id": "'"$SUBMISSION_ID"'",
              "event": "started",
              "workflow_run_id": ${{ github.run_id }},
              "workflow_run_url": "https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}"
            }' || echo "::warning::Failed to notify skillstore"

      - name: Clone source repository
        id: clone
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          URL="${{ env.GITHUB_URL }}"
          URL="${URL%.git}"

          if [[ "$URL" =~ github\.com[:/]([^/]+)/([^/]+) ]]; then
            OWNER="${BASH_REMATCH[1]}"
            REPO="${BASH_REMATCH[2]}"
          else
            echo "::error::Invalid GitHub URL: $URL"
            exit 1
          fi

          echo "owner=$OWNER" >> $GITHUB_OUTPUT
          echo "repo=$REPO" >> $GITHUB_OUTPUT

          # Extract skillPath from URL (e.g., /tree/master/.claude/skills/clojure-review)
          SKILL_PATH=""
          if [[ "$URL" =~ /tree/[^/]+/(.+)$ ]]; then
            SKILL_PATH="${BASH_REMATCH[1]}"
            echo "ðŸ“ Skill path specified: $SKILL_PATH"
          fi
          echo "skill_path=$SKILL_PATH" >> $GITHUB_OUTPUT

          BRANCH=$(gh api "repos/$OWNER/$REPO" --jq '.default_branch')
          echo "branch=$BRANCH" >> $GITHUB_OUTPUT

          SOURCE_DIR="/tmp/source-repo-${{ github.run_id }}"
          git clone --depth 1 --branch "$BRANCH" "https://github.com/$OWNER/$REPO.git" "$SOURCE_DIR"

          echo "source_dir=$SOURCE_DIR" >> $GITHUB_OUTPUT
          echo "ðŸ“¦ Cloned $OWNER/$REPO (branch: $BRANCH)"

      - name: Discover skills (fast - no AI)
        id: discover
        env:
          SKILL_PATH: ${{ steps.clone.outputs.skill_path }}
        run: |
          SOURCE_DIR="${{ steps.clone.outputs.source_dir }}"

          # If skill_path is specified, only search within that path
          if [ -n "$SKILL_PATH" ]; then
            SEARCH_DIR="$SOURCE_DIR/$SKILL_PATH"
            echo "ðŸ“ Searching within: $SKILL_PATH"
          else
            SEARCH_DIR="$SOURCE_DIR"
            echo "ðŸ” Searching entire repository"
          fi

          SKILLS_JSON="["
          FIRST=true

          while IFS= read -r skill_md; do
            SKILL_DIR=$(dirname "$skill_md")

            SLUG=$(grep -E '^name:' "$skill_md" 2>/dev/null | head -1 | sed 's/name:[[:space:]]*//' | tr '[:upper:]' '[:lower:]' | sed 's/[^a-z0-9]/-/g' | sed 's/^-*//;s/-*$//' | sed 's/--*/-/g')
            [ -z "$SLUG" ] && SLUG=$(basename "$SKILL_DIR" | tr '[:upper:]' '[:lower:]' | sed 's/[^a-z0-9]/-/g' | sed 's/^-*//;s/-*$//')

            if [ "$FIRST" = true ]; then
              FIRST=false
            else
              SKILLS_JSON+=","
            fi
            SKILLS_JSON+="\"$SLUG\""
          done < <(find "$SEARCH_DIR" -name "SKILL.md" -type f ! -path "*/node_modules/*" ! -path "*/.git/*" ! -path "*/.venv/*" ! -path "*/venv/*" 2>/dev/null | sort)

          SKILLS_JSON+="]"

          SKILL_COUNT=$(echo "$SKILLS_JSON" | jq 'length')

          echo "skills_json=$SKILLS_JSON" >> $GITHUB_OUTPUT
          echo "skill_count=$SKILL_COUNT" >> $GITHUB_OUTPUT

          echo "ðŸ“Š Discovered $SKILL_COUNT skill(s)"

      - name: Check for hash changes (skip unchanged repos)
        id: hash_check
        env:
          OWNER: ${{ steps.clone.outputs.owner }}
          REPO: ${{ steps.clone.outputs.repo }}
          SKILLS_JSON: ${{ steps.discover.outputs.skills_json }}
        run: |
          # Fetch existing hashes from skillstore API
          RESPONSE=$(curl -sS "${{ secrets.SKILLSTORE_API_URL }}/api/skills/hash?repo=$OWNER/$REPO" 2>/dev/null || echo '{"success":false}')
          
          HAS_EXISTING=$(echo "$RESPONSE" | jq -r '.data.has_skills // false')
          
          if [ "$HAS_EXISTING" = "false" ]; then
            echo "ðŸ“¦ New repository - no existing skills found"
            echo "skip_processing=false" >> $GITHUB_OUTPUT
            echo "changed_slugs=$SKILLS_JSON" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          # Get existing hashes
          EXISTING_HASHES=$(echo "$RESPONSE" | jq -r '.data.skills // []')
          EXISTING_COUNT=$(echo "$EXISTING_HASHES" | jq 'length')
          
          echo "ðŸ“Š Found $EXISTING_COUNT existing skill(s) from this repo"
          
          # For now, we always process - the CLI will handle detailed hash comparison
          # This step is for future optimization when we compute tree_hash before clone
          echo "skip_processing=false" >> $GITHUB_OUTPUT
          echo "changed_slugs=$SKILLS_JSON" >> $GITHUB_OUTPUT
          echo "existing_count=$EXISTING_COUNT" >> $GITHUB_OUTPUT

      - name: Plan processing strategy
        id: plan
        env:
          SKILL_COUNT: ${{ steps.discover.outputs.skill_count }}
          SKILLS_JSON: ${{ steps.discover.outputs.skills_json }}
        run: |
          COUNT=$SKILL_COUNT
          THRESHOLD=${{ env.SHARD_THRESHOLD }}
          MAX_SHARDS=${{ env.MAX_SHARDS }}
          
          if [ "$COUNT" -eq 0 ]; then
            echo "âŒ No skills found"
            echo 'matrix={"include":[]}' >> $GITHUB_OUTPUT
            echo "is_sharded=false" >> $GITHUB_OUTPUT
            echo "shard_count=0" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          if [ "$COUNT" -lt "$THRESHOLD" ]; then
            echo "ðŸ“¦ Simple mode: $COUNT skills (below threshold $THRESHOLD)"
            ESCAPED_SLUGS=$(echo "$SKILLS_JSON" | jq -r 'join(",")')
            echo "matrix={\"include\":[{\"shard\":0,\"slugs\":\"$ESCAPED_SLUGS\"}]}" >> $GITHUB_OUTPUT
            echo "is_sharded=false" >> $GITHUB_OUTPUT
            echo "shard_count=1" >> $GITHUB_OUTPUT
          else
            # Dynamic shard count: use MAX_SHARDS or fewer if skills < MAX_SHARDS * 5
            if [ "$COUNT" -lt $((MAX_SHARDS * 5)) ]; then
              SHARDS=$(( (COUNT + 4) / 5 ))
              [ "$SHARDS" -lt 2 ] && SHARDS=2
            else
              SHARDS=$MAX_SHARDS
            fi
            
            echo "ðŸ”€ Sharded mode: $COUNT skills â†’ $SHARDS shards (dynamic sizing)"
            
            # Calculate base size and remainder for even distribution
            BASE_SIZE=$((COUNT / SHARDS))
            REMAINDER=$((COUNT % SHARDS))
            
            MATRIX='{"include":['
            CURRENT_IDX=0
            
            for i in $(seq 0 $((SHARDS - 1))); do
              # First REMAINDER shards get BASE_SIZE + 1
              if [ $i -lt $REMAINDER ]; then
                THIS_SIZE=$((BASE_SIZE + 1))
              else
                THIS_SIZE=$BASE_SIZE
              fi
              
              # Extract slugs for this shard
              SHARD_SLUGS=$(echo "$SKILLS_JSON" | jq -r ".[$CURRENT_IDX:$((CURRENT_IDX + THIS_SIZE))] | join(\",\")")
              CURRENT_IDX=$((CURRENT_IDX + THIS_SIZE))
              
              [ $i -gt 0 ] && MATRIX+=','
              MATRIX+="{\"shard\":$i,\"slugs\":\"$SHARD_SLUGS\"}"
              
              echo "  Shard $i: $THIS_SIZE skills"
            done
            MATRIX+=']}'
            
            echo "matrix=$MATRIX" >> $GITHUB_OUTPUT
            echo "is_sharded=true" >> $GITHUB_OUTPUT
            echo "shard_count=$SHARDS" >> $GITHUB_OUTPUT
          fi

      - name: Cleanup source
        if: always()
        run: rm -rf /tmp/source-repo-${{ github.run_id }}

  # ============================================================
  # JOB 2: PROCESS (Parallel Matrix)
  # Each shard processes a subset of skills with retry logic
  # ============================================================
  process:
    needs: discover-and-plan
    if: needs.discover-and-plan.outputs.shard_count != '0'
    runs-on: self-hosted
    continue-on-error: true
    strategy:
      fail-fast: false
      max-parallel: ${{ fromJSON(inputs.max_parallel || '6') }}
      matrix: ${{ fromJSON(needs.discover-and-plan.outputs.matrix) }}
    steps:
      - name: Generate GitHub App Token
        id: app-token
        uses: actions/create-github-app-token@v2
        with:
          app-id: ${{ secrets.APP_ID }}
          private-key: ${{ secrets.APP_PRIVATE_KEY }}
          # Include skillstore repo for CLI download access
          repositories: marketplace,skillstore

      - name: Checkout marketplace
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Download Skillstore CLI
        uses: ./.github/actions/download-skillstore-cli
        with:
          version: ${{ inputs.cli_version || 'latest' }}
          token: ${{ steps.app-token.outputs.token }}

      - name: Process shard ${{ matrix.shard }}
        id: process
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          SKILLSTORE_AGENTS: ${{ vars.SKILLSTORE_AGENTS }}
          PUBLIC_SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
          SLUGS: ${{ matrix.slugs }}
        run: |
          echo "=== Shard ${{ matrix.shard }} ==="
          SKILL_COUNT=$(echo "$SLUGS" | tr ',' '\n' | grep -c . || echo 0)
          echo "Processing $SKILL_COUNT skill(s)"
          
          MODEL_FLAG=""
          if [ -n "${{ inputs.model }}" ]; then
            MODEL_FLAG="--model ${{ inputs.model }}"
          fi
          
          # First attempt (--skip-pr: workflow handles PR creation in merge-and-create-pr job)
          set +e
          ./skillstore-cli skill process "${{ env.GITHUB_URL }}" \
            --slugs "$SLUGS" \
            --output . \
            --marketplace-repo "${{ github.repository }}" \
            --skip-pr \
            $MODEL_FLAG \
            --verbose \
            2>&1 | tee process-output-${{ matrix.shard }}.log
          FIRST_EXIT=$?
          set -e
          
          # Check for failed skills and retry (match by directory path, not JSON content)
          FAILED_SLUGS=""
          for slug in $(echo "$SLUGS" | tr ',' '\n'); do
            [ -z "$slug" ] && continue
            FOUND=$(find pending -path "*/$slug/skill-report.json" 2>/dev/null | head -1)
            if [ -z "$FOUND" ]; then
              [ -n "$FAILED_SLUGS" ] && FAILED_SLUGS="$FAILED_SLUGS,"
              FAILED_SLUGS="$FAILED_SLUGS$slug"
            fi
          done
          
          # Retry failed skills once
          if [ -n "$FAILED_SLUGS" ]; then
            RETRY_COUNT=$(echo "$FAILED_SLUGS" | tr ',' '\n' | grep -c . || echo 0)
            echo ""
            echo "ðŸ”„ Retrying $RETRY_COUNT failed skill(s): $FAILED_SLUGS"
            sleep 10
            
            ./skillstore-cli skill process "${{ env.GITHUB_URL }}" \
              --slugs "$FAILED_SLUGS" \
              --output . \
              --marketplace-repo "${{ github.repository }}" \
              --skip-pr \
              $MODEL_FLAG \
              --verbose \
              2>&1 | tee -a process-output-${{ matrix.shard }}.log || true
          fi
          
          # Collect final results
          PROCESSED=0
          ERRORS=0
          HIGHEST_RISK="safe"
          PROCESSED_SLUGS=""
          
          for report in $(find pending -name "skill-report.json" 2>/dev/null); do
            SLUG=$(jq -r '.meta.slug' "$report")
            RISK=$(jq -r '.security_audit.risk_level // "unknown"' "$report")
            
            PROCESSED_SLUGS="$PROCESSED_SLUGS,$SLUG"
            PROCESSED=$((PROCESSED + 1))
            
            case "$RISK" in
              critical) HIGHEST_RISK="critical" ;;
              high) [ "$HIGHEST_RISK" != "critical" ] && HIGHEST_RISK="high" ;;
              medium) [ "$HIGHEST_RISK" = "safe" ] || [ "$HIGHEST_RISK" = "low" ] && HIGHEST_RISK="medium" ;;
              low) [ "$HIGHEST_RISK" = "safe" ] && HIGHEST_RISK="low" ;;
            esac
          done
          
          # Count remaining failures (match by directory path, not JSON content)
          for slug in $(echo "$SLUGS" | tr ',' '\n'); do
            [ -z "$slug" ] && continue
            FOUND=$(find pending -path "*/$slug/skill-report.json" 2>/dev/null | head -1)
            [ -z "$FOUND" ] && ERRORS=$((ERRORS + 1))
          done
          
          PROCESSED_SLUGS=$(echo "$PROCESSED_SLUGS" | sed 's/^,//')
          
          echo "processed=$PROCESSED" >> $GITHUB_OUTPUT
          echo "errors=$ERRORS" >> $GITHUB_OUTPUT
          echo "highest_risk=$HIGHEST_RISK" >> $GITHUB_OUTPUT
          echo "processed_slugs=$PROCESSED_SLUGS" >> $GITHUB_OUTPUT
          
          echo ""
          echo "ðŸ“Š Shard ${{ matrix.shard }}: $PROCESSED processed, $ERRORS errors, highest risk: $HIGHEST_RISK"

      - name: Upload shard results
        uses: actions/upload-artifact@v4
        with:
          name: process-shard-${{ matrix.shard }}
          path: |
            pending/
            process-output-${{ matrix.shard }}.log
          retention-days: 1

      - name: Cleanup
        if: always()
        run: rm -f skillstore-cli

  # ============================================================
  # JOB 3: MERGE AND CREATE PR
  # Combine all shard results and create a single PR
  # Uses fresh clone to temp directory - eliminates state pollution from self-hosted runners
  # ============================================================
  merge-and-create-pr:
    needs: [discover-and-plan, process]
    if: always() && needs.discover-and-plan.outputs.shard_count != '0'
    runs-on: self-hosted
    steps:
      - name: Generate GitHub App Token
        id: app-token
        uses: actions/create-github-app-token@v2
        with:
          app-id: ${{ secrets.APP_ID }}
          private-key: ${{ secrets.APP_PRIVATE_KEY }}

      - name: Download all shard artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: process-shard-*
          merge-multiple: true
          path: /tmp/submission-artifacts-${{ github.run_id }}

      - name: Merge results and create PR
        id: create_pr
        env:
          GH_TOKEN: ${{ steps.app-token.outputs.token }}
        run: |
          set -euo pipefail

          WORK_DIR="/tmp/marketplace-${{ github.run_id }}"
          ARTIFACTS_DIR="/tmp/submission-artifacts-${{ github.run_id }}"

          cleanup() {
            echo "ðŸ§¹ Cleaning up temp directories..."
            rm -rf "$WORK_DIR" "$ARTIFACTS_DIR" 2>/dev/null || true
          }
          trap cleanup EXIT

          echo "ðŸ“¦ Cloning fresh repository to $WORK_DIR..."
          git clone --depth 1 "https://x-access-token:${{ steps.app-token.outputs.token }}@github.com/${{ github.repository }}.git" "$WORK_DIR"
          cd "$WORK_DIR"
          
          git config user.name "ai-skill-store[bot]"
          git config user.email "2628292+ai-skill-store[bot]@users.noreply.github.com"
          
          echo "=== Merging results from all shards ==="
          mkdir -p pending
          if [ -d "$ARTIFACTS_DIR/pending" ]; then
            cp -r "$ARTIFACTS_DIR/pending/"* ./pending/ 2>/dev/null || true
          fi
          
          PROCESSED_COUNT=0
          HIGHEST_RISK="safe"
          PROCESSED_SKILLS=""
          
          for report in $(find pending -name "skill-report.json" 2>/dev/null); do
            NAMESPACED_SLUG=$(jq -r 'if .meta.source_type == "official" then .meta.slug else .meta.owner + "/" + .meta.slug end' "$report")
            RISK=$(jq -r '.security_audit.risk_level // "unknown"' "$report")
            
            PROCESSED_SKILLS="$PROCESSED_SKILLS,$NAMESPACED_SLUG"
            PROCESSED_COUNT=$((PROCESSED_COUNT + 1))
            
            case "$RISK" in
              critical) HIGHEST_RISK="critical" ;;
              high) [ "$HIGHEST_RISK" != "critical" ] && HIGHEST_RISK="high" ;;
              medium) [ "$HIGHEST_RISK" = "safe" ] || [ "$HIGHEST_RISK" = "low" ] && HIGHEST_RISK="medium" ;;
              low) [ "$HIGHEST_RISK" = "safe" ] && HIGHEST_RISK="low" ;;
            esac
          done
          
          PROCESSED_SKILLS="${PROCESSED_SKILLS#,}"
          
          TOTAL_ERRORS=0
          for log in "$ARTIFACTS_DIR"/process-output-*.log; do
            if [ -f "$log" ]; then
              ERR_COUNT=$(grep -c "âŒ error" "$log" 2>/dev/null) || ERR_COUNT=0
              TOTAL_ERRORS=$((TOTAL_ERRORS + ERR_COUNT))
            fi
          done
          
          echo "ðŸ“Š Merged Results:"
          echo "  Total processed: $PROCESSED_COUNT"
          echo "  Total errors: $TOTAL_ERRORS"
          echo "  Highest risk: $HIGHEST_RISK"
          
          if [ "$PROCESSED_COUNT" -eq 0 ]; then
            echo "::error::No skills were successfully processed"
            echo "has_results=false" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          echo "has_results=true" >> $GITHUB_OUTPUT
          echo "processed_count=$PROCESSED_COUNT" >> $GITHUB_OUTPUT
          echo "skills_list=$PROCESSED_SKILLS" >> $GITHUB_OUTPUT
          echo "highest_risk=$HIGHEST_RISK" >> $GITHUB_OUTPUT
          echo "total_errors=$TOTAL_ERRORS" >> $GITHUB_OUTPUT
          
          REPO_NAME=$(echo "${{ env.GITHUB_URL }}" | sed -E 's|.*/([^/]+)/?$|\1|' | sed 's/\.git$//')
          BRANCH_NAME="submission/${REPO_NAME}-${{ env.SUBMISSION_ID }}"
          IS_SHARDED="${{ needs.discover-and-plan.outputs.is_sharded }}"
          SHARD_COUNT="${{ needs.discover-and-plan.outputs.shard_count }}"
          SKILL_COUNT="${{ needs.discover-and-plan.outputs.skill_count }}"
          
          git push origin --delete "$BRANCH_NAME" 2>/dev/null || true
          
          git checkout -b "$BRANCH_NAME"
          git add pending/
          
          if [ "$PROCESSED_COUNT" -eq 1 ]; then
            FIRST_SKILL=$(echo "$PROCESSED_SKILLS" | cut -d',' -f1)
            git commit -m "Add pending plugin: $FIRST_SKILL [submission: ${{ env.SUBMISSION_ID }}]"
            PR_TITLE="New plugin: $FIRST_SKILL ($HIGHEST_RISK risk)"
          else
            git commit -m "Add $PROCESSED_COUNT pending plugins from $REPO_NAME [submission: ${{ env.SUBMISSION_ID }}]"
            if [ "$IS_SHARDED" = "true" ]; then
              PR_TITLE="New plugins: $PROCESSED_COUNT skills from $REPO_NAME ($HIGHEST_RISK) [parallel: ${SHARD_COUNT} shards]"
            else
              PR_TITLE="New plugins: $PROCESSED_COUNT skills from $REPO_NAME ($HIGHEST_RISK risk)"
            fi
          fi
          
          git push origin "$BRANCH_NAME"
          
          RISK_BADGE="ðŸŸ¢"
          [ "$HIGHEST_RISK" = "critical" ] && RISK_BADGE="ðŸ”´"
          [ "$HIGHEST_RISK" = "high" ] && RISK_BADGE="ðŸŸ "
          [ "$HIGHEST_RISK" = "medium" ] && RISK_BADGE="ðŸŸ¡"
          [ "$HIGHEST_RISK" = "low" ] && RISK_BADGE="ðŸŸ¡"
          
          SKILLS_TABLE="| Skill | Risk | Status |
          |-------|------|--------|"
          
          for report in $(find pending -name "skill-report.json" 2>/dev/null | head -50); do
            NAMESPACED_SLUG=$(jq -r 'if .meta.source_type == "official" then .meta.slug else .meta.owner + "/" + .meta.slug end' "$report")
            SKILL_RISK=$(jq -r '.security_audit.risk_level // "unknown"' "$report")
            SKILLS_TABLE="$SKILLS_TABLE
          | \`$NAMESPACED_SLUG\` | $SKILL_RISK | Ready |"
          done
          
          if [ "$PROCESSED_COUNT" -gt 50 ]; then
            SKILLS_TABLE="$SKILLS_TABLE
          | ... | ... | ... |
          | *and $((PROCESSED_COUNT - 50)) more* | | |"
          fi
          
          cat > pr-body.md << EOF
          ## Skill Submission: $REPO_NAME
          
          **Submission ID**: \`${{ env.SUBMISSION_ID }}\`
          **Source**: ${{ env.GITHUB_URL }}
          
          ### Summary $RISK_BADGE
          - Skills discovered: $SKILL_COUNT
          - Skills processed: $PROCESSED_COUNT
          - Highest risk: $HIGHEST_RISK
          EOF
          
          if [ "$IS_SHARDED" = "true" ]; then
            echo "- Processing mode: **Parallel** ($SHARD_COUNT shards)" >> pr-body.md
          fi
          
          if [ "$TOTAL_ERRORS" -gt 0 ]; then
            echo "- âš ï¸ Failed skills: $TOTAL_ERRORS" >> pr-body.md
          fi
          
          cat >> pr-body.md << EOF
          
          ### Skills
          $SKILLS_TABLE
          
          ### Review Checklist
          - [ ] All skill contents are appropriate
          - [ ] Security audit findings reviewed
          - [ ] Source repository checked
          
          ---
          *Processed by skillstore-cli*
          EOF
          
          # Use gh pr create with JSON output for reliable URL extraction
          PR_RESULT=$(gh pr create \
            --title "$PR_TITLE" \
            --body-file pr-body.md \
            --label "pending-review" \
            --base main \
            --head "$BRANCH_NAME" 2>&1) || true

          # Extract PR URL from output (last line typically contains URL)
          PR_URL=$(echo "$PR_RESULT" | grep -oE 'https://github.com/[^/]+/[^/]+/pull/[0-9]+' | head -1)

          if [ -z "$PR_URL" ]; then
            echo "::warning::Could not extract PR URL from: $PR_RESULT"
            # Fallback: try getting the URL from the last line
            PR_URL=$(echo "$PR_RESULT" | tail -1)
          fi

          echo "pr_url=$PR_URL" >> $GITHUB_OUTPUT
          echo "Created PR: $PR_URL"

      - name: Notify skillstore - PR created
        if: steps.create_pr.outputs.pr_url && github.event_name == 'repository_dispatch'
        env:
          PR_URL: ${{ steps.create_pr.outputs.pr_url }}
          SKILLSTORE_API_URL: ${{ secrets.SKILLSTORE_API_URL }}
          SKILLSTORE_CALLBACK_TOKEN: ${{ secrets.SKILLSTORE_CALLBACK_TOKEN }}
        run: |
          # Validate PR URL before sending callback
          if [[ ! "$PR_URL" =~ ^https://github.com/.*/pull/[0-9]+$ ]]; then
            echo "::warning::Invalid PR URL format: $PR_URL"
          fi

          echo "ðŸ“¤ Notifying skillstore: PR created at $PR_URL"
          curl -sS -X POST "$SKILLSTORE_API_URL/api/submit/callback" \
            -H "Authorization: Bearer $SKILLSTORE_CALLBACK_TOKEN" \
            -H "Content-Type: application/json" \
            -H "User-Agent: GitHub-Actions/SkillstoreBot" \
            -H "X-Skillstore-Callback: true" \
            -d '{
              "submission_id": "'"${{ env.SUBMISSION_ID }}"'",
              "event": "pr_created",
              "pr_url": "'"$PR_URL"'",
              "processed_count": ${{ steps.create_pr.outputs.processed_count }},
              "is_sharded": ${{ needs.discover-and-plan.outputs.is_sharded }},
              "shard_count": ${{ needs.discover-and-plan.outputs.shard_count }},
              "workflow_run_id": ${{ github.run_id }},
              "workflow_run_url": "https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}"
            }' || echo "::warning::Failed to notify skillstore"

      - name: Notify skillstore - Failed
        if: failure() && github.event_name == 'repository_dispatch'
        run: |
          ERROR_MSG="Processing failed. Check GitHub Actions log for details."
          ARTIFACTS_DIR="/tmp/submission-artifacts-${{ github.run_id }}"
          if [ -f "$ARTIFACTS_DIR/process-output-0.log" ]; then
            ERROR_MSG=$(tail -10 "$ARTIFACTS_DIR/process-output-0.log" | tr '\n' ' ' | cut -c1-500)
          fi
          rm -rf "$ARTIFACTS_DIR" 2>/dev/null || true

          curl -sS -X POST "${{ secrets.SKILLSTORE_API_URL }}/api/submit/callback" \
            -H "Authorization: Bearer ${{ secrets.SKILLSTORE_CALLBACK_TOKEN }}" \
            -H "Content-Type: application/json" \
            -H "User-Agent: GitHub-Actions/SkillstoreBot" \
            -H "X-Skillstore-Callback: true" \
            -d '{
              "submission_id": "'"${{ env.SUBMISSION_ID }}"'",
              "event": "failed",
              "error_message": "'"${ERROR_MSG//\"/\\\"}"'",
              "workflow_run_id": ${{ github.run_id }},
              "workflow_run_url": "https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}"
            }' || echo "::warning::Failed to notify skillstore"

      - name: Summary
        if: always()
        run: |
          cat << EOF >> $GITHUB_STEP_SUMMARY
          ## Processing Summary
          
          **Source**: ${{ env.GITHUB_URL }}
          **Submission ID**: \`${{ env.SUBMISSION_ID }}\`
          
          | Metric | Value |
          |--------|-------|
          | Skills Discovered | ${{ needs.discover-and-plan.outputs.skill_count }} |
          | Processing Mode | $([ "${{ needs.discover-and-plan.outputs.is_sharded }}" = "true" ] && echo "**Parallel** (${{ needs.discover-and-plan.outputs.shard_count }} shards)" || echo "Simple") |
          | Successfully Processed | ${{ steps.merge.outputs.processed_count }} |
          | Errors | ${{ steps.merge.outputs.total_errors }} |
          | Highest Risk | ${{ steps.merge.outputs.highest_risk }} |
          
          EOF
          
          if [ -n "${{ steps.create_pr.outputs.pr_url }}" ]; then
            echo "ðŸ”— **PR Created**: ${{ steps.create_pr.outputs.pr_url }}" >> $GITHUB_STEP_SUMMARY
          fi

      - name: Cleanup
        if: always()
        run: rm -f pr-body.md
