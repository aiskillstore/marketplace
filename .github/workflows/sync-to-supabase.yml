name: Sync to Supabase (Incremental)

on:
  push:
    branches: [main]
    paths:
      - 'plugins/**'
  workflow_dispatch:
    inputs:
      full_sync:
        description: 'Force full sync (ignore incremental)'
        type: boolean
        default: false
      skip_cache_warm:
        description: 'Skip cache warming after sync'
        type: boolean
        default: false

concurrency:
  group: sync-supabase
  cancel-in-progress: false

jobs:
  sync:
    runs-on: self-hosted
    outputs:
      synced_slugs: ${{ steps.sync.outputs.synced_slugs }}
      skip_sync: ${{ steps.changes.outputs.skip_sync }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          # Full history needed to diff against last successful sync
          fetch-depth: 0

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '24'

      - name: Install dependencies
        run: npm install @supabase/supabase-js

      - name: Find last successful sync commit
        id: last_sync
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          # Find the commit SHA of the last successful sync workflow run
          # This ensures we catch ALL changes since the last sync, even if multiple PRs merged
          LAST_SHA=$(gh api "repos/${{ github.repository }}/actions/workflows/sync-to-supabase.yml/runs?status=success&per_page=5" \
            --jq '.workflow_runs[0].head_sha' 2>/dev/null || echo "")
          
          if [ -n "$LAST_SHA" ] && [ "$LAST_SHA" != "null" ] && [ "$LAST_SHA" != "${{ github.sha }}" ]; then
            # Verify the commit exists in our history
            if git cat-file -e "$LAST_SHA" 2>/dev/null; then
              echo "Last successful sync at: $LAST_SHA"
              echo "base_sha=$LAST_SHA" >> $GITHUB_OUTPUT
            else
              echo "Last sync commit $LAST_SHA not in history, falling back to HEAD~1"
              echo "base_sha=HEAD~1" >> $GITHUB_OUTPUT
            fi
          else
            echo "No previous successful sync found, falling back to HEAD~1"
            echo "base_sha=HEAD~1" >> $GITHUB_OUTPUT
          fi

      - name: Detect changed plugins
        id: changes
        run: |
          BASE_SHA="${{ steps.last_sync.outputs.base_sha }}"
          echo "Comparing HEAD against: $BASE_SHA"
          
          # Find all plugin slugs by locating marketplace-entry.json files
          find_all_plugins() {
            for entry in $(find plugins -name "marketplace-entry.json" 2>/dev/null); do
              # Extract directory path relative to plugins/
              dir=$(dirname "$entry")
              echo "${dir#plugins/}"
            done | sort -u
          }
          
          # Get plugin slug from a changed file path
          # Supports both flat (plugins/name/) and namespaced (plugins/owner/name/)
          get_plugin_slug() {
            local path="$1"
            local first=$(echo "$path" | cut -d'/' -f1)
            local first_two=$(echo "$path" | cut -d'/' -f1,2)
            
            # Check if first segment is a plugin (flat structure)
            if [ -f "plugins/$first/marketplace-entry.json" ] || [ -d "plugins/$first/.claude-plugin" ]; then
              echo "$first"
            # Check if first two segments are a plugin (namespaced: owner/name)
            elif [ -f "plugins/$first_two/marketplace-entry.json" ] || [ -d "plugins/$first_two/.claude-plugin" ]; then
              echo "$first_two"
            fi
          }
          
          if [ "${{ inputs.full_sync }}" = "true" ]; then
            echo "Full sync requested"
            CHANGED=$(find_all_plugins | tr '\n' ' ')
            echo "mode=full" >> $GITHUB_OUTPUT
          else
            # Get changed paths since last successful sync and extract plugin slugs
            # Using $BASE_SHA..${{ github.sha }} to catch ALL commits between syncs
            CHANGED=$(git diff "$BASE_SHA" --name-only 2>/dev/null | \
              grep '^plugins/' | \
              sed 's|^plugins/||' | \
              while read -r path; do
                get_plugin_slug "$path"
              done | sort -u | tr '\n' ' ')
            echo "mode=incremental" >> $GITHUB_OUTPUT
            echo "Diff range: $BASE_SHA..HEAD"
          fi
          
          echo "changed_plugins=$CHANGED" >> $GITHUB_OUTPUT
          
          if [ -z "$CHANGED" ]; then
            echo "No plugins to sync"
            echo "skip_sync=true" >> $GITHUB_OUTPUT
          else
            echo "Plugins to sync: $CHANGED"
            echo "skip_sync=false" >> $GITHUB_OUTPUT
          fi

      - name: Sync plugins to Supabase
        id: sync
        if: steps.changes.outputs.skip_sync != 'true'
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
          CHANGED_PLUGINS: ${{ steps.changes.outputs.changed_plugins }}
          SYNC_MODE: ${{ steps.changes.outputs.mode }}
        run: |
          SYNCED_SLUGS=$(node << 'EOF'
          const { createClient } = require('@supabase/supabase-js');
          const fs = require('fs');
          const path = require('path');

          const supabase = createClient(
            process.env.SUPABASE_URL,
            process.env.SUPABASE_SERVICE_KEY
          );

          // Extract GitHub username from repository URL
          // e.g., "https://github.com/K-Dense-AI/repo" ‚Üí "K-Dense-AI"
          function extractGithubUsername(repoUrl) {
            if (!repoUrl) return null;
            const match = repoUrl.match(/github\.com\/([^\/]+)/);
            return match ? match[1] : null;
          }

          /**
           * Validate that SKILL.md content has valid structure (YAML frontmatter)
           * Returns error message if invalid, null if valid
           */
          function validateSkillMdContent(rawContent) {
            if (!rawContent) return 'Empty content';
            // Check for YAML frontmatter delimiters
            if (!rawContent.startsWith('---')) {
              return 'Missing YAML frontmatter (must start with ---)';
            }
            // Check for closing delimiter
            const endIndex = rawContent.indexOf('---', 3);
            if (endIndex === -1) {
              return 'Missing closing YAML frontmatter delimiter (---)';
            }
            // Check if frontmatter section has content
            const frontmatterContent = rawContent.slice(3, endIndex).trim();
            if (!frontmatterContent) {
              return 'Empty YAML frontmatter (no metadata found)';
            }
            return null; // Valid
          }

          // Sanitize and truncate text field
          function sanitizeText(text, maxLength = 2048) {
            if (!text) return '';
            // Truncate to max length
            return String(text).slice(0, maxLength);
          }

          async function syncPlugins() {
            const changedPlugins = process.env.CHANGED_PLUGINS.trim().split(/\s+/).filter(Boolean);
            const mode = process.env.SYNC_MODE;
            
            console.error(`Sync mode: ${mode}`);
            console.error(`Syncing ${changedPlugins.length} plugin(s): ${changedPlugins.join(', ')}`);

            let synced = 0;
            let errors = 0;
            const syncedSlugs = [];

            for (const dirPath of changedPlugins) {
              const pluginPath = `plugins/${dirPath}`;
              const reportPath = path.join(pluginPath, 'skill-report.json');
              const manifestPath = path.join(pluginPath, '.claude-plugin', 'plugin.json');
              const entryPath = path.join(pluginPath, 'marketplace-entry.json');

              if (!fs.existsSync(pluginPath)) {
                console.error(`Skipping ${dirPath}: directory not found`);
                continue;
              }

              let skillReport = null;
              let manifest = null;
              let entry = null;

              if (fs.existsSync(reportPath)) {
                skillReport = JSON.parse(fs.readFileSync(reportPath, 'utf8'));
              }
              if (fs.existsSync(manifestPath)) {
                manifest = JSON.parse(fs.readFileSync(manifestPath, 'utf8'));
              }
              if (fs.existsSync(entryPath)) {
                entry = JSON.parse(fs.readFileSync(entryPath, 'utf8'));
              }

              if (!skillReport && !entry) {
                console.error(`Skipping ${dirPath}: no skill-report.json or marketplace-entry.json`);
                continue;
              }

              // Validate SKILL.md has proper YAML frontmatter
              const skillMdPath = path.join(pluginPath, 'SKILL.md');
              if (fs.existsSync(skillMdPath)) {
                const skillMdContent = fs.readFileSync(skillMdPath, 'utf8');
                const validationError = validateSkillMdContent(skillMdContent);
                if (validationError) {
                  console.error(`Skipping ${dirPath}: invalid SKILL.md - ${validationError}`);
                  errors++;
                  continue;
                }
              }

              const description = skillReport?.skill?.description || entry?.description || '';
              const summary = skillReport?.skill?.summary || '';
              const slug = entry?.name || manifest?.name || dirPath.replace(/\//g, '-');

              // ============================================================
              // 1. SYNC TO skills TABLE (main skill record)
              // ============================================================
              const skillRecord = {
                slug: slug,

                // Basic info - prefer skill-report, fallback to entry
                // Apply truncation to prevent database constraint violations
                name: skillReport?.skill?.name || entry?.name || slug,
                description: sanitizeText(description, 2048),
                summary: sanitizeText(summary, 1024),
                icon: skillReport?.skill?.icon || null,
                
                // Categorization - default to 'productivity' (must match skillstore.categories table)
                category: skillReport?.skill?.category || 'productivity',
                tags: skillReport?.skill?.tags || entry?.keywords || [],
                supported_tools: skillReport?.skill?.supported_tools || ['claude', 'codex', 'claude-code'],
                
                // Version & licensing
                version: skillReport?.skill?.version || entry?.version || '1.0.0',
                license: skillReport?.skill?.license || entry?.license || 'MIT',
                
                // Author info
                author_name: entry?.author?.name || skillReport?.skill?.author || 'Community',
                author_email: entry?.author?.email || null,
                github_username: extractGithubUsername(entry?.repository || skillReport?.meta?.source_url),
                
                // URLs & paths
                repository: entry?.repository || skillReport?.meta?.source_url || null,
                source_ref: skillReport?.meta?.source_ref || 'main',
                plugin_path: pluginPath,
                
                // Content hashes for deduplication
                content_hash: skillReport?.meta?.content_hash || null,
                tree_hash: skillReport?.meta?.tree_hash || null,
                skill_report_url: `https://github.com/aiskillstore/marketplace/blob/main/${pluginPath}/skill-report.json`,
                homepage: `https://skillstore.io/skills/${slug}`,
                
                // File structure (from skill-report.json)
                file_structure: skillReport?.file_structure || null,
                
                // Marketplace source
                marketplace_source: 'aiskillstore',
                
                // Risk assessment (5-tier: safe, low, medium, high, critical)
                risk_level: skillReport?.security_audit?.risk_level || 'safe',
                risk_factors: skillReport?.skill?.risk_factors || [],
                
                // Publishing status - directly approved with KV-based ISR
                // No more 'building' status needed since pages render on-demand
                status: 'approved',
                published_at: new Date().toISOString(),
                updated_at: new Date().toISOString(),
              };

              // Upsert skill record
              const { data: skillData, error: skillError } = await supabase
                .schema('skillstore')
                .from('skills')
                .upsert(skillRecord, { onConflict: 'slug' })
                .select('id')
                .single();

              if (skillError) {
                console.error(`Error syncing skill ${slug}: ${skillError.message}`);
                errors++;
                continue;
              }

              const skillId = skillData.id;
              console.error(`‚úÖ Synced skill: ${slug} (id: ${skillId})`);
              syncedSlugs.push(slug);

              // ============================================================
              // 2. SYNC TO skill_ai_content TABLE (rich AI-generated content)
              // ============================================================
              if (skillReport?.content) {
                const extraContent = {
                  meta: {
                    schema_version: skillReport.schema_version || null,
                    generated_at: skillReport.meta?.generated_at || null,
                    analysis_version: skillReport.meta?.analysis_version || null,
                    model: skillReport.meta?.model || null,
                  },
                };

                const aiContentRecord = {
                  skill_id: skillId,
                  
                  // Basic AI content
                  user_title: skillReport.content.user_title || '',
                  value_statement: skillReport.content.value_statement || '',
                  seo_keywords: skillReport.content.seo_keywords || [],
                  
                  // Structured content
                  use_cases: skillReport.content.use_cases || [],
                  prompt_templates: skillReport.content.prompt_templates || [],
                  output_examples: skillReport.content.output_examples || [],
                  faq: skillReport.content.faq || [],
                  
                  // Lists
                  best_practices: skillReport.content.best_practices || [],
                  anti_patterns: skillReport.content.anti_patterns || [],
                  actual_capabilities: skillReport.content.actual_capabilities || [],
                  limitations: skillReport.content.limitations || [],
                  
                  // Extra content (JSONB for display-only metadata)
                  extra_content: extraContent,
                  
                  // Versioning
                  content_version: 1,
                  updated_at: new Date().toISOString(),
                };

                const { error: aiError } = await supabase
                  .schema('skillstore')
                  .from('skill_ai_content')
                  .upsert(aiContentRecord, { onConflict: 'skill_id' });

                if (aiError) {
                  console.error(`  ‚ö†Ô∏è Error syncing AI content for ${slug}: ${aiError.message}`);
                } else {
                  console.error(`  ‚úÖ Synced AI content for ${slug}`);
                }
              }

              // ============================================================
              // 3. SYNC TO skill_security_audit TABLE (security analysis)
              // Deduplication: only insert if content changed OR 24+ hours elapsed
              // ============================================================
              if (skillReport?.security_audit) {
                const audit = skillReport.security_audit;
                const crypto = require('crypto');

                // Build content object for hashing (excludes version, timestamps, metadata)
                const auditContent = {
                  risk_level: audit.risk_level || 'low',
                  is_blocked: audit.is_blocked ?? false,
                  safe_to_publish: audit.safe_to_publish ?? true,
                  summary: audit.summary || '',
                  critical_findings: audit.critical_findings || [],
                  high_findings: audit.high_findings || [],
                  medium_findings: audit.medium_findings || [],
                  low_findings: audit.low_findings || [],
                  dangerous_patterns: audit.dangerous_patterns || [],
                  risk_factor_evidence: audit.risk_factor_evidence || [],
                  files_scanned: audit.files_scanned || 0,
                  total_lines: audit.total_lines || 0,
                };

                // Calculate content hash
                const contentHash = crypto
                  .createHash('sha256')
                  .update(JSON.stringify(auditContent))
                  .digest('hex')
                  .substring(0, 32); // Use first 32 chars for brevity

                // Get latest audit for this skill (version, content_hash, created_at)
                const { data: existingAudits } = await supabase
                  .schema('skillstore')
                  .from('skill_security_audit')
                  .select('version, content_hash, created_at')
                  .eq('skill_id', skillId)
                  .order('version', { ascending: false })
                  .limit(1);

                const latestAudit = existingAudits?.[0];
                const currentVersion = latestAudit?.version ?? 0;
                const lastHash = latestAudit?.content_hash;
                const lastCreatedAt = latestAudit?.created_at ? new Date(latestAudit.created_at) : null;

                // Check if we should insert a new version:
                // 1. Content hash differs (audit content changed), OR
                // 2. 24+ hours since last audit (periodic re-audit allowed)
                const TWENTY_FOUR_HOURS = 24 * 60 * 60 * 1000;
                const timeSinceLastAudit = lastCreatedAt ? (Date.now() - lastCreatedAt.getTime()) : Infinity;
                const hashChanged = !lastHash || lastHash !== contentHash;
                const timeElapsed = timeSinceLastAudit >= TWENTY_FOUR_HOURS;

                if (!hashChanged && !timeElapsed) {
                  // Skip: same content and less than 24 hours
                  console.error(`  ‚è≠Ô∏è Skipped security audit for ${slug} (unchanged, ${Math.round(timeSinceLastAudit / 3600000)}h ago)`);
                } else {
                  const nextVersion = currentVersion + 1;
                  const auditRecord = {
                    skill_id: skillId,
                    version: nextVersion,
                    content_hash: contentHash,

                    // Risk assessment
                    risk_level: auditContent.risk_level,
                    is_blocked: auditContent.is_blocked,
                    safe_to_publish: auditContent.safe_to_publish,
                    summary: auditContent.summary,

                    // Findings by severity
                    critical_findings: auditContent.critical_findings,
                    high_findings: auditContent.high_findings,
                    medium_findings: auditContent.medium_findings,
                    low_findings: auditContent.low_findings,

                    // Patterns detected
                    dangerous_patterns: auditContent.dangerous_patterns,

                    // Risk factor evidence
                    risk_factor_evidence: auditContent.risk_factor_evidence,

                    // Metrics
                    files_scanned: auditContent.files_scanned,
                    total_lines: auditContent.total_lines,

                    // Audit metadata
                    audit_model: audit.audit_model || 'claude',
                    audited_at: audit.audited_at || new Date().toISOString(),
                  };

                  const { error: auditError } = await supabase
                    .schema('skillstore')
                    .from('skill_security_audit')
                    .insert(auditRecord);

                  if (auditError) {
                    console.error(`  ‚ö†Ô∏è Error syncing security audit for ${slug}: ${auditError.message}`);
                  } else {
                    const reason = hashChanged ? 'content changed' : '24h+ elapsed';
                    console.error(`  ‚úÖ Synced security audit v${nextVersion} for ${slug} (${reason})`);
                  }
                }
              }

              synced++;
            }

            console.error(`\n========================================`);
            console.error(`Sync complete: ${synced} synced, ${errors} errors`);
            console.error(`========================================`);
            
            // Output synced slugs to stdout (comma-separated for translate workflow)
            console.log(syncedSlugs.join(','));
            
            if (errors > 0) {
              process.exit(1);
            }
          }

          syncPlugins().catch(err => {
            console.error('Sync failed:', err);
            process.exit(1);
          });
          EOF
          )
          
          echo "synced_slugs=$SYNCED_SLUGS" >> $GITHUB_OUTPUT
          echo "::notice::Synced skills: $SYNCED_SLUGS"

      - name: Report sync status
        run: |
          echo "::notice::Sync completed - Mode: ${{ steps.changes.outputs.mode }}, Plugins: ${{ steps.changes.outputs.changed_plugins }}"

  # ============================================================
  # CALCULATE QUALITY SCORES
  # Calculates quality scores for synced skills using skillstore-cli
  # ============================================================
  calculate-scores:
    needs: sync
    if: needs.sync.outputs.skip_sync != 'true' && needs.sync.outputs.synced_slugs != ''
    runs-on: self-hosted
    steps:
      - name: Download skillstore-cli
        run: |
          CLI_URL="https://github.com/aiskillstore/skillstore/releases/latest/download/skillstore-cli-linux-x64"
          curl -fsSL "$CLI_URL" -o skillstore-cli
          chmod +x skillstore-cli
          ./skillstore-cli --version

      - name: Calculate quality scores for synced skills
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
          SYNCED_SLUGS: ${{ needs.sync.outputs.synced_slugs }}
        run: |
          echo "üéØ Calculating quality scores for: $SYNCED_SLUGS"

          # Convert comma-separated to space-separated
          SLUGS=$(echo "$SYNCED_SLUGS" | tr ',' ' ')

          for slug in $SLUGS; do
            echo "Scoring: $slug"
            ./skillstore-cli skill score "$slug" || echo "‚ö†Ô∏è Failed to score $slug"
          done

          echo "‚úÖ Quality score calculation complete"

  # ============================================================
  # CACHE INVALIDATION JOB
  # Invalidates API and page cache for synced skills
  # ============================================================
  cache-invalidate:
    needs: [sync, calculate-scores]
    if: needs.sync.outputs.skip_sync != 'true'
    runs-on: self-hosted
    steps:
      - name: Invalidate cache for synced skills
        env:
          SYNCED_SLUGS: ${{ needs.sync.outputs.synced_slugs }}
          SITE_URL: https://skillstore.io
          CACHE_INVALIDATE_SECRET: ${{ secrets.CACHE_INVALIDATE_SECRET }}
        run: |
          if [ -z "$SYNCED_SLUGS" ]; then
            echo "No slugs to invalidate"
            exit 0
          fi
          
          SLUGS_JSON=$(echo "$SYNCED_SLUGS" | tr ',' '\n' | jq -R . | jq -s .)
          
          echo "Invalidating cache for: $SYNCED_SLUGS"
          
          RESPONSE=$(curl -sf -X POST "$SITE_URL/api/cache/invalidate" \
            -H "Content-Type: application/json" \
            -H "Authorization: Bearer $CACHE_INVALIDATE_SECRET" \
            -d "{\"type\": \"skills\", \"slugs\": $SLUGS_JSON, \"invalidateApi\": true}" \
            --max-time 30 2>&1) || {
            echo "‚ö†Ô∏è Cache invalidation failed (non-critical)"
            echo "Response: $RESPONSE"
            exit 0
          }
          
          echo "‚úÖ Cache invalidated: $RESPONSE"

  # ============================================================
  # CACHE WARMING JOB
  # Warms KV cache for synced skills across all locales
  # ============================================================
  cache-warm:
    needs: [sync, calculate-scores, cache-invalidate]
    if: needs.sync.outputs.skip_sync != 'true' && inputs.skip_cache_warm != true
    runs-on: self-hosted
    steps:
      - name: Warm KV cache for synced skills
        env:
          SYNCED_SLUGS: ${{ needs.sync.outputs.synced_slugs }}
          SITE_URL: https://skillstore.io
        run: |
          if [ -z "$SYNCED_SLUGS" ]; then
            echo "No slugs to warm"
            exit 0
          fi
          
          LOCALES="en zh-hans zh-hant ja ko de fr es pt ru ar"
          CONCURRENCY=5
          
          # Convert comma-separated to space-separated for iteration
          SLUGS_SPACE=$(echo "$SYNCED_SLUGS" | tr ',' ' ')
          echo "Warming cache for: $SLUGS_SPACE"
          echo "Locales: $LOCALES"
          echo ""
          
          # Generate URLs for all slugs √ó locales
          generate_urls() {
            for slug in $SLUGS_SPACE; do
              [ -z "$slug" ] && continue
              for locale in $LOCALES; do
                if [ "$locale" = "en" ]; then
                  echo "$SITE_URL/skills/$slug"
                else
                  echo "$SITE_URL/$locale/skills/$slug"
                fi
              done
            done
          }
          
          URLS=$(generate_urls)
          URL_COUNT=$(echo "$URLS" | grep -c . || echo 0)
          
          echo "Total URLs to warm: $URL_COUNT"
          echo ""
          
          if [ "$URL_COUNT" -gt 0 ]; then
            SUCCESS=0
            FAILED=0
            
            echo "$URLS" | xargs -P $CONCURRENCY -I {} sh -c '
              STATUS=$(curl -sf -o /dev/null -w "%{http_code}" --max-time 30 "{}" 2>/dev/null || echo "000")
              if [ "$STATUS" = "200" ]; then
                echo "‚úì {}"
              else
                echo "‚úó {} ($STATUS)" >&2
              fi
            '
          fi
          
          echo ""
          echo "Cache warming complete!"

      - name: Summary
        env:
          SYNCED_SLUGS: ${{ needs.sync.outputs.synced_slugs }}
        run: |
          SLUG_COUNT=$(echo "$SYNCED_SLUGS" | tr ',' '\n' | grep -c . || echo 0)
          LOCALE_COUNT=11
          TOTAL_URLS=$((SLUG_COUNT * LOCALE_COUNT))
          
          echo "## Cache Warming Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Metric | Value |" >> $GITHUB_STEP_SUMMARY
          echo "|--------|-------|" >> $GITHUB_STEP_SUMMARY
          echo "| Skills synced | $SLUG_COUNT |" >> $GITHUB_STEP_SUMMARY
          echo "| Locales | $LOCALE_COUNT |" >> $GITHUB_STEP_SUMMARY
          echo "| URLs warmed | $TOTAL_URLS |" >> $GITHUB_STEP_SUMMARY
          echo "| Slugs | $SYNCED_SLUGS |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "‚úÖ KV cache warming completed." >> $GITHUB_STEP_SUMMARY

  # ============================================================
  # TRIGGER TRANSLATION (Async - Fire and Forget)
  # Uses repository_dispatch to start translation as a separate workflow run
  # This decouples sync from slow translation, completing sync faster
  # ============================================================
  trigger-translate:
    needs: [sync, cache-warm]
    if: needs.sync.outputs.skip_sync != 'true' && needs.sync.outputs.synced_slugs != ''
    runs-on: self-hosted
    steps:
      - name: Generate GitHub App Token
        id: app-token
        uses: actions/create-github-app-token@v2
        with:
          app-id: ${{ secrets.APP_ID }}
          private-key: ${{ secrets.APP_PRIVATE_KEY }}

      - name: Trigger translation workflow
        env:
          GH_TOKEN: ${{ steps.app-token.outputs.token }}
        run: |
          SLUGS="${{ needs.sync.outputs.synced_slugs }}"
          echo "üåç Triggering translation for: $SLUGS"
          
          gh api repos/${{ github.repository }}/dispatches \
            --method POST \
            -f event_type=translate-skills \
            -f "client_payload[plugin_slugs]=$SLUGS" \
            -f "client_payload[triggered_by]=sync-to-supabase" \
            -f "client_payload[run_id]=${{ github.run_id }}"
          
          echo "‚úÖ Translation triggered asynchronously"
          echo "   Skills: $SLUGS"
          echo "   Monitor at: https://github.com/${{ github.repository }}/actions/workflows/translate-skills.yml"
