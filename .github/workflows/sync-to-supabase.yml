name: Sync to Supabase (Incremental)

on:
  push:
    branches: [main]
    paths:
      - 'skills/**'
  workflow_run:
    workflows: ["On PR Merge - Approve Skill"]
    types: [completed]
    branches: [main]
  workflow_dispatch:
    inputs:
      full_sync:
        description: 'Force full sync (ignore incremental)'
        type: boolean
        default: false
      skip_cache_warm:
        description: 'Skip cache warming after sync'
        type: boolean
        default: false

concurrency:
  group: sync-supabase
  cancel-in-progress: false

jobs:
  sync:
    runs-on: self-hosted
    timeout-minutes: 120
    outputs:
      synced_slugs: ${{ steps.sync.outputs.synced_slugs }}
      skip_sync: ${{ steps.changes.outputs.skip_sync }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          # Full history needed to diff against last successful sync
          fetch-depth: 0

      - name: Generate GitHub App Token
        id: app-token
        uses: actions/create-github-app-token@v2
        with:
          app-id: ${{ secrets.APP_ID }}
          private-key: ${{ secrets.APP_PRIVATE_KEY }}
          repositories: marketplace,skillstore

      - name: Find last successful sync commit
        id: last_sync
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          # Find the commit SHA of the last successful sync workflow run
          # This ensures we catch ALL changes since the last sync, even if multiple PRs merged
          LAST_SHA=$(gh api "repos/${{ github.repository }}/actions/workflows/sync-to-supabase.yml/runs?status=success&per_page=5" \
            --jq '.workflow_runs[0].head_sha' 2>/dev/null || echo "")
          
          if [ -n "$LAST_SHA" ] && [ "$LAST_SHA" != "null" ] && [ "$LAST_SHA" != "${{ github.sha }}" ]; then
            # Verify the commit exists in our history
            if git cat-file -e "$LAST_SHA" 2>/dev/null; then
              echo "Last successful sync at: $LAST_SHA"
              echo "base_sha=$LAST_SHA" >> $GITHUB_OUTPUT
            else
              echo "Last sync commit $LAST_SHA not in history, falling back to HEAD~1"
              echo "base_sha=HEAD~1" >> $GITHUB_OUTPUT
            fi
          else
            echo "No previous successful sync found, falling back to HEAD~1"
            echo "base_sha=HEAD~1" >> $GITHUB_OUTPUT
          fi

      - name: Detect changed skills
        id: changes
        run: |
          BASE_SHA="${{ steps.last_sync.outputs.base_sha }}"
          echo "Comparing HEAD against: $BASE_SHA"
          
          # Find all skill slugs by locating SKILL.md files
          find_all_skills() {
            for entry in $(find skills -name "SKILL.md" 2>/dev/null); do
              # Extract directory path relative to skills/
              dir=$(dirname "$entry")
              echo "${dir#skills/}"
            done | sort -u
          }
          
          # Get skill slug from a changed file path
          # Supports both flat (skills/name/) and namespaced (skills/owner/name/)
          get_skill_slug() {
            local path="$1"
            local first=$(echo "$path" | cut -d'/' -f1)
            local first_two=$(echo "$path" | cut -d'/' -f1,2)
            
            # Check if first segment is a skill (flat structure)
            if [ -f "skills/$first/SKILL.md" ]; then
              echo "$first"
            # Check if first two segments are a skill (namespaced: owner/name)
            elif [ -f "skills/$first_two/SKILL.md" ]; then
              echo "$first_two"
            fi
          }
          
          if [ "${{ inputs.full_sync }}" = "true" ]; then
            echo "Full sync requested"
            CHANGED=$(find_all_skills | tr '\n' ' ')
            echo "mode=full" >> $GITHUB_OUTPUT
          else
            # Get changed paths since last successful sync and extract skill slugs
            # IMPORTANT: Use explicit HEAD to compare commits, not working directory
            # On self-hosted runners, working directory may have stale files
            CHANGED=$(git diff "$BASE_SHA" HEAD --name-only 2>/dev/null | \
              grep '^skills/' | \
              sed 's|^skills/||' | \
              while read -r path; do
                get_skill_slug "$path"
              done | sort -u | tr '\n' ' ')
            echo "mode=incremental" >> $GITHUB_OUTPUT
            echo "Diff range: $BASE_SHA..HEAD"
          fi
          
          echo "changed_skills=$CHANGED" >> $GITHUB_OUTPUT
          
          if [ -z "$CHANGED" ]; then
            echo "No skills to sync"
            echo "skip_sync=true" >> $GITHUB_OUTPUT
          else
            echo "Skills to sync: $CHANGED"
            echo "skip_sync=false" >> $GITHUB_OUTPUT
          fi

      - name: Download skillstore-cli
        if: steps.changes.outputs.skip_sync != 'true'
        uses: ./.github/actions/download-skillstore-cli
        with:
          token: ${{ steps.app-token.outputs.token }}

      - name: Sync skills to Supabase
        id: sync
        if: steps.changes.outputs.skip_sync != 'true'
        env:
          PUBLIC_SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
          CHANGED_SKILLS: ${{ steps.changes.outputs.changed_skills }}
          SYNC_MODE: ${{ steps.changes.outputs.mode }}
        run: |
          echo "Sync mode: $SYNC_MODE"
          echo "Syncing skills: $CHANGED_SKILLS"

          # Transform space-separated relative paths to comma-separated full paths
          # Input:  "author1/skill1 author2/skill2"
          # Output: "skills/author1/skill1,skills/author2/skill2"
          # Filter empty lines to prevent trailing "skills/" from spaces
          SKILL_PATHS=$(echo "$CHANGED_SKILLS" | tr ' ' '\n' | grep -v '^$' | sed 's|^|skills/|' | tr '\n' ',' | sed 's/,$//')

          echo "Skill paths: $SKILL_PATHS"

          # Run skillstore-cli sync command with parallel processing
          # --concurrency 10: Process 10 skills in parallel for faster sync
          # Save full output to file, display to console, then extract result from last line
          # This preserves detailed logs for debugging while capturing the synced slugs
          ./skillstore-cli skill sync --slugs "$SKILL_PATHS" --concurrency 10 2>&1 | tee sync-output.log
          SYNCED_SLUGS=$(tail -1 sync-output.log)

          echo "synced_slugs=$SYNCED_SLUGS" >> $GITHUB_OUTPUT
          echo "::notice::Synced skills: $SYNCED_SLUGS"

      - name: Report sync status
        run: |
          echo "::notice::Sync completed - Mode: ${{ steps.changes.outputs.mode }}, Skills: ${{ steps.changes.outputs.changed_skills }}"

      - name: Cleanup CLI
        if: always()
        run: rm -f skillstore-cli

  # ============================================================
  # CALCULATE QUALITY SCORES
  # Calculates quality scores for synced skills using skillstore-cli
  # ============================================================
  calculate-scores:
    needs: sync
    if: needs.sync.outputs.skip_sync != 'true' && needs.sync.outputs.synced_slugs != ''
    runs-on: self-hosted
    timeout-minutes: 60
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Generate GitHub App Token
        id: app-token
        uses: actions/create-github-app-token@v2
        with:
          app-id: ${{ secrets.APP_ID }}
          private-key: ${{ secrets.APP_PRIVATE_KEY }}
          repositories: marketplace,skillstore

      - name: Download skillstore-cli
        uses: ./.github/actions/download-skillstore-cli
        with:
          token: ${{ steps.app-token.outputs.token }}

      - name: Calculate quality scores for synced skills
        env:
          PUBLIC_SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
          SYNCED_SLUGS: ${{ needs.sync.outputs.synced_slugs }}
        run: |
          echo "üéØ Calculating quality scores for: $SYNCED_SLUGS"

          # Run batch scoring with concurrency 5 (faster than sequential)
          ./skillstore-cli skill score --slugs "$SYNCED_SLUGS" --concurrency 5

          echo "‚úÖ Quality score calculation complete"

  # ============================================================
  # CACHE INVALIDATION JOB
  # Invalidates API and page cache for synced skills
  # ============================================================
  cache-invalidate:
    needs: [sync, calculate-scores]
    if: needs.sync.outputs.skip_sync != 'true'
    runs-on: self-hosted
    timeout-minutes: 15
    steps:
      - name: Invalidate cache for synced skills
        id: invalidate
        continue-on-error: true
        env:
          SYNCED_SLUGS: ${{ needs.sync.outputs.synced_slugs }}
          SITE_URL: https://skillstore.io
          CACHE_INVALIDATE_SECRET: ${{ secrets.CACHE_INVALIDATE_SECRET }}
        run: |
          if [ -z "$SYNCED_SLUGS" ]; then
            echo "No slugs to invalidate"
            exit 0
          fi

          SLUGS_JSON=$(echo "$SYNCED_SLUGS" | tr ',' '\n' | jq -R . | jq -s .)

          echo "Invalidating cache for: $SYNCED_SLUGS"

          set +e
          RESPONSE=$(curl -sf -X POST "$SITE_URL/api/cache/invalidate" \
            -H "Content-Type: application/json" \
            -H "Authorization: Bearer $CACHE_INVALIDATE_SECRET" \
            -d "{\"type\": \"skills\", \"slugs\": $SLUGS_JSON, \"invalidateApi\": true}" \
            --max-time 30 2>&1)
          EXIT_CODE=$?
          set -e

          if [ $EXIT_CODE -ne 0 ]; then
            echo "::warning::Cache invalidation failed (non-critical, continuing workflow)"
            echo "Response: $RESPONSE"
            echo "invalidation_failed=true" >> $GITHUB_OUTPUT
            exit 0
          fi

          echo "‚úÖ Cache invalidated: $RESPONSE"
          echo "invalidation_failed=false" >> $GITHUB_OUTPUT

      - name: Report cache invalidation failure
        if: steps.invalidate.outputs.invalidation_failed == 'true'
        run: |
          cat << EOF >> $GITHUB_STEP_SUMMARY
          ## ‚ö†Ô∏è Cache Invalidation Warning

          Cache invalidation failed for synced skills. This is non-critical and the workflow continued.
          Skills were synced successfully but may take longer to appear on the website.

          **Impact**: Low - Cache will expire naturally within 24 hours
          **Action Required**: None - Monitor next sync cycle
          EOF

  # ============================================================
  # CACHE WARMING JOB
  # Warms KV cache for synced skills across all locales
  # ============================================================
  cache-warm:
    needs: [sync, calculate-scores, cache-invalidate]
    if: needs.sync.outputs.skip_sync != 'true' && inputs.skip_cache_warm != true
    runs-on: self-hosted
    timeout-minutes: 60
    steps:
      - name: Warm KV cache for synced skills
        env:
          SYNCED_SLUGS: ${{ needs.sync.outputs.synced_slugs }}
          SITE_URL: https://skillstore.io
        run: |
          if [ -z "$SYNCED_SLUGS" ]; then
            echo "No slugs to warm"
            exit 0
          fi
          
          LOCALES="en zh-hans zh-hant ja ko de fr es pt ru ar"
          CONCURRENCY=5
          
          # Convert comma-separated to space-separated for iteration
          SLUGS_SPACE=$(echo "$SYNCED_SLUGS" | tr ',' ' ')
          echo "Warming cache for: $SLUGS_SPACE"
          echo "Locales: $LOCALES"
          echo ""
          
          # Generate URLs for all slugs √ó locales
          generate_urls() {
            for slug in $SLUGS_SPACE; do
              [ -z "$slug" ] && continue
              for locale in $LOCALES; do
                if [ "$locale" = "en" ]; then
                  echo "$SITE_URL/skills/$slug"
                else
                  echo "$SITE_URL/$locale/skills/$slug"
                fi
              done
            done
          }
          
          URLS=$(generate_urls)
          URL_COUNT=$(echo "$URLS" | grep -c . || echo 0)
          
          echo "Total URLs to warm: $URL_COUNT"
          echo ""
          
          if [ "$URL_COUNT" -gt 0 ]; then
            SUCCESS=0
            FAILED=0
            
            echo "$URLS" | xargs -P $CONCURRENCY -I {} sh -c '
              STATUS=$(curl -sf -o /dev/null -w "%{http_code}" --max-time 30 "{}" 2>/dev/null || echo "000")
              if [ "$STATUS" = "200" ]; then
                echo "‚úì {}"
              else
                echo "‚úó {} ($STATUS)" >&2
              fi
            '
          fi
          
          echo ""
          echo "Cache warming complete!"

      - name: Summary
        env:
          SYNCED_SLUGS: ${{ needs.sync.outputs.synced_slugs }}
        run: |
          SLUG_COUNT=$(echo "$SYNCED_SLUGS" | tr ',' '\n' | grep -c . || echo 0)
          LOCALE_COUNT=11
          TOTAL_URLS=$((SLUG_COUNT * LOCALE_COUNT))
          
          echo "## Cache Warming Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Metric | Value |" >> $GITHUB_STEP_SUMMARY
          echo "|--------|-------|" >> $GITHUB_STEP_SUMMARY
          echo "| Skills synced | $SLUG_COUNT |" >> $GITHUB_STEP_SUMMARY
          echo "| Locales | $LOCALE_COUNT |" >> $GITHUB_STEP_SUMMARY
          echo "| URLs warmed | $TOTAL_URLS |" >> $GITHUB_STEP_SUMMARY
          echo "| Slugs | $SYNCED_SLUGS |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "‚úÖ KV cache warming completed." >> $GITHUB_STEP_SUMMARY

  # ============================================================
  # TRIGGER TRANSLATION (Async - Fire and Forget)
  # Uses repository_dispatch to start translation as a separate workflow run
  # This decouples sync from slow translation, completing sync faster
  # ============================================================
  trigger-translate:
    needs: [sync, cache-warm]
    if: needs.sync.outputs.skip_sync != 'true' && needs.sync.outputs.synced_slugs != ''
    runs-on: self-hosted
    timeout-minutes: 15
    steps:
      - name: Generate GitHub App Token
        id: app-token
        uses: actions/create-github-app-token@v2
        with:
          app-id: ${{ secrets.APP_ID }}
          private-key: ${{ secrets.APP_PRIVATE_KEY }}

      - name: Trigger translation workflow
        env:
          GH_TOKEN: ${{ steps.app-token.outputs.token }}
          SYNCED_SLUGS: ${{ needs.sync.outputs.synced_slugs }}
        run: |
          echo "üåç Triggering translation for synced skills"

          # Split slugs into batches of 50 to avoid GitHub's ~10KB payload limit
          BATCH_SIZE=50

          # Convert to array
          IFS=',' read -ra SLUGS_ARRAY <<< "$SYNCED_SLUGS"
          TOTAL_SLUGS=${#SLUGS_ARRAY[@]}

          echo "   Total skills: $TOTAL_SLUGS"

          # Calculate number of batches
          BATCH_COUNT=$(( (TOTAL_SLUGS + BATCH_SIZE - 1) / BATCH_SIZE ))
          echo "   Batches needed: $BATCH_COUNT"

          # Process each batch
          for ((BATCH=0; BATCH<BATCH_COUNT; BATCH++)); do
            START=$((BATCH * BATCH_SIZE))
            END=$((START + BATCH_SIZE))
            [ $END -gt $TOTAL_SLUGS ] && END=$TOTAL_SLUGS

            # Build batch string
            BATCH_SLUGS=""
            for ((i=START; i<END; i++)); do
              [ -n "$BATCH_SLUGS" ] && BATCH_SLUGS="$BATCH_SLUGS,"
              BATCH_SLUGS="$BATCH_SLUGS${SLUGS_ARRAY[$i]}"
            done

            BATCH_NUM=$((BATCH + 1))
            BATCH_LEN=$((END - START))
            echo "üì§ Dispatching batch $BATCH_NUM/$BATCH_COUNT ($BATCH_LEN slugs)"

            gh api repos/${{ github.repository }}/dispatches \
              --method POST \
              -f event_type=translate-skills \
              -f "client_payload[skill_slugs]=$BATCH_SLUGS" \
              -f "client_payload[triggered_by]=sync-to-supabase" \
              -f "client_payload[run_id]=${{ github.run_id }}" \
              -f "client_payload[batch]=$BATCH_NUM" \
              -f "client_payload[total_batches]=$BATCH_COUNT"
          done

          echo "‚úÖ Translation triggered in $BATCH_COUNT batches"
          echo "   Monitor at: https://github.com/${{ github.repository }}/actions/workflows/translate-skills.yml"
