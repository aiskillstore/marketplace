name: Warm KV Cache

on:
  workflow_dispatch:
    inputs:
      mode:
        description: 'warm = fill missing cache, force = clear all and regenerate'
        required: true
        type: choice
        options:
          - warm
          - force
        default: warm
      type:
        description: 'Content type to warm'
        required: true
        type: choice
        options:
          - skills
          - workflows
          - releases
          - all
        default: skills
      slugs:
        description: 'Specific slugs to warm (comma-separated, optional). If empty, warm all items.'
        required: false
        type: string
        default: ''
      warm_zip:
        description: 'Warm ZIP download cache for skills'
        required: false
        type: boolean
        default: false
      source_run_id:
        description: 'Source workflow run ID to download slugs artifact from (alternative to slugs input)'
        required: false
        type: string
        default: ''

concurrency:
  group: warm-cache
  cancel-in-progress: false

env:
  SITE_URL: https://skillstore.io
  LOCALES: 'en zh-hans zh-hant ja ko de fr es pt ru ar'
  CONCURRENCY: 10
  INVALIDATE_BATCH_SIZE: 30

jobs:
  warm:
    runs-on: self-hosted
    timeout-minutes: 1440
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          sparse-checkout: .github/actions

      - name: Download slugs from source workflow
        if: inputs.source_run_id != ''
        uses: actions/download-artifact@v4
        with:
          name: synced-slugs
          run-id: ${{ inputs.source_run_id }}
          github-token: ${{ github.token }}

      - name: Read slugs from artifact
        if: inputs.source_run_id != ''
        id: artifact-slugs
        run: |
          if [ -f synced-slugs.txt ]; then
            # Convert newline-separated slugs to space-separated (for compatibility)
            SLUGS=$(cat synced-slugs.txt | tr '\n' ' ' | sed 's/ $//')
            SLUG_COUNT=$(cat synced-slugs.txt | grep -c . || echo 0)
            echo "ðŸ“¥ Loaded $SLUG_COUNT slugs from artifact"
            echo "slugs=$SLUGS" >> $GITHUB_OUTPUT
          else
            echo "::error::synced-slugs.txt not found in artifact"
            exit 1
          fi

      - name: Fetch all slugs from Supabase
        id: fetch
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
          CONTENT_TYPE: ${{ inputs.type }}
          INPUT_SLUGS: ${{ inputs.slugs }}
          ARTIFACT_SLUGS: ${{ steps.artifact-slugs.outputs.slugs }}
        run: |
          # Priority: artifact slugs > input slugs > fetch from Supabase
          if [ -n "$ARTIFACT_SLUGS" ]; then
            echo "Using slugs from artifact"
            SLUGS_SPACE="$ARTIFACT_SLUGS"

            if [ "$CONTENT_TYPE" = "skills" ] || [ "$CONTENT_TYPE" = "all" ]; then
              echo "skills_slugs=$SLUGS_SPACE" >> $GITHUB_OUTPUT
              SKILLS_COUNT=$(echo $SLUGS_SPACE | wc -w | tr -d ' ')
              echo "Found $SKILLS_COUNT skills (from artifact)"
            fi
            exit 0
          fi

          # If specific slugs provided via input, use them instead of fetching from Supabase
          if [ -n "$INPUT_SLUGS" ]; then
            echo "Using provided slugs: $INPUT_SLUGS"
            SLUGS_SPACE=$(echo "$INPUT_SLUGS" | tr ',' ' ')

            if [ "$CONTENT_TYPE" = "skills" ] || [ "$CONTENT_TYPE" = "all" ]; then
              echo "skills_slugs=$SLUGS_SPACE" >> $GITHUB_OUTPUT
              SKILLS_COUNT=$(echo $SLUGS_SPACE | wc -w | tr -d ' ')
              echo "Found $SKILLS_COUNT skills (from input)"
            fi

            # For workflows/releases, still need to fetch from Supabase if type=all
            if [ "$CONTENT_TYPE" = "workflows" ] || ( [ "$CONTENT_TYPE" = "all" ] && [ "$INPUT_SLUGS" = "" ] ); then
              echo "Fetching workflows from Supabase (input only supports skills)"
              WORKFLOWS_SLUGS=$(fetch_all_from_supabase "workflows" "slug")
              echo "workflows_slugs=$WORKFLOWS_SLUGS" >> $GITHUB_OUTPUT
              WORKFLOWS_COUNT=$(echo $WORKFLOWS_SLUGS | wc -w | tr -d ' ')
              echo "Found $WORKFLOWS_COUNT workflows"
            fi

            if [ "$CONTENT_TYPE" = "releases" ] || ( [ "$CONTENT_TYPE" = "all" ] && [ "$INPUT_SLUGS" = "" ] ); then
              echo "Fetching releases from Supabase (input only supports skills)"
              RELEASES_TAGS=$(fetch_all_from_supabase "releases" "tag")
              echo "releases_tags=$RELEASES_TAGS" >> $GITHUB_OUTPUT
              RELEASES_COUNT=$(echo $RELEASES_TAGS | wc -w | tr -d ' ')
              echo "Found $RELEASES_COUNT releases"
            fi

            exit 0
          fi

          # Otherwise, fetch from Supabase as usual
          fetch_all_from_supabase() {
            local table=$1
            local column=${2:-slug}
            local offset=0
            local limit=1000
            local all_items=""
            
            while true; do
              response=$(curl -sf "${SUPABASE_URL}/rest/v1/${table}?select=${column}&offset=${offset}&limit=${limit}" \
                -H "apikey: ${SUPABASE_SERVICE_KEY}" \
                -H "Authorization: Bearer ${SUPABASE_SERVICE_KEY}" \
                -H "Accept-Profile: skillstore")
              
              items=$(echo "$response" | jq -r ".[].${column}" | tr '\n' ' ')
              count=$(echo "$items" | wc -w | tr -d ' ')
              
              if [ "$count" -eq 0 ]; then
                break
              fi
              
              all_items="$all_items $items"
              offset=$((offset + limit))
              echo "  Fetched $count items (offset: $((offset - limit)))" >&2
            done
            
            echo "$all_items" | tr -s ' '
          }
          
          SKILLS_SLUGS=""
          WORKFLOWS_SLUGS=""
          RELEASES_TAGS=""
          
          if [ "$CONTENT_TYPE" = "skills" ] || [ "$CONTENT_TYPE" = "all" ]; then
            echo "Fetching all skills from Supabase..."
            SKILLS_SLUGS=$(fetch_all_from_supabase "skills" "slug")
            echo "skills_slugs=$SKILLS_SLUGS" >> $GITHUB_OUTPUT
            SKILLS_COUNT=$(echo $SKILLS_SLUGS | wc -w | tr -d ' ')
            echo "Found $SKILLS_COUNT skills"
          fi
          
          if [ "$CONTENT_TYPE" = "workflows" ] || [ "$CONTENT_TYPE" = "all" ]; then
            echo "Fetching all workflows from Supabase..."
            WORKFLOWS_SLUGS=$(fetch_all_from_supabase "workflows" "slug")
            echo "workflows_slugs=$WORKFLOWS_SLUGS" >> $GITHUB_OUTPUT
            WORKFLOWS_COUNT=$(echo $WORKFLOWS_SLUGS | wc -w | tr -d ' ')
            echo "Found $WORKFLOWS_COUNT workflows"
          fi
          
          if [ "$CONTENT_TYPE" = "releases" ] || [ "$CONTENT_TYPE" = "all" ]; then
            echo "Fetching all releases from Supabase..."
            RELEASES_TAGS=$(fetch_all_from_supabase "releases" "tag")
            echo "releases_tags=$RELEASES_TAGS" >> $GITHUB_OUTPUT
            RELEASES_COUNT=$(echo $RELEASES_TAGS | wc -w | tr -d ' ')
            echo "Found $RELEASES_COUNT releases"
          fi

      - name: Invalidate skills cache (force mode only)
        if: inputs.mode == 'force' && (inputs.type == 'skills' || inputs.type == 'all') && steps.fetch.outputs.skills_slugs != ''
        uses: ./.github/actions/invalidate-cache
        with:
          type: skills
          slugs: ${{ steps.fetch.outputs.skills_slugs }}
          secret: ${{ secrets.CACHE_INVALIDATE_SECRET }}
          batch-size: ${{ env.INVALIDATE_BATCH_SIZE }}

      - name: Invalidate workflows cache (force mode only)
        if: inputs.mode == 'force' && (inputs.type == 'workflows' || inputs.type == 'all') && steps.fetch.outputs.workflows_slugs != ''
        uses: ./.github/actions/invalidate-cache
        with:
          type: workflows
          slugs: ${{ steps.fetch.outputs.workflows_slugs }}
          secret: ${{ secrets.CACHE_INVALIDATE_SECRET }}
          batch-size: ${{ env.INVALIDATE_BATCH_SIZE }}

      - name: Invalidate releases cache (force mode only)
        if: inputs.mode == 'force' && (inputs.type == 'releases' || inputs.type == 'all') && steps.fetch.outputs.releases_tags != ''
        uses: ./.github/actions/invalidate-cache
        with:
          type: releases
          slugs: ${{ steps.fetch.outputs.releases_tags }}
          secret: ${{ secrets.CACHE_INVALIDATE_SECRET }}
          batch-size: ${{ env.INVALIDATE_BATCH_SIZE }}

      - name: Warm skills page cache
        if: inputs.type == 'skills' || inputs.type == 'all'
        env:
          SLUGS: ${{ steps.fetch.outputs.skills_slugs }}
        run: |
          if [ -z "$SLUGS" ]; then
            echo "No skills to warm"
            exit 0
          fi

          generate_urls() {
            for slug in $SLUGS; do
              [ -z "$slug" ] && continue
              for locale in $LOCALES; do
                if [ "$locale" = "en" ]; then
                  echo "$SITE_URL/skills/$slug"
                else
                  echo "$SITE_URL/$locale/skills/$slug"
                fi
              done
            done
          }

          URLS=$(generate_urls)
          URL_COUNT=$(echo "$URLS" | grep -c . || echo 0)
          SKILL_COUNT=$(echo $SLUGS | wc -w | tr -d ' ')

          echo "Warming $URL_COUNT skill URLs ($SKILL_COUNT skills Ã— 11 locales)..."
          echo "Progress will be reported every 500 URLs..."
          echo ""

          COUNTER=0
          SUCCESS=0
          FAILED=0
          START_TIME=$(date +%s)

          echo "$URLS" | xargs -P $CONCURRENCY -I {} sh -c '
            STATUS=$(curl -sf -o /dev/null -w "%{http_code}" --max-time 60 -H "User-Agent: GitHub-Actions/SkillstoreBot" -H "X-Skillstore-Callback: true" "{}" 2>/dev/null || echo "000")
            if [ "$STATUS" = "200" ]; then
              echo "success"
            else
              echo "failed:{}" >&2
            fi
          ' | while read -r result; do
            COUNTER=$((COUNTER + 1))
            if [ "$result" = "success" ]; then
              SUCCESS=$((SUCCESS + 1))
            else
              FAILED=$((FAILED + 1))
            fi

            if [ $((COUNTER % 500)) -eq 0 ]; then
              ELAPSED=$(($(date +%s) - START_TIME))
              RATE=$(awk "BEGIN {printf \"%.1f\", $COUNTER / $ELAPSED}")
              echo "Progress: $COUNTER/$URL_COUNT URLs | Success: $SUCCESS | Failed: $FAILED | Rate: ${RATE} URLs/s"
            fi
          done

          END_TIME=$(date +%s)
          TOTAL_TIME=$((END_TIME - START_TIME))
          AVG_RATE=$(awk "BEGIN {printf \"%.1f\", $URL_COUNT / $TOTAL_TIME}")

          echo ""
          echo "âœ… Skills page cache warming complete"
          echo "Total: $URL_COUNT URLs | Success: $SUCCESS | Failed: $FAILED | Time: ${TOTAL_TIME}s | Avg: ${AVG_RATE} URLs/s"

      - name: Warm skills ZIP download cache
        if: inputs.warm_zip && (inputs.type == 'skills' || inputs.type == 'all')
        env:
          SLUGS: ${{ steps.fetch.outputs.skills_slugs }}
        run: |
          if [ -z "$SLUGS" ]; then
            echo "No skills to warm ZIP cache"
            exit 0
          fi

          SLUG_COUNT=$(echo $SLUGS | wc -w | tr -d ' ')
          echo "Warming ZIP cache for $SLUG_COUNT skills..."
          echo "Progress will be reported every 100 skills..."
          echo ""

          COUNTER=0
          SUCCESS=0
          FAILED=0
          START_TIME=$(date +%s)

          for slug in $SLUGS; do
            [ -z "$slug" ] && continue
            URL="$SITE_URL/api/skills/$slug/download"
            STATUS=$(curl -sf -o /dev/null -w "%{http_code}" --max-time 120 -H "User-Agent: GitHub-Actions/SkillstoreBot" -H "X-Skillstore-Callback: true" "$URL" 2>/dev/null || echo "000")

            COUNTER=$((COUNTER + 1))
            if [ "$STATUS" = "200" ]; then
              SUCCESS=$((SUCCESS + 1))
            else
              FAILED=$((FAILED + 1))
            fi

            if [ $((COUNTER % 100)) -eq 0 ]; then
              ELAPSED=$(($(date +%s) - START_TIME))
              RATE=$(awk "BEGIN {printf \"%.1f\", $COUNTER / $ELAPSED}")
              echo "Progress: $COUNTER/$SLUG_COUNT ZIPs | Success: $SUCCESS | Failed: $FAILED | Rate: ${RATE} ZIPs/s"
            fi
          done

          END_TIME=$(date +%s)
          TOTAL_TIME=$((END_TIME - START_TIME))
          AVG_RATE=$(awk "BEGIN {printf \"%.1f\", $SLUG_COUNT / $TOTAL_TIME}")

          echo ""
          echo "âœ… Skills ZIP cache warming complete"
          echo "Total: $SLUG_COUNT ZIPs | Success: $SUCCESS | Failed: $FAILED | Time: ${TOTAL_TIME}s | Avg: ${AVG_RATE} ZIPs/s"

      - name: Warm workflows cache
        if: inputs.type == 'workflows' || inputs.type == 'all'
        env:
          SLUGS: ${{ steps.fetch.outputs.workflows_slugs }}
        run: |
          if [ -z "$SLUGS" ]; then
            echo "No workflows to warm"
            exit 0
          fi

          generate_urls() {
            for slug in $SLUGS; do
              [ -z "$slug" ] && continue
              for locale in $LOCALES; do
                if [ "$locale" = "en" ]; then
                  echo "$SITE_URL/workflows/$slug"
                else
                  echo "$SITE_URL/$locale/workflows/$slug"
                fi
              done
            done
          }

          URLS=$(generate_urls)
          URL_COUNT=$(echo "$URLS" | grep -c . || echo 0)
          WORKFLOW_COUNT=$(echo $SLUGS | wc -w | tr -d ' ')

          echo "Warming $URL_COUNT workflow URLs ($WORKFLOW_COUNT workflows Ã— 11 locales)..."
          echo "Progress will be reported every 500 URLs..."
          echo ""

          COUNTER=0
          SUCCESS=0
          FAILED=0
          START_TIME=$(date +%s)

          echo "$URLS" | xargs -P $CONCURRENCY -I {} sh -c '
            STATUS=$(curl -sf -o /dev/null -w "%{http_code}" --max-time 60 -H "User-Agent: GitHub-Actions/SkillstoreBot" -H "X-Skillstore-Callback: true" "{}" 2>/dev/null || echo "000")
            if [ "$STATUS" = "200" ]; then
              echo "success"
            else
              echo "failed:{}" >&2
            fi
          ' | while read -r result; do
            COUNTER=$((COUNTER + 1))
            if [ "$result" = "success" ]; then
              SUCCESS=$((SUCCESS + 1))
            else
              FAILED=$((FAILED + 1))
            fi

            if [ $((COUNTER % 500)) -eq 0 ]; then
              ELAPSED=$(($(date +%s) - START_TIME))
              RATE=$(awk "BEGIN {printf \"%.1f\", $COUNTER / $ELAPSED}")
              echo "Progress: $COUNTER/$URL_COUNT URLs | Success: $SUCCESS | Failed: $FAILED | Rate: ${RATE} URLs/s"
            fi
          done

          END_TIME=$(date +%s)
          TOTAL_TIME=$((END_TIME - START_TIME))
          AVG_RATE=$(awk "BEGIN {printf \"%.1f\", $URL_COUNT / $TOTAL_TIME}")

          echo ""
          echo "âœ… Workflows cache warming complete"
          echo "Total: $URL_COUNT URLs | Success: $SUCCESS | Failed: $FAILED | Time: ${TOTAL_TIME}s | Avg: ${AVG_RATE} URLs/s"

      - name: Warm releases cache
        if: inputs.type == 'releases' || inputs.type == 'all'
        env:
          TAGS: ${{ steps.fetch.outputs.releases_tags }}
        run: |
          if [ -z "$TAGS" ]; then
            echo "No releases to warm"
            exit 0
          fi

          generate_urls() {
            for tag in $TAGS; do
              [ -z "$tag" ] && continue
              for locale in $LOCALES; do
                if [ "$locale" = "en" ]; then
                  echo "$SITE_URL/releases/$tag"
                else
                  echo "$SITE_URL/$locale/releases/$tag"
                fi
              done
            done
          }

          URLS=$(generate_urls)
          URL_COUNT=$(echo "$URLS" | grep -c . || echo 0)
          RELEASE_COUNT=$(echo $TAGS | wc -w | tr -d ' ')

          echo "Warming $URL_COUNT release URLs ($RELEASE_COUNT releases Ã— 11 locales)..."
          echo "Progress will be reported every 500 URLs..."
          echo ""

          COUNTER=0
          SUCCESS=0
          FAILED=0
          START_TIME=$(date +%s)

          echo "$URLS" | xargs -P $CONCURRENCY -I {} sh -c '
            STATUS=$(curl -sf -o /dev/null -w "%{http_code}" --max-time 60 -H "User-Agent: GitHub-Actions/SkillstoreBot" -H "X-Skillstore-Callback: true" "{}" 2>/dev/null || echo "000")
            if [ "$STATUS" = "200" ]; then
              echo "success"
            else
              echo "failed:{}" >&2
            fi
          ' | while read -r result; do
            COUNTER=$((COUNTER + 1))
            if [ "$result" = "success" ]; then
              SUCCESS=$((SUCCESS + 1))
            else
              FAILED=$((FAILED + 1))
            fi

            if [ $((COUNTER % 500)) -eq 0 ]; then
              ELAPSED=$(($(date +%s) - START_TIME))
              RATE=$(awk "BEGIN {printf \"%.1f\", $COUNTER / $ELAPSED}")
              echo "Progress: $COUNTER/$URL_COUNT URLs | Success: $SUCCESS | Failed: $FAILED | Rate: ${RATE} URLs/s"
            fi
          done

          END_TIME=$(date +%s)
          TOTAL_TIME=$((END_TIME - START_TIME))
          AVG_RATE=$(awk "BEGIN {printf \"%.1f\", $URL_COUNT / $TOTAL_TIME}")

          echo ""
          echo "âœ… Releases cache warming complete"
          echo "Total: $URL_COUNT URLs | Success: $SUCCESS | Failed: $FAILED | Time: ${TOTAL_TIME}s | Avg: ${AVG_RATE} URLs/s"

      - name: Summary
        env:
          MODE: ${{ inputs.mode }}
          CONTENT_TYPE: ${{ inputs.type }}
          WARM_ZIP: ${{ inputs.warm_zip }}
          SKILLS_SLUGS: ${{ steps.fetch.outputs.skills_slugs }}
          WORKFLOWS_SLUGS: ${{ steps.fetch.outputs.workflows_slugs }}
          RELEASES_TAGS: ${{ steps.fetch.outputs.releases_tags }}
        run: |
          SKILLS_COUNT=$(echo $SKILLS_SLUGS | wc -w | tr -d ' ')
          WORKFLOWS_COUNT=$(echo $WORKFLOWS_SLUGS | wc -w | tr -d ' ')
          RELEASES_COUNT=$(echo $RELEASES_TAGS | wc -w | tr -d ' ')
          LOCALE_COUNT=11
          
          SKILLS_URLS=$((SKILLS_COUNT * LOCALE_COUNT))
          if [ "$WARM_ZIP" = "true" ]; then
            SKILLS_ZIPS=$SKILLS_COUNT
          else
            SKILLS_ZIPS=0
          fi
          WORKFLOWS_URLS=$((WORKFLOWS_COUNT * LOCALE_COUNT))
          RELEASES_URLS=$((RELEASES_COUNT * LOCALE_COUNT))
          TOTAL_URLS=$((SKILLS_URLS + SKILLS_ZIPS + WORKFLOWS_URLS + RELEASES_URLS))
          
          echo "## Cache Warming Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Setting | Value |" >> $GITHUB_STEP_SUMMARY
          echo "|---------|-------|" >> $GITHUB_STEP_SUMMARY
          echo "| Mode | \`$MODE\` |" >> $GITHUB_STEP_SUMMARY
          echo "| Content Type | \`$CONTENT_TYPE\` |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ "$MODE" = "force" ]; then
            echo "> **Force mode**: All caches were invalidated before warming" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "| Metric | Count |" >> $GITHUB_STEP_SUMMARY
          echo "|--------|-------|" >> $GITHUB_STEP_SUMMARY
          
          if [ "$CONTENT_TYPE" = "skills" ] || [ "$CONTENT_TYPE" = "all" ]; then
            echo "| Skills | $SKILLS_COUNT |" >> $GITHUB_STEP_SUMMARY
            echo "| Skill Page URLs | $SKILLS_URLS |" >> $GITHUB_STEP_SUMMARY
            if [ "$WARM_ZIP" = "true" ]; then
              echo "| Skill ZIP Downloads | $SKILLS_COUNT |" >> $GITHUB_STEP_SUMMARY
            fi
          fi
          
          if [ "$CONTENT_TYPE" = "workflows" ] || [ "$CONTENT_TYPE" = "all" ]; then
            echo "| Workflows | $WORKFLOWS_COUNT |" >> $GITHUB_STEP_SUMMARY
            echo "| Workflow URLs | $WORKFLOWS_URLS |" >> $GITHUB_STEP_SUMMARY
          fi
          
          if [ "$CONTENT_TYPE" = "releases" ] || [ "$CONTENT_TYPE" = "all" ]; then
            echo "| Releases | $RELEASES_COUNT |" >> $GITHUB_STEP_SUMMARY
            echo "| Release URLs | $RELEASES_URLS |" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "| **Total URLs** | **$TOTAL_URLS** |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "âœ… Cache warming completed" >> $GITHUB_STEP_SUMMARY
