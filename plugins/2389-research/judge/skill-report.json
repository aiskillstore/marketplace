{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-10T09:25:13.906Z",
    "slug": "2389-research-judge",
    "source_url": "https://github.com/2389-research/claude-plugins/tree/main/test-kitchen/skills/judge",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "2.0.0",
    "source_type": "community",
    "content_hash": "22ea97b2617e4a391197e61afec63e1084312cfcae1c7ea90d675d7049fa0258",
    "tree_hash": "f38060560ea29702c538bfa9224beaff17b52e9aae4f1d5e4ad6db24592bdd9b"
  },
  "skill": {
    "name": "judge",
    "description": "Scoring framework for test-kitchen cookoff and omakase-off. Invoked at Phase 4 to evaluate implementations using 5-criteria scoring. Do not invoke directly - called by cookoff/omakase-off.",
    "summary": "Scoring framework for test-kitchen cookoff and omakase-off. Invoked at Phase 4 to evaluate implement...",
    "icon": "⚖️",
    "version": "1.0.0",
    "author": "2389-research",
    "license": "MIT",
    "category": "development",
    "tags": [
      "evaluation",
      "scoring",
      "comparison",
      "testing",
      "quality"
    ],
    "supported_tools": [
      "claude-code"
    ],
    "risk_factors": []
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "Pure prompt-based skill with no executable code. Contains only markdown instructions for AI scoring framework. No filesystem access, network calls, or command execution capabilities.",
    "risk_factor_evidence": [],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 1,
    "total_lines": 178,
    "audit_model": "claude",
    "audited_at": "2026-01-10T09:25:13.906Z"
  },
  "content": {
    "user_title": "Score parallel implementations",
    "value_statement": "When multiple implementations compete in cookoff or omakase-off, the judge skill evaluates each using 5 criteria to pick the winner. This ensures quality decisions when parallel agents produce different results.",
    "seo_keywords": [
      "judge skill",
      "Claude Code",
      "implementation scoring",
      "parallel evaluation",
      "cookoff",
      "omakase-off",
      "quality assessment",
      "test-kitchen",
      "implementation comparison",
      "code review"
    ],
    "actual_capabilities": [
      "Scores implementations on 5 criteria: fitness, complexity, readability, robustness, maintainability",
      "Fills out detailed scoring worksheets with checklist items",
      "Applies hard gates: fitness delta >= 2 triggers auto-win, critical flaws eliminate impls",
      "Produces winner selection with rationale and trade-off analysis",
      "Works for both cookoff (same design, different implementations) and omakase (different approaches)"
    ],
    "limitations": [
      "Not invoked directly - only called by cookoff or omakase-off skills",
      "Requires implementations to already exist in context",
      "Does not run tests or check code - only evaluates code visible in conversation",
      "Integer scores only - no half points or nuanced scoring"
    ],
    "use_cases": [
      {
        "target_user": "Development teams using parallel implementation workflows",
        "title": "Cookoff evaluation",
        "description": "Score competing implementations of the same design to pick the best approach"
      },
      {
        "target_user": "Architects exploring design alternatives",
        "title": "Omakase-off comparison",
        "description": "Evaluate different architectural approaches and select the optimal solution"
      },
      {
        "target_user": "Quality assurance processes",
        "title": "Automated quality gates",
        "description": "Apply consistent scoring criteria across multiple implementations"
      }
    ],
    "prompt_templates": [
      {
        "title": "Basic scoring request",
        "scenario": "When implementations are ready for evaluation",
        "prompt": "Judge the implementations in context using the 5-criteria scoring framework. Fill out complete worksheets for each impl."
      },
      {
        "title": "Cookoff evaluation",
        "scenario": "After parallel agent implementations",
        "prompt": "Run the judge skill on impl-1, impl-2, and impl-3 from the cookoff. Apply all scoring criteria and announce the winner."
      },
      {
        "title": "Omakase comparison",
        "scenario": "When comparing architectural variants",
        "prompt": "Compare variant-a and variant-b using the judge skill. Note that these are different approaches, not different implementations of the same design."
      },
      {
        "title": "Detailed analysis",
        "scenario": "When comprehensive scoring is needed",
        "prompt": "Provide complete scoring worksheets with all checklist items filled. Include feasibility checks and hard gate results. Explain trade-offs between all implementations."
      }
    ],
    "output_examples": [
      {
        "input": "Judge the three implementations in context using the 5-criteria framework",
        "output": [
          "## Gate Check: impl-1: 4/4 tests pass, Design Adherence: Yes; impl-2: 3/4 tests pass, Design Adherence: Yes; impl-3: 4/4 tests pass, Design Adherence: No",
          "## Judge Scorecard: impl-1: 21/25; impl-2: 18/25; impl-3: 15/25",
          "## Winner: impl-1 - Best balance of readability and maintainability with strong fitness score"
        ]
      }
    ],
    "best_practices": [
      "Ensure all implementations are visible in context before invoking judge",
      "Run fresh-eyes review on survivors before judge evaluation",
      "Document the selection rationale for future reference"
    ],
    "anti_patterns": [
      "Invoking judge directly - it should be called by cookoff or omakase-off",
      "Skipping feasibility checks - they catch critical issues early",
      "Using half-point scores - only integer scores 1-5 are valid"
    ],
    "faq": [
      {
        "question": "How is the winner determined?",
        "answer": "The highest scoring implementation wins unless a hard gate triggers. The fitness gate (delta >= 2) auto-advances the higher fitness impl. Critical flaws (any score of 1) eliminate implementations."
      },
      {
        "question": "Can I invoke judge directly?",
        "answer": "No. Judge is called automatically by cookoff or omakase-off at Phase 4. Direct invocation may produce incomplete results."
      },
      {
        "question": "What happens if implementations have equal scores?",
        "answer": "The skill does not specify tie-breaking. Review the worksheets to identify differences, or request human judgment based on the detailed criteria."
      },
      {
        "question": "Does judge run tests?",
        "answer": "No. Judge assumes tests already ran and results are available in context. It evaluates the code and design adherence, not test execution."
      },
      {
        "question": "Can judge evaluate more than 3 implementations?",
        "answer": "The format shows 3 columns but can be extended. The skill works for any number of implementations, with columns added as needed."
      },
      {
        "question": "What is the difference between cookoff and omakase evaluation?",
        "answer": "Cookoff compares implementations of the same design. Omakase compares different architectural approaches. The scoring framework is the same but interpretation differs."
      }
    ]
  },
  "file_structure": [
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md"
    }
  ]
}
