{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-10T12:13:24.548Z",
    "slug": "cam10001110101-music-generation",
    "source_url": "https://github.com/Cam10001110101/claude-skills-base/tree/main/mnt/skills/examples/music-generation",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "2.0.0",
    "source_type": "community",
    "content_hash": "a303d13eaf8346f05041faf180251c67bd86b145940a2a5989a9b006cc885166",
    "tree_hash": "d7ba524553a035596429b7855121da4c219789c8e5d3f63f7688b057390ac49d"
  },
  "skill": {
    "name": "music-generation",
    "description": "Tools, patterns, and utilities for generating professional music with realistic instrument sounds. Write custom compositions using music21 or learn from existing MIDI files.",
    "summary": "Tools, patterns, and utilities for generating professional music with realistic instrument sounds. W...",
    "icon": "ðŸŽµ",
    "version": "2.0.0",
    "author": "Cam10001110101",
    "license": "MIT",
    "category": "data",
    "tags": [
      "music",
      "midi",
      "audio",
      "composition",
      "synthesis"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": [
      "scripts",
      "filesystem",
      "external_commands"
    ]
  },
  "security_audit": {
    "risk_level": "low",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "This music generation skill contains legitimate audio processing code with no malicious behavior detected. The skill uses standard Python libraries (music21, pydub, mido) for MIDI composition and audio rendering. Low risk rating due to subprocess usage for rendering pipelines and filesystem access for reading/writing audio files.",
    "risk_factor_evidence": [
      {
        "factor": "scripts",
        "evidence": [
          {
            "file": "install.sh",
            "line_start": 1,
            "line_end": 66
          },
          {
            "file": "scripts/audio_validate.py",
            "line_start": 1,
            "line_end": 208
          },
          {
            "file": "scripts/render_electronic.py",
            "line_start": 1,
            "line_end": 514
          }
        ]
      },
      {
        "factor": "filesystem",
        "evidence": [
          {
            "file": "scripts/midi_inventory.py",
            "line_start": 171,
            "line_end": 189
          },
          {
            "file": "scripts/midi_render.py",
            "line_start": 180,
            "line_end": 191
          },
          {
            "file": "scripts/audio_validate.py",
            "line_start": 58,
            "line_end": 67
          }
        ]
      },
      {
        "factor": "external_commands",
        "evidence": [
          {
            "file": "SKILL.md",
            "line_start": 146,
            "line_end": 156
          },
          {
            "file": "scripts/render_electronic.py",
            "line_start": 498,
            "line_end": 510
          }
        ]
      }
    ],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [
      {
        "title": "Subprocess usage for script execution",
        "description": "The skill uses subprocess.run() to execute Python scripts for rendering MIDI to audio. While this is standard practice for audio processing pipelines, improper validation of input arguments could theoretically allow command injection. The code at SKILL.md lines 146-151 and render_electronic.py lines 498-510 passes user-provided paths to subprocess without explicit validation. An attacker controlling output paths could potentially inject shell metacharacters. However, Path.resolve() is used in render_electronic.py to normalize paths, and the usage is consistent with legitimate music rendering workflows.",
        "locations": [
          {
            "file": "SKILL.md",
            "line_start": 146,
            "line_end": 156
          },
          {
            "file": "scripts/render_electronic.py",
            "line_start": 498,
            "line_end": 510
          }
        ]
      }
    ],
    "dangerous_patterns": [],
    "files_scanned": 13,
    "total_lines": 4443,
    "audit_model": "claude",
    "audited_at": "2026-01-10T12:13:24.548Z"
  },
  "content": {
    "user_title": "Generate Professional Music with MIDI",
    "value_statement": "Create original music compositions and convert MIDI files to MP3 or WAV audio files. Uses music21 library for intelligent composition and supports both orchestral and electronic music generation with realistic instrument sounds.",
    "seo_keywords": [
      "music generation",
      "MIDI to MP3",
      "audio synthesis",
      "Claude Code",
      "Claude",
      "Codex",
      "music composition",
      "electronic music",
      "orchestral music",
      "audio rendering"
    ],
    "actual_capabilities": [
      "Generate original compositions using music21 library with algorithmic note generation",
      "Convert MIDI files to downloadable MP3 or WAV audio files",
      "Create electronic music with real-time synthesis (808-style drums, synth bass, pads, leads)",
      "Extract and analyze musical structure from existing MIDI files",
      "Apply transformations to MIDI compositions (transpose, tempo change, instrument swap)",
      "Validate audio file quality and detect issues like clipping or excessive silence"
    ],
    "limitations": [
      "Instrumental music only - cannot generate lyrics or vocals",
      "MIDI-based synthesis quality depends on SoundFont files used",
      "Requires installation of system dependencies (FluidSynth, FFmpeg) for full functionality",
      "No real-time playback - audio must be rendered before listening"
    ],
    "use_cases": [
      {
        "target_user": "Content creators",
        "title": "Background music for videos",
        "description": "Generate original royalty-free music for YouTube videos, podcasts, or presentations"
      },
      {
        "target_user": "Music producers",
        "title": "MIDI to audio conversion",
        "description": "Convert MIDI compositions to high-quality MP3 files with realistic instrument sounds"
      },
      {
        "target_user": "Educators",
        "title": "Music theory examples",
        "description": "Create educational examples demonstrating chord progressions, scales, and musical structures"
      }
    ],
    "prompt_templates": [
      {
        "title": "Simple melody",
        "scenario": "Create a basic melody",
        "prompt": "Generate a 16-bar melody in C major at 120 BPM using piano. Save the output as /mnt/user-data/outputs/piano_melody.mp3"
      },
      {
        "title": "Electronic track",
        "scenario": "Create an electronic house track",
        "prompt": "Create a 32-bar deep house track with four-on-the-floor drums, synth bass on A1, and atmospheric pads. Render using the electronic pipeline with deep_house preset. Save to /mnt/user-data/outputs/deep_house.mp3"
      },
      {
        "title": "Orchestral piece",
        "scenario": "Compose orchestral music",
        "prompt": "Compose a 24-bar orchestral piece with violin, cello, and trumpet sections. Use a I-IV-V-I progression. Export to /mnt/user-data/outputs/orchestral.mp3"
      },
      {
        "title": "MIDI transformation",
        "scenario": "Transform existing MIDI",
        "prompt": "Take the MIDI file at /mnt/user-data/inputs/song.mid, transpose it up by 2 semitones, change tempo to 1.2x, and render the result to /mnt/user-data/outputs/transformed.mp3"
      }
    ],
    "output_examples": [
      {
        "input": "Generate a 16-bar ambient piece with soft pads and subtle percussion at 80 BPM",
        "output": [
          "Created: /mnt/user-data/outputs/ambient_piece.mp3",
          "Duration: 24 seconds (16 bars at 80 BPM)",
          "Pipeline: Electronic synthesis with ambient preset",
          "Instruments: Soft pads (synth), subtle percussion, atmospheric effects"
        ]
      }
    ],
    "best_practices": [
      "Always use .insert() with explicit timing offsets for layered compositions instead of .append()",
      "Set appropriate MIDI velocities for each instrument role (lead: 90-105, background: 50-65)",
      "Choose the correct rendering pipeline based on genre (traditional for orchestral, electronic for EDM/house)"
    ],
    "anti_patterns": [
      "Using .append() for drum patterns - creates sequential rather than layered notes",
      "Setting all instruments to the same velocity - causes poor mix balance",
      "Using orchestral SoundFont for electronic music - results in poor quality synthetic sounds"
    ],
    "faq": [
      {
        "question": "Which rendering pipeline should I use?",
        "answer": "Use the traditional pipeline (FluidSynth) for orchestral, classical, or acoustic music. Use the electronic pipeline (real-time synthesis) for house, techno, trance, or any synth-heavy music."
      },
      {
        "question": "What is the maximum duration for generated music?",
        "answer": "There is no hard limit, but rendering time increases with duration. Practical limits are around 10-15 minutes for complex compositions."
      },
      {
        "question": "How do I set specific instruments in my composition?",
        "answer": "For orchestral instruments, use music21 instrument classes like instrument.Violin(). For electronic instruments, use mido to insert program_change messages after MIDI export."
      },
      {
        "question": "Is my data safe when using this skill?",
        "answer": "Yes. This skill processes audio locally on your machine. No audio data is sent to external servers. All output files are written to directories you specify."
      },
      {
        "question": "Why does the audio sound different from professional productions?",
        "answer": "MIDI synthesis cannot match studio-quality recordings. Sound quality depends on SoundFont files and synthesis parameters. For best results, use appropriate presets and velocity settings."
      },
      {
        "question": "How does this compare to other music generation tools?",
        "answer": "Unlike AI-based generators that create audio directly, this skill uses MIDI synthesis for controllable, theory-based composition. It gives you precise control over every note and instrument."
      }
    ]
  },
  "file_structure": [
    {
      "name": "scripts",
      "type": "dir",
      "path": "scripts",
      "children": [
        {
          "name": "__init__.py",
          "type": "file",
          "path": "scripts/__init__.py"
        },
        {
          "name": "audio_validate.py",
          "type": "file",
          "path": "scripts/audio_validate.py"
        },
        {
          "name": "drum_synthesizer.py",
          "type": "file",
          "path": "scripts/drum_synthesizer.py"
        },
        {
          "name": "melodic_synthesizer.py",
          "type": "file",
          "path": "scripts/melodic_synthesizer.py"
        },
        {
          "name": "midi_inventory.py",
          "type": "file",
          "path": "scripts/midi_inventory.py"
        },
        {
          "name": "midi_render.py",
          "type": "file",
          "path": "scripts/midi_render.py"
        },
        {
          "name": "midi_transform.py",
          "type": "file",
          "path": "scripts/midi_transform.py"
        },
        {
          "name": "midi_utils.py",
          "type": "file",
          "path": "scripts/midi_utils.py"
        },
        {
          "name": "render_electronic.py",
          "type": "file",
          "path": "scripts/render_electronic.py"
        },
        {
          "name": "synthesis_presets.py",
          "type": "file",
          "path": "scripts/synthesis_presets.py"
        }
      ]
    },
    {
      "name": "install.sh",
      "type": "file",
      "path": "install.sh"
    },
    {
      "name": "requirements.txt",
      "type": "file",
      "path": "requirements.txt"
    },
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md"
    }
  ]
}
