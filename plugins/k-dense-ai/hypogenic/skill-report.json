{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-04T16:39:27.605Z",
    "slug": "k-dense-ai-hypogenic",
    "source_url": "https://github.com/K-Dense-AI/claude-scientific-skills/tree/main/scientific-skills/hypogenic",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "2.0.0",
    "source_type": "community",
    "content_hash": "31984c21232fa5e90625f712590ba9849dc514e578497596a0afb00df0b49d14",
    "tree_hash": "11854fcdc253f69fd47e2b0f08e342c650142f28d4b92b4c6b4c8970104bc218"
  },
  "skill": {
    "name": "hypogenic",
    "description": "Automated hypothesis generation and testing using large language models. Use this skill when generating scientific hypotheses from datasets, combining literature insights with empirical data, testing hypotheses against observational data, or conducting systematic hypothesis exploration for research discovery in domains like deception detection, AI content detection, mental health analysis, or other empirical research tasks.",
    "summary": "Automated hypothesis generation and testing using large language models. Use this skill when generat...",
    "icon": "ðŸ§ª",
    "version": "1.0.0",
    "author": "K-Dense Inc.",
    "license": "MIT license",
    "category": "research",
    "tags": [
      "hypothesis-generation",
      "scientific-research",
      "llm",
      "literature",
      "evaluation"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": [
      "network"
    ]
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "The skill files are pure documentation and configuration templates. No executable code exists in the skill directory. All described functionality (CLI commands, Python API, Redis caching) refers to an external hypogenic package that users install separately. The skill itself only provides guidance, templates, and usage instructions for Claude to help users work with this external package.",
    "risk_factor_evidence": [
      {
        "factor": "network",
        "evidence": [
          {
            "file": "references/config_template.yaml",
            "line_start": 15,
            "line_end": 19
          }
        ]
      }
    ],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 5,
    "total_lines": 1036,
    "audit_model": "claude",
    "audited_at": "2026-01-04T16:39:27.605Z"
  },
  "content": {
    "user_title": "Generate scientific hypotheses from your data",
    "value_statement": "Turning raw datasets into testable hypotheses is time-consuming and error-prone. This skill provides automated hypothesis generation and testing using LLMs with three methods: data-driven HypoGeniC, literature-integrated HypoRefine, and combined Union approaches.",
    "seo_keywords": [
      "hypothesis generation",
      "scientific discovery",
      "LLM research tool",
      "dataset analysis",
      "Claude",
      "Codex",
      "Claude Code",
      "HypoGeniC",
      "HypoRefine",
      "hypothesis testing"
    ],
    "actual_capabilities": [
      "Generate 10-20+ testable hypotheses from observational datasets automatically",
      "Combine literature insights with empirical patterns using HypoRefine workflows",
      "Test hypotheses against held-out data using CLI or Python API",
      "Configure prompts and datasets through YAML templates with variable injection",
      "Use Redis caching to reduce API costs during iterative experiments"
    ],
    "limitations": [
      "Requires installing the external hypogenic Python package via pip",
      "Datasets must follow the specified JSON format with text features and labels",
      "Literature workflows require GROBID service for PDF preprocessing",
      "Output quality depends on prompt template design and dataset quality"
    ],
    "use_cases": [
      {
        "target_user": "Research scientist",
        "title": "Data-driven discovery",
        "description": "Generate and compare hypotheses for new observational datasets without existing theoretical frameworks."
      },
      {
        "target_user": "Data analyst",
        "title": "Pattern hypothesis testing",
        "description": "Create testable explanations for class differences and validate them on held-out data."
      },
      {
        "target_user": "Graduate student",
        "title": "Literature synthesis",
        "description": "Combine insights from research papers with data patterns to form stronger research hypotheses."
      }
    ],
    "prompt_templates": [
      {
        "title": "Quick start",
        "scenario": "Create hypotheses from a dataset",
        "prompt": "Use HypoGeniC to generate hypotheses for my task using config.yaml. Show me the CLI commands and explain the next steps."
      },
      {
        "title": "Run and test",
        "scenario": "Execute generation and inference",
        "prompt": "Generate 20 hypotheses with method hypogenic and describe how to run inference on my test dataset."
      },
      {
        "title": "Integrate papers",
        "scenario": "Use literature with data",
        "prompt": "Outline a HypoRefine workflow for my PDFs and dataset, including required GROBID preprocessing steps."
      },
      {
        "title": "Combine methods",
        "scenario": "Union hypothesis banks",
        "prompt": "Explain how to run the union method to deduplicate and combine literature and data hypotheses."
      }
    ],
    "output_examples": [
      {
        "input": "Generate hypotheses for detecting AI-generated content in text.",
        "output": [
          "Five testable hypotheses focused on linguistic cues like formality patterns, grammatical consistency, and tone markers",
          "A step-by-step plan to evaluate each hypothesis on a labeled validation set",
          "Recommended prompt template adjustments to improve hypothesis specificity and testability"
        ]
      }
    ],
    "best_practices": [
      "Use a custom extract_label function that matches your dataset label format exactly",
      "Start with a small dataset slice to validate prompts before scaling to full experiments",
      "Enable Redis caching if you plan multiple iterations to reduce API costs significantly"
    ],
    "anti_patterns": [
      "Running literature workflows without first preprocessing PDFs with GROBID",
      "Using label formats in your data that do not match your extract_label function output",
      "Generating a large number of hypotheses without intermediate validation checkpoints"
    ],
    "faq": [
      {
        "question": "Is this compatible with Claude and Codex?",
        "answer": "Yes. Configure model.name to use Claude, GPT-4, or Codex models. The templates are model-agnostic."
      },
      {
        "question": "What are the main limitations?",
        "answer": "Quality depends on your dataset, prompt design, and external tool setup for literature processing workflows."
      },
      {
        "question": "How do I integrate this with my pipeline?",
        "answer": "Use the CLI commands or Python API. Point to your config.yaml and dataset paths to generate and test hypotheses."
      },
      {
        "question": "Does this skill read or upload my data?",
        "answer": "No. This skill provides documentation only. The external hypogenic package handles data when you run it locally."
      },
      {
        "question": "What should I do if results are too generic?",
        "answer": "Refine your prompt templates to demand specific, measurable hypotheses. Reduce batch sizes and increase iterations."
      },
      {
        "question": "How does this compare to manual hypothesis writing?",
        "answer": "It accelerates ideation and systematic testing. Expert review remains essential for scientific validity and interpretation."
      }
    ]
  },
  "file_structure": [
    {
      "name": "references",
      "type": "dir",
      "path": "references",
      "children": [
        {
          "name": "config_template.yaml",
          "type": "file",
          "path": "references/config_template.yaml"
        }
      ]
    },
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md"
    }
  ]
}
