{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-02T02:38:09.555Z",
    "slug": "K-Dense-AI-hypogenic",
    "source_url": "https://github.com/K-Dense-AI/claude-scientific-skills/tree/main/scientific-skills/hypogenic",
    "source_ref": "main",
    "model": "codex",
    "analysis_version": "2.0.0",
    "source_type": "community"
  },
  "skill": {
    "name": "hypogenic",
    "description": "Automated hypothesis generation and testing using large language models. Use this skill when generating scientific hypotheses from datasets, combining literature insights with empirical data, testing hypotheses against observational data, or conducting systematic hypothesis exploration for research discovery in domains like deception detection, AI content detection, mental health analysis, or other empirical research tasks.",
    "summary": "Automated hypothesis generation and testing using large language models. Use this skill when generat...",
    "icon": "ðŸ§ª",
    "version": "unknown",
    "author": "K-Dense Inc.",
    "license": "MIT license",
    "category": "research",
    "tags": [
      "hypothesis-generation",
      "scientific-research",
      "llm",
      "literature",
      "evaluation"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": [
      "network"
    ]
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "The skill files are documentation and configuration templates only. No code executes, no network calls exist, and no sensitive file access patterns are present.",
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 2,
    "total_lines": 802,
    "audit_model": "codex",
    "audited_at": "2026-01-02T02:38:09.555Z"
  },
  "content": {
    "user_title": "Generate testable hypotheses from your dataset",
    "value_statement": "Research teams struggle to turn messy datasets into clear, testable hypotheses. This skill guides hypothesis generation, refinement, and testing workflows with templates and examples.",
    "seo_keywords": [
      "hypothesis generation",
      "scientific discovery",
      "LLM research",
      "dataset analysis",
      "Claude",
      "Codex",
      "Claude Code",
      "HypoGeniC",
      "HypoRefine",
      "hypothesis testing"
    ],
    "actual_capabilities": [
      "Run hypothesis generation and inference via CLI commands",
      "Use a Python API to generate hypotheses and test them",
      "Configure prompts and datasets through a YAML template",
      "Integrate literature processing steps for HypoRefine workflows",
      "Support union methods to combine literature and data hypotheses"
    ],
    "limitations": [
      "Requires installing the hypogenic package and external dependencies",
      "Datasets must follow the specified JSON format",
      "Literature workflows need GROBID and PDF preprocessing",
      "Output quality depends on prompt templates and data quality"
    ],
    "use_cases": [
      {
        "target_user": "Research scientist",
        "title": "Hypothesis discovery",
        "description": "Generate and compare hypotheses for new observational datasets in a research domain."
      },
      {
        "target_user": "Data analyst",
        "title": "Model insight testing",
        "description": "Create testable explanations for class differences and validate them on held out data."
      },
      {
        "target_user": "Graduate student",
        "title": "Literature grounded ideas",
        "description": "Combine paper insights with data patterns to form stronger research hypotheses."
      }
    ],
    "prompt_templates": [
      {
        "title": "Quick start",
        "scenario": "Create hypotheses from a dataset",
        "prompt": "Use HypoGeniC to generate 10 hypotheses for my task using config.yaml and explain the next steps for inference."
      },
      {
        "title": "Data driven run",
        "scenario": "Run generation and testing",
        "prompt": "Generate 20 hypotheses with method hypogenic and describe how to run inference on the test set."
      },
      {
        "title": "Literature refine",
        "scenario": "Integrate papers with data",
        "prompt": "Outline a HypoRefine workflow using my PDFs and dataset, including required preprocessing steps."
      },
      {
        "title": "Union method tuning",
        "scenario": "Combine hypothesis banks",
        "prompt": "Explain how to run the union method and deduplicate literature and data hypotheses for my task."
      }
    ],
    "output_examples": [
      {
        "input": "Generate 5 hypotheses for deception detection in reviews and describe how to test them.",
        "output": [
          "Five testable hypotheses focused on language cues such as specificity, sentiment shifts, and pronoun use",
          "A brief plan to evaluate each hypothesis on a labeled validation set",
          "Suggested prompt template adjustments to improve hypothesis specificity"
        ]
      }
    ],
    "best_practices": [
      "Use a custom extract_label function that matches your dataset labels",
      "Start with a small dataset slice to validate prompts before scaling",
      "Enable caching if you plan iterative experiments"
    ],
    "anti_patterns": [
      "Running literature workflows without PDF preprocessing",
      "Using mismatched label formats between data and extraction",
      "Generating too many hypotheses without validation checkpoints"
    ],
    "faq": [
      {
        "question": "Is this compatible with Claude and Codex?",
        "answer": "Yes. The templates reference API based models and can be adapted for Claude, Codex, and Claude Code."
      },
      {
        "question": "What are the main limits?",
        "answer": "It depends on dataset quality, prompt design, and external tool setup for literature processing."
      },
      {
        "question": "How do I integrate with my pipeline?",
        "answer": "Use the CLI or Python API and point to your config.yaml and dataset paths."
      },
      {
        "question": "Does it read or upload my data?",
        "answer": "No. The skill files are documentation only and do not execute any data access."
      },
      {
        "question": "What should I do if results are generic?",
        "answer": "Refine prompt templates to demand specific, measurable hypotheses and adjust generation counts."
      },
      {
        "question": "How does it compare to manual hypothesis writing?",
        "answer": "It speeds ideation and testing, but expert review is still needed for scientific validity."
      }
    ]
  },
  "file_structure": [
    {
      "name": "references",
      "type": "dir",
      "path": "references",
      "children": [
        {
          "name": "config_template.yaml",
          "type": "file",
          "path": "references/config_template.yaml"
        }
      ]
    },
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md"
    }
  ]
}