{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-04T17:40:26.324Z",
    "slug": "k-dense-ai-polars",
    "source_url": "https://github.com/K-Dense-AI/claude-scientific-skills/tree/main/scientific-skills/polars",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "2.0.0",
    "source_type": "community",
    "content_hash": "24446c8a65865406e26323f86b1a3efb50451f164013ab10cb81304955d5b402",
    "tree_hash": "2d8d671926af5335b8ac3dbcb50c932df8091dbca75d1d6e84d1bc6279c73cba"
  },
  "skill": {
    "name": "polars",
    "description": "Fast DataFrame library (Apache Arrow). Select, filter, group_by, joins, lazy evaluation, CSV/Parquet I/O, expression API, for high-performance data analysis workflows.",
    "summary": "Fast DataFrame library (Apache Arrow). Select, filter, group_by, joins, lazy evaluation, CSV/Parquet...",
    "icon": "ðŸ“Š",
    "version": "1.0.0",
    "author": "K-Dense Inc.",
    "license": "https://github.com/pola-rs/polars/blob/main/LICENSE",
    "category": "data",
    "tags": [
      "polars",
      "dataframe",
      "performance",
      "lazy-evaluation",
      "data-analysis"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": []
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "Pure documentation skill containing only markdown guides and code examples for Polars library usage. No executable code, file access, network calls, or external commands present. Users receive guidance only.",
    "risk_factor_evidence": [],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 10,
    "total_lines": 3536,
    "audit_model": "claude",
    "audited_at": "2026-01-04T17:40:26.324Z"
  },
  "content": {
    "user_title": "Analyze data faster with Polars workflows",
    "value_statement": "Large datasets can be slow and memory intensive in pandas. This skill provides Polars expressions, lazy queries, and fast I/O patterns for efficient data analysis.",
    "seo_keywords": [
      "Polars DataFrame",
      "lazy evaluation",
      "data wrangling",
      "CSV Parquet IO",
      "pandas migration",
      "Claude",
      "Codex",
      "Claude Code",
      "Arrow analytics",
      "Python data pipelines"
    ],
    "actual_capabilities": [
      "Explain Polars expressions for select, filter, and with_columns operations",
      "Guide group_by aggregations, window functions, and conditional transformations",
      "Show joins, concat, pivot, and unpivot patterns for data reshaping",
      "Provide CSV, Parquet, JSON, and Excel I/O workflows with best practices",
      "Map common pandas operations to Polars equivalents for safe migration"
    ],
    "limitations": [
      "Does not execute code or access user data files",
      "No pandas index features or advanced pandas ecosystem tools covered",
      "Streaming mode limitations for certain operations not detailed",
      "Custom Python UDFs can reduce performance but are outside skill scope"
    ],
    "use_cases": [
      {
        "target_user": "Data analyst",
        "title": "Speed up reporting",
        "description": "Convert slow pandas reports to Polars with lazy queries and optimized I/O patterns."
      },
      {
        "target_user": "Data engineer",
        "title": "Optimize pipelines",
        "description": "Design efficient Polars data pipelines with predicate pushdown and streaming guidance."
      },
      {
        "target_user": "Python developer",
        "title": "Migrate safely",
        "description": "Translate pandas code to Polars with clear operation mappings and syntax examples."
      }
    ],
    "prompt_templates": [
      {
        "title": "Basic filtering",
        "scenario": "Small CSV analysis",
        "prompt": "Show how to read a CSV with Polars and filter rows where age is over 30, then select name and age columns."
      },
      {
        "title": "Group by summary",
        "scenario": "Sales aggregation",
        "prompt": "Provide a Polars group_by example to compute total sales and average order value grouped by region."
      },
      {
        "title": "Lazy pipeline",
        "scenario": "Large dataset workflow",
        "prompt": "Create a lazy Polars pipeline that scans Parquet, filters by date, selects columns, and collects with streaming."
      },
      {
        "title": "Pandas migration",
        "scenario": "Rewrite pandas chain",
        "prompt": "Rewrite this pandas chain in Polars: filter active users, add revenue column, group by plan, compute mean revenue."
      }
    ],
    "output_examples": [
      {
        "input": "Explain how to join two tables and then pivot by month in Polars.",
        "output": [
          "Describe the join type and keys to use for your data",
          "Show inner join example with matching column names",
          "Explain pivot operation to convert months to columns",
          "Note when to aggregate before pivoting for best performance",
          "Mention filtering early in pipeline for optimization"
        ]
      }
    ],
    "best_practices": [
      "Use lazy scan functions for large files to enable predicate and projection pushdown",
      "Select only needed columns early in the pipeline to reduce memory usage",
      "Prefer native expression API over Python UDFs for parallel execution"
    ],
    "anti_patterns": [
      "Reading large files with eager read_csv instead of lazy scan_csv",
      "Using row iteration or heavy map_elements in performance-critical paths",
      "Joining large tables before filtering reduces data size first"
    ],
    "faq": [
      {
        "question": "What environments are supported?",
        "answer": "Any Python environment with Polars installed including Jupyter notebooks, scripts, and production code."
      },
      {
        "question": "Are there limits on data size?",
        "answer": "Performance scales with available memory. Lazy mode and streaming help process datasets larger than RAM."
      },
      {
        "question": "Can it integrate with databases?",
        "answer": "Yes, Polars supports PostgreSQL, MySQL, SQLite via database readers and connectorx for high-performance queries."
      },
      {
        "question": "Does this skill access my data?",
        "answer": "No, this skill only provides documentation and guidance. It does not read files, execute code, or send data."
      },
      {
        "question": "What if my query is slow?",
        "answer": "Use lazy mode with scan functions, filter early, select only needed columns, and check optimized plan with explain()."
      },
      {
        "question": "How does it compare to pandas?",
        "answer": "Polars is faster for most operations with parallel execution. It lacks pandas index but offers better lazy optimization and memory efficiency."
      }
    ]
  },
  "file_structure": [
    {
      "name": "references",
      "type": "dir",
      "path": "references",
      "children": [
        {
          "name": "best_practices.md",
          "type": "file",
          "path": "references/best_practices.md"
        },
        {
          "name": "core_concepts.md",
          "type": "file",
          "path": "references/core_concepts.md"
        },
        {
          "name": "io_guide.md",
          "type": "file",
          "path": "references/io_guide.md"
        },
        {
          "name": "operations.md",
          "type": "file",
          "path": "references/operations.md"
        },
        {
          "name": "pandas_migration.md",
          "type": "file",
          "path": "references/pandas_migration.md"
        },
        {
          "name": "transformations.md",
          "type": "file",
          "path": "references/transformations.md"
        }
      ]
    },
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md"
    }
  ]
}
