{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-04T17:12:32.238Z",
    "slug": "k-dense-ai-dnanexus-integration",
    "source_url": "https://github.com/K-Dense-AI/claude-scientific-skills/tree/main/scientific-skills/dnanexus-integration",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "2.0.0",
    "source_type": "community",
    "content_hash": "28f8e5deb64f8b82e6622c4c8bba1e188696d5a4eba53fd295367cd860c44c8d",
    "tree_hash": "f854ceacf7df1ee6d93b25324bcf3854823b13d6826e0f4b07ea067301970995"
  },
  "skill": {
    "name": "dnanexus-integration",
    "description": "DNAnexus cloud genomics platform. Build apps/applets, manage data (upload/download), dxpy Python SDK, run workflows, FASTQ/BAM/VCF, for genomics pipeline development and execution.",
    "summary": "DNAnexus cloud genomics platform. Build apps/applets, manage data (upload/download), dxpy Python SDK...",
    "icon": "ðŸ§¬",
    "version": "1.0.0",
    "author": "K-Dense Inc.",
    "license": "MIT",
    "category": "research",
    "tags": [
      "genomics",
      "dnanexus",
      "dxpy",
      "bioinformatics",
      "workflows"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": []
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "Documentation-only skill providing reference material for DNAnexus platform. Contains no executable code, no file access, no network operations. All capabilities are informational - users must install and use the official dxpy SDK separately.",
    "risk_factor_evidence": [],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 8,
    "total_lines": 1465,
    "audit_model": "claude",
    "audited_at": "2026-01-04T17:12:32.238Z"
  },
  "content": {
    "user_title": "Integrate DNAnexus Genomics Platform",
    "value_statement": "Build and deploy bioinformatics workflows on the DNAnexus cloud platform. Upload sequencing data, run analyses, and manage genomics pipelines using the dxpy Python SDK and CLI tools.",
    "seo_keywords": [
      "DNAnexus",
      "genomics",
      "dxpy",
      "bioinformatics",
      "workflows",
      "Claude",
      "Codex",
      "Claude Code",
      "sequencing",
      "FASTQ"
    ],
    "actual_capabilities": [
      "Create and deploy DNAnexus apps and applets using dxpy SDK",
      "Upload and download genomic files (FASTQ, BAM, VCF)",
      "Run jobs and workflows on cloud infrastructure",
      "Search and organize data objects within projects",
      "Configure app dependencies and instance types",
      "Build multi-step analysis pipelines with job chaining"
    ],
    "limitations": [
      "Requires a DNAnexus account and API authentication",
      "Does not install dxpy SDK - users must install separately",
      "Actual job execution happens on DNAnexus cloud, not locally",
      "Limited to capabilities supported by the official DNAnexus API"
    ],
    "use_cases": [
      {
        "target_user": "Bioinformatician",
        "title": "Build Genomics Pipelines",
        "description": "Create automated workflows for sequence alignment, variant calling, and RNA-seq analysis on cloud infrastructure"
      },
      {
        "target_user": "Data Manager",
        "title": "Organize Sequencing Data",
        "description": "Upload, catalog, and manage large genomic datasets with metadata tags and folder organization"
      },
      {
        "target_user": "Research Scientist",
        "title": "Run Cloud Analyses",
        "description": "Execute computational analyses on sequencing data using scalable cloud compute resources"
      }
    ],
    "prompt_templates": [
      {
        "title": "Upload Files",
        "scenario": "Upload genomic data",
        "prompt": "Show me how to upload FASTQ files to my DNAnexus project and tag them with experiment metadata"
      },
      {
        "title": "Run Analysis",
        "scenario": "Execute computational job",
        "prompt": "How do I run an applet on DNAnexus to process BAM files and monitor job status"
      },
      {
        "title": "Build Pipeline",
        "scenario": "Create multi-step workflow",
        "prompt": "Create a workflow that chains quality control, alignment, and variant calling stages with proper input/output links"
      },
      {
        "title": "Configure App",
        "scenario": "Set up app configuration",
        "prompt": "Write a complete dxapp.json for a Python app that uses samtools and requires 8 CPU cores with 24 hour timeout"
      }
    ],
    "output_examples": [
      {
        "input": "Upload FASTQ files to DNAnexus",
        "output": [
          "Upload local file to project using dxpy.upload_local_file()",
          "Add properties and tags for experiment tracking",
          "Close file to make it immutable and ready for analysis"
        ]
      }
    ],
    "best_practices": [
      "Always close files and records after writing to make them immutable and accessible",
      "Use dxpy.dxlink() to create references between data objects and jobs",
      "Set appropriate instance types and timeouts based on expected workload requirements"
    ],
    "anti_patterns": [
      "Hardcoding API tokens in source code - use environment variables or dx login",
      "Processing files without verifying they are in closed state",
      "Running large jobs without proper error handling or job monitoring"
    ],
    "faq": [
      {
        "question": "What programming languages are supported?",
        "answer": "Python and Bash are the primary languages. Apps use @dxpy.entry_point decorators for Python or shell scripts for Bash."
      },
      {
        "question": "What are the resource limits for jobs?",
        "answer": "Instance types range from 2 to 36 CPU cores. Timeouts can be configured up to several days depending on account type."
      },
      {
        "question": "Can I integrate with other tools?",
        "answer": "Yes, you can use Docker containers, bundled dependencies, and system packages. External API calls require network access permissions."
      },
      {
        "question": "Is my data secure?",
        "answer": "DNAnexus handles authentication and encryption. You control project permissions. Credentials should never be hardcoded in code."
      },
      {
        "question": "Why did my job fail?",
        "answer": "Common causes include missing dependencies, insufficient memory, invalid input files, or timeout. Check job logs with dx watch."
      },
      {
        "question": "How is this different from local tools?",
        "answer": "DNAnexus provides scalable cloud compute, automatic resource management, and collaboration features. Your code runs on remote infrastructure."
      }
    ]
  },
  "file_structure": [
    {
      "name": "references",
      "type": "dir",
      "path": "references",
      "children": [
        {
          "name": "app-development.md",
          "type": "file",
          "path": "references/app-development.md"
        },
        {
          "name": "configuration.md",
          "type": "file",
          "path": "references/configuration.md"
        },
        {
          "name": "data-operations.md",
          "type": "file",
          "path": "references/data-operations.md"
        },
        {
          "name": "job-execution.md",
          "type": "file",
          "path": "references/job-execution.md"
        },
        {
          "name": "python-sdk.md",
          "type": "file",
          "path": "references/python-sdk.md"
        }
      ]
    },
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md"
    }
  ]
}
