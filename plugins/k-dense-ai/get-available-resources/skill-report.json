{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-12T16:13:49.483Z",
    "slug": "k-dense-ai-get-available-resources",
    "source_url": "https://github.com/K-Dense-AI/claude-scientific-skills/tree/main/scientific-skills/get-available-resources",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "3.0.0",
    "source_type": "community",
    "content_hash": "3fb76837e44d4860feb402f8da6cadd707bcab6ca1a27df91cc0e09516e14fde",
    "tree_hash": "e4c2b784f70bb8dec79cb51c3daa19ccc67a00e117e2221b7bd356d159d33334"
  },
  "skill": {
    "name": "get-available-resources",
    "description": "This skill should be used at the start of any computationally intensive scientific task to detect and report available system resources (CPU cores, GPUs, memory, disk space). It creates a JSON file with resource information and strategic recommendations that inform computational approach decisions such as whether to use parallel processing (joblib, multiprocessing), out-of-core computing (Dask, Zarr), GPU acceleration (PyTorch, JAX), or memory-efficient strategies. Use this skill before running analyses, training models, processing large datasets, or any task where resource constraints matter.",
    "summary": "This skill should be used at the start of any computationally intensive scientific task to detect an...",
    "icon": "üîç",
    "version": "1.0.0",
    "author": "K-Dense-AI",
    "license": "MIT license",
    "category": "data",
    "tags": [
      "scientific-computing",
      "system-monitoring",
      "resource-optimization",
      "gpu-detection"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": [
      "external_commands",
      "scripts",
      "filesystem"
    ]
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "All static findings are false positives. The skill performs legitimate system resource detection using subprocess calls to standard system utilities (nvidia-smi, rocm-smi, system_profiler) for GPU/CPU detection. All commands use hardcoded arguments in list format, preventing shell injection. No user input is processed. The skill outputs a JSON file with resource information for informed computational decisions.",
    "risk_factor_evidence": [
      {
        "factor": "external_commands",
        "evidence": [
          {
            "file": "scripts/detect_resources.py",
            "line_start": 87,
            "line_end": 93
          },
          {
            "file": "scripts/detect_resources.py",
            "line_start": 122,
            "line_end": 128
          },
          {
            "file": "scripts/detect_resources.py",
            "line_start": 156,
            "line_end": 161
          },
          {
            "file": "scripts/detect_resources.py",
            "line_start": 177,
            "line_end": 182
          }
        ]
      },
      {
        "factor": "scripts",
        "evidence": [
          {
            "file": "scripts/detect_resources.py",
            "line_start": 255,
            "line_end": 255
          }
        ]
      },
      {
        "factor": "filesystem",
        "evidence": [
          {
            "file": "scripts/detect_resources.py",
            "line_start": 267,
            "line_end": 268
          }
        ]
      }
    ],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 2,
    "total_lines": 679,
    "audit_model": "claude",
    "audited_at": "2026-01-12T16:13:49.483Z"
  },
  "content": {
    "user_title": "Detect System Resources for Scientific Computing",
    "value_statement": "Scientific computing tasks require knowledge of available hardware resources to choose appropriate computational strategies. This skill automatically detects CPU cores, GPU availability, memory, and disk space, then generates strategic recommendations for parallel processing, GPU acceleration, and memory-efficient approaches.",
    "seo_keywords": [
      "Claude scientific skills",
      "system resource detection",
      "GPU detection",
      "scientific computing",
      "parallel processing",
      "Claude Code",
      "resource optimization",
      "hardware detection",
      "memory management",
      "Codex"
    ],
    "actual_capabilities": [
      "Detect CPU cores, architecture, and frequency using psutil and platform modules",
      "Identify NVIDIA GPUs via nvidia-smi, AMD GPUs via rocm-smi, and Apple Silicon via system_profiler",
      "Monitor memory usage including RAM and swap space with percentage calculations",
      "Check disk space availability for working directory and calculate usage percentages",
      "Generate strategic recommendations for parallel processing, memory strategy, GPU acceleration, and large data handling"
    ],
    "limitations": [
      "GPU detection requires nvidia-smi, rocm-smi, or system_profiler to be installed and in system PATH",
      "Available memory is a snapshot at detection time; actual available memory changes with system load",
      "Script must be re-run to get updated resource information; does not provide real-time monitoring"
    ],
    "use_cases": [
      {
        "target_user": "Data Scientists",
        "title": "Optimize Dataset Processing",
        "description": "Detect available memory to determine if datasets can fit in RAM or require Dask/Zarr chunking."
      },
      {
        "target_user": "ML Engineers",
        "title": "Choose GPU Acceleration Path",
        "description": "Identify available GPU backends (CUDA, Metal, ROCm) to select appropriate PyTorch/TensorFlow builds."
      },
      {
        "target_user": "Research Scientists",
        "title": "Scale Parallel Workers",
        "description": "Determine optimal worker count based on physical cores for joblib or multiprocessing workflows."
      }
    ],
    "prompt_templates": [
      {
        "title": "Basic Resource Check",
        "scenario": "Before starting analysis",
        "prompt": "Run the get-available-resources skill to detect what hardware is available for this computation."
      },
      {
        "title": "Memory-Aware Processing",
        "scenario": "Handling large datasets",
        "prompt": "Use get-available-resources to check available memory, then suggest whether to use pandas, Dask, or Zarr for loading this 50GB dataset."
      },
      {
        "title": "GPU-Optimized Training",
        "scenario": "Training neural networks",
        "prompt": "Run get-available-resources to detect GPU availability. If GPU is available, recommend the appropriate PyTorch device (cuda, mps, or cpu)."
      },
      {
        "title": "Multi-Worker Parallelization",
        "scenario": "Scaling computation",
        "prompt": "Use get-available-resources to get CPU core count, then configure joblib Parallel with the optimal number of workers for this grid search."
      }
    ],
    "output_examples": [
      {
        "input": "Run get-available-resources to check what resources I have for training this model.",
        "output": [
          "CPU: 8 cores (8 physical) on arm64 architecture",
          "Memory: 16 GB total, 8.5 GB available (46.9% used)",
          "Disk: 500 GB total, 200 GB available",
          "GPU: Apple M2 with Metal backend, unified memory",
          "Recommendation: Use Metal GPU acceleration with PyTorch-MPS",
          "Recommendation: 6 workers for parallel processing (cores - 2)"
        ]
      }
    ],
    "best_practices": [
      "Run resource detection at the start of any computationally intensive task before making architectural decisions.",
      "Re-run detection when switching between tasks or after significant time passes, as memory usage changes.",
      "Save the .claude_resources.json file in project directories to document resource-aware decisions for reproducibility."
    ],
    "anti_patterns": [
      "Running the skill once and assuming resources remain constant throughout long workflows.",
      "Ignoring the memory recommendations and attempting to load datasets larger than available RAM.",
      "Using the suggested worker count without considering other running processes that may consume CPU resources."
    ],
    "faq": [
      {
        "question": "What platforms does this skill support?",
        "answer": "Full support for macOS (including Apple Silicon M1-M4), Linux (NVIDIA and AMD), and Windows (NVIDIA GPUs)."
      },
      {
        "question": "Does this skill require any dependencies?",
        "answer": "The script requires psutil (install via uv pip install psutil). GPU utilities must be installed separately."
      },
      {
        "question": "How often should I re-run the skill?",
        "answer": "Re-run before major computational tasks or when switching contexts. Memory availability changes constantly."
      },
      {
        "question": "Can I customize the output file location?",
        "answer": "Yes, use the -o or --output flag to specify a custom path for the .claude_resources.json file."
      },
      {
        "question": "What if GPU detection fails?",
        "answer": "Check that GPU drivers are installed and in system PATH. The skill gracefully handles missing utilities."
      },
      {
        "question": "Are the recommendations customizable?",
        "answer": "The skill provides general recommendations based on hardware thresholds. Modify the script for custom logic."
      }
    ]
  },
  "file_structure": [
    {
      "name": "scripts",
      "type": "dir",
      "path": "scripts",
      "children": [
        {
          "name": "detect_resources.py",
          "type": "file",
          "path": "scripts/detect_resources.py"
        }
      ]
    },
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md"
    }
  ]
}
