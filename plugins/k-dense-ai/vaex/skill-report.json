{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-02T04:36:24.781Z",
    "slug": "k-dense-ai-vaex",
    "source_url": "https://github.com/K-Dense-AI/claude-scientific-skills/tree/main/scientific-skills/vaex",
    "source_ref": "main",
    "model": "codex",
    "analysis_version": "2.0.0",
    "source_type": "community"
  },
  "skill": {
    "name": "vaex",
    "description": "Use this skill for processing and analyzing large tabular datasets (billions of rows) that exceed available RAM. Vaex excels at out-of-core DataFrame operations, lazy evaluation, fast aggregations, efficient visualization of big data, and machine learning on large datasets. Apply when users need to work with large CSV/HDF5/Arrow/Parquet files, perform fast statistics on massive datasets, create visualizations of big data, or build ML pipelines that don't fit in memory.",
    "summary": "Use this skill for processing and analyzing large tabular datasets (billions of rows) that exceed av...",
    "icon": "ðŸ“Š",
    "version": "1.0.0",
    "author": "K-Dense Inc.",
    "license": "MIT license",
    "category": "data",
    "tags": [
      "dataframes",
      "big-data",
      "visualization",
      "machine-learning",
      "python"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": [
      "filesystem",
      "external_commands"
    ]
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "No code execution or network activity is present. The content is documentation for Vaex usage and examples only. No data theft or malicious patterns detected.",
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 7,
    "total_lines": 3716,
    "audit_model": "codex",
    "audited_at": "2026-01-02T04:36:24.780Z"
  },
  "content": {
    "user_title": "Analyze massive datasets with Vaex",
    "value_statement": "Large tabular files overwhelm memory and slow analysis. This skill guides Vaex workflows for fast, out-of-core processing, visualization, and ML features.",
    "seo_keywords": [
      "Vaex",
      "out-of-core dataframe",
      "big data analytics",
      "lazy evaluation",
      "CSV to HDF5",
      "data visualization",
      "machine learning pipelines",
      "Claude",
      "Codex",
      "Claude Code"
    ],
    "actual_capabilities": [
      "Load HDF5, Arrow, Parquet, and CSV files into Vaex DataFrames",
      "Create virtual columns, filters, selections, and aggregations",
      "Batch aggregations with delay and async execution patterns",
      "Build ML preprocessing and models with vaex.ml and external libraries",
      "Produce 1D and 2D plots and heatmaps with selections",
      "Export data to HDF5, Arrow, Parquet, CSV, and manage state files"
    ],
    "limitations": [
      "Does not execute code or access files without your environment setup",
      "Large CSV conversion can be slow and needs disk space",
      "Plotting relies on matplotlib or notebook environments",
      "Some ML integrations require extra libraries installed"
    ],
    "use_cases": [
      {
        "target_user": "Data analyst",
        "title": "Summarize giant CSVs",
        "description": "Convert large CSV files to HDF5, compute fast statistics, and generate summary plots."
      },
      {
        "target_user": "Research scientist",
        "title": "Explore billion-row data",
        "description": "Use lazy expressions, selections, and heatmaps to analyze massive scientific datasets."
      },
      {
        "target_user": "ML engineer",
        "title": "Scale preprocessing pipelines",
        "description": "Apply encoders, scalers, and models on large datasets without loading everything into RAM."
      }
    ],
    "prompt_templates": [
      {
        "title": "Load and inspect data",
        "scenario": "Beginner loads a large file",
        "prompt": "Open a large HDF5 or Arrow file with Vaex and show a quick overview, column names, and basic statistics."
      },
      {
        "title": "Fast filtering and stats",
        "scenario": "Intermediate explores segments",
        "prompt": "Create selections for two groups, compute mean and count for each, and explain how to batch with delay."
      },
      {
        "title": "Visualize large data",
        "scenario": "Intermediate creates heatmaps",
        "prompt": "Plot a 2D density heatmap with percentile limits and suggest a good resolution for speed and clarity."
      },
      {
        "title": "Build ML pipeline",
        "scenario": "Advanced modeling on big data",
        "prompt": "Outline a Vaex ML pipeline with encoding, scaling, and a scikit-learn model, plus how to save and reload state."
      }
    ],
    "output_examples": [
      {
        "input": "Show me the best way to convert a huge CSV to a fast format and run basic stats.",
        "output": [
          "Open the CSV with chunking and convert it to HDF5 for instant future loads",
          "Compute mean, standard deviation, and counts using delay for a single pass",
          "Explain when to keep columns virtual versus materialize for export"
        ]
      }
    ],
    "best_practices": [
      "Prefer HDF5 or Arrow for instant loading and memory mapping",
      "Use virtual columns and delay batching to minimize passes",
      "Save state files to reproduce transformations in production"
    ],
    "anti_patterns": [
      "Converting large datasets to pandas before analysis",
      "Materializing many large columns without need",
      "Using very high plot resolutions for quick exploration"
    ],
    "faq": [
      {
        "question": "Is this compatible with Vaex on my platform?",
        "answer": "It targets standard Vaex usage on Linux, macOS, and Windows where Vaex is installed."
      },
      {
        "question": "What are the data size limits?",
        "answer": "Vaex works out-of-core, so limits depend on disk speed and available storage rather than RAM."
      },
      {
        "question": "Can it integrate with scikit-learn or XGBoost?",
        "answer": "Yes, it documents integration patterns for scikit-learn, XGBoost, LightGBM, CatBoost, and Keras."
      },
      {
        "question": "Does it access my data or credentials?",
        "answer": "No, the skill content is documentation only and performs no access or exfiltration."
      },
      {
        "question": "What if a plot is slow or empty?",
        "answer": "Reduce plot shape for speed or use percentile limits like 99 percent to match data range."
      },
      {
        "question": "How does it compare to pandas?",
        "answer": "Vaex is designed for out-of-core and lazy evaluation, while pandas loads data into memory."
      }
    ]
  },
  "file_structure": [
    {
      "name": "references",
      "type": "dir",
      "path": "references",
      "children": [
        {
          "name": "core_dataframes.md",
          "type": "file",
          "path": "references/core_dataframes.md"
        },
        {
          "name": "data_processing.md",
          "type": "file",
          "path": "references/data_processing.md"
        },
        {
          "name": "io_operations.md",
          "type": "file",
          "path": "references/io_operations.md"
        },
        {
          "name": "machine_learning.md",
          "type": "file",
          "path": "references/machine_learning.md"
        },
        {
          "name": "performance.md",
          "type": "file",
          "path": "references/performance.md"
        },
        {
          "name": "visualization.md",
          "type": "file",
          "path": "references/visualization.md"
        }
      ]
    },
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md"
    }
  ]
}
