{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-04T16:34:52.292Z",
    "slug": "k-dense-ai-gtars",
    "source_url": "https://github.com/K-Dense-AI/claude-scientific-skills/tree/main/scientific-skills/gtars",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "2.0.0",
    "source_type": "community",
    "content_hash": "137e0f894f4eaa3b8e2cbe6b0e069220f4a2d2cc3ba0a1fefbcfd25e6536ec6c",
    "tree_hash": "9ffcba0fa7f31dec920efb3e7313fc9725672d7977f8600ac421b3f35b86fe92"
  },
  "skill": {
    "name": "gtars",
    "description": "High-performance toolkit for genomic interval analysis in Rust with Python bindings. Use when working with genomic regions, BED files, coverage tracks, overlap detection, tokenization for ML models, or fragment analysis in computational genomics and machine learning applications.",
    "summary": "High-performance toolkit for genomic interval analysis in Rust with Python bindings. Use when workin...",
    "icon": "ðŸ§¬",
    "version": "0.1.0",
    "author": "K-Dense Inc.",
    "license": "MIT",
    "category": "data",
    "tags": [
      "genomics",
      "intervals",
      "coverage",
      "tokenization",
      "rust"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": []
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "Documentation-only skill containing markdown guides and reference materials for a genomic analysis toolkit. No executable code, scripts, or malicious patterns detected. All described file operations align with legitimate genomic data processing workflows.",
    "risk_factor_evidence": [],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 10,
    "total_lines": 1331,
    "audit_model": "claude",
    "audited_at": "2026-01-04T16:34:52.292Z"
  },
  "content": {
    "user_title": "Analyze genomic intervals with gtars",
    "value_statement": "You need fast overlap detection, coverage analysis, and tokenization for genomic data. This skill provides step-by-step guidance for gtars Python and CLI operations with clear examples.",
    "seo_keywords": [
      "gtars",
      "genomic intervals",
      "BED analysis",
      "coverage tracks",
      "overlap detection",
      "tokenization",
      "Claude",
      "Codex",
      "Claude Code",
      "Rust genomics"
    ],
    "actual_capabilities": [
      "Build and query IGD indexes for fast overlap detection between genomic regions",
      "Generate WIG or BigWig coverage tracks from sequencing fragments",
      "Tokenize genomic regions into discrete tokens for machine learning models",
      "Compute refget digests and extract reference genome subsequences",
      "Split fragment files by cell barcodes or clusters for single-cell analysis"
    ],
    "limitations": [
      "Requires gtars package installed in your Python or Rust environment",
      "Works only with standard genomic formats: BED, WIG, BigWig, FASTA, and TSV",
      "Does not provide visualization or genome browser rendering capabilities",
      "No built-in cloud upload or remote data storage features"
    ],
    "use_cases": [
      {
        "target_user": "Bioinformatician",
        "title": "Overlap Analysis",
        "description": "Compare peak sets and identify overlapping regulatory regions using IGD indexing."
      },
      {
        "target_user": "Genomics Engineer",
        "title": "Coverage Pipeline",
        "description": "Generate BigWig coverage tracks for ATAC-seq or ChIP-seq visualization."
      },
      {
        "target_user": "ML Researcher",
        "title": "Genomic Tokenization",
        "description": "Create tokenized inputs for transformer models from BED region files."
      }
    ],
    "prompt_templates": [
      {
        "title": "Quick Overlap",
        "scenario": "Find overlaps between two BED files",
        "prompt": "Show Python code to load regions_a.bed and regions_b.bed with gtars, find overlapping peaks, and save results to overlaps.bed."
      },
      {
        "title": "Coverage Track",
        "scenario": "Generate BigWig coverage file",
        "prompt": "Give the gtars CLI commands to create a BigWig coverage track from fragments.bed at resolution 10."
      },
      {
        "title": "Tokenizer Setup",
        "scenario": "Create tokens for ML training",
        "prompt": "Explain how to build a TreeTokenizer from training_peaks.bed and tokenize the region chr1:1000-2000."
      },
      {
        "title": "Reference Validation",
        "scenario": "Verify genome file integrity",
        "prompt": "Show Python code to load hg38.fa, compute refget digests, and verify chr1 against an expected digest value."
      }
    ],
    "output_examples": [
      {
        "input": "Find overlaps between chip_peaks.bed and promoters.bed and save to peaks_in_promoters.bed",
        "output": [
          "Load chip_peaks.bed and promoters.bed into gtars RegionSet objects",
          "Run filter_overlapping to keep only peaks that fall within promoter regions",
          "Write the filtered peaks to peaks_in_promoters.bed using to_bed()"
        ]
      }
    ],
    "best_practices": [
      "Use parallel processing and memory-mapped options for large BED files to improve performance",
      "Prefer BigWig output format for large coverage tracks to reduce file size",
      "Build IGD indexes before running multiple overlap queries on the same reference"
    ],
    "anti_patterns": [
      "Tokenizing regions without a consistent training region set for vocabulary",
      "Generating WIG format for very large datasets instead of compressed BigWig",
      "Running overlap queries on large files without building an IGD index first"
    ],
    "faq": [
      {
        "question": "Is this skill compatible with Claude, Codex, and Claude Code?",
        "answer": "Yes, all prompts and examples are plain text and work across those AI platforms."
      },
      {
        "question": "What data sizes can gtars handle efficiently?",
        "answer": "Gtars is designed for large genomic datasets with streaming, parallel, and memory-mapped options."
      },
      {
        "question": "Can I integrate this with my existing Python pipeline?",
        "answer": "Yes, the Python API provides RegionSet operations, NumPy integration, and standard export methods."
      },
      {
        "question": "Does the skill access or send my data externally?",
        "answer": "No external network behavior is documented. All processing is local to your files."
      },
      {
        "question": "What should I do if commands fail or files are not found?",
        "answer": "Enable verbose mode with gtars --verbose and verify input file formats and paths are correct."
      },
      {
        "question": "How does gtars compare to basic BED file tools?",
        "answer": "Gtars adds Rust-level performance, IGD indexing for fast queries, and ML tokenization features."
      }
    ]
  },
  "file_structure": [
    {
      "name": "references",
      "type": "dir",
      "path": "references",
      "children": [
        {
          "name": "cli.md",
          "type": "file",
          "path": "references/cli.md"
        },
        {
          "name": "coverage.md",
          "type": "file",
          "path": "references/coverage.md"
        },
        {
          "name": "overlap.md",
          "type": "file",
          "path": "references/overlap.md"
        },
        {
          "name": "python-api.md",
          "type": "file",
          "path": "references/python-api.md"
        },
        {
          "name": "refget.md",
          "type": "file",
          "path": "references/refget.md"
        },
        {
          "name": "tokenizers.md",
          "type": "file",
          "path": "references/tokenizers.md"
        }
      ]
    },
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md"
    }
  ]
}
