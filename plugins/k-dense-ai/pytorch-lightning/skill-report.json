{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-02T03:45:02.878Z",
    "slug": "k-dense-ai-pytorch-lightning",
    "source_url": "https://github.com/K-Dense-AI/claude-scientific-skills/tree/main/scientific-skills/pytorch-lightning",
    "source_ref": "main",
    "model": "codex",
    "analysis_version": "2.0.0",
    "source_type": "community"
  },
  "skill": {
    "name": "pytorch-lightning",
    "description": "Deep learning framework (PyTorch Lightning). Organize PyTorch code into LightningModules, configure Trainers for multi-GPU/TPU, implement data pipelines, callbacks, logging (W&B, TensorBoard), distributed training (DDP, FSDP, DeepSpeed), for scalable neural network training.",
    "summary": "Deep learning framework (PyTorch Lightning). Organize PyTorch code into LightningModules, configure ...",
    "icon": "âš¡",
    "version": "1.0.0",
    "author": "K-Dense Inc.",
    "license": "Apache-2.0 license",
    "category": "research",
    "tags": [
      "pytorch",
      "lightning",
      "training",
      "distributed",
      "deep-learning"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": [
      "scripts",
      "network"
    ]
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "No data theft, exfiltration, or malicious execution patterns detected in the skill files. Content is instructional templates and references for PyTorch Lightning usage.",
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 11,
    "total_lines": 5450,
    "audit_model": "codex",
    "audited_at": "2026-01-02T03:45:02.877Z"
  },
  "content": {
    "user_title": "Build PyTorch Lightning training workflows",
    "value_statement": "Complex training setups slow research and create boilerplate. This skill provides clear templates and guidance to build scalable Lightning projects quickly.",
    "seo_keywords": [
      "PyTorch Lightning",
      "LightningModule",
      "Trainer setup",
      "distributed training",
      "FSDP",
      "DeepSpeed",
      "Claude",
      "Codex",
      "Claude Code"
    ],
    "actual_capabilities": [
      "Provides LightningModule boilerplate with training, validation, and optimizer hooks",
      "Provides LightningDataModule boilerplate for data preparation and loaders",
      "Offers Trainer configurations for single GPU, multi GPU, FSDP, and DeepSpeed",
      "Documents callbacks and logging integrations with common platforms",
      "Explains distributed training strategies and configuration options"
    ],
    "limitations": [
      "Does not run training or supply datasets",
      "Does not install dependencies or configure environments",
      "Does not generate custom model architectures",
      "Does not validate hardware availability"
    ],
    "use_cases": [
      {
        "target_user": "Research engineer",
        "title": "Prototype a new model",
        "description": "Start with a LightningModule template and a basic Trainer to test ideas quickly."
      },
      {
        "target_user": "ML engineer",
        "title": "Scale to multi GPU",
        "description": "Select DDP or FSDP configurations and apply best practices for distributed runs."
      },
      {
        "target_user": "Experiment owner",
        "title": "Add logging and callbacks",
        "description": "Integrate TensorBoard or W and B and add checkpoints and early stopping."
      }
    ],
    "prompt_templates": [
      {
        "title": "Start a module",
        "scenario": "Create a minimal LightningModule",
        "prompt": "Create a LightningModule template with training_step, validation_step, and configure_optimizers for a classification model."
      },
      {
        "title": "Add data module",
        "scenario": "Organize data loading",
        "prompt": "Draft a LightningDataModule with prepare_data, setup, train_dataloader, and val_dataloader for an image dataset."
      },
      {
        "title": "Configure Trainer",
        "scenario": "Set up multi GPU training",
        "prompt": "Suggest a Trainer configuration for 4 GPUs using DDP with checkpointing and learning rate monitoring."
      },
      {
        "title": "Scale large model",
        "scenario": "Train a large transformer",
        "prompt": "Provide an FSDP Trainer setup with activation checkpointing and mixed precision for a large transformer model."
      }
    ],
    "output_examples": [
      {
        "input": "Set up a production single GPU Trainer with checkpoints and TensorBoard logging",
        "output": [
          "Trainer uses GPU acceleration with mixed precision",
          "Checkpointing saves best and last models to a chosen directory",
          "TensorBoard logger writes runs under a named experiment",
          "Includes early stopping and learning rate monitoring callbacks"
        ]
      }
    ],
    "best_practices": [
      "Use save_hyperparameters and self.log for consistent tracking",
      "Start with single GPU and fast_dev_run before scaling",
      "Choose DDP for smaller models and FSDP for large models"
    ],
    "anti_patterns": [
      "Manually invoking callback methods outside the Trainer",
      "Hard coding cuda calls instead of using device agnostic code",
      "Scaling to multi GPU without syncing metrics"
    ],
    "faq": [
      {
        "question": "Is this skill compatible with current PyTorch Lightning versions",
        "answer": "It targets modern Lightning APIs, but you should verify version specific arguments in your environment."
      },
      {
        "question": "What are the limits of this skill",
        "answer": "It provides templates and guidance only, and does not run training or install dependencies."
      },
      {
        "question": "How do I integrate it with my project",
        "answer": "Copy the templates into your codebase and adapt the Trainer and module settings to your dataset."
      },
      {
        "question": "Does it access or send my data",
        "answer": "No. The files are static templates and documentation with no data access or network logic."
      },
      {
        "question": "What should I do if training fails",
        "answer": "Start with debug Trainer settings, reduce batch size, and verify hardware and precision settings."
      },
      {
        "question": "How does it compare to a full tutorial",
        "answer": "It is shorter and template focused, designed for fast setup rather than full conceptual coverage."
      }
    ]
  },
  "file_structure": [
    {
      "name": "references",
      "type": "dir",
      "path": "references",
      "children": [
        {
          "name": "best_practices.md",
          "type": "file",
          "path": "references/best_practices.md"
        },
        {
          "name": "callbacks.md",
          "type": "file",
          "path": "references/callbacks.md"
        },
        {
          "name": "data_module.md",
          "type": "file",
          "path": "references/data_module.md"
        },
        {
          "name": "distributed_training.md",
          "type": "file",
          "path": "references/distributed_training.md"
        },
        {
          "name": "lightning_module.md",
          "type": "file",
          "path": "references/lightning_module.md"
        },
        {
          "name": "logging.md",
          "type": "file",
          "path": "references/logging.md"
        },
        {
          "name": "trainer.md",
          "type": "file",
          "path": "references/trainer.md"
        }
      ]
    },
    {
      "name": "scripts",
      "type": "dir",
      "path": "scripts",
      "children": [
        {
          "name": "quick_trainer_setup.py",
          "type": "file",
          "path": "scripts/quick_trainer_setup.py"
        },
        {
          "name": "template_datamodule.py",
          "type": "file",
          "path": "scripts/template_datamodule.py"
        },
        {
          "name": "template_lightning_module.py",
          "type": "file",
          "path": "scripts/template_lightning_module.py"
        }
      ]
    },
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md"
    }
  ]
}
