{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-04T16:31:49.228Z",
    "slug": "k-dense-ai-pymc-bayesian-modeling",
    "source_url": "https://github.com/K-Dense-AI/claude-scientific-skills/tree/main/scientific-skills/pymc",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "2.0.0",
    "source_type": "community",
    "content_hash": "d7ece1381e2b94c0800d5096ae6139505f9c79b22c26ced4644799a6f6524408",
    "tree_hash": "13ba339ce3942249a1a0b35b05cc8fb8fff2555fc00e320a9f7e3e61f43a79c6"
  },
  "skill": {
    "name": "pymc-bayesian-modeling",
    "description": "Bayesian modeling with PyMC. Build hierarchical models, MCMC (NUTS), variational inference, LOO/WAIC comparison, posterior checks, for probabilistic programming and inference.",
    "summary": "Bayesian modeling with PyMC. Build hierarchical models, MCMC (NUTS), variational inference, LOO/WAIC...",
    "icon": "ðŸ“Š",
    "version": "1.0.0",
    "author": "K-Dense Inc.",
    "license": "Apache License, Version 2.0",
    "category": "research",
    "tags": [
      "bayesian",
      "pymc",
      "inference",
      "probabilistic-programming",
      "model-diagnostics"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": [
      "scripts"
    ]
  },
  "security_audit": {
    "risk_level": "low",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "Legitimate scientific computing skill with Python scripts for model comparison and diagnostics. All code uses standard libraries (PyMC, ArviZ, NumPy, Matplotlib) appropriate for Bayesian analysis. No network access, credential harvesting, or suspicious capabilities detected.",
    "risk_factor_evidence": [
      {
        "factor": "scripts",
        "evidence": [
          {
            "file": "scripts/model_comparison.py",
            "line_start": 1,
            "line_end": 388
          },
          {
            "file": "scripts/model_diagnostics.py",
            "line_start": 1,
            "line_end": 351
          },
          {
            "file": "assets/linear_regression_template.py",
            "line_start": 1,
            "line_end": 242
          },
          {
            "file": "assets/hierarchical_model_template.py",
            "line_start": 1,
            "line_end": 334
          }
        ]
      }
    ],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 11,
    "total_lines": 3150,
    "audit_model": "claude",
    "audited_at": "2026-01-04T16:31:49.228Z"
  },
  "content": {
    "user_title": "Build Bayesian models with PyMC",
    "value_statement": "You need a reliable Bayesian workflow for modeling and inference. This skill provides templates, diagnostics, and model comparison utilities for PyMC users. Build hierarchical models, run NUTS sampling, validate convergence, and compare models using LOO or WAIC.",
    "seo_keywords": [
      "PyMC",
      "Bayesian modeling",
      "probabilistic programming",
      "MCMC sampling",
      "NUTS",
      "LOO",
      "WAIC",
      "hierarchical models",
      "ArviZ",
      "Claude Code"
    ],
    "actual_capabilities": [
      "Build Bayesian linear and hierarchical models using PyMC",
      "Run diagnostic checks for R-hat, ESS, divergences, and tree depth",
      "Generate diagnostic reports with trace plots, rank plots, and autocorrelation plots",
      "Compare multiple models using LOO or WAIC with interpretation guidance",
      "Check LOO reliability using Pareto-k diagnostics",
      "Perform posterior predictive checks and generate predictions with uncertainty"
    ],
    "limitations": [
      "Does not install or manage PyMC or ArviZ dependencies",
      "Requires user-provided data and domain-specific prior specification",
      "No automated data cleaning or feature engineering capabilities",
      "Model comparison requires log likelihood computed during sampling"
    ],
    "use_cases": [
      {
        "target_user": "Researcher",
        "title": "Validate hierarchical study data",
        "description": "Build a multilevel model and run diagnostics before reporting effects with uncertainty."
      },
      {
        "target_user": "Data scientist",
        "title": "Compare regression models",
        "description": "Fit multiple models and rank them using LOO with reliability checks."
      },
      {
        "target_user": "Analyst",
        "title": "Generate predictions with uncertainty",
        "description": "Use a linear model template to produce posterior predictive intervals for new data."
      }
    ],
    "prompt_templates": [
      {
        "title": "Create linear regression",
        "scenario": "Beginner building first PyMC model",
        "prompt": "Create a simple Bayesian linear regression in PyMC and explain how to run prior predictive checks."
      },
      {
        "title": "Run diagnostics",
        "scenario": "Intermediate user with sampled model",
        "prompt": "Use the diagnostics script to check R-hat, ESS, and divergences for my sampled model."
      },
      {
        "title": "Compare models",
        "scenario": "User with multiple fitted models",
        "prompt": "Compare two PyMC models using LOO and explain which model is preferred."
      },
      {
        "title": "Hierarchical workflow",
        "scenario": "Advanced user with grouped data",
        "prompt": "Adapt the hierarchical template for grouped outcomes and show how to validate convergence."
      }
    ],
    "output_examples": [
      {
        "input": "Compare two Bayesian regression models and tell me which is better.",
        "output": [
          "Model A ranks first with lower LOO and higher model weight",
          "Delta LOO is 4.2, indicating moderate evidence for Model A",
          "Pareto-k values are all below 0.7, so the comparison is reliable",
          "Consider Model A unless Model B has stronger domain justification"
        ]
      }
    ],
    "best_practices": [
      "Run prior and posterior predictive checks before interpreting model results",
      "Use multiple chains and verify R-hat below 1.01 and ESS above 400",
      "Include log_likelihood during sampling for reliable model comparison"
    ],
    "anti_patterns": [
      "Skipping diagnostics and trusting a single chain without convergence checks",
      "Using flat priors without validating prior predictive behavior",
      "Comparing models without computing log likelihood or checking Pareto-k diagnostics"
    ],
    "faq": [
      {
        "question": "What PyMC versions are supported?",
        "answer": "This skill targets PyMC 5.x with ArviZ for visualization. Syntax may differ for older versions."
      },
      {
        "question": "What are the main limits of this skill?",
        "answer": "It does not clean data, select priors automatically, or optimize runtime settings."
      },
      {
        "question": "Can I integrate this with my existing pipeline?",
        "answer": "Yes. Import the scripts and templates as modules in your Python workflow."
      },
      {
        "question": "Does this skill access or send my data?",
        "answer": "No. All computations run locally with your data saved only to disk."
      },
      {
        "question": "What should I do if diagnostics fail?",
        "answer": "Increase target_accept, use non-centered parameterization, add stronger priors, or run longer chains."
      },
      {
        "question": "How does this compare to other Bayesian tools?",
        "answer": "It provides focused PyMC utilities with built-in diagnostics and LOO or WAIC comparison functions."
      }
    ]
  },
  "file_structure": [
    {
      "name": "assets",
      "type": "dir",
      "path": "assets",
      "children": [
        {
          "name": "hierarchical_model_template.py",
          "type": "file",
          "path": "assets/hierarchical_model_template.py"
        },
        {
          "name": "linear_regression_template.py",
          "type": "file",
          "path": "assets/linear_regression_template.py"
        }
      ]
    },
    {
      "name": "references",
      "type": "dir",
      "path": "references",
      "children": [
        {
          "name": "distributions.md",
          "type": "file",
          "path": "references/distributions.md"
        },
        {
          "name": "sampling_inference.md",
          "type": "file",
          "path": "references/sampling_inference.md"
        },
        {
          "name": "workflows.md",
          "type": "file",
          "path": "references/workflows.md"
        }
      ]
    },
    {
      "name": "scripts",
      "type": "dir",
      "path": "scripts",
      "children": [
        {
          "name": "model_comparison.py",
          "type": "file",
          "path": "scripts/model_comparison.py"
        },
        {
          "name": "model_diagnostics.py",
          "type": "file",
          "path": "scripts/model_diagnostics.py"
        }
      ]
    },
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md"
    }
  ]
}
