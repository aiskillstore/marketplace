{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-02T03:38:52.616Z",
    "slug": "k-dense-ai-pymc-bayesian-modeling",
    "source_url": "https://github.com/K-Dense-AI/claude-scientific-skills/tree/main/scientific-skills/pymc",
    "source_ref": "main",
    "model": "codex",
    "analysis_version": "2.0.0",
    "source_type": "community"
  },
  "skill": {
    "name": "pymc-bayesian-modeling",
    "description": "Bayesian modeling with PyMC. Build hierarchical models, MCMC (NUTS), variational inference, LOO/WAIC comparison, posterior checks, for probabilistic programming and inference.",
    "summary": "Bayesian modeling with PyMC. Build hierarchical models, MCMC (NUTS), variational inference, LOO/WAIC...",
    "icon": "ðŸ“ˆ",
    "version": "1.0.0",
    "author": "K-Dense Inc.",
    "license": "Apache License, Version 2.0",
    "category": "research",
    "tags": [
      "bayesian",
      "pymc",
      "inference",
      "probabilistic-programming",
      "model-diagnostics"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": [
      "scripts"
    ]
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "No credential access, environment harvesting, or exfiltration logic detected. The code contains only local modeling utilities, plots, and file saves that match the stated purpose.",
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 8,
    "total_lines": 3150,
    "audit_model": "codex",
    "audited_at": "2026-01-02T03:38:52.615Z"
  },
  "content": {
    "user_title": "Build Bayesian models with PyMC",
    "value_statement": "You need a reliable Bayesian workflow for modeling and validation. This skill provides templates, diagnostics, and model comparison utilities in PyMC.",
    "seo_keywords": [
      "PyMC",
      "Bayesian modeling",
      "probabilistic programming",
      "MCMC diagnostics",
      "LOO",
      "WAIC",
      "Claude",
      "Codex",
      "Claude Code",
      "ArviZ"
    ],
    "actual_capabilities": [
      "Run diagnostic checks for R-hat, ESS, divergences, and tree depth",
      "Generate diagnostic reports with trace, rank, autocorr, energy, and ESS plots",
      "Compare multiple models using LOO or WAIC with interpretation guidance",
      "Check LOO reliability using Pareto-k diagnostics",
      "Perform Bayesian model averaging across fitted models",
      "Use linear and hierarchical model templates with predictive checks"
    ],
    "limitations": [
      "Does not install or manage PyMC or ArviZ dependencies",
      "Templates require user-provided data and domain-specific priors",
      "No automated data cleaning or feature engineering",
      "Model comparison relies on provided log likelihoods"
    ],
    "use_cases": [
      {
        "target_user": "Researcher",
        "title": "Validate hierarchical study data",
        "description": "Build a multilevel model and run diagnostics before reporting effects with uncertainty."
      },
      {
        "target_user": "Data scientist",
        "title": "Compare competing regression models",
        "description": "Fit multiple models and rank them using LOO or WAIC with reliability checks."
      },
      {
        "target_user": "Analyst",
        "title": "Generate predictions with uncertainty",
        "description": "Use a linear model template to produce posterior predictive intervals for new data."
      }
    ],
    "prompt_templates": [
      {
        "title": "Start a linear model",
        "scenario": "Beginner building first PyMC regression",
        "prompt": "Create a simple Bayesian linear regression in PyMC and explain how to run prior predictive checks."
      },
      {
        "title": "Run diagnostics",
        "scenario": "Intermediate user with sampled idata",
        "prompt": "Use the diagnostics script to check R-hat, ESS, and divergences, and summarize the issues found."
      },
      {
        "title": "Compare models",
        "scenario": "User has multiple fitted models",
        "prompt": "Compare three PyMC models with LOO and explain which model is preferred and why."
      },
      {
        "title": "Hierarchical workflow",
        "scenario": "Advanced user with grouped data",
        "prompt": "Adapt the hierarchical template for grouped outcomes and describe how to validate fit and predict for new groups."
      }
    ],
    "output_examples": [
      {
        "input": "Compare two Bayesian models and explain which is better.",
        "output": [
          "Model A ranks best with lower LOO and higher weight",
          "Delta LOO is small, so both models are close in fit",
          "Pareto-k warnings are low, so the comparison is reliable",
          "Choose Model A for simplicity unless Model B has stronger domain justification"
        ]
      }
    ],
    "best_practices": [
      "Run prior and posterior predictive checks before interpreting results",
      "Use multiple chains and report R-hat and ESS for key parameters",
      "Include log likelihood in sampling for reliable model comparison"
    ],
    "anti_patterns": [
      "Skipping diagnostics and trusting a single chain",
      "Using flat priors without checking prior predictive behavior",
      "Comparing models without log likelihood or reliability checks"
    ],
    "faq": [
      {
        "question": "What PyMC versions are supported?",
        "answer": "The guidance targets PyMC 5.x and ArviZ. Older versions may need syntax changes."
      },
      {
        "question": "What are the main limits of this skill?",
        "answer": "It does not clean data, choose priors for you, or optimize runtime settings automatically."
      },
      {
        "question": "Can I integrate this with my existing pipeline?",
        "answer": "Yes. Use the scripts and templates as modules inside your Python workflow."
      },
      {
        "question": "Does it access or send my data?",
        "answer": "No. The code reads your inputs locally and saves plots and CSV files only to disk."
      },
      {
        "question": "What should I do if diagnostics fail?",
        "answer": "Increase target_accept, reparameterize, add stronger priors, or run longer chains."
      },
      {
        "question": "How does it compare to other Bayesian tools?",
        "answer": "It focuses on PyMC with built-in diagnostics and LOO or WAIC comparison utilities."
      }
    ]
  },
  "file_structure": [
    {
      "name": "assets",
      "type": "dir",
      "path": "assets",
      "children": [
        {
          "name": "hierarchical_model_template.py",
          "type": "file",
          "path": "assets/hierarchical_model_template.py"
        },
        {
          "name": "linear_regression_template.py",
          "type": "file",
          "path": "assets/linear_regression_template.py"
        }
      ]
    },
    {
      "name": "references",
      "type": "dir",
      "path": "references",
      "children": [
        {
          "name": "distributions.md",
          "type": "file",
          "path": "references/distributions.md"
        },
        {
          "name": "sampling_inference.md",
          "type": "file",
          "path": "references/sampling_inference.md"
        },
        {
          "name": "workflows.md",
          "type": "file",
          "path": "references/workflows.md"
        }
      ]
    },
    {
      "name": "scripts",
      "type": "dir",
      "path": "scripts",
      "children": [
        {
          "name": "model_comparison.py",
          "type": "file",
          "path": "scripts/model_comparison.py"
        },
        {
          "name": "model_diagnostics.py",
          "type": "file",
          "path": "scripts/model_diagnostics.py"
        }
      ]
    },
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md"
    }
  ]
}
