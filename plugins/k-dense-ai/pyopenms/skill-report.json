{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-02T03:41:32.192Z",
    "slug": "k-dense-ai-pyopenms",
    "source_url": "https://github.com/K-Dense-AI/claude-scientific-skills/tree/main/scientific-skills/pyopenms",
    "source_ref": "main",
    "model": "codex",
    "analysis_version": "2.0.0",
    "source_type": "community"
  },
  "skill": {
    "name": "pyopenms",
    "description": "Python interface to OpenMS for mass spectrometry data analysis. Use for LC-MS/MS proteomics and metabolomics workflows including file handling (mzML, mzXML, mzTab, FASTA, pepXML, protXML, mzIdentML), signal processing, feature detection, peptide identification, and quantitative analysis. Apply when working with mass spectrometry data, analyzing proteomics experiments, or processing metabolomics datasets.",
    "summary": "Python interface to OpenMS for mass spectrometry data analysis. Use for LC-MS/MS proteomics and meta...",
    "icon": "ðŸ”¬",
    "version": "unknown",
    "author": "K-Dense Inc.",
    "license": "3 clause BSD license",
    "category": "research",
    "tags": [
      "mass-spectrometry",
      "proteomics",
      "metabolomics",
      "pyopenms",
      "bioinformatics"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": [
      "network"
    ]
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "No credential access, environment harvesting, or exfiltration patterns were found. The files contain documentation and example code for local data analysis only.",
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 7,
    "total_lines": 2807,
    "audit_model": "codex",
    "audited_at": "2026-01-02T03:41:32.190Z"
  },
  "content": {
    "user_title": "Analyze LC-MS data with PyOpenMS",
    "value_statement": "Mass spectrometry workflows are complex and hard to standardize across datasets. This skill provides clear PyOpenMS steps for file I/O, processing, and identification.",
    "seo_keywords": [
      "PyOpenMS",
      "OpenMS",
      "mass spectrometry",
      "proteomics",
      "metabolomics",
      "LC-MS",
      "feature detection",
      "Claude",
      "Codex",
      "Claude Code"
    ],
    "actual_capabilities": [
      "Load and write mzML, mzXML, FASTA, and idXML formats",
      "Apply smoothing, peak picking, and normalization to spectra",
      "Detect and link features across samples with consensus maps",
      "Filter peptide identifications with FDR and perform protein inference",
      "Run untargeted metabolomics pipelines with adduct grouping",
      "Export results to pandas tables and mzTab reports"
    ],
    "limitations": [
      "Requires a working PyOpenMS installation in the Python environment",
      "Search engines like Comet or Mascot must be installed separately",
      "Gap filling is not available directly in the Python API",
      "Spectral library matching needs external tools or custom code"
    ],
    "use_cases": [
      {
        "target_user": "Proteomics analyst",
        "title": "QC and feature counts",
        "description": "Load mzML files, detect features, and summarize counts for quality control."
      },
      {
        "target_user": "Metabolomics researcher",
        "title": "Untargeted pipeline setup",
        "description": "Run feature detection, adduct grouping, and export a metabolite table for statistics."
      },
      {
        "target_user": "Bioinformatics engineer",
        "title": "Identification postprocessing",
        "description": "Apply FDR filtering and protein inference to idXML results."
      }
    ],
    "prompt_templates": [
      {
        "title": "Load and inspect mzML",
        "scenario": "Beginner needs quick stats",
        "prompt": "Load sample.mzML, print spectrum count, chromatogram count, and first spectrum MS level with PyOpenMS."
      },
      {
        "title": "Smooth and pick peaks",
        "scenario": "Basic preprocessing",
        "prompt": "Apply Gaussian smoothing and high resolution peak picking to raw_data.mzML, then save processed_data.mzML."
      },
      {
        "title": "Detect and link features",
        "scenario": "Multi sample analysis",
        "prompt": "Detect features in three mzML files, align retention times, and create a consensusXML output."
      },
      {
        "title": "FDR filter identifications",
        "scenario": "Advanced identification workflow",
        "prompt": "Load idXML results, apply FDR at 1 percent, and save filtered identifications to a new idXML file."
      }
    ],
    "output_examples": [
      {
        "input": "Process two mzML files and create a consensus map with feature counts.",
        "output": [
          "Loaded 2 mzML files and detected features per sample",
          "Aligned retention times across samples",
          "Linked features into a consensus map",
          "Saved consensus.consensusXML with total feature count"
        ]
      }
    ],
    "best_practices": [
      "Use indexed or streaming access for large mzML files",
      "Tune mass trace tolerances on representative QC samples",
      "Keep original data and process on copies"
    ],
    "anti_patterns": [
      "Running feature detection without centroiding when needed",
      "Interpreting search engine scores without checking score type",
      "Using default tolerances across all instruments and gradients"
    ],
    "faq": [
      {
        "question": "Is this compatible with Claude, Codex, and Claude Code?",
        "answer": "Yes, the skill content is plain instructions that work across Claude, Codex, and Claude Code."
      },
      {
        "question": "What are the main limits?",
        "answer": "Large files may require indexed access and memory planning, and some workflows need external search engines."
      },
      {
        "question": "Can I integrate outputs with pandas or CSV tools?",
        "answer": "Yes, examples show export to pandas DataFrames and CSV for downstream analysis."
      },
      {
        "question": "Does the skill access my credentials or files?",
        "answer": "No, it only describes local analysis steps and does not include network or credential access."
      },
      {
        "question": "What should I do if installation fails?",
        "answer": "Verify Python version, install pyopenms with uv or pip, and check the OpenMS dependencies."
      },
      {
        "question": "How does it compare to raw OpenMS CLI tools?",
        "answer": "PyOpenMS offers Python scripting flexibility, while OpenMS CLI can provide more complete pipelines."
      }
    ]
  },
  "file_structure": [
    {
      "name": "references",
      "type": "dir",
      "path": "references",
      "children": [
        {
          "name": "data_structures.md",
          "type": "file",
          "path": "references/data_structures.md"
        },
        {
          "name": "feature_detection.md",
          "type": "file",
          "path": "references/feature_detection.md"
        },
        {
          "name": "file_io.md",
          "type": "file",
          "path": "references/file_io.md"
        },
        {
          "name": "identification.md",
          "type": "file",
          "path": "references/identification.md"
        },
        {
          "name": "metabolomics.md",
          "type": "file",
          "path": "references/metabolomics.md"
        },
        {
          "name": "signal_processing.md",
          "type": "file",
          "path": "references/signal_processing.md"
        }
      ]
    },
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md"
    }
  ]
}
