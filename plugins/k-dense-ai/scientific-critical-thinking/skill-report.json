{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-02T03:58:46.515Z",
    "slug": "k-dense-ai-scientific-critical-thinking",
    "source_url": "https://github.com/K-Dense-AI/claude-scientific-skills/tree/main/scientific-skills/scientific-critical-thinking",
    "source_ref": "main",
    "model": "codex",
    "analysis_version": "2.0.0",
    "source_type": "community",
    "content_hash": "a55a0d27c84704e578bf38652eea29eed77b3c8386279e766971d89ad8312bfc",
    "tree_hash": "fa67bc5b5b6676c526e6126a8101b74cebbe351bc9cbdf2f31ae4e20f7004ea7"
  },
  "skill": {
    "name": "scientific-critical-thinking",
    "description": "Evaluate research rigor. Assess methodology, experimental design, statistical validity, biases, confounding, evidence quality (GRADE, Cochrane ROB), for critical analysis of scientific claims.",
    "summary": "Evaluate research rigor. Assess methodology, experimental design, statistical validity, biases, conf...",
    "icon": "ðŸ”¬",
    "version": "1.0.0",
    "author": "K-Dense Inc.",
    "license": "MIT license",
    "category": "research",
    "tags": [
      "critical thinking",
      "research methods",
      "bias detection",
      "statistics",
      "evidence quality"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": [
      "filesystem"
    ]
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "No code execution or network behavior is present. The content is guidance text only and matches the stated research evaluation purpose.",
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 7,
    "total_lines": 3066,
    "audit_model": "codex",
    "audited_at": "2026-01-02T03:58:46.514Z"
  },
  "content": {
    "user_title": "Evaluate scientific claims with rigor",
    "value_statement": "You need a structured way to judge research quality and bias. This skill provides clear checklists for design, statistics, and evidence strength.",
    "seo_keywords": [
      "scientific critical thinking",
      "research methodology review",
      "evidence quality assessment",
      "bias detection",
      "GRADE evaluation",
      "Cochrane ROB",
      "Claude",
      "Codex",
      "Claude Code"
    ],
    "actual_capabilities": [
      "Assess study design and validity threats",
      "Identify cognitive, selection, and analysis biases",
      "Evaluate statistical methods and reporting quality",
      "Apply evidence hierarchy and GRADE concepts",
      "Detect logical fallacies in scientific claims",
      "Provide research design improvement guidance"
    ],
    "limitations": [
      "Does not access or fetch papers without user input",
      "Does not run statistical analyses on raw data",
      "Does not generate diagrams without the scientific-schematics skill",
      "Does not replace domain specific expert review"
    ],
    "use_cases": [
      {
        "target_user": "Researcher",
        "title": "Pre study design review",
        "description": "Check protocol rigor, bias control, and analysis planning before data collection."
      },
      {
        "target_user": "Journal editor",
        "title": "Manuscript quality screening",
        "description": "Assess methodology and evidence strength for accept, revise, or reject decisions."
      },
      {
        "target_user": "Policy analyst",
        "title": "Evidence brief validation",
        "description": "Evaluate claim strength and bias risk in reports used for policy decisions."
      }
    ],
    "prompt_templates": [
      {
        "title": "Quick claim check",
        "scenario": "You read a headline about a study",
        "prompt": "Evaluate this claim for strength and possible overreach. Include key red flags and needed evidence."
      },
      {
        "title": "Study methods critique",
        "scenario": "You have a methods section",
        "prompt": "Review this study design for internal, external, and construct validity issues. Provide prioritized concerns."
      },
      {
        "title": "Statistics review",
        "scenario": "You have results and analysis text",
        "prompt": "Assess statistical tests, power, multiple comparisons, and interpretation. Note any reporting gaps."
      },
      {
        "title": "Evidence synthesis",
        "scenario": "You have several studies on one question",
        "prompt": "Compare evidence strength using hierarchy and GRADE concepts. Summarize confidence in the conclusion."
      }
    ],
    "output_examples": [
      {
        "input": "Review a study that claims a supplement improves memory based on a small trial.",
        "output": [
          "Small sample suggests low power and inflated effect risk",
          "No blinding increases placebo and observer bias",
          "Causal claim needs stronger design and replication",
          "Recommend larger randomized trial with preregistration"
        ]
      }
    ],
    "best_practices": [
      "Provide study details and key excerpts for accurate critique",
      "State whether the claim is causal or associational",
      "Ask for preregistration or protocol information when available"
    ],
    "anti_patterns": [
      "Using this skill to confirm a preferred conclusion",
      "Ignoring limitations or counterevidence",
      "Treating statistical significance as practical importance"
    ],
    "faq": [
      {
        "question": "Is this compatible with Claude, Codex, and Claude Code?",
        "answer": "Yes. It is plain text guidance and works with any assistant that can follow structured prompts."
      },
      {
        "question": "What are the main limits of this skill?",
        "answer": "It does not fetch papers or run analyses. It relies on the information you provide."
      },
      {
        "question": "Can it integrate with my literature review workflow?",
        "answer": "Yes. Use it after you extract methods and results for structured critique."
      },
      {
        "question": "Does it access or store my data?",
        "answer": "No. It only evaluates the text you share in the session."
      },
      {
        "question": "What should I do if the output seems too harsh or too soft?",
        "answer": "Provide more context and ask for a severity ranked critique with explicit evidence links."
      },
      {
        "question": "How does it compare to a domain expert review?",
        "answer": "It offers a general framework, but it does not replace deep domain expertise or formal peer review."
      }
    ]
  },
  "file_structure": [
    {
      "name": "references",
      "type": "dir",
      "path": "references",
      "children": [
        {
          "name": "common_biases.md",
          "type": "file",
          "path": "references/common_biases.md"
        },
        {
          "name": "evidence_hierarchy.md",
          "type": "file",
          "path": "references/evidence_hierarchy.md"
        },
        {
          "name": "experimental_design.md",
          "type": "file",
          "path": "references/experimental_design.md"
        },
        {
          "name": "logical_fallacies.md",
          "type": "file",
          "path": "references/logical_fallacies.md"
        },
        {
          "name": "scientific_method.md",
          "type": "file",
          "path": "references/scientific_method.md"
        },
        {
          "name": "statistical_pitfalls.md",
          "type": "file",
          "path": "references/statistical_pitfalls.md"
        }
      ]
    },
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md"
    }
  ]
}
