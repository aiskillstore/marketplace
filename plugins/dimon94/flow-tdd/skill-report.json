{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-10T14:22:36.136Z",
    "slug": "dimon94-flow-tdd",
    "source_url": "https://github.com/Dimon94/cc-devflow/tree/main/.claude/skills/flow-tdd",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "2.0.0",
    "source_type": "community",
    "content_hash": "79086e20caa1630557b3b2522e0d1aa0c0a07712e5e95da68a116ac8cf2e7bd8",
    "tree_hash": "728c25b98af3eb6a4e40cff18406239bbdb6b1de7698b2b8a0b57cf85a7752d0"
  },
  "skill": {
    "name": "flow-tdd",
    "description": "Enforces TDD Iron Law in flow-dev. NO PRODUCTION CODE WITHOUT A FAILING TEST FIRST.",
    "summary": "Enforces TDD Iron Law in flow-dev. NO PRODUCTION CODE WITHOUT A FAILING TEST FIRST.",
    "icon": "ðŸ§ª",
    "version": "1.0.0",
    "author": "Dimon94",
    "license": "MIT",
    "category": "coding",
    "tags": [
      "tdd",
      "testing",
      "code-quality",
      "discipline",
      "development-process"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": []
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "Pure Markdown documentation skill containing TDD guidelines and error recording protocols. No executable code, scripts, network calls, or filesystem access. This is a policy document for AI agent behavior enforcement.",
    "risk_factor_evidence": [],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 1,
    "total_lines": 219,
    "audit_model": "claude",
    "audited_at": "2026-01-10T14:22:36.136Z"
  },
  "content": {
    "user_title": "Enforce Test-Driven Development Discipline",
    "value_statement": "AI coding workflows often skip tests or write them after code, leading to untested functionality and hidden bugs. This skill enforces the TDD Iron Law: no production code until a failing test exists. It provides enforcement checkpoints, error recording protocols, and rationalization prevention to ensure every feature has proper test coverage.",
    "seo_keywords": [
      "test-driven development",
      "TDD",
      "Claude Code",
      "testing discipline",
      "code quality",
      "AI coding",
      "test-first",
      "unit testing",
      "CI/CD",
      "software engineering"
    ],
    "actual_capabilities": [
      "Enforces TDD Iron Law: no production code without failing test first",
      "Validates test execution with checkpoint verification",
      "Provides error recording protocol for test failures",
      "Prevents rationalization and shortcuts during development",
      "Documents test quality requirements for good tests",
      "Integrates with flow-dev phases for TDD workflow"
    ],
    "limitations": [
      "Enforces discipline but cannot automatically run test commands",
      "Requires user to execute test commands manually or via other tools",
      "Cannot prevent code from being written in editor outside AI context",
      "Does not generate test code automatically"
    ],
    "use_cases": [
      {
        "target_user": "Software Developers",
        "title": "Maintain Test Coverage",
        "description": "Enforce TDD discipline in AI-assisted coding to ensure every feature has failing test before implementation"
      },
      {
        "target_user": "QA Engineers",
        "title": "Validate Test Quality",
        "description": "Use checkpoint system to verify tests fail before code and pass after implementation"
      },
      {
        "target_user": "AI Agent Developers",
        "title": "Embed TDD Workflows",
        "description": "Integrate TDD enforcement into AI coding agents for consistent test-first development"
      }
    ],
    "prompt_templates": [
      {
        "title": "Start New Feature",
        "scenario": "Begin feature implementation with TDD",
        "prompt": "Use flow-tdd to implement this feature. Start by writing failing tests that define the expected behavior before any production code."
      },
      {
        "title": "Verify Tests Fail",
        "scenario": "Check test execution before coding",
        "prompt": "flow-tdd: Run tests to confirm new tests fail. Do not proceed until all new tests fail with expected errors."
      },
      {
        "title": "Implement Minimal Code",
        "scenario": "Write code to pass tests",
        "prompt": "flow-tdd: Implement minimal code to make the failing tests pass. No extra features. One test at a time."
      },
      {
        "title": "Record Errors",
        "scenario": "Log test failures systematically",
        "prompt": "flow-tdd: Record this test failure in ERROR_LOG.md with timestamp, phase, error type, root cause, and resolution."
      }
    ],
    "output_examples": [
      {
        "input": "Use flow-tdd to implement a user login function",
        "output": [
          "Phase 1 (Tests): Write failing tests first",
          "  â†’ User login returns token for valid credentials",
          "  â†’ User login rejects invalid email format",
          "  â†’ User login rejects wrong password",
          "Phase 2 (Verify): Run tests â†’ All FAIL expected",
          "Phase 3 (Implement): Write minimal code to pass tests",
          "Phase 4 (Refactor): Clean up while keeping tests green"
        ]
      }
    ],
    "best_practices": [
      "Always run tests after writing them to confirm they fail before implementation",
      "Write only enough code to pass the current failing test, avoid speculative features",
      "Record every test failure and its resolution in ERROR_LOG.md for future reference"
    ],
    "anti_patterns": [
      "Writing production code before tests - violates TDD Iron Law",
      "Tests that pass immediately - proves nothing and indicates invalid test",
      "Keeping exploration code without tests - delete and restart with TDD"
    ],
    "faq": [
      {
        "question": "Does this skill run tests automatically?",
        "answer": "No. The skill enforces TDD discipline and provides protocols. You must execute test commands via your terminal or test runner."
      },
      {
        "question": "What happens if tests pass immediately?",
        "answer": "This is a red flag. Passing tests immediately mean either the test is invalid or code already exists. Delete the code and restart with tests first."
      },
      {
        "question": "Can I skip tests for simple code?",
        "answer": "No. Simple code breaks. The TDD Iron Law has no exceptions. All production code requires failing tests first."
      },
      {
        "question": "How does this integrate with Claude Code?",
        "answer": "The skill provides prompts and workflows that can be invoked when asking Claude Code to implement features. It works with any AI coding tool."
      },
      {
        "question": "Is my data safe?",
        "answer": "Yes. This is a documentation-only skill. It does not access files, networks, or execute code. It only provides guidelines and protocols."
      },
      {
        "question": "How is this different from other testing tools?",
        "answer": "This skill enforces workflow discipline rather than running tests. It complements test runners by ensuring tests are written first and quality requirements are met."
      }
    ]
  },
  "file_structure": [
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md"
    }
  ]
}
