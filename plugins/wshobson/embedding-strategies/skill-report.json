{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-02T00:17:33.958Z",
    "slug": "wshobson-embedding-strategies",
    "source_url": "https://github.com/wshobson/agents/tree/main/plugins/llm-application-dev/skills/embedding-strategies",
    "source_ref": "main",
    "model": "codex",
    "analysis_version": "2.0.0",
    "source_type": "community",
    "content_hash": "03e6481e39240999e3eeb94103d7e2ae5393274624280107bfdc72389e0c2920",
    "tree_hash": "f1da1c688169f6e7ad9a66b9239e140057f0ac6d4c587abb27b00b797afb8e71"
  },
  "skill": {
    "name": "embedding-strategies",
    "description": "Select and optimize embedding models for semantic search and RAG applications. Use when choosing embedding models, implementing chunking strategies, or optimizing embedding quality for specific domains.",
    "summary": "Select and optimize embedding models for semantic search and RAG applications. Use when choosing emb...",
    "icon": "ðŸ§­",
    "version": "1.0.0",
    "license": "MIT",
    "category": "data",
    "tags": [
      "embeddings",
      "rag",
      "semantic-search",
      "chunking",
      "evaluation"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": [
      "network"
    ]
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "No credential access, exfiltration, or persistence patterns found. The skill contains documentation and sample code for embedding workflows only.",
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 1,
    "total_lines": 479,
    "audit_model": "codex",
    "audited_at": "2026-01-02T00:17:33.958Z"
  },
  "content": {
    "user_title": "Optimize embedding selection and chunking",
    "value_statement": "Choosing embeddings and chunking can be unclear and costly. This skill provides model comparisons, templates, and evaluation steps to improve retrieval quality.",
    "seo_keywords": [
      "embedding models",
      "RAG chunking",
      "semantic search",
      "OpenAI embeddings",
      "Sentence Transformers",
      "Claude",
      "Codex",
      "Claude Code",
      "vector search",
      "embedding evaluation"
    ],
    "actual_capabilities": [
      "Compare common embedding models with dimensions and use cases",
      "Provide OpenAI embeddings batching and dimension reduction template",
      "Provide local embedding templates using sentence-transformers",
      "Offer multiple chunking strategies including token and sentence methods",
      "Show retrieval quality evaluation metrics such as MRR and nDCG"
    ],
    "limitations": [
      "Does not run or deploy models for you",
      "Requires external libraries such as openai and sentence-transformers",
      "Does not supply datasets or benchmarks",
      "Templates require adaptation for your infrastructure"
    ],
    "use_cases": [
      {
        "target_user": "RAG developer",
        "title": "Choose an embedding model",
        "description": "Compare model options and pick a cost and accuracy balance for a new retrieval system."
      },
      {
        "target_user": "ML engineer",
        "title": "Optimize chunking strategy",
        "description": "Select chunk sizes and overlaps to improve recall and reduce indexing costs."
      },
      {
        "target_user": "Product analyst",
        "title": "Evaluate search quality",
        "description": "Apply standard metrics to compare retrieval improvements across releases."
      }
    ],
    "prompt_templates": [
      {
        "title": "Model selection",
        "scenario": "I need an embedding model for RAG",
        "prompt": "Recommend an embedding model for English support docs, moderate budget, and high recall. Include dimensions and tradeoffs."
      },
      {
        "title": "Chunking plan",
        "scenario": "I need a chunking strategy",
        "prompt": "Design a chunking strategy for long markdown docs. Include chunk size, overlap, and a method to keep headings with content."
      },
      {
        "title": "Local embeddings",
        "scenario": "I want a local model",
        "prompt": "Provide a local embedding setup using sentence-transformers with normalization and query prefixes for search."
      },
      {
        "title": "Quality evaluation",
        "scenario": "I must evaluate retrieval quality",
        "prompt": "Show how to compute precision@k, recall@k, MRR, and nDCG for my retrieval results."
      }
    ],
    "output_examples": [
      {
        "input": "Help me choose an embedding model for multilingual support tickets with limited GPU.",
        "output": [
          "Shortlist multilingual-e5-large for multilingual coverage",
          "Consider text-embedding-3-small for cost and latency",
          "Keep chunk size near 512 tokens with 50 overlap",
          "Measure recall@10 and nDCG before final selection"
        ]
      }
    ],
    "best_practices": [
      "Match the model to language and domain needs",
      "Normalize embeddings when using cosine similarity",
      "Evaluate changes with consistent retrieval metrics"
    ],
    "anti_patterns": [
      "Mixing embeddings from different models in one index",
      "Skipping preprocessing for noisy text sources",
      "Overlapping chunks so heavily that context repeats"
    ],
    "faq": [
      {
        "question": "Is this compatible with Claude, Codex, and Claude Code?",
        "answer": "Yes, it is a guidance skill and can be used in any of those platforms."
      },
      {
        "question": "What are the limits of the templates?",
        "answer": "They are examples only and require library installs and environment configuration."
      },
      {
        "question": "How do I integrate it with my vector database?",
        "answer": "Use the chunking and embedding steps, then store vectors with your database API."
      },
      {
        "question": "Does it access or transmit my data?",
        "answer": "No, the skill is static documentation without data collection or network calls."
      },
      {
        "question": "What if I get poor retrieval results?",
        "answer": "Adjust chunking, try another model, and measure with the evaluation metrics."
      },
      {
        "question": "How does it compare to generic RAG guides?",
        "answer": "It provides focused embedding model choices, chunking patterns, and evaluation metrics."
      }
    ]
  },
  "file_structure": [
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md"
    }
  ]
}
