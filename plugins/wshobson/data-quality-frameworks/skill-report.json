{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-03T02:22:58.106Z",
    "slug": "wshobson-data-quality-frameworks",
    "source_url": "https://github.com/wshobson/agents/tree/main/plugins/data-engineering/skills/data-quality-frameworks",
    "source_ref": "main",
    "model": "codex",
    "analysis_version": "2.0.0",
    "source_type": "community"
  },
  "skill": {
    "name": "data-quality-frameworks",
    "description": "Implement data quality validation with Great Expectations, dbt tests, and data contracts. Use when building data quality pipelines, implementing validation rules, or establishing data contracts.",
    "summary": "Implement data quality validation with Great Expectations, dbt tests, and data contracts. Use when b...",
    "icon": "ðŸ“Š",
    "version": "1.0.0",
    "author": "wshobson",
    "license": "MIT",
    "category": "data",
    "tags": [
      "data-quality",
      "great-expectations",
      "dbt",
      "data-contracts",
      "validation"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": [
      "network"
    ]
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "No malicious behaviors or suspicious access patterns were found. The skill content is documentation and example snippets only.",
    "risk_factors": [
      "network"
    ],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 3,
    "total_lines": 782,
    "audit_model": "codex",
    "audited_at": "2026-01-03T02:22:58.106Z"
  },
  "content": {
    "user_title": "Implement data quality frameworks fast",
    "value_statement": "Data quality gaps create unreliable analytics and pipeline failures. This skill provides concrete patterns for validation, tests, and contracts to reduce risk.",
    "seo_keywords": [
      "data quality frameworks",
      "Great Expectations",
      "dbt tests",
      "data contracts",
      "data validation",
      "Claude",
      "Codex",
      "Claude Code",
      "data pipeline checks",
      "data quality metrics"
    ],
    "actual_capabilities": [
      "Provide Great Expectations suite examples with schema, null, unique, and range checks",
      "Show checkpoint configuration with validation actions and failure handling",
      "Define dbt schema tests plus custom generic and singular tests",
      "Provide a data contract template with quality checks and SLAs",
      "Sketch a Python quality pipeline that generates a readable report"
    ],
    "limitations": [
      "Does not execute validations or connect to real data sources",
      "Requires Great Expectations, dbt, or contract tooling installed by the user",
      "Examples are generic and must be adapted to your schema and thresholds",
      "No packaged monitoring or alerting integrations are included"
    ],
    "use_cases": [
      {
        "target_user": "Data engineer",
        "title": "Validate warehouse tables",
        "description": "Create Great Expectations suites and checkpoints for critical tables."
      },
      {
        "target_user": "Analytics engineer",
        "title": "Expand dbt test coverage",
        "description": "Add schema, column, and custom dbt tests for marts."
      },
      {
        "target_user": "Data platform lead",
        "title": "Define data contracts",
        "description": "Specify contracts with schema, quality checks, and SLAs."
      }
    ],
    "prompt_templates": [
      {
        "title": "Starter checks",
        "scenario": "New table validation",
        "prompt": "Create a basic Great Expectations suite for an orders table with primary key, status, amount, and created_at checks."
      },
      {
        "title": "dbt test plan",
        "scenario": "Marts testing",
        "prompt": "Draft dbt tests for fct_orders and dim_customers including recency, relationships, and accepted values."
      },
      {
        "title": "Contract outline",
        "scenario": "Team data contract",
        "prompt": "Write a data contract outline for an orders dataset with schema, quality checks, and SLAs."
      },
      {
        "title": "Automated pipeline",
        "scenario": "Multi table validation",
        "prompt": "Describe an automated data quality pipeline that runs suites for multiple tables and generates a report."
      }
    ],
    "output_examples": [
      {
        "input": "Give me a minimal Great Expectations suite for orders data.",
        "output": [
          "Defines required columns and primary key checks",
          "Validates status values and amount range",
          "Adds freshness and row count checks"
        ]
      }
    ],
    "best_practices": [
      "Start with critical columns and expand tests over time",
      "Document expectations and ownership for each dataset",
      "Alert on failures and review trends regularly"
    ],
    "anti_patterns": [
      "Testing every column without prioritization",
      "Hardcoding thresholds without a rationale",
      "Skipping freshness checks for event data"
    ],
    "faq": [
      {
        "question": "Is this compatible with Claude and Codex?",
        "answer": "Yes, the content is plain text examples and works with Claude, Codex, and Claude Code."
      },
      {
        "question": "Are there limits on dataset size?",
        "answer": "The templates do not impose limits, but performance depends on your warehouse and test design."
      },
      {
        "question": "Can it integrate with CI or orchestration tools?",
        "answer": "It provides patterns that you can adapt for CI pipelines or schedulers."
      },
      {
        "question": "Does it access or store sensitive data?",
        "answer": "No, it only provides documentation and example code snippets."
      },
      {
        "question": "What if a check fails unexpectedly?",
        "answer": "Review recent data changes, adjust thresholds, and confirm source freshness."
      },
      {
        "question": "How does this compare to a full framework setup?",
        "answer": "It is guidance and templates, not a prebuilt framework or package."
      }
    ]
  },
  "file_structure": [
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md"
    }
  ]
}
