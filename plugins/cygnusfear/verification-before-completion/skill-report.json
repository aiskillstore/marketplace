{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-10T13:04:33.185Z",
    "slug": "cygnusfear-verification-before-completion",
    "source_url": "https://github.com/Cygnusfear/claude-stuff/tree/main/skills/verification-before-completion",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "2.0.0",
    "source_type": "community",
    "content_hash": "963f6b63d58d88e029181126528a1c720f76c4f8cfaec3532ece14795aef5b77",
    "tree_hash": "a47ef4ef5b04c2bc29852a290adc9789c5480fde2db005d4f45b021355653408"
  },
  "skill": {
    "name": "verification-before-completion",
    "description": "Use when about to claim work is complete, fixed, or passing, before committing or creating PRs - requires running verification commands and confirming output before making any success claims; evidence before assertions always",
    "summary": "Use when about to claim work is complete, fixed, or passing, before committing or creating PRs - req...",
    "icon": "üîç",
    "version": "1.0.0",
    "author": "Cygnusfear",
    "license": "MIT",
    "category": "productivity",
    "tags": [
      "verification",
      "testing",
      "quality",
      "compliance",
      "discipline"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": []
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "This is a pure prompt-based skill with no code execution, file access, or network activity. It provides guidelines for verifying work before claiming completion.",
    "risk_factor_evidence": [],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 1,
    "total_lines": 140,
    "audit_model": "claude",
    "audited_at": "2026-01-10T13:04:33.185Z"
  },
  "content": {
    "user_title": "Verify Work Before Declaring Success",
    "value_statement": "Stop false completion claims that waste time and damage trust. This skill forces fresh verification evidence before any success assertions.",
    "seo_keywords": [
      "verification",
      "testing",
      "Claude",
      "quality assurance",
      "code review",
      "Claude Code",
      "completion validation",
      "evidence-based",
      "software development",
      "best practices"
    ],
    "actual_capabilities": [
      "Forces verification commands before completion claims",
      "Prevents false success assertions",
      "Enforces evidence-before-assertion discipline",
      "Provides red flag detection for risky language",
      "Establishes verification gate function protocol"
    ],
    "limitations": [
      "Requires manual verification execution",
      "Cannot automate verification commands",
      "Depends on user discipline",
      "No integration with testing frameworks"
    ],
    "use_cases": [
      {
        "target_user": "Software developers",
        "title": "Prevent premature commits",
        "description": "Verify tests pass and builds succeed before committing code to avoid breaking builds"
      },
      {
        "target_user": "QA engineers",
        "title": "Validate bug fixes properly",
        "description": "Run regression tests to confirm bugs are actually fixed before marking tickets complete"
      },
      {
        "target_user": "Team leads",
        "title": "Ensure quality standards",
        "description": "Enforce verification discipline across team before accepting work as complete"
      }
    ],
    "prompt_templates": [
      {
        "title": "Before committing",
        "scenario": "About to commit changes",
        "prompt": "I need to verify my work before claiming completion. What specific command should I run to prove this works? Run it now and show me the output."
      },
      {
        "title": "After fixing bugs",
        "scenario": "Claiming a bug is fixed",
        "prompt": "Before I say this bug is fixed, I need to run verification. What test confirms the fix? Run it fresh and show results."
      },
      {
        "title": "Before pull request",
        "scenario": "Creating a pull request",
        "prompt": "I'm about to create a PR. Run the full test suite and build process. Show me the complete output before I claim it's ready."
      },
      {
        "title": "After agent work",
        "scenario": "Agent reports success",
        "prompt": "An agent said the task is complete. I need to verify independently. Show me the VCS diff and run any relevant tests to confirm."
      }
    ],
    "output_examples": [
      {
        "input": "I think the tests should pass now",
        "output": [
          "STOP - Rule violation detected",
          "You said 'should pass' without verification",
          "Required: Run test command ‚Üí Show output ‚Üí Then claim",
          "Example: 'npm test' ‚Üí Shows 45/45 passing ‚Üí 'All tests pass'"
        ]
      }
    ],
    "best_practices": [
      "Always run full verification commands fresh",
      "Read complete output before claiming success",
      "Document verification evidence with claims",
      "Apply rule to all success implications"
    ],
    "anti_patterns": [
      "Saying 'should work' without testing",
      "Trusting previous test runs",
      "Using confidence instead of evidence",
      "Partial verification shortcuts"
    ],
    "faq": [
      {
        "question": "Does this replace my testing workflow?",
        "answer": "No, it enforces discipline within your existing workflow by requiring verification evidence before claims."
      },
      {
        "question": "What if I'm absolutely sure it works?",
        "answer": "Confidence doesn't equal evidence. Run the verification anyway - the rule has no exceptions."
      },
      {
        "question": "Can I use this with automated CI/CD?",
        "answer": "Yes, it ensures you verify locally before pushing, complementing automated pipeline checks."
      },
      {
        "question": "How does this handle different project types?",
        "answer": "The skill adapts to your project's verification commands - tests, builds, linters, whatever proves correctness."
      },
      {
        "question": "What happens if verification fails?",
        "answer": "Report the actual status with evidence. Never claim success when verification shows failures."
      },
      {
        "question": "Is this too strict for rapid development?",
        "answer": "False claims waste more time than verification. The discipline prevents costly rework and maintains trust."
      }
    ]
  },
  "file_structure": [
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md"
    }
  ]
}
