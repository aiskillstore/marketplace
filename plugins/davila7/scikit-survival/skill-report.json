{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-07T00:52:26.620Z",
    "slug": "davila7-scikit-survival",
    "source_url": "https://github.com/davila7/claude-code-templates/tree/main/cli-tool/components/skills/scientific/scikit-survival",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "2.0.0",
    "source_type": "community",
    "content_hash": "5c26e43c36f60d28483b07619365643cc72183b939d327ec0b7f114e41d60854",
    "tree_hash": "1acccacc42f12083531ac69d7697ca98ca0b8bcb5dbce60c31b382ed2de4de4a"
  },
  "skill": {
    "name": "scikit-survival",
    "description": "Comprehensive toolkit for survival analysis and time-to-event modeling in Python using scikit-survival. Use this skill when working with censored survival data, performing time-to-event analysis, fitting Cox models, Random Survival Forests, Gradient Boosting models, or Survival SVMs, evaluating survival predictions with concordance index or Brier score, handling competing risks, or implementing any survival analysis workflow with the scikit-survival library.",
    "summary": "Comprehensive toolkit for survival analysis and time-to-event modeling in Python using scikit-surviv...",
    "icon": "ðŸ“Š",
    "version": "1.0.0",
    "author": "davila7",
    "license": "MIT",
    "category": "data",
    "tags": [
      "survival-analysis",
      "machine-learning",
      "time-to-event",
      "scikit-survival"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": []
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "This is a pure documentation skill containing only survival analysis reference materials and Python code examples. No executable scripts, network calls, file system access, or environment variable access. The skill provides guidance for using the scikit-survival library.",
    "risk_factor_evidence": [],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 7,
    "total_lines": 2167,
    "audit_model": "claude",
    "audited_at": "2026-01-07T00:52:26.620Z"
  },
  "content": {
    "user_title": "Perform survival analysis with scikit-survival",
    "value_statement": "Time-to-event analysis requires specialized methods for censored data. This skill provides complete guidance on fitting Cox models, Random Survival Forests, and Survival SVMs while properly evaluating predictions with concordance index and Brier score.",
    "seo_keywords": [
      "scikit-survival",
      "survival analysis",
      "time-to-event modeling",
      "Cox proportional hazards",
      "Random Survival Forest",
      "concordance index",
      "censored data analysis",
      "Claude Code",
      "Codex",
      "machine learning"
    ],
    "actual_capabilities": [
      "Fit Cox proportional hazards models including penalized Cox (Coxnet) for high-dimensional data",
      "Build ensemble survival models with Random Survival Forest and Gradient Boosting Survival Analysis",
      "Train Survival Support Vector Machines with linear and kernel variants",
      "Evaluate models using concordance index (Harrell's and Uno's), time-dependent AUC, and Brier score",
      "Handle competing risks with cumulative incidence functions and cause-specific hazard models",
      "Preprocess survival data and integrate with scikit-learn pipelines"
    ],
    "limitations": [
      "Does not directly support time-varying covariates (requires alternative approaches)",
      "Fine-Gray sub-distribution hazard models require other packages like lifelines",
      "Built-in feature importance for Random Survival Forest is unreliable (use permutation importance instead)"
    ],
    "use_cases": [
      {
        "target_user": "Clinical researchers",
        "title": "Clinical survival prediction",
        "description": "Build prognostic models for patient survival using hospital cohort data with censored outcomes"
      },
      {
        "target_user": "Data scientists",
        "title": "Churn and retention modeling",
        "description": "Predict customer time-to-churn while accounting for right-censored observations"
      },
      {
        "target_user": "Biostatisticians",
        "title": "Epidemiological cohort analysis",
        "description": "Analyze time-to-event data from longitudinal studies with multiple event types"
      }
    ],
    "prompt_templates": [
      {
        "title": "Basic Cox model",
        "scenario": "Fit a standard Cox model",
        "prompt": "Fit a Cox proportional hazards model to my survival data using scikit-survival. Show how to interpret the coefficients and calculate hazard ratios."
      },
      {
        "title": "Ensemble comparison",
        "scenario": "Compare multiple survival models",
        "prompt": "Compare Random Survival Forest, Gradient Boosting Survival Analysis, and FastSurvivalSVM on my dataset using concordance index and integrated Brier score."
      },
      {
        "title": "High-dimensional data",
        "scenario": "Analyze genomic data",
        "prompt": "Perform survival analysis on high-dimensional genomic data with scikit-survival. Use CoxnetSurvivalAnalysis for feature selection and regularization."
      },
      {
        "title": "Competing risks",
        "scenario": "Multi-event analysis",
        "prompt": "Analyze competing risks in my survival data where patients can experience different event types. Show cumulative incidence functions and cause-specific hazard models."
      }
    ],
    "output_examples": [
      {
        "input": "Fit a Cox model to breast cancer survival data",
        "output": [
          "Model fitted: CoxPHSurvivalAnalysis with 15 features",
          "C-index (Uno's): 0.742 (95% CI: 0.701-0.783)",
          "Key hazard ratios: Age=1.02, TumorSize=1.05, ER_Positive=0.72",
          "Positive coefficient means higher hazard (shorter survival)",
          "ER_Positive patients have 28% lower hazard (protective factor)"
        ]
      }
    ],
    "best_practices": [
      "Always standardize features for SVMs and regularized Cox models before fitting",
      "Use Uno's C-index instead of Harrell's when censoring exceeds 40%",
      "Validate data quality first: check for negative times and ensure at least 10 events per feature"
    ],
    "anti_patterns": [
      "Using Harrell's C-index with high censoring rates without adjusting to Uno's version",
      "Treating competing events as simple censoring instead of using competing risks methods",
      "Using built-in feature importance for Random Survival Forest without permutation importance"
    ],
    "faq": [
      {
        "question": "Which model should I start with?",
        "answer": "Start with CoxPHSurvivalAnalysis for interpretability or RandomSurvivalForest for predictive performance. CoxnetSurvivalAnalysis is best for high-dimensional data."
      },
      {
        "question": "What censoring rate can scikit-survival handle?",
        "answer": "Scikit-survival handles all censoring rates but Uno's C-index should be used when censoring exceeds 40% to avoid biased estimates."
      },
      {
        "question": "Can I use scikit-survival with scikit-learn pipelines?",
        "answer": "Yes, scikit-survival models fully integrate with scikit-learn pipelines, GridSearchCV, and cross_val_score using specialized scorers."
      },
      {
        "question": "Is my data safe when using this skill?",
        "answer": "This skill only provides documentation. Your data stays local and is processed only when you run the code examples in your own environment."
      },
      {
        "question": "Why is my model not converging?",
        "answer": "Check data standardization, ensure no missing values, verify positive survival times, and consider reducing regularization (alpha parameter)."
      },
      {
        "question": "How does this compare tolifelines package?",
        "answer": "Scikit-survival integrates with scikit-learn for advanced ML workflows while lifelines provides more traditional statistical survival analysis methods like log-rank tests."
      }
    ]
  },
  "file_structure": [
    {
      "name": "references",
      "type": "dir",
      "path": "references",
      "children": [
        {
          "name": "competing-risks.md",
          "type": "file",
          "path": "references/competing-risks.md"
        },
        {
          "name": "cox-models.md",
          "type": "file",
          "path": "references/cox-models.md"
        },
        {
          "name": "data-handling.md",
          "type": "file",
          "path": "references/data-handling.md"
        },
        {
          "name": "ensemble-models.md",
          "type": "file",
          "path": "references/ensemble-models.md"
        },
        {
          "name": "evaluation-metrics.md",
          "type": "file",
          "path": "references/evaluation-metrics.md"
        },
        {
          "name": "svm-models.md",
          "type": "file",
          "path": "references/svm-models.md"
        }
      ]
    },
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md"
    }
  ]
}
