{
  "name": "davila7-shap",
  "source": "./plugins/davila7/shap",
  "description": "Model interpretability and explainability using SHAP (SHapley Additive exPlanations). Use this skill when explaining machine learning model predictions, computing feature importance, generating SHAP plots (waterfall, beeswarm, bar, scatter, force, heatmap), debugging models, analyzing model bias or fairness, comparing models, or implementing explainable AI. Works with tree-based models (XGBoost, LightGBM, Random Forest), deep learning (TensorFlow, PyTorch), linear models, and any black-box model.",
  "version": "1.0.0",
  "author": {
    "name": "davila7"
  },
  "repository": "https://github.com/davila7/claude-code-templates/tree/main/cli-tool/components/skills/scientific/shap",
  "license": "MIT",
  "keywords": [
    "machine-learning",
    "model-interpretation",
    "explainable-ai",
    "feature-importance"
  ],
  "category": "data",
  "tags": [
    "machine-learning",
    "model-interpretation",
    "explainable-ai",
    "feature-importance"
  ]
}
