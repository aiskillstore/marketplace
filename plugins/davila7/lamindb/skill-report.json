{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-07T01:38:24.976Z",
    "slug": "davila7-lamindb",
    "source_url": "https://github.com/davila7/claude-code-templates/tree/main/cli-tool/components/skills/scientific/lamindb",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "2.0.0",
    "source_type": "community",
    "content_hash": "0d2b97e7ad656da5789938c4d518d46dbe44a485d7315086130a68da49b91963",
    "tree_hash": "fa60631bc2e9ebec671d3c4a7b12d6c14f875ccc07b8ac18d6fb51dbf2f680f5"
  },
  "skill": {
    "name": "lamindb",
    "description": "This skill should be used when working with LaminDB, an open-source data framework for biology that makes data queryable, traceable, reproducible, and FAIR. Use when managing biological datasets (scRNA-seq, spatial, flow cytometry, etc.), tracking computational workflows, curating and validating data with biological ontologies, building data lakehouses, or ensuring data lineage and reproducibility in biological research. Covers data management, annotation, ontologies (genes, cell types, diseases, tissues), schema validation, integrations with workflow managers (Nextflow, Snakemake) and MLOps platforms (W&B, MLflow), and deployment strategies.",
    "summary": "This skill should be used when working with LaminDB, an open-source data framework for biology that ...",
    "icon": "ðŸ”¬",
    "version": "1.0.0",
    "author": "davila7",
    "license": "MIT",
    "category": "research",
    "tags": [
      "data-management",
      "bioinformatics",
      "ontology",
      "workflow-tracking",
      "scientific"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": []
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "This is a pure documentation skill containing reference materials for LaminDB. No executable code, scripts, or network operations are present. All content consists of documentation explaining how to use the external LaminDB Python package.",
    "risk_factor_evidence": [],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 7,
    "total_lines": 3589,
    "audit_model": "claude",
    "audited_at": "2026-01-07T01:38:24.976Z"
  },
  "content": {
    "user_title": "Manage biological data with LaminDB",
    "value_statement": "Biological datasets are hard to track, query, and reproduce. LaminDB provides a unified framework for managing scientific data with built-in ontology validation, workflow lineage tracking, and FAIR compliance for research reproducibility.",
    "seo_keywords": [
      "lamindb",
      "biological data management",
      "single-cell genomics",
      "scRNA-seq data",
      "data lineage tracking",
      "FAIR data",
      "bioinformatics workflow",
      "cell ontology",
      "scientific reproducibility",
      "Claude Code"
    ],
    "actual_capabilities": [
      "Version and track biological datasets (scRNA-seq, spatial, flow cytometry)",
      "Validate and annotate data with biological ontologies (genes, cell types, tissues, diseases)",
      "Track computational workflow lineage from raw data to published results",
      "Integrate with workflow managers (Nextflow, Snakemake) and MLOps platforms (W&B, MLflow)",
      "Build queryable data lakehouses with standardized metadata schemas",
      "Manage cloud storage (S3, GCS) with local caching for large datasets"
    ],
    "limitations": [
      "Requires external LaminDB package installation and database setup",
      "Does not perform analysis itself - guides on using LaminDB for data management",
      "Ontology validation requires importing relevant biological databases",
      "Does not generate visualizations or perform statistical analysis"
    ],
    "use_cases": [
      {
        "target_user": "Bioinformatics researchers",
        "title": "Track single-cell analysis",
        "description": "Track scRNA-seq analysis pipelines with automatic lineage from raw counts to final plots"
      },
      {
        "target_user": "Data curators",
        "title": "Validate biological annotations",
        "description": "Standardize cell type and tissue annotations against Cell Ontology and Uberon"
      },
      {
        "target_user": "ML engineers",
        "title": "Integrate experiment tracking",
        "description": "Combine LaminDB data versioning with Weights & Biases or MLflow for reproducible ML pipelines"
      }
    ],
    "prompt_templates": [
      {
        "title": "Get started with LaminDB",
        "scenario": "Initial setup and concepts",
        "prompt": "Help me set up LaminDB for managing single-cell RNA-seq data. Include installation, initialization with local storage, and creating my first artifact from an AnnData object."
      },
      {
        "title": "Add ontology validation",
        "scenario": "Standardize annotations",
        "prompt": "Show me how to validate cell type annotations in my scRNA-seq data using the Cell Ontology (Bionty). Include importing the ontology, standardizing terms, and creating validated artifacts."
      },
      {
        "title": "Track workflow lineage",
        "scenario": "Reproducible pipelines",
        "prompt": "I want to track my analysis pipeline with LaminDB. Create a workflow using ln.track() that captures git commits, parameters, input artifacts, and output artifacts for a Nextflow or Snakemake pipeline."
      },
      {
        "title": "Query biological data",
        "scenario": "Find and reuse datasets",
        "prompt": "How do I query my LaminDB artifacts by biological features? Show me how to filter artifacts by cell type, tissue, or disease, and how to use feature-based queries to find relevant datasets."
      }
    ],
    "output_examples": [
      {
        "input": "Set up LaminDB with ontology validation for my scRNA-seq data",
        "output": [
          "Initialize LaminDB with local storage: lamin init --storage ./mydata",
          "Import Cell Ontology: bt.CellType.import_source()",
          "Create artifact: ln.Artifact.from_anndata(adata, key='scrna/batch1.h5ad').save()",
          "Standardize cell types: adata.obs['cell_type'] = bt.CellType.standardize(adata.obs['cell_type'])",
          "Validate with curator: curator = ln.curators.AnnDataCurator(adata, schema); curator.validate()"
        ]
      }
    ],
    "best_practices": [
      "Call ln.track() at the start of every notebook or script to capture complete lineage",
      "Use hierarchical keys (project/experiment/batch/file.h5ad) for organized data browsing",
      "Import and use biological ontologies (CellType, Tissue, Gene) before data validation",
      "Define typed features upfront for consistent metadata annotation and querying"
    ],
    "anti_patterns": [
      "Skipping ln.track() - breaks lineage tracking and reproducibility",
      "Using hardcoded paths instead of LaminDB keys for artifact management",
      "Validating data without first importing relevant ontologies",
      "Loading entire datasets into memory without using streaming for large files"
    ],
    "faq": [
      {
        "question": "What databases does LaminDB support?",
        "answer": "SQLite for local development and PostgreSQL for production. Cloud storage supports AWS S3, Google Cloud Storage, and S3-compatible services like MinIO and Cloudflare R2."
      },
      {
        "question": "How many biological ontologies are available?",
        "answer": "LaminDB via Bionty provides access to 20+ ontologies including Cell Ontology, Uberon, Gene Ontology, Disease Ontology, UniProt, Ensembl, and more."
      },
      {
        "question": "Can LaminDB integrate with existing workflow managers?",
        "answer": "Yes, LaminDB integrates with Nextflow, Snakemake, and Redun. Use ln.track() within pipeline scripts to capture execution lineage automatically."
      },
      {
        "question": "Is my data sent to LaminDB servers?",
        "answer": "No. Authentication collects only basic user metadata. Your actual data remains in your configured storage (local or cloud) and is never transmitted to LaminDB servers."
      },
      {
        "question": "Why does validation fail for valid terms?",
        "answer": "Ensure you called import_source() for the relevant ontology. Validation requires the ontology to be loaded into your local registry. Use bt.Registry.validate() to check terms before annotation."
      },
      {
        "question": "How does LaminDB compare to other data management tools?",
        "answer": "LaminDB combines data versioning, lineage tracking, and biological ontology validation in one framework. Unlike general tools, it specializes in FAIR compliance for life sciences with built-in support for single-cell and multi-modal data formats."
      }
    ]
  },
  "file_structure": [
    {
      "name": "references",
      "type": "dir",
      "path": "references",
      "children": [
        {
          "name": "annotation-validation.md",
          "type": "file",
          "path": "references/annotation-validation.md"
        },
        {
          "name": "core-concepts.md",
          "type": "file",
          "path": "references/core-concepts.md"
        },
        {
          "name": "data-management.md",
          "type": "file",
          "path": "references/data-management.md"
        },
        {
          "name": "integrations.md",
          "type": "file",
          "path": "references/integrations.md"
        },
        {
          "name": "ontologies.md",
          "type": "file",
          "path": "references/ontologies.md"
        },
        {
          "name": "setup-deployment.md",
          "type": "file",
          "path": "references/setup-deployment.md"
        }
      ]
    },
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md"
    }
  ]
}
