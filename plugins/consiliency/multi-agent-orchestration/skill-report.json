{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-10T12:34:54.557Z",
    "slug": "consiliency-multi-agent-orchestration",
    "source_url": "https://github.com/Consiliency/treesitter-chunker/tree/main/.ai-dev-kit/skills/multi-agent-orchestration",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "2.0.0",
    "source_type": "community",
    "content_hash": "9d48088e028cf0ddb41903347984cb7dc3587f1d2db66b85521a5894093ff498",
    "tree_hash": "6f0844204530dbe1d24d613c49b5bcacf2d86b8f5267a8676190092f1bb0092d"
  },
  "skill": {
    "name": "multi-agent-orchestration",
    "description": "Orchestrate tasks across multiple AI providers (Claude, OpenAI, Gemini, Cursor, OpenCode, Ollama). Use when delegating tasks to specialized providers, routing based on capabilities, or implementing fallback strategies.",
    "summary": "Orchestrate tasks across multiple AI providers (Claude, OpenAI, Gemini, Cursor, OpenCode, Ollama). U...",
    "icon": "ðŸ”€",
    "version": "1.0.0",
    "author": "Consiliency",
    "license": "MIT",
    "category": "productivity",
    "tags": [
      "orchestration",
      "routing",
      "multi-provider",
      "delegation",
      "ai"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": []
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "This is a documentation-only skill with no executable code. It provides routing guidance for delegating tasks to other AI providers. No scripts, network calls, file system access, environment variable reading, or external command execution were detected in this skill.",
    "risk_factor_evidence": [],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 9,
    "total_lines": 1368,
    "audit_model": "claude",
    "audited_at": "2026-01-10T12:34:54.557Z"
  },
  "content": {
    "user_title": "Route tasks to optimal AI providers",
    "value_statement": "Working with multiple AI providers requires understanding their strengths and limitations. This skill provides routing decisions, provider comparisons, and delegation patterns to match tasks with the best-suited AI for each situation.",
    "seo_keywords": [
      "Claude Code",
      "OpenAI Codex",
      "Gemini CLI",
      "Cursor agent",
      "Ollama local",
      "AI routing",
      "multi-agent",
      "task delegation",
      "provider selection",
      "orchestration"
    ],
    "actual_capabilities": [
      "Route tasks based on requirements (context size, modality, sandbox needs)",
      "Compare provider capabilities and limitations using decision matrices",
      "Delegate to specialized providers (Claude, OpenAI, Gemini, Cursor, OpenCode, Ollama)",
      "Implement fallback strategies when primary providers are unavailable",
      "Apply parallel execution patterns for concurrent agent launches",
      "Select appropriate model tiers (fast, default, heavy) for different task types"
    ],
    "limitations": [
      "Does not execute code or make API calls directly",
      "Does not store credentials or manage authentication",
      "Requires external CLI tools to be installed for actual delegation",
      "Routing decisions are guidelines, actual results depend on provider availability"
    ],
    "use_cases": [
      {
        "target_user": "Developers using multiple AI coding tools",
        "title": "Choose best provider per task",
        "description": "Route coding tasks to the optimal AI provider based on context needs, sandbox requirements, or privacy constraints."
      },
      {
        "target_user": "Teams with cost constraints",
        "title": "Optimize provider costs",
        "description": "Match simple tasks to fast/cheap models and reserve heavy models for complex reasoning to control AI spending."
      },
      {
        "target_user": "Privacy-conscious users",
        "title": "Process sensitive data locally",
        "description": "Delegate privacy-sensitive tasks to Ollama for local processing when cloud providers are not appropriate."
      }
    ],
    "prompt_templates": [
      {
        "title": "Quick routing query",
        "scenario": "Route a coding task",
        "prompt": "Which AI provider should I use for [task description]? Consider [specific requirements like context size, sandbox, or privacy needs]."
      },
      {
        "title": "Compare providers",
        "scenario": "Evaluate options for a task type",
        "prompt": "Compare Claude, OpenAI, and Gemini for [task type]. Include reasoning, context limits, and cost considerations."
      },
      {
        "title": "Parallel delegation",
        "scenario": "Launch multiple agents",
        "prompt": "Set up parallel execution for [task description]. Recommend agent count, model tiers, and timeout settings."
      },
      {
        "title": "Model tier selection",
        "scenario": "Choose model for specific work",
        "prompt": "Select the best model tier (fast, default, heavy) for these tasks: [list of tasks with complexity levels]."
      }
    ],
    "output_examples": [
      {
        "input": "I need to analyze a 500-line Python file for security issues and also run some test code safely.",
        "output": [
          "â€¢ Security analysis: Use Claude Code (strong reasoning, multi-file context)",
          "â€¢ Safe code execution: Use OpenAI Codex (sandboxed environment)",
          "â€¢ Recommended: Analyze with Claude first, then delegate testing to Codex"
        ]
      }
    ],
    "best_practices": [
      "Check provider availability and cost status before delegating high-volume tasks",
      "Use conversation history as a key factorâ€”keep context-heavy work in Claude",
      "Match model tier to task complexity: fast for simple lookups, heavy for architecture decisions"
    ],
    "anti_patterns": [
      "Delegating all tasks to a single provider regardless of task requirements",
      "Using heavy/expensive models for simple lookup or verification tasks",
      "Skipping the routing decision tree and guessing which provider to use"
    ],
    "faq": [
      {
        "question": "Which providers does this skill support?",
        "answer": "Claude, OpenAI/Codex, Gemini, Cursor, OpenCode, and Ollama are supported with routing guidance for each."
      },
      {
        "question": "What are the context window limits?",
        "answer": "Claude: 200k tokens, Gemini: 2M tokens, others: 128k. See provider-matrix.md for current details."
      },
      {
        "question": "How does this skill integrate with Claude Code?",
        "answer": "It provides routing decisions and delegation patterns. Actual delegation requires external CLI tools installed."
      },
      {
        "question": "Is my data sent to external providers?",
        "answer": "This skill only provides guidance. Actual data flow depends on which provider you delegate to and their policies."
      },
      {
        "question": "What if the delegated provider fails?",
        "answer": "Implement fallback chains. See the provider-matrix for backup options when primary providers are unavailable."
      },
      {
        "question": "How is this different from model-discovery skill?",
        "answer": "Model-discovery finds current model names. This skill routes tasks to providers based on capabilities and requirements."
      }
    ]
  },
  "file_structure": [
    {
      "name": "cookbook",
      "type": "dir",
      "path": "cookbook",
      "children": [
        {
          "name": "cursor-agent.md",
          "type": "file",
          "path": "cookbook/cursor-agent.md"
        },
        {
          "name": "gemini-cli.md",
          "type": "file",
          "path": "cookbook/gemini-cli.md"
        },
        {
          "name": "ollama-local.md",
          "type": "file",
          "path": "cookbook/ollama-local.md"
        },
        {
          "name": "openai-codex.md",
          "type": "file",
          "path": "cookbook/openai-codex.md"
        },
        {
          "name": "opencode-cli.md",
          "type": "file",
          "path": "cookbook/opencode-cli.md"
        },
        {
          "name": "parallel-execution.md",
          "type": "file",
          "path": "cookbook/parallel-execution.md"
        }
      ]
    },
    {
      "name": "reference",
      "type": "dir",
      "path": "reference",
      "children": [
        {
          "name": "model-selection.md",
          "type": "file",
          "path": "reference/model-selection.md"
        },
        {
          "name": "provider-matrix.md",
          "type": "file",
          "path": "reference/provider-matrix.md"
        }
      ]
    },
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md"
    }
  ]
}
