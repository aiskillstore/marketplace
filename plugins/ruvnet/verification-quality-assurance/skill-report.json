{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-06T08:16:17.772Z",
    "slug": "ruvnet-verification-quality-assurance",
    "source_url": "https://github.com/ruvnet/claude-flow/tree/main/.claude/skills/verification-quality",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "2.0.0",
    "source_type": "community",
    "content_hash": "df13bdbfca6bf22f42d319e1572fca8c594103ed435968f5e851ea7a43e8402b",
    "tree_hash": "62b6a88a5c03b87c642a58c6bb8407117155433c64e1fab12aee9f718cf46cd4"
  },
  "skill": {
    "name": "Verification & Quality Assurance",
    "description": "Comprehensive truth scoring, code quality verification, and automatic rollback system with 0.95 accuracy threshold for ensuring high-quality agent outputs and codebase reliability.",
    "summary": "Comprehensive truth scoring, code quality verification, and automatic rollback system with 0.95 accu...",
    "icon": "‚úÖ",
    "version": "2.0.0",
    "author": "ruvnet",
    "license": "MIT",
    "category": "quality-assurance",
    "tags": [
      "verification",
      "truth-scoring",
      "quality",
      "rollback",
      "metrics",
      "ci-cd"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": []
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "This skill contains only documentation with no executable code. It describes a quality assurance system for Claude Flow with truth scoring and verification capabilities. No security risks detected.",
    "risk_factor_evidence": [],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 1,
    "total_lines": 650,
    "audit_model": "claude",
    "audited_at": "2026-01-06T08:16:17.772Z"
  },
  "content": {
    "user_title": "Verify Code Quality with Truth Scoring",
    "value_statement": "Ensure your AI-generated code meets quality standards with automated verification and rollback. Get real-time truth scores and prevent bad code from entering your codebase.",
    "seo_keywords": [
      "Claude Code verification",
      "AI code quality",
      "truth scoring",
      "automated rollback",
      "code verification",
      "Claude Flow quality",
      "AI quality assurance",
      "code metrics",
      "Claude verification",
      "Codex quality"
    ],
    "actual_capabilities": [
      "Provides truth scoring from 0.0-1.0 for code quality assessment",
      "Automatically rolls back changes that fail verification (default threshold 0.95)",
      "Integrates with CI/CD pipelines for automated quality checks",
      "Generates real-time dashboards with quality metrics and trends",
      "Supports multiple output formats (JSON, CSV, HTML, Markdown)",
      "Includes watch mode for continuous verification during development"
    ],
    "limitations": [
      "Requires Git repository for rollback functionality",
      "Node.js 18+ needed for dashboard features",
      "Verification thresholds may need tuning for different project types",
      "Performance depends on codebase size and complexity"
    ],
    "use_cases": [
      {
        "target_user": "Development teams",
        "title": "CI/CD Quality Gates",
        "description": "Integrate automated quality checks into your deployment pipeline to prevent bad code from reaching production."
      },
      {
        "target_user": "AI pair programmers",
        "title": "Real-time Code Verification",
        "description": "Get instant feedback on AI-generated code quality during pair programming sessions with Claude."
      },
      {
        "target_user": "Project managers",
        "title": "Quality Metrics Dashboard",
        "description": "Monitor team performance and code quality trends with automated reports and visualizations."
      }
    ],
    "prompt_templates": [
      {
        "title": "Basic Verification",
        "scenario": "Check if my code meets quality standards",
        "prompt": "Run verification check on the current project and show me the truth score with any issues found."
      },
      {
        "title": "Strict Quality Gate",
        "scenario": "Verify code with high quality requirements",
        "prompt": "Verify my code with a 0.99 threshold and enable auto-rollback if verification fails."
      },
      {
        "title": "Continuous Monitoring",
        "scenario": "Watch for quality regressions",
        "prompt": "Start verification watch mode on the src directory and notify me if any changes drop below 0.95 truth score."
      },
      {
        "title": "Quality Report",
        "scenario": "Generate quality metrics for stakeholders",
        "prompt": "Generate a comprehensive quality report for the last 30 days with trends and export it as HTML for the team."
      }
    ],
    "output_examples": [
      {
        "input": "Check code quality for my React app",
        "output": [
          "üìä Truth Metrics Dashboard",
          "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ",
          "Overall Truth Score: 0.947 ‚úÖ",
          "Trend: ‚ÜóÔ∏è +2.3% (7d)",
          "Top Performers:",
          "  verification-agent   0.982 ‚≠ê",
          "  code-analyzer       0.971 ‚≠ê",
          "  test-generator      0.958 ‚úÖ",
          "Needs Attention:",
          "  refactor-agent      0.821 ‚ö†Ô∏è",
          "All checks passed with score above 0.95 threshold"
        ]
      }
    ],
    "best_practices": [
      "Set appropriate thresholds: 0.99 for critical code, 0.95 for standard, 0.90 for experimental",
      "Enable auto-rollback to prevent bad code from persisting in your repository",
      "Integrate verification into your CI/CD pipeline for automated quality gates"
    ],
    "anti_patterns": [
      "Setting verification threshold too low (below 0.90) defeats the purpose of quality assurance",
      "Ignoring verification failures without understanding root causes leads to quality degradation",
      "Running verification only at deployment time instead of during development increases fix costs"
    ],
    "faq": [
      {
        "question": "Is this compatible with my existing CI/CD setup?",
        "answer": "Yes, it integrates with GitHub Actions, GitLab CI, and other platforms through JSON output and exit codes."
      },
      {
        "question": "What happens if verification fails?",
        "answer": "By default, it automatically rolls back to the last known good state if auto-rollback is enabled."
      },
      {
        "question": "Can I customize the verification criteria?",
        "answer": "Yes, you can configure checks for code correctness, security, performance, documentation, and best practices."
      },
      {
        "question": "Is my code safe during verification?",
        "answer": "Yes, verification is read-only by default. Rollback creates backups before any changes."
      },
      {
        "question": "How do I troubleshoot low truth scores?",
        "answer": "Use --verbose flag to get detailed breakdown of issues and run specific agent analysis."
      },
      {
        "question": "How does this compare to traditional linting tools?",
        "answer": "It provides holistic quality assessment including AI-specific metrics, not just syntax checking."
      }
    ]
  },
  "file_structure": [
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md"
    }
  ]
}
