{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-06T07:31:06.602Z",
    "slug": "ruvnet-agentdb-performance-optimization",
    "source_url": "https://github.com/ruvnet/claude-flow/tree/main/.claude/skills/agentdb-optimization",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "2.0.0",
    "source_type": "community",
    "content_hash": "25240b10a1a7d94b5e826489cb869e1cba1946a4414f07e87bc3b40e41ebc16a",
    "tree_hash": "eea530b284d246d89879ffea532e927646782c14d7b22c3dee991ad3d0783d75"
  },
  "skill": {
    "name": "AgentDB Performance Optimization",
    "description": "Optimize AgentDB performance with quantization (4-32x memory reduction), HNSW indexing (150x faster search), caching, and batch operations. Use when optimizing memory usage, improving search speed, or scaling to millions of vectors.",
    "summary": "Optimize AgentDB performance with quantization (4-32x memory reduction), HNSW indexing (150x faster ...",
    "icon": "ðŸš€",
    "version": "1.0.0",
    "author": "ruvnet",
    "license": "MIT",
    "category": "data",
    "tags": [
      "performance",
      "optimization",
      "vector-database",
      "quantization",
      "indexing"
    ],
    "supported_tools": [
      "claude",
      "claude-code"
    ],
    "risk_factors": []
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "This skill contains only documentation and configuration examples for AgentDB performance optimization. No executable code, network operations, or security-sensitive operations were found. The content is purely educational with TypeScript/JavaScript configuration examples.",
    "risk_factor_evidence": [],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 1,
    "total_lines": 510,
    "audit_model": "claude",
    "audited_at": "2026-01-06T07:31:06.602Z"
  },
  "content": {
    "user_title": "Optimize AgentDB vector database performance 150x faster",
    "value_statement": "AgentDB vector searches slow down as data grows, causing application lag. This skill provides quantization and indexing techniques to achieve 150x faster searches with 4-32x memory reduction while maintaining accuracy.",
    "seo_keywords": [
      "AgentDB optimization",
      "vector database performance",
      "quantization techniques",
      "HNSW indexing",
      "Claude Code skills",
      "memory reduction",
      "search optimization",
      "Claude AI",
      "vector search speed",
      "database scaling"
    ],
    "actual_capabilities": [
      "Configure binary quantization for 32x memory reduction",
      "Implement HNSW indexing for O(log n) search complexity",
      "Set up in-memory caching with LRU eviction",
      "Execute batch operations for 500x faster inserts",
      "Monitor performance with real-time metrics",
      "Apply scaling strategies for millions of vectors"
    ],
    "limitations": [
      "Requires AgentDB v1.0.7+ via agentic-flow",
      "Quantization may cause 2-7% accuracy loss",
      "Binary quantization not suitable for all use cases",
      "Performance gains vary by dataset size and dimension"
    ],
    "use_cases": [
      {
        "target_user": "AI developers building RAG systems",
        "title": "Speed up vector similarity search",
        "description": "Reduce search latency from 15ms to 100Âµs in retrieval-augmented generation systems with HNSW indexing."
      },
      {
        "target_user": "Mobile app developers",
        "title": "Reduce memory usage for edge deployment",
        "description": "Deploy vector databases on mobile devices using binary quantization to shrink 3GB to 96MB."
      },
      {
        "target_user": "Data engineers handling large datasets",
        "title": "Scale to millions of vectors efficiently",
        "description": "Handle million-vector datasets with optimized batch operations and memory-efficient configurations."
      }
    ],
    "prompt_templates": [
      {
        "title": "Basic optimization setup",
        "scenario": "First-time AgentDB optimization",
        "prompt": "Help me set up AgentDB with balanced performance using scalar quantization and standard caching for a 50K vector dataset"
      },
      {
        "title": "Memory-constrained optimization",
        "scenario": "Mobile app with limited memory",
        "prompt": "Configure AgentDB for maximum memory efficiency on a mobile app that needs to store 100K vectors in under 50MB"
      },
      {
        "title": "High-performance search",
        "scenario": "Real-time recommendation system",
        "prompt": "Optimize AgentDB for sub-100Âµs search latency in a recommendation engine with 500K vectors, accepting 5% accuracy loss"
      },
      {
        "title": "Large-scale batch processing",
        "scenario": "Bulk vector ingestion pipeline",
        "prompt": "Set up AgentDB to efficiently ingest 10K vectors per batch with product quantization and monitor performance metrics"
      }
    ],
    "output_examples": [
      {
        "input": "Configure AgentDB for a mobile app with 200K vectors targeting under 100MB memory usage",
        "output": [
          "âœ… Applied binary quantization (32x reduction): 3GB â†’ 96MB",
          "âœ… Set cache size to 500 for mobile constraints",
          "âœ… Configured HNSW with M=8 for fast mobile searches",
          "âœ… Expected performance: <100Âµs search, 95-98% accuracy",
          "âœ… Memory target achieved: 96MB for 200K vectors"
        ]
      }
    ],
    "best_practices": [
      "Start with scalar quantization for balanced performance, then adjust based on accuracy requirements",
      "Monitor cache hit rates and aim for >80% - increase cache size if below target",
      "Use batch operations for bulk inserts to achieve 500x performance improvement"
    ],
    "anti_patterns": [
      "Don't use binary quantization for high-accuracy requirements - it causes 2-5% accuracy loss",
      "Avoid individual vector inserts in loops - always use batch operations for multiple vectors",
      "Don't skip performance monitoring - cache hit rates below 50% indicate configuration issues"
    ],
    "faq": [
      {
        "question": "Which quantization type should I use?",
        "answer": "Use scalar for balanced performance (98-99% accuracy), binary for maximum memory reduction (95-98% accuracy), or product for high-dimensional vectors (93-97% accuracy)."
      },
      {
        "question": "What's the minimum AgentDB version required?",
        "answer": "AgentDB v1.0.7+ via agentic-flow is required. Install with: npm install agentic-flow"
      },
      {
        "question": "How do I integrate this with my existing Node.js app?",
        "answer": "Import createAgentDBAdapter from 'agentic-flow/reasoningbank' and pass optimization parameters to the constructor."
      },
      {
        "question": "Is my data safe during optimization?",
        "answer": "Yes, optimization techniques only affect storage format and indexing - your original data remains intact and accessible."
      },
      {
        "question": "Why are my searches still slow after optimization?",
        "answer": "Check cache hit rate (>80% target), reduce efSearch parameter for speed, and ensure HNSW indexing is enabled."
      },
      {
        "question": "How does this compare to other vector databases?",
        "answer": "AgentDB with these optimizations achieves <100Âµs search times and 32x memory reduction, outperforming most alternatives for similarity search workloads."
      }
    ]
  },
  "file_structure": [
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md"
    }
  ]
}
