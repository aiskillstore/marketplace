{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-04T16:23:35.087Z",
    "slug": "mcp-builder",
    "source_url": "https://github.com/anthropics/skills/tree/main/skills/mcp-builder",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "2.0.0",
    "source_type": "official",
    "content_hash": "c0bd02483acbb365fbbc2370e6b68beba048e5267398a27ceb7332f6cc29b008",
    "tree_hash": "33bebdd0d7389e2b75287bbd23fbf90f45b699ad1e4be86ccd74beb6f801e43b"
  },
  "skill": {
    "name": "mcp-builder",
    "description": "Guide for creating high-quality MCP (Model Context Protocol) servers that enable LLMs to interact with external services through well-designed tools. Use when building MCP servers to integrate external APIs or services, whether in Python (FastMCP) or Node/TypeScript (MCP SDK).",
    "summary": "Guide for creating high-quality MCP (Model Context Protocol) servers that enable LLMs to interact wi...",
    "icon": "üõ†Ô∏è",
    "version": "1.0.0",
    "author": "anthropics",
    "license": "Complete terms in LICENSE.txt",
    "category": "coding",
    "tags": [
      "mcp",
      "servers",
      "evaluation",
      "typescript",
      "python"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": []
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "This is an official Anthropic skill from github.com/anthropics/skills. No security findings were identified in the scanned files. The codebase consists of documentation and Python evaluation scripts.",
    "risk_factor_evidence": [],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 13,
    "total_lines": 3812,
    "audit_model": "claude",
    "audited_at": "2026-01-04T16:23:35.087Z"
  },
  "content": {
    "user_title": "Build MCP servers with proven workflows",
    "value_statement": "Building a reliable MCP server requires understanding tool design, schema patterns, and evaluation methods. This skill provides a complete workflow from research through testing with language-specific guides for Python and TypeScript.",
    "seo_keywords": [
      "MCP server guide",
      "Model Context Protocol",
      "Claude",
      "Codex",
      "Claude Code",
      "FastMCP",
      "TypeScript MCP SDK",
      "MCP evaluation",
      "tool schema design",
      "MCP server tutorial"
    ],
    "actual_capabilities": [
      "Provides a four-phase workflow for MCP server development: research, implementation, review, and evaluation.",
      "Includes TypeScript implementation guide with Zod schemas, project structure, and McpServer patterns.",
      "Includes Python FastMCP guide with Pydantic models, tool registration, and async patterns.",
      "Supplies an evaluation harness that runs XML-based test questions through Claude with MCP tools.",
      "Supports stdio, SSE, and streamable HTTP transports for different deployment scenarios.",
      "Documents MCP best practices for naming, pagination, error handling, and response formats."
    ],
    "limitations": [
      "Does not provide a complete MCP server implementation for a specific API service.",
      "Evaluation harness requires valid Anthropic API credentials to run tests.",
      "Python scripts depend on the anthropic and mcp packages being installed.",
      "External SDK documentation must be fetched from GitHub using WebFetch separately."
    ],
    "use_cases": [
      {
        "target_user": "API integrator",
        "title": "Plan a new MCP server",
        "description": "Turn an API into clear tools with proper naming, input schemas, and pagination support."
      },
      {
        "target_user": "Platform engineer",
        "title": "Choose transport and stack",
        "description": "Decide between stdio, SSE, and streamable HTTP with language-specific implementation patterns."
      },
      {
        "target_user": "QA lead",
        "title": "Evaluate tool quality",
        "description": "Run XML evaluation tasks and review accuracy metrics with agent feedback."
      }
    ],
    "prompt_templates": [
      {
        "title": "Start a server plan",
        "scenario": "You have an API and need an MCP plan",
        "prompt": "Create a step-by-step plan to build an MCP server for the Example API. Include tool naming conventions, schema patterns, and pagination choices."
      },
      {
        "title": "Design tool list",
        "scenario": "You need tools for common API tasks",
        "prompt": "List the MCP tools you would implement for the Example API with clear names, short descriptions, and input parameters."
      },
      {
        "title": "Create eval questions",
        "scenario": "You want strong evaluation coverage",
        "prompt": "Draft 10 evaluation questions for an MCP server that integrates the Example API. Each question must be read-only and verifiable with a single answer."
      },
      {
        "title": "Run eval harness",
        "scenario": "You want to test your MCP server",
        "prompt": "Explain how to run the evaluation script against a stdio MCP server, including required arguments for command, environment variables, and output file options."
      }
    ],
    "output_examples": [
      {
        "input": "Summarize how to evaluate my MCP server",
        "output": [
          "Create an XML evaluation file with ten read-only questions and expected answers.",
          "Use the evaluation script with stdio transport to connect to your MCP server.",
          "Run the script and review accuracy metrics, tool calls, and agent feedback.",
          "Save the report to a file for tracking improvements over time."
        ]
      }
    ],
    "best_practices": [
      "Use clear tool names with action verbs and consistent prefixes like github_create_issue.",
      "Return structured content with schemas to help clients parse and validate results.",
      "Include evaluation tasks that require multiple tool calls to test agent effectiveness."
    ],
    "anti_patterns": [
      "Creating tools with vague names that hide intent or purpose.",
      "Returning unstructured data blobs without pagination, limits, or filters.",
      "Skipping evaluation and relying only on manual testing to verify tool quality."
    ],
    "faq": [
      {
        "question": "Is this compatible with Claude, Codex, and Claude Code?",
        "answer": "Yes. The guidance is platform agnostic, and the evaluation script uses Claude via the Anthropic SDK."
      },
      {
        "question": "What are the main limits of this skill?",
        "answer": "It provides guidance and scripts but does not ship a finished MCP server implementation for any specific service."
      },
      {
        "question": "How do I integrate this with my existing API?",
        "answer": "Use the tool design and schema sections to plan your tools, then implement endpoints following the language-specific guide."
      },
      {
        "question": "Does the evaluation script store my data?",
        "answer": "No local storage is added by default. Data is sent only to the model API you configure through your credentials."
      },
      {
        "question": "What should I do if evaluation fails to connect?",
        "answer": "Check your transport settings, verify the command or URL is correct, and ensure required headers or environment variables are set."
      },
      {
        "question": "How does this compare to generic API wrappers?",
        "answer": "It focuses specifically on MCP tool design, schemas, and evaluation for agent effectiveness rather than basic API access."
      }
    ]
  },
  "file_structure": [
    {
      "name": "reference",
      "type": "dir",
      "path": "reference",
      "children": [
        {
          "name": "evaluation.md",
          "type": "file",
          "path": "reference/evaluation.md"
        },
        {
          "name": "mcp_best_practices.md",
          "type": "file",
          "path": "reference/mcp_best_practices.md"
        },
        {
          "name": "node_mcp_server.md",
          "type": "file",
          "path": "reference/node_mcp_server.md"
        },
        {
          "name": "python_mcp_server.md",
          "type": "file",
          "path": "reference/python_mcp_server.md"
        }
      ]
    },
    {
      "name": "scripts",
      "type": "dir",
      "path": "scripts",
      "children": [
        {
          "name": "connections.py",
          "type": "file",
          "path": "scripts/connections.py"
        },
        {
          "name": "evaluation.py",
          "type": "file",
          "path": "scripts/evaluation.py"
        },
        {
          "name": "example_evaluation.xml",
          "type": "file",
          "path": "scripts/example_evaluation.xml"
        },
        {
          "name": "requirements.txt",
          "type": "file",
          "path": "scripts/requirements.txt"
        }
      ]
    },
    {
      "name": "LICENSE.txt",
      "type": "file",
      "path": "LICENSE.txt"
    },
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md"
    }
  ]
}
