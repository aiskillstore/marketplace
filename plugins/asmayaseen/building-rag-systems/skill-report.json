{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-10T10:41:49.965Z",
    "slug": "asmayaseen-building-rag-systems",
    "source_url": "https://github.com/Asmayaseen/hackathon-2/tree/main/.claude/skills/building-rag-systems",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "2.0.0",
    "source_type": "community",
    "content_hash": "0febde2c95e074dc2eb2ab839745cabe7b9b8d057434c6ffdab4371eddeaa621",
    "tree_hash": "b3a19d740b8de5f720b41b338ff94d6442ced41a3559a6e3844bd5781a495d33"
  },
  "skill": {
    "name": "building-rag-systems",
    "description": "Build production RAG systems with semantic chunking, incremental indexing, and filtered retrieval.\nUse when implementing document ingestion pipelines, vector search with Qdrant, or context-aware\nretrieval. Covers chunking strategies, change detection, payload indexing, and context expansion.\nNOT when doing simple similarity search without production requirements.\n",
    "summary": "Build production RAG systems with semantic chunking, incremental indexing, and filtered retrieval.\nU...",
    "icon": "üîç",
    "version": "1.0.0",
    "author": "Asmayaseen",
    "license": "MIT",
    "category": "data",
    "tags": [
      "rag",
      "vector-search",
      "qdrant",
      "embeddings",
      "document-ingestion"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": [
      "scripts",
      "filesystem",
      "network"
    ]
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "Pure documentation skill containing code examples and patterns for building RAG systems. No executable code that poses security risks. The verification script only checks file existence.",
    "risk_factor_evidence": [
      {
        "factor": "scripts",
        "evidence": [
          {
            "file": "scripts/verify.py",
            "line_start": 1,
            "line_end": 25
          }
        ]
      },
      {
        "factor": "filesystem",
        "evidence": [
          {
            "file": "SKILL.md",
            "line_start": 95,
            "line_end": 99
          },
          {
            "file": "references/ingestion-patterns.md",
            "line_start": 48,
            "line_end": 51
          }
        ]
      },
      {
        "factor": "network",
        "evidence": [
          {
            "file": "SKILL.md",
            "line_start": 150,
            "line_end": 156
          },
          {
            "file": "references/ingestion-patterns.md",
            "line_start": 202,
            "line_end": 221
          }
        ]
      }
    ],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 4,
    "total_lines": 1131,
    "audit_model": "claude",
    "audited_at": "2026-01-10T10:41:49.965Z"
  },
  "content": {
    "user_title": "Build Production RAG Systems",
    "value_statement": "Build production-grade RAG systems with semantic chunking, incremental indexing, and filtered retrieval using Qdrant and OpenAI embeddings.",
    "seo_keywords": [
      "RAG systems",
      "vector search",
      "Qdrant",
      "semantic chunking",
      "incremental indexing",
      "Claude Code",
      "OpenAI embeddings",
      "filtered retrieval",
      "document ingestion",
      "context expansion"
    ],
    "actual_capabilities": [
      "Implement semantic chunking on ## headers with 400 tokens and 15% overlap",
      "Build incremental indexing with SHA-256 change detection",
      "Create filtered retrieval with multi-field Qdrant payload indexes",
      "Implement context expansion using prev_chunk_id and next_chunk_id chain walking",
      "Configure batched OpenAI embeddings with text-embedding-3-small model",
      "Set up Qdrant collection with indexed payloads for tenant isolation"
    ],
    "limitations": [
      "Does not include a complete runnable application - provides patterns and examples",
      "Requires external Qdrant and OpenAI API setup",
      "Does not cover authentication or authorization implementation",
      "Does not include deployment or scaling guidance"
    ],
    "use_cases": [
      {
        "target_user": "ML Engineers",
        "title": "Production RAG Pipelines",
        "description": "Build scalable RAG ingestion and retrieval pipelines for production deployment."
      },
      {
        "target_user": "Documentation Teams",
        "title": "Document Search Systems",
        "description": "Create searchable knowledge bases with semantic chunking and filtered retrieval."
      },
      {
        "target_user": "AI Application Developers",
        "title": "Context-Aware AI Apps",
        "description": "Implement retrieval with context expansion for improved LLM responses."
      }
    ],
    "prompt_templates": [
      {
        "title": "Basic RAG Setup",
        "scenario": "Start a RAG system",
        "prompt": "Help me set up a RAG system with semantic chunking, OpenAI embeddings, and Qdrant storage. Include the ingestion pipeline components."
      },
      {
        "title": "Change Detection",
        "scenario": "Implement incremental updates",
        "prompt": "How do I implement incremental file change detection for my RAG system using SHA-256 hashes and Qdrant state tracking?"
      },
      {
        "title": "Filtered Search",
        "scenario": "Build filtered retrieval",
        "prompt": "Show me how to build a filtered retrieval system in Qdrant with tenant isolation, hardware tier, and proficiency level filters."
      },
      {
        "title": "Context Expansion",
        "scenario": "Add surrounding context",
        "prompt": "Implement context expansion for RAG chunks by walking the prev_chunk_id and next_chunk_id chain to retrieve surrounding sections."
      }
    ],
    "output_examples": [
      {
        "input": "Help me set up a RAG ingestion pipeline with semantic chunking",
        "output": [
          "Semantic chunker splits on ## headers with 400 tokens target",
          "Chunk IDs use file_hash + content_hash for stability",
          "15% overlap ensures context continuity between chunks",
          "OpenAI embed_batch processes 20 chunks per API call",
          "Qdrant uploader batches 100 points per upsert operation"
        ]
      }
    ],
    "best_practices": [
      "Use semantic boundaries (## headers) instead of fixed-size chunking for better recall",
      "Index all filterable payload fields (book_id, module, hardware_tier) in Qdrant",
      "Track file hashes for incremental re-indexing - only process changed files"
    ],
    "anti_patterns": [
      "Fixed character chunking - breaks semantic units and harms retrieval quality",
      "Missing payload indexes - causes slow filtered queries",
      "Full re-indexing on every change - wastes resources and increases latency"
    ],
    "faq": [
      {
        "question": "What vector database does this skill support?",
        "answer": "Qdrant is the primary vector database covered. The patterns can adapt to other databases with similar APIs."
      },
      {
        "question": "What embedding models are supported?",
        "answer": "OpenAI text-embedding-3-small is used as the default. The patterns work with any OpenAI-compatible embedding API."
      },
      {
        "question": "How do I integrate with my existing codebase?",
        "answer": "Import the pattern classes (SemanticChunker, QdrantUploader) and adapt the configuration to your environment."
      },
      {
        "question": "Is my data safe when using these patterns?",
        "answer": "These are local patterns. Your data is only sent to configured APIs (OpenAI, Qdrant). Configure endpoints securely."
      },
      {
        "question": "Why is my filtered search slow?",
        "answer": "Ensure all filter fields have payload indexes created. Missing indexes cause full collection scans."
      },
      {
        "question": "How does this compare to using LangChain?",
        "answer": "These patterns provide more control over chunking and filtering. LangChain offers higher-level abstractions but less customization."
      }
    ]
  },
  "file_structure": [
    {
      "name": "references",
      "type": "dir",
      "path": "references",
      "children": [
        {
          "name": "ingestion-patterns.md",
          "type": "file",
          "path": "references/ingestion-patterns.md"
        },
        {
          "name": "retrieval-patterns.md",
          "type": "file",
          "path": "references/retrieval-patterns.md"
        }
      ]
    },
    {
      "name": "scripts",
      "type": "dir",
      "path": "scripts",
      "children": [
        {
          "name": "verify.py",
          "type": "file",
          "path": "scripts/verify.py"
        }
      ]
    },
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md"
    }
  ]
}
