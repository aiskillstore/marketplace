{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-10T10:29:42.234Z",
    "slug": "asmayaseen-deploying-kafka-k8s",
    "source_url": "https://github.com/Asmayaseen/hackathon-2/tree/main/.claude/skills/deploying-kafka-k8s",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "2.0.0",
    "source_type": "community",
    "content_hash": "d9d483c0170deb61f414e4946a480d7412cdcad85d3a3a495cf46fa1eeb529ba",
    "tree_hash": "093d5d1c49c46404f546194360148b9018186374f783513c5717b280b06f12e0"
  },
  "skill": {
    "name": "deploying-kafka-k8s",
    "description": "Deploys Apache Kafka on Kubernetes using the Strimzi operator with KRaft mode.\nUse when setting up Kafka for event-driven microservices, message queuing, or pub/sub patterns.\nCovers operator installation, cluster creation, topic management, and producer/consumer testing.\nNOT when using managed Kafka (Confluent Cloud, MSK) or local development without K8s.\n",
    "summary": "Deploys Apache Kafka on Kubernetes using the Strimzi operator with KRaft mode.\nUse when setting up K...",
    "icon": "ðŸ“¬",
    "version": "1.0.0",
    "author": "Asmayaseen",
    "license": "MIT",
    "category": "devops",
    "tags": [
      "kubernetes",
      "kafka",
      "strimzi",
      "devops",
      "microservices"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": [
      "filesystem"
    ]
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "This skill consists of documentation and a simple validation script. The SKILL.md file contains Kubernetes deployment instructions for Strimzi Kafka operator. The verify.py script only validates the markdown file structure. No network calls, credential access, or external command execution detected. Behavior matches stated purpose.",
    "risk_factor_evidence": [
      {
        "factor": "filesystem",
        "evidence": [
          {
            "file": "scripts/verify.py",
            "line_start": 8,
            "line_end": 9
          }
        ]
      }
    ],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 2,
    "total_lines": 321,
    "audit_model": "claude",
    "audited_at": "2026-01-10T10:29:42.233Z"
  },
  "content": {
    "user_title": "Deploy Kafka on Kubernetes with Strimzi",
    "value_statement": "Setting up Apache Kafka on Kubernetes requires complex operator configuration, KRaft mode setup, and topic management. This skill provides production-ready YAML templates and step-by-step commands for deploying Kafka clusters using the Strimzi operator.",
    "seo_keywords": [
      "Kafka Kubernetes",
      "Strimzi operator",
      "KRaft mode",
      "Claude Code",
      "Claude",
      "Codex",
      "Kubernetes deployment",
      "event streaming",
      "message queue",
      "pub/sub"
    ],
    "actual_capabilities": [
      "Install Strimzi operator on Kubernetes cluster",
      "Deploy single-node development Kafka clusters",
      "Configure production-ready 3-node Kafka clusters with KRaft",
      "Create and manage Kafka topics via CRDs",
      "Test producers and consumers with console tools",
      "Enable Prometheus monitoring for Kafka clusters"
    ],
    "limitations": [
      "Does not support managed Kafka services like Confluent Cloud or MSK",
      "Requires existing Kubernetes cluster with kubectl access",
      "Does not configure external load balancers or ingress"
    ],
    "use_cases": [
      {
        "target_user": "DevOps Engineers",
        "title": "Production Kafka Deployment",
        "description": "Deploy highly available Kafka clusters with proper replication and monitoring on Kubernetes"
      },
      {
        "target_user": "Backend Developers",
        "title": "Event-Driven Microservices",
        "description": "Set up Kafka infrastructure for event sourcing, pub/sub patterns, and message queuing"
      },
      {
        "target_user": "Platform Teams",
        "title": "Kubernetes Integration",
        "description": "Integrate Strimzi Kafka with existing Kubernetes namespaces and monitoring stacks"
      }
    ],
    "prompt_templates": [
      {
        "title": "Quick Start",
        "scenario": "Deploy Kafka for development",
        "prompt": "Deploy a single-node Kafka cluster on Kubernetes using Strimzi for development testing"
      },
      {
        "title": "Production Setup",
        "scenario": "Configure production Kafka",
        "prompt": "Create a production-ready 3-node Kafka cluster with KRaft mode, TLS listeners, and proper resource limits"
      },
      {
        "title": "Topic Management",
        "scenario": "Create Kafka topics",
        "prompt": "Create a Kafka topic with 3 partitions and 3 replicas for event streaming"
      },
      {
        "title": "Dapr Integration",
        "scenario": "Connect Dapr to Kafka",
        "prompt": "Configure a Dapr pub/sub component to connect to my Strimzi Kafka cluster"
      }
    ],
    "output_examples": [
      {
        "input": "Deploy a single-node Kafka cluster on Kubernetes using Strimzi for development testing",
        "output": [
          "âœ“ Created namespace 'kafka'",
          "âœ“ Installed Strimzi operator v0.49.1",
          "âœ“ Deployed Kafka cluster 'my-cluster' with 1 replica",
          "âœ“ Configured plain listener on port 9092",
          "âœ“ Enabled ephemeral storage for development",
          "âœ“ Kafka cluster is ready after 120s",
          "",
          "Bootstrap server: my-cluster-kafka-bootstrap:9092",
          "Topic management: Use KafkaTopic CRD",
          "Test producer: kubectl -n kafka run kafka-producer..."
        ]
      }
    ],
    "best_practices": [
      "Use KRaft mode to eliminate ZooKeeper dependency and simplify deployment",
      "Set appropriate replication factors matching your fault tolerance requirements",
      "Enable Prometheus metrics export for monitoring Kafka cluster health"
    ],
    "anti_patterns": [
      "Using ephemeral storage in production without backup strategy",
      "Skipping TLS encryption for internal communications",
      "Deploying single-node clusters for production workloads"
    ],
    "faq": [
      {
        "question": "Does this skill work with managed Kafka services?",
        "answer": "No. This skill is for self-managed Kafka on Kubernetes using Strimzi. Use Confluent Cloud or MSK documentation for managed services."
      },
      {
        "question": "What Kubernetes versions are supported?",
        "answer": "Strimzi supports Kubernetes 1.21 and later. Check Strimzi documentation for specific version compatibility."
      },
      {
        "question": "How does KRaft mode differ from ZooKeeper?",
        "answer": "KRaft mode uses Kafka's internal Raft consensus instead of ZooKeeper, simplifying deployment and reducing operational complexity."
      },
      {
        "question": "Is my data safe when deleting clusters?",
        "answer": "By default, persistent claims retain data. Set deleteClaim: true in storage config or manually delete PVCs to clean up."
      },
      {
        "question": "Why are my Kafka pods stuck in pending state?",
        "answer": "Common causes include insufficient cluster resources, missing storage class, or node selector constraints. Check kubectl describe events for details."
      },
      {
        "question": "How does this compare to other Kafka deployment methods?",
        "answer": "Strimzi provides Kubernetes-native deployment with CRDs. It offers better integration than manual deployment but less control than custom operators."
      }
    ]
  },
  "file_structure": [
    {
      "name": "scripts",
      "type": "dir",
      "path": "scripts",
      "children": [
        {
          "name": "verify.py",
          "type": "file",
          "path": "scripts/verify.py"
        }
      ]
    },
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md"
    }
  ]
}
