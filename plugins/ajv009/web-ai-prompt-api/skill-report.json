{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-10T09:43:24.933Z",
    "slug": "ajv009-web-ai-prompt-api",
    "source_url": "https://github.com/AJV009/ajv009.github.io/tree/main/.claude/skills/web_ai_prompt_api",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "2.0.0",
    "source_type": "community",
    "content_hash": "1a52c4b402bd1f9fe5b57bdfee01d871ef1ae9168b839bcd8b96efa11ffd04ad",
    "tree_hash": "27a4a94ab1a350f66232095802b61b6b5fa6dd2ca542be0743a02ba6fab467a9"
  },
  "skill": {
    "name": "web-ai-prompt-api",
    "description": "Chrome's built-in Prompt API implementation guide. Use Gemini Nano locally in browser for AI features - session management, multimodal input, structured output, streaming, Chrome Extensions. Reference for all Prompt API development.",
    "summary": "Chrome's built-in Prompt API implementation guide. Use Gemini Nano locally in browser for AI feature...",
    "icon": "ðŸ¤–",
    "version": "1.0.0",
    "author": "AJV009",
    "license": "MIT",
    "category": "coding",
    "tags": [
      "Chrome",
      "Gemini Nano",
      "Prompt API",
      "Browser AI",
      "On-device AI"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": []
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "Pure documentation skill containing only reference material for Chrome's built-in Prompt API. No executable code, no file system access, no network calls, no external commands.",
    "risk_factor_evidence": [],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 1,
    "total_lines": 452,
    "audit_model": "claude",
    "audited_at": "2026-01-10T09:43:24.932Z"
  },
  "content": {
    "user_title": "Implement Chrome Prompt API with Gemini Nano",
    "value_statement": "Build on-device AI features using Chrome's built-in Prompt API. Gemini Nano runs locally in the browser for privacy-sensitive tasks with support for text, images, and audio.",
    "seo_keywords": [
      "Chrome Prompt API",
      "Gemini Nano",
      "Claude Code",
      "Claude",
      "Codex",
      "on-device AI",
      "browser AI",
      "multimodal AI",
      "structured output",
      "streaming responses"
    ],
    "actual_capabilities": [
      "Check API availability and model parameters",
      "Create and manage AI sessions with custom settings",
      "Process multimodal input (text, images, audio)",
      "Generate structured JSON output with response constraints",
      "Stream responses for long-form content",
      "Clone and restore sessions for parallel conversations"
    ],
    "limitations": [
      "Desktop Chrome only (no mobile support)",
      "Requires 22 GB storage for model download",
      "Output is text-only even with multimodal input",
      "No Web Workers support due to permission policy"
    ],
    "use_cases": [
      {
        "target_user": "Extension Developers",
        "title": "Build AI Extensions",
        "description": "Create Chrome extensions with on-device AI for content analysis, classification, and intelligent search features."
      },
      {
        "target_user": "Privacy-Focused Developers",
        "title": "Process Data Locally",
        "description": "Build applications that process sensitive data locally without sending it to external servers."
      },
      {
        "target_user": "Web App Developers",
        "title": "Add Browser AI Features",
        "description": "Integrate Gemini Nano for content summarization, translation, and interactive chatbots in web applications."
      }
    ],
    "prompt_templates": [
      {
        "title": "Check API Availability",
        "scenario": "Verify Chrome supports the Prompt API",
        "prompt": "Check if chrome.languageModel is available and what the availability status is. Report whether the model is unavailable, downloadable, downloading, or available."
      },
      {
        "title": "Create Basic Session",
        "scenario": "Start a new AI conversation",
        "prompt": "Create a new LanguageModel session with default parameters. Then use it to generate a short response to: 'Explain quantum computing in simple terms.'"
      },
      {
        "title": "Generate Structured JSON",
        "scenario": "Get predictable structured output",
        "prompt": "Create a session with a JSON Schema response constraint for extracting { title, sentiment, key_points }. Prompt the model to analyze this product review and return valid JSON."
      },
      {
        "title": "Build Multimodal Pipeline",
        "scenario": "Process images with AI",
        "prompt": "Create a session configured for multimodal input with images. Use append() to add an image file and then prompt the model to analyze it for specific patterns or objects."
      }
    ],
    "output_examples": [
      {
        "input": "Use Chrome's Prompt API to create a session and summarize this article",
        "output": [
          "â€¢ Check availability: await LanguageModel.availability()",
          "â€¢ Create session with optional initial prompts for context",
          "â€¢ Use session.prompt() for short responses or session.promptStreaming() for longer content",
          "â€¢ Monitor inputUsage to track conversation limits",
          "â€¢ Remember to destroy() sessions when done to free resources"
        ]
      }
    ],
    "best_practices": [
      "Keep one empty session alive to avoid reloading the model between requests",
      "Use AbortController to let users cancel long-running generations",
      "Clone sessions instead of recreating when you need parallel conversations with the same context"
    ],
    "anti_patterns": [
      "Creating a new session for every request (reloading the model is expensive)",
      "Ignoring inputUsage and exceeding the conversation quota",
      "Assuming the model is available without checking availability first"
    ],
    "faq": [
      {
        "question": "What Chrome version do I need for the Prompt API?",
        "answer": "Chrome 138+ for extensions, 138+ for web with origin trial. Check chrome://on-device-internals for model status."
      },
      {
        "question": "How much storage does Gemini Nano require?",
        "answer": "The model requires 22 GB of free storage. It will be removed automatically if storage drops below 10 GB."
      },
      {
        "question": "Can I use this in a Chrome extension?",
        "answer": "Yes, the Prompt API is available in Chrome 138+ stable for extensions without needing origin trial permissions."
      },
      {
        "question": "Is my data sent to external servers?",
        "answer": "No, Gemini Nano runs entirely on-device. No data leaves the browser for processing."
      },
      {
        "question": "Why is the model not available even though I have Chrome 138+?",
        "answer": "Check storage (22 GB needed), GPU/CPU requirements, and ensure you have the right OS version. Try enabling chrome://flags/#prompt-api-for-gemini-nano-multimodal-input."
      },
      {
        "question": "How does this compare to using Claude or GPT APIs?",
        "answer": "On-device AI offers privacy and zero latency but has smaller context windows and less capability than cloud models. Best for privacy-sensitive or offline use cases."
      }
    ]
  },
  "file_structure": [
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md"
    }
  ]
}
