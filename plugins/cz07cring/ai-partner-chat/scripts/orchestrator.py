"""
æ ¸å¿ƒåè°ƒå™¨ - Orchestrator

æ•´ä¸ª AI Partner Chat 2.0 çš„æ ¸å¿ƒå¤§è„‘ï¼Œä¸²è”æ‰€æœ‰åŠŸèƒ½ï¼š
1. å¤„ç†æ–°ç¬”è®°ï¼ˆæ ‡ç­¾ã€ä»£ç ã€æƒ…ç»ªã€å‘é‡åŒ–ï¼‰
2. å¤„ç†å¯¹è¯ï¼ˆçŠ¶æ€æ„ŸçŸ¥ã€å¤šæºæ£€ç´¢ã€è®°å½•ï¼‰
3. ç”Ÿæˆåˆ†ææŠ¥å‘Š
4. ç»Ÿä¸€è°ƒåº¦æ‰€æœ‰æ¨¡å—

ç‰ˆæœ¬: 2.0
"""

import sys
from pathlib import Path
from typing import Dict, List, Optional
from datetime import datetime

# å¯¼å…¥æ‰€æœ‰æ¨¡å—
sys.path.insert(0, str(Path(__file__).parent))

from tag_generator import TagGenerator
from tag_indexer import TagIndexer
from conversation_logger import ConversationLogger
from code_parser import CodeParser
from emotion_analyzer import EmotionAnalyzer
from thinking_analyzer import ThinkingAnalyzer
from vector_indexer import VectorIndexer
from vector_utils import MultiSourceRetriever
from chunk_schema import (
    create_note_metadata, create_code_metadata,
    CHUNK_TYPE_NOTE, CHUNK_TYPE_CODE
)


class AIPartnerOrchestrator:
    """AI Partner æ ¸å¿ƒåè°ƒå™¨ - ä¸²è”æ‰€æœ‰åŠŸèƒ½"""

    def __init__(self, project_root: str = ".", skill_dir: str = None):
        """
        åˆå§‹åŒ–åè°ƒå™¨

        Args:
            project_root: é¡¹ç›®æ ¹ç›®å½•ï¼ˆç”¨äºè¯»å– notes/ å’Œ config/ï¼‰
            skill_dir: skill ç›®å½•è·¯å¾„ï¼ˆé»˜è®¤ ~/.claude/skills/ai-partner-chatï¼‰
        """
        self.project_root = Path(project_root).resolve()

        # ç¡®å®š skill æ•°æ®ç›®å½•
        if skill_dir is None:
            skill_dir = Path.home() / '.claude' / 'skills' / 'ai-partner-chat'
        self.skill_dir = Path(skill_dir)
        self.data_dir = self.skill_dir / 'data'

        # ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨
        self.data_dir.mkdir(parents=True, exist_ok=True)
        (self.data_dir / 'vector_db').mkdir(exist_ok=True)
        (self.data_dir / 'conversations').mkdir(exist_ok=True)
        (self.data_dir / 'indexes').mkdir(exist_ok=True)
        (self.data_dir / 'analysis').mkdir(exist_ok=True)

        # åˆå§‹åŒ–æ‰€æœ‰æ¨¡å—ï¼ˆä½¿ç”¨ skill ç›®å½•çš„æ•°æ®è·¯å¾„ï¼‰
        self.tag_generator = TagGenerator()
        self.tag_indexer = TagIndexer(
            index_dir=str(self.data_dir / 'indexes')
        )
        self.conversation_logger = ConversationLogger(
            conversations_dir=str(self.data_dir / 'conversations')
        )
        self.code_parser = CodeParser()
        self.emotion_analyzer = EmotionAnalyzer(
            index_dir=str(self.data_dir / 'indexes')
        )
        self.thinking_analyzer = ThinkingAnalyzer()
        self.vector_indexer = VectorIndexer(
            db_path=str(self.data_dir / 'vector_db')
        )
        self.retriever = MultiSourceRetriever(
            db_path=str(self.data_dir / 'vector_db')
        )

        # æ˜¾ç¤ºåˆå§‹åŒ–ä¿¡æ¯
        stats = self.vector_indexer.get_stats()
        print(f"âœ… AI Partner åè°ƒå™¨å·²åˆå§‹åŒ–")
        print(f"   é¡¹ç›®: {self.project_root.name}")
        print(f"   æ•°æ®: ~/.claude/skills/ai-partner-chat/data/")
        print(f"   å‘é‡åº“: {stats['total_chunks']} chunks")
        if stats['total_chunks'] > 0:
            print(f"   ğŸ’­ é•¿æœŸè®°å¿†å·²åŠ è½½")

    def process_new_note(self, note_path: str, content: str) -> Dict:
        """
        å¤„ç†æ–°ç¬”è®° - å…¨æµç¨‹

        æµç¨‹ï¼š
        1. åˆ†ææ ‡ç­¾
        2. æå–ä»£ç å—
        3. åˆ†ææƒ…ç»ªçŠ¶æ€
        4. åˆ¤æ–­æ€ç»´å±‚æ¬¡
        5. ç”Ÿæˆchunks
        6. å‘é‡åŒ–
        7. æ›´æ–°ç´¢å¼•

        Args:
            note_path: ç¬”è®°æ–‡ä»¶è·¯å¾„
            content: ç¬”è®°å†…å®¹

        Returns:
            å¤„ç†ç»“æœæ‘˜è¦
        """
        print(f"\nğŸ“ å¤„ç†æ–°ç¬”è®°: {note_path}")

        # 1. å¹¶è¡Œåˆ†æ
        tags_layers = self.tag_generator.generate_tag_layers(content, 'note')
        all_tags = (tags_layers['topic'] + tags_layers['tech'] +
                   tags_layers['custom'])

        code_blocks = self.code_parser.extract_code_blocks(content)
        emotion = self.emotion_analyzer.analyze_emotion(content)
        thinking_level = self.thinking_analyzer.analyze_thinking_level(content)

        print(f"  æ ‡ç­¾: {all_tags}")
        print(f"  æƒ…ç»ª: {emotion['state']}")
        print(f"  æ€ç»´å±‚æ¬¡: Level {thinking_level}")
        print(f"  ä»£ç å—: {len(code_blocks)} ä¸ª")

        # 2. ç”Ÿæˆ chunks
        chunks = []
        today = datetime.now().strftime('%Y-%m-%d')

        # ç¬”è®°ä¸»ä½“ chunk
        note_chunk = {
            'content': content,
            'metadata': create_note_metadata(
                filename=Path(note_path).name,
                filepath=note_path,
                chunk_id=0,
                date=today,
                tags=all_tags,
                tag_layers=tags_layers,
                emotion=emotion,
                thinking_level=thinking_level,
                created_at=datetime.now().isoformat()
            )
        }
        chunks.append(note_chunk)

        # ä»£ç å— chunks
        for idx, code_block in enumerate(code_blocks):
            code_analysis = self.code_parser.analyze_code(
                code_block['code'],
                code_block['language']
            )

            code_chunk = {
                'content': code_block['code'],
                'metadata': create_code_metadata(
                    filename=Path(note_path).name,
                    filepath=note_path,
                    chunk_id=idx + 1,
                    **code_analysis,  # code_analysis å·²åŒ…å« language
                    tags=all_tags,  # ç»§æ‰¿ç¬”è®°æ ‡ç­¾
                    date=today,
                    created_at=datetime.now().isoformat()
                )
            }
            chunks.append(code_chunk)

        # 3. å‘é‡åŒ–
        indexed = self.vector_indexer.append_chunks(chunks)

        # 4. æ›´æ–°ç´¢å¼•
        self.tag_indexer.add_tags(note_path, all_tags)

        # 5. æ›´æ–°æƒ…ç»ªæ—¶é—´çº¿
        self.emotion_analyzer.update_timeline(today, emotion, notes_count=1)

        return {
            'chunks_created': len(chunks),
            'chunks_indexed': indexed,
            'tags': all_tags,
            'emotion': emotion,
            'thinking_level': thinking_level,
            'code_blocks': len(code_blocks)
        }

    def handle_conversation(
        self,
        user_message: str,
        ai_response: str = None,
        generate_response: bool = True,
        save_conversation: bool = True
    ) -> Dict:
        """
        å¤„ç†å¯¹è¯ - å…¨æµç¨‹

        ä¸¤ç§ä½¿ç”¨æ¨¡å¼ï¼š

        **æ¨¡å¼ 1 - ä¸¤æ­¥è°ƒç”¨ï¼ˆæ¨èï¼‰**:
        ```python
        # ç¬¬ä¸€æ­¥: è·å–ä¸Šä¸‹æ–‡ï¼ˆç”¨äºç”Ÿæˆå›å¤ï¼‰
        context = orch.handle_conversation(
            user_message="é—®é¢˜",
            generate_response=True,
            save_conversation=False  # æš‚ä¸ä¿å­˜
        )

        # ç¬¬äºŒæ­¥: ç”Ÿæˆå›å¤å¹¶ä¿å­˜
        ai_response = your_ai_function(context)
        orch.handle_conversation(
            user_message="é—®é¢˜",
            ai_response=ai_response,
            save_conversation=True
        )
        ```

        **æ¨¡å¼ 2 - ä¸€æ­¥è°ƒç”¨ï¼ˆç®€å•ä½†æ—  AI å›å¤ï¼‰**:
        ```python
        # ç›´æ¥ä¿å­˜ç”¨æˆ·æ¶ˆæ¯ï¼ˆAI å›å¤ä¸ºç©ºï¼‰
        orch.handle_conversation(
            user_message="é—®é¢˜",
            save_conversation=True
        )
        ```

        Args:
            user_message: ç”¨æˆ·æ¶ˆæ¯
            ai_response: AIå›å¤ï¼ˆå¦‚æœå·²ç”Ÿæˆï¼‰
            generate_response: æ˜¯å¦éœ€è¦ç”Ÿæˆå›å¤ä¸Šä¸‹æ–‡
            save_conversation: æ˜¯å¦ä¿å­˜å¯¹è¯

        Returns:
            åŒ…å«ä¸Šä¸‹æ–‡å’Œå¤„ç†ç»“æœçš„å­—å…¸
        """
        print(f"\nğŸ’¬ å¤„ç†å¯¹è¯: {user_message[:50]}...")

        # 1. çŠ¶æ€æ„ŸçŸ¥
        current_state = self.emotion_analyzer.get_current_state(days=7)
        print(f"  å½“å‰çŠ¶æ€: {current_state['state']} (è¶‹åŠ¿: {current_state['trend']})")

        # 2. å¤šæºæ£€ç´¢
        search_results = self.retriever.search_all(
            query=user_message,
            notes_k=3,
            conversations_k=2,
            code_k=2
        )

        print(f"  æ£€ç´¢ç»“æœ: {len(search_results['notes'])} ç¬”è®°, "
              f"{len(search_results['conversations'])} å¯¹è¯, "
              f"{len(search_results['code'])} ä»£ç ")

        # 3. æ„å»ºä¸Šä¸‹æ–‡
        context = {
            'user_state': current_state,
            'search_results': search_results,
            'user_message': user_message
        }

        # 4. ä¿å­˜å¯¹è¯ï¼ˆå¦‚æœéœ€è¦ï¼‰
        conv_id = None
        emotion_updated = False

        if save_conversation:
            # è®°å½•å¯¹è¯ï¼ˆå³ä½¿æ²¡æœ‰ AI å›å¤ä¹Ÿä¿å­˜ç”¨æˆ·æ¶ˆæ¯ï¼‰
            conv_id = self.conversation_logger.log_conversation(
                user_message=user_message,
                ai_response=ai_response or "[ç­‰å¾…å›å¤]"  # å¦‚æœæ²¡æœ‰å›å¤ï¼Œæ ‡è®°ä¸ºç­‰å¾…
            )
            print(f"  âœ… å¯¹è¯å·²ä¿å­˜: {conv_id}")

            # åˆ†æå¯¹è¯æƒ…ç»ªå¹¶æ›´æ–°ï¼ˆå¦‚æœæœ‰ AI å›å¤ï¼‰
            if ai_response:
                combined = user_message + " " + ai_response
                emotion = self.emotion_analyzer.analyze_emotion(combined)
                today = datetime.now().strftime('%Y-%m-%d')
                self.emotion_analyzer.update_timeline(today, emotion)
                emotion_updated = True

        # è¿”å›ç»“æœ
        return {
            'conversation_id': conv_id,
            'context': context,
            'emotion_updated': emotion_updated,
            'needs_response': ai_response is None
        }

    def generate_weekly_report(self) -> str:
        """
        ç”Ÿæˆæœ¬å‘¨åˆ†ææŠ¥å‘Š

        Returns:
            æŠ¥å‘Šæ–‡ä»¶è·¯å¾„
        """
        print("\nğŸ“Š ç”Ÿæˆå‘¨æŠ¥...")

        # 1. å¯¹è¯æ‘˜è¦
        conv_summary = self.conversation_logger.generate_weekly_summary()

        # 2. è·å–æœ¬å‘¨æ‰€æœ‰ chunks è¿›è¡Œåˆ†æ
        recent_chunks = self.retriever.get_recent(days=7, top_k=100)

        # 3. ç”Ÿæˆå­¦ä¹ æŠ¥å‘Š
        learning_report = self.thinking_analyzer.generate_learning_report(
            recent_chunks,
            period="æœ¬å‘¨"
        )

        print(f"âœ… æŠ¥å‘Šå·²ç”Ÿæˆ")
        print(f"  å¯¹è¯æ‘˜è¦: {conv_summary}")
        print(f"  å­¦ä¹ æŠ¥å‘Š: {learning_report}")

        return learning_report

    def get_system_stats(self) -> Dict:
        """
        è·å–ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯

        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        # å‘é‡åº“ç»Ÿè®¡
        db_stats = self.vector_indexer.get_stats()

        # æ ‡ç­¾ç»Ÿè®¡
        tag_stats = self.tag_indexer.get_tag_statistics()

        # æƒ…ç»ªçŠ¶æ€
        current_state = self.emotion_analyzer.get_current_state()

        return {
            'vector_db': db_stats,
            'tags': tag_stats,
            'current_state': current_state,
            'timestamp': datetime.now().isoformat()
        }


# ä¾¿æ·å‡½æ•°

def process_note(note_path: str, content: str) -> Dict:
    """
    ä¾¿æ·å‡½æ•°ï¼šå¤„ç†ç¬”è®°

    Args:
        note_path: ç¬”è®°è·¯å¾„
        content: ç¬”è®°å†…å®¹

    Returns:
        å¤„ç†ç»“æœ
    """
    orchestrator = AIPartnerOrchestrator()
    return orchestrator.process_new_note(note_path, content)


def handle_conversation_simple(user_msg: str, ai_msg: str) -> Dict:
    """
    ä¾¿æ·å‡½æ•°ï¼šå¤„ç†å¯¹è¯

    Args:
        user_msg: ç”¨æˆ·æ¶ˆæ¯
        ai_msg: AIå›å¤

    Returns:
        å¤„ç†ç»“æœ
    """
    orchestrator = AIPartnerOrchestrator()
    return orchestrator.handle_conversation(user_msg, ai_msg)


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # åˆå§‹åŒ–
    orch = AIPartnerOrchestrator()

    # ç¤ºä¾‹1: å¤„ç†ç¬”è®°
    result = orch.process_new_note(
        note_path="./notes/test.md",
        content="""# React Hooks å­¦ä¹ 

ä»Šå¤©å­¦ä¹ äº† useStateï¼Œç»ˆäºç†è§£äº†çŠ¶æ€æ›´æ–°çš„åŸç†ï¼

```javascript
const [count, setCount] = useState(0);
```

å¤ªå¥½äº†ï¼ŒåŸæ¥æ˜¯è¿™æ ·å·¥ä½œçš„ï¼
"""
    )
    print(f"\nå¤„ç†ç»“æœ: {result}")

    # ç¤ºä¾‹2: ç³»ç»Ÿç»Ÿè®¡
    stats = orch.get_system_stats()
    print(f"\nç³»ç»Ÿç»Ÿè®¡: {stats}")
