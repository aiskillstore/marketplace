{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-16T19:23:43.299Z",
    "slug": "bextuychiev-firecrawl-web",
    "source_url": "https://github.com/BexTuychiev/firecrawl-claude-code-skill/tree/main/",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "3.0.0",
    "source_type": "community",
    "content_hash": "aa3585c8af0fb38103d087ec29f326de26fb1981c566e1282b778f551faace1a",
    "tree_hash": "420cec8934f73dce58d1d33b7130f34e47d6ad82582968e7f0b6f0cdaac25184"
  },
  "skill": {
    "name": "firecrawl-web",
    "description": "Fetch web content, take screenshots, extract structured data, search the web, and crawl documentation sites. Use when the user needs current web information, asks to scrape a URL, wants a screenshot, needs to extract specific data from a page, or wants to learn about a framework or library.",
    "summary": "Fetch web content, take screenshots, extract structured data, search the web, and crawl documentatio...",
    "icon": "ðŸ”¥",
    "version": "1.0.0",
    "author": "BexTuychiev",
    "license": "MIT",
    "category": "data",
    "tags": [
      "web-scraping",
      "firecrawl",
      "screenshots",
      "data-extraction",
      "web-search"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": [
      "network",
      "filesystem",
      "env_access"
    ]
  },
  "security_audit": {
    "risk_level": "low",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "This skill provides legitimate web scraping functionality via Firecrawl API. The 120 static findings are overwhelmingly false positives caused by documentation examples showing bash commands, standard dotenv usage for API key management, and base64 decoding of API responses. Network and filesystem access are core intended features, not security risks.",
    "risk_factor_evidence": [
      {
        "factor": "network",
        "evidence": [
          {
            "file": "fc.py",
            "line_start": 8,
            "line_end": 8
          },
          {
            "file": "fc.py",
            "line_start": 36,
            "line_end": 36
          }
        ]
      },
      {
        "factor": "filesystem",
        "evidence": [
          {
            "file": "fc.py",
            "line_start": 45,
            "line_end": 46
          },
          {
            "file": "fc.py",
            "line_start": 149,
            "line_end": 150
          }
        ]
      },
      {
        "factor": "env_access",
        "evidence": [
          {
            "file": "fc.py",
            "line_start": 84,
            "line_end": 85
          }
        ]
      }
    ],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [
      {
        "title": "Reads API key from environment",
        "description": "The skill loads FIRECRAWL_API_KEY from .env files. This is expected behavior for API authentication.",
        "evidence": {
          "file": "fc.py",
          "line_start": 84,
          "line_end": 85
        }
      }
    ],
    "dangerous_patterns": [],
    "files_scanned": 5,
    "total_lines": 601,
    "audit_model": "claude",
    "audited_at": "2026-01-16T19:23:43.299Z"
  },
  "content": {
    "user_title": "Scrape websites and extract data with Firecrawl API",
    "value_statement": "Getting web content into your coding workflow is tedious and unreliable. This skill gives Claude instant access to any webpage as clean markdown, screenshots, structured data, or search results.",
    "seo_keywords": [
      "Firecrawl",
      "web scraping",
      "Claude Code",
      "Claude",
      "Codex",
      "screenshot capture",
      "data extraction",
      "web search",
      "documentation crawler",
      "markdown conversion"
    ],
    "actual_capabilities": [
      "Fetch any webpage as clean, LLM-ready markdown content",
      "Capture full-page screenshots of websites",
      "Extract structured data from pages using JSON schemas",
      "Search the web and return results with content summaries",
      "Crawl documentation sites to learn about frameworks",
      "Filter page content to exclude navigation and footers"
    ],
    "limitations": [
      "Requires a Firecrawl API key with available credits",
      "Cannot bypass login walls or access private content",
      "Crawling costs one credit per page which can add up quickly",
      "Some dynamic JavaScript content may not render correctly"
    ],
    "use_cases": [
      {
        "target_user": "Backend Developer",
        "title": "Research new framework documentation",
        "description": "Crawl the docs for a new library or framework to quickly understand its API and best practices without leaving your editor."
      },
      {
        "target_user": "Data Engineer",
        "title": "Extract product data from websites",
        "description": "Define a JSON schema and extract structured data like prices, titles, and features from product pages for analysis."
      },
      {
        "target_user": "Frontend Developer",
        "title": "Capture visual references of websites",
        "description": "Take screenshots of design inspiration or competitor sites to reference while building your UI components."
      }
    ],
    "prompt_templates": [
      {
        "title": "Get page content",
        "scenario": "Need to read a webpage's text content",
        "prompt": "Get the markdown content from https://example.com/docs/getting-started"
      },
      {
        "title": "Take a screenshot",
        "scenario": "Want to capture a visual of a website",
        "prompt": "Take a screenshot of https://example.com and save it as homepage.png"
      },
      {
        "title": "Extract structured data",
        "scenario": "Need specific fields from a product page",
        "prompt": "Extract the product name, price, and description from https://store.example.com/product/123 as JSON"
      },
      {
        "title": "Crawl documentation",
        "scenario": "Learning a new framework",
        "prompt": "Crawl the FastAPI documentation at https://fastapi.tiangolo.com and summarize the main concepts for building REST APIs"
      }
    ],
    "output_examples": [
      {
        "input": "Get the markdown from the Python 3.13 release notes",
        "output": [
          "Returns clean markdown with headings for each new feature",
          "Includes code examples from the documentation",
          "Removes navigation bars and footer content"
        ]
      },
      {
        "input": "Extract the price and title from this Amazon product page",
        "output": [
          "Product title: Wireless Bluetooth Headphones",
          "Price: $79.99",
          "Availability: In Stock"
        ]
      },
      {
        "input": "Search the web for React 19 new features",
        "output": [
          "Returns 5 relevant search results with titles and URLs",
          "Each result includes a description summary",
          "Results are ordered by relevance"
        ]
      }
    ],
    "best_practices": [
      "Set reasonable crawl limits to avoid burning through API credits quickly",
      "Use the --main-only flag to get cleaner content without navigation elements",
      "Create precise JSON schemas when extracting data for more accurate results"
    ],
    "anti_patterns": [
      "Avoid crawling entire large sites without setting a page limit",
      "Do not use this skill to bypass paywalls or access restricted content",
      "Avoid extracting data without a schema as results will be unstructured"
    ],
    "faq": [
      {
        "question": "How do I get a Firecrawl API key?",
        "answer": "Sign up at firecrawl.dev and generate an API key from your dashboard. Add it to your ~/.env file as FIRECRAWL_API_KEY."
      },
      {
        "question": "How much does each operation cost?",
        "answer": "Each scrape, screenshot, extract, or search costs 1 credit. Crawling costs 1 credit per page. Free tier includes 500 credits."
      },
      {
        "question": "Can this skill scrape JavaScript-heavy single-page applications?",
        "answer": "Yes, Firecrawl renders JavaScript before scraping. Most SPAs work correctly, though some dynamic content may require time to load."
      },
      {
        "question": "Why is my extracted data incomplete or incorrect?",
        "answer": "Add a prompt to guide extraction and ensure your JSON schema matches the page structure. Complex pages may need refined schemas."
      },
      {
        "question": "Can I crawl sites that require login?",
        "answer": "No, this skill cannot handle authenticated sessions. It only works with publicly accessible pages."
      },
      {
        "question": "Where are screenshots saved?",
        "answer": "Screenshots are saved to the path you specify with the -o flag. If no output path is given, a URL or base64 reference is returned."
      }
    ]
  },
  "file_structure": [
    {
      "name": "fc.py",
      "type": "file",
      "path": "fc.py",
      "lines": 162
    },
    {
      "name": "README.md",
      "type": "file",
      "path": "README.md",
      "lines": 74
    },
    {
      "name": "requirements.txt",
      "type": "file",
      "path": "requirements.txt",
      "lines": 3
    },
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md",
      "lines": 94
    }
  ]
}
