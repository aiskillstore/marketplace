{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-17T03:26:31.813Z",
    "slug": "diversioteam-process-code-review",
    "source_url": "https://github.com/DiversioTeam/agent-skills-marketplace/tree/main/plugins/process-code-review/skills/process-code-review",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "3.0.0",
    "source_type": "community",
    "content_hash": "573c8e89448bb05e4cd676f553945d948331712e0063854c2c9cf4fe8df2cda5",
    "tree_hash": "432a4ee4d3bdc33fc845d0a075cdea23f0746474b7f84c8f83a9d461fc2ac30c"
  },
  "skill": {
    "name": "process-code-review",
    "description": "Process code review findings interactively - fix or skip issues from monty-code-review output. Presents issues in severity order, applies fixes, runs quality checks, and updates review documents with status markers.\n",
    "summary": "Process code review findings interactively - fix or skip issues from monty-code-review output. Prese...",
    "icon": "ðŸ”§",
    "version": "1.0.0",
    "author": "DiversioTeam",
    "license": "MIT",
    "category": "coding",
    "tags": [
      "code-review",
      "refactoring",
      "quality-assurance",
      "interactive"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": [
      "filesystem",
      "external_commands"
    ]
  },
  "security_audit": {
    "risk_level": "medium",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "All 63 static findings are FALSE POSITIVES. The analyzer misinterpreted markdown documentation backticks as shell execution and content hash references as weak cryptography. The skill is legitimate documentation for code review processing with actual medium-risk factors being file modification and command execution, both requiring user confirmation.",
    "risk_factor_evidence": [
      {
        "factor": "filesystem",
        "evidence": [
          {
            "file": "SKILL.md",
            "line_start": 129,
            "line_end": 142
          }
        ]
      },
      {
        "factor": "external_commands",
        "evidence": [
          {
            "file": "SKILL.md",
            "line_start": 163,
            "line_end": 167
          }
        ]
      }
    ],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [
      {
        "title": "File modification based on external review documents",
        "description": "The skill modifies source files based on instructions from review documents. A malicious review file could instruct the skill to modify sensitive files.",
        "locations": [
          {
            "file": "SKILL.md",
            "line_start": 130,
            "line_end": 131
          }
        ]
      },
      {
        "title": "Command execution with user confirmation",
        "description": "The skill executes external commands (ruff, ty) based on review file instructions. User confirmation is required for each fix.",
        "locations": [
          {
            "file": "SKILL.md",
            "line_start": 163,
            "line_end": 166
          }
        ]
      }
    ],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 2,
    "total_lines": 549,
    "audit_model": "claude",
    "audited_at": "2026-01-17T03:26:31.813Z"
  },
  "content": {
    "user_title": "Process code review findings interactively",
    "value_statement": "Code reviews generate long lists of issues that are tedious to fix manually. This skill processes review documents systematically, letting you fix or skip each issue while tracking progress and running quality checks.",
    "seo_keywords": [
      "code review",
      "Claude Code",
      "interactive refactoring",
      "code quality",
      "review automation",
      "fix code issues",
      "Codex",
      "AI coding assistant",
      "systematic code fixes",
      "bug triage"
    ],
    "actual_capabilities": [
      "Parses review documents with severity-tagged issues",
      "Interactive fix or skip prompts for each issue",
      "Applies code fixes and runs quality checks automatically",
      "Updates review status with emoji markers",
      "Groups issues by severity: BLOCKING, SHOULD_FIX, NIT",
      "Integrates with ruff formatter and linter for Python"
    ],
    "limitations": [
      "Requires review documents from monty-code-review skill format",
      "Cannot fix issues without clear proposed solutions",
      "May need manual intervention for complex refactorings",
      "Quality checks depend on project-specific tooling availability"
    ],
    "use_cases": [
      {
        "target_user": "Senior developers",
        "title": "Process team code reviews efficiently",
        "description": "Systematically address review feedback from colleagues, fixing critical issues first while documenting skipped items."
      },
      {
        "target_user": "Tech leads",
        "title": "Manage large refactoring projects",
        "description": "Process automated review findings across multiple files, ensuring consistent fixes and quality standards."
      },
      {
        "target_user": "Junior developers",
        "title": "Learn from code review feedback",
        "description": "Work through review findings interactively, understanding each issue before applying suggested fixes."
      }
    ],
    "prompt_templates": [
      {
        "title": "Basic review processing",
        "scenario": "Process a review document interactively",
        "prompt": "Process the wellbeing_service_review.md file and help me fix the issues one by one."
      },
      {
        "title": "Auto-fix minor issues",
        "scenario": "Fix only NIT issues automatically",
        "prompt": "Use process-code-review to auto-fix all NIT issues in api_review.md but prompt me for BLOCKING and SHOULD_FIX items."
      },
      {
        "title": "Focus on critical issues",
        "scenario": "Address only blocking issues first",
        "prompt": "Process only the BLOCKING severity issues in the review document, I'll handle the rest later."
      },
      {
        "title": "Preview without changes",
        "scenario": "See what would be fixed",
        "prompt": "Show me all the issues in my_review.md with their proposed fixes but do not make any changes yet."
      }
    ],
    "output_examples": [
      {
        "input": "Process the authentication_review.md file and help me fix the issues",
        "output": [
          "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”",
          "[BLOCKING] Missing authentication check (1 of 5)",
          "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”",
          "Location: auth/middleware.py:L45-L52",
          "Current Code: if not user.is_authenticated: # No redirect",
          "Problem: Missing authentication redirect logic",
          "Proposed Fix: Add redirect to login page",
          "Fix this issue or skip it? > Fix",
          "Applied fix and ran quality checks",
          "",
          "Summary: 5 issues processed, 4 fixed, 1 skipped"
        ]
      },
      {
        "input": "Process the api_review.md file with dry-run to preview all changes",
        "output": [
          "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”",
          "DRY RUN MODE - No changes will be made",
          "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”",
          "Issue 1 of 8: [BLOCKING] N+1 Query Pattern",
          "Location: services/user.py:L45-L52",
          "Proposed Fix: Use prefetch_related for related objects",
          "Issue 2 of 8: [SHOULD_FIX] Missing type hint",
          "Location: schemas/user.py:L12",
          "Proposed Fix: Add -> dict return type annotation"
        ]
      }
    ],
    "best_practices": [
      "Always review the proposed fix before applying to understand the change",
      "Process BLOCKING issues first to address critical security and correctness problems",
      "Run pre-commit checks after processing to validate all changes"
    ],
    "anti_patterns": [
      "Auto-fixing all issues without reviewing each change carefully",
      "Processing reviews without understanding the codebase context",
      "Skipping quality checks after applying fixes"
    ],
    "faq": [
      {
        "question": "What review formats does this skill support?",
        "answer": "It supports review documents generated by the monty-code-review skill with severity tags like BLOCKING, SHOULD_FIX, and NIT."
      },
      {
        "question": "Can I undo changes if I make a mistake?",
        "answer": "The skill modifies files directly. Use your version control system to review and revert changes if needed."
      },
      {
        "question": "Does it work with any programming language?",
        "answer": "It works with any language supported by your projects quality tools. Python projects get the best integration with ruff."
      },
      {
        "question": "Is it safe to auto-fix all issues?",
        "answer": "Use auto-fix cautiously. It is safest for NIT issues. Always review BLOCKING and SHOULD_FIX changes before applying."
      },
      {
        "question": "What happens to skipped issues?",
        "answer": "Skipped issues are marked with status and reason in the review document for future reference."
      },
      {
        "question": "How does it integrate with my workflow?",
        "answer": "It is step 2 of a 3-step workflow: generate review with monty-code-review, process fixes, then run pre-commit checks."
      }
    ]
  },
  "file_structure": [
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md",
      "lines": 310
    }
  ]
}
