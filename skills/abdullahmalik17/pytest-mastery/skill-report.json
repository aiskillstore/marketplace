{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-16T16:04:24.930Z",
    "slug": "abdullahmalik17-pytest-mastery",
    "source_url": "https://github.com/AbdullahMalik17/Cloud-Native-AI/tree/main/.claude/skills/pytest-mastery",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "3.0.0",
    "source_type": "community",
    "content_hash": "28d0c39ef515a0fc9a3740a7421a720c45812c85afb0b6df61cabb0945f7cc42",
    "tree_hash": "5864c983c69af6d6021b5051623ee7e62c3e1a3aad2740752d09a3b3095b1aea"
  },
  "skill": {
    "name": "pytest-mastery",
    "description": "Python testing with pytest using uv package manager. Use when: (1) Running Python tests, (2) Writing test files or test functions, (3) Setting up fixtures, (4) Parametrizing tests, (5) Generating coverage reports, (6) Testing FastAPI applications, (7) Debugging test failures, (8) Configuring pytest options. Triggers: \"run tests\", \"write tests\", \"test coverage\", \"pytest\", \"unit test\", \"integration test\", \"test FastAPI\".\n",
    "summary": "Python testing with pytest using uv package manager. Use when: (1) Running Python tests, (2) Writing...",
    "icon": "ðŸ§ª",
    "version": "1.0.0",
    "author": "AbdullahMalik17",
    "license": "MIT",
    "category": "coding",
    "tags": [
      "pytest",
      "testing",
      "python",
      "uv",
      "fastapi"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": [
      "scripts",
      "external_commands"
    ]
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "This is a legitimate testing documentation skill. Static analyzer flagged 110 issues, but all are false positives: markdown code fences were mistaken for shell backticks, and keywords in test examples triggered crypto/network patterns. The actual code is a pytest runner that executes tests locally with hardcoded arguments.",
    "risk_factor_evidence": [
      {
        "factor": "scripts",
        "evidence": [
          {
            "file": "scripts/run_tests.py",
            "line_start": 1,
            "line_end": 72
          }
        ]
      },
      {
        "factor": "external_commands",
        "evidence": [
          {
            "file": "scripts/run_tests.py",
            "line_start": 28,
            "line_end": 32
          }
        ]
      }
    ],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 4,
    "total_lines": 801,
    "audit_model": "claude",
    "audited_at": "2026-01-16T16:04:24.930Z"
  },
  "content": {
    "user_title": "Write and run Python tests with pytest",
    "value_statement": "Writing tests for Python applications can be confusing without guidance on fixtures, parametrization, and coverage tools. This skill provides ready-to-use pytest patterns including FastAPI testing, fixtures, and coverage reporting.",
    "seo_keywords": [
      "pytest testing",
      "Python testing",
      "pytest fixtures",
      "pytest parametrization",
      "test coverage",
      "uv package manager",
      "FastAPI testing",
      "Claude Code testing",
      "unit tests",
      "integration tests"
    ],
    "actual_capabilities": [
      "Run pytest tests with uv package manager",
      "Create and use pytest fixtures with different scopes",
      "Parametrize tests with multiple inputs",
      "Generate coverage reports in multiple formats",
      "Test FastAPI applications with TestClient and httpx",
      "Debug test failures with pytest options"
    ],
    "limitations": [
      "Does not generate test code from specifications",
      "Does not integrate with CI/CD pipelines",
      "Does not perform snapshot testing"
    ],
    "use_cases": [
      {
        "target_user": "Python developers",
        "title": "Add tests to Python projects",
        "description": "Set up pytest with fixtures and parametrization for Python libraries and applications"
      },
      {
        "target_user": "FastAPI developers",
        "title": "Test FastAPI endpoints",
        "description": "Write integration tests for FastAPI endpoints using TestClient and async testing patterns"
      },
      {
        "target_user": "QA engineers",
        "title": "Generate coverage reports",
        "description": "Run tests with coverage analysis and generate HTML or XML reports for CI/CD pipelines"
      }
    ],
    "prompt_templates": [
      {
        "title": "Run basic tests",
        "scenario": "Running pytest with uv",
        "prompt": "Run all pytest tests with uv package manager"
      },
      {
        "title": "Create fixture",
        "scenario": "Setting up test fixtures",
        "prompt": "Create a pytest fixture for database connection with proper teardown"
      },
      {
        "title": "Parametrize tests",
        "scenario": "Running same test with multiple inputs",
        "prompt": "Write a parametrized test that checks multiple input combinations"
      },
      {
        "title": "Coverage report",
        "scenario": "Generating test coverage",
        "prompt": "Run pytest with coverage and generate an HTML coverage report"
      }
    ],
    "output_examples": [
      {
        "input": "Run pytest tests with coverage",
        "output": [
          "Running: uv run pytest --cov=src --cov-report=html",
          "Coverage report generated in htmlcov/",
          "View report: open htmlcov/index.html"
        ]
      },
      {
        "input": "Create a test fixture for API client",
        "output": [
          "Created fixture in tests/conftest.py",
          "Use @pytest.fixture decorator",
          "Scope defaults to function, use scope=\"session\" for shared"
        ]
      },
      {
        "input": "Write a test that checks multiple inputs",
        "output": [
          "Use @pytest.mark.parametrize decorator",
          "Define test cases as list of tuples",
          "pytest runs the test once per input"
        ]
      }
    ],
    "best_practices": [
      "Use fixtures for reusable test setup instead of repeating initialization code",
      "Run coverage reports regularly to identify untested code paths",
      "Use parametrization to test multiple input cases with a single test function"
    ],
    "anti_patterns": [
      "Avoid hardcoding test data directly in test functions",
      "Do not skip fixture scopes without considering resource usage",
      "Avoid mixing unit and integration tests in the same test suite without markers"
    ],
    "faq": [
      {
        "question": "Which Python versions support pytest?",
        "answer": "pytest supports Python 3.8+ and works with uv package manager on all major platforms."
      },
      {
        "question": "What is the maximum test count per run?",
        "answer": "pytest runs all discovered tests. For large projects, use markers or parallel execution with pytest-xdist."
      },
      {
        "question": "Does this skill integrate with CI/CD tools?",
        "answer": "Commands can be run in any CI/CD pipeline that supports Python and uv. Use --tb=short for cleaner logs."
      },
      {
        "question": "Is test data stored or transmitted?",
        "answer": "All tests run locally. Coverage reports are generated locally and never leave the machine."
      },
      {
        "question": "Why are my tests not being discovered?",
        "answer": "Ensure files match test_*.py or *_test.py pattern. Functions must start with test_ and classes with Test*."
      },
      {
        "question": "How does this compare to unittest?",
        "answer": "pytest offers simpler syntax, powerful fixtures, parametrization, and better reporting compared to Python's built-in unittest."
      }
    ]
  },
  "file_structure": [
    {
      "name": "references",
      "type": "dir",
      "path": "references",
      "children": [
        {
          "name": "fastapi-testing.md",
          "type": "file",
          "path": "references/fastapi-testing.md",
          "lines": 266
        }
      ]
    },
    {
      "name": "scripts",
      "type": "dir",
      "path": "scripts",
      "children": [
        {
          "name": "run_tests.py",
          "type": "file",
          "path": "scripts/run_tests.py",
          "lines": 72
        }
      ]
    },
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md",
      "lines": 240
    }
  ]
}
