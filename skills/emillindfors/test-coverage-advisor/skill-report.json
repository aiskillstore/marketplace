{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-23T02:37:00.442Z",
    "slug": "emillindfors-test-coverage-advisor",
    "source_url": "https://github.com/EmilLindfors/claude-marketplace/tree/main/plugins/rust-testing/skills/test-coverage-advisor",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "3.0.0",
    "source_type": "community",
    "content_hash": "4fdf2045e97fd396a1b1d919786091d23877972f781f92e414917b2d6c4298e2",
    "tree_hash": "de995c7e22df8fd7209d28a84b4c8f9922193b14fd9fbbeda809d2473efa5200"
  },
  "skill": {
    "name": "test-coverage-advisor",
    "description": "Reviews test coverage and suggests missing test cases for error paths, edge cases, and business logic. Activates when users write tests or implement new features.",
    "summary": "Reviews test coverage and suggests missing test cases for error paths, edge cases, and business logic.",
    "icon": "ðŸ“¦",
    "version": "1.0.0",
    "author": "EmilLindfors",
    "license": "MIT",
    "tags": [
      "testing",
      "rust",
      "code-quality",
      "test-coverage"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": [
      "external_commands"
    ]
  },
  "security_audit": {
    "risk_level": "low",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "Static scanner flagged patterns in documentation code examples. All findings are FALSE POSITIVES. The 'external_commands' detections are markdown code fences showing Rust test patterns, not actual shell execution. 'Weak cryptographic algorithm' and 'System reconnaissance' flagged legitimate test case data and documentation. No executable code exists in this skill.",
    "risk_factor_evidence": [
      {
        "factor": "external_commands",
        "evidence": [
          {
            "file": "SKILL.md",
            "line_start": 27,
            "line_end": 34
          },
          {
            "file": "SKILL.md",
            "line_start": 41,
            "line_end": 53
          },
          {
            "file": "SKILL.md",
            "line_start": 57,
            "line_end": 84
          },
          {
            "file": "SKILL.md",
            "line_start": 87,
            "line_end": 101
          },
          {
            "file": "SKILL.md",
            "line_start": 117,
            "line_end": 135
          },
          {
            "file": "SKILL.md",
            "line_start": 143,
            "line_end": 156
          },
          {
            "file": "SKILL.md",
            "line_start": 164,
            "line_end": 178
          },
          {
            "file": "SKILL.md",
            "line_start": 182,
            "line_end": 204
          },
          {
            "file": "SKILL.md",
            "line_start": 210,
            "line_end": 224
          },
          {
            "file": "SKILL.md",
            "line_start": 228,
            "line_end": 241
          },
          {
            "file": "SKILL.md",
            "line_start": 245,
            "line_end": 263
          },
          {
            "file": "SKILL.md",
            "line_start": 281,
            "line_end": 320
          }
        ]
      }
    ],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [
      {
        "title": "False Positive: External Command Detection in Documentation",
        "description": "Scanner detected 'Ruby/shell backtick execution' in SKILL.md code fences. These are markdown documentation showing Rust test patterns, not actual shell commands. The backticks are code fence delimiters.",
        "locations": [
          {
            "file": "SKILL.md",
            "line_start": 27,
            "line_end": 34
          },
          {
            "file": "SKILL.md",
            "line_start": 57,
            "line_end": 84
          },
          {
            "file": "SKILL.md",
            "line_start": 117,
            "line_end": 135
          },
          {
            "file": "SKILL.md",
            "line_start": 143,
            "line_end": 156
          },
          {
            "file": "SKILL.md",
            "line_start": 182,
            "line_end": 204
          },
          {
            "file": "SKILL.md",
            "line_start": 281,
            "line_end": 320
          }
        ],
        "verdict": "FALSE_POSITIVE",
        "confidence": 0.95,
        "confidence_reasoning": "Content is static markdown documentation with Rust code examples. No actual shell commands or Ruby execution occurs. Code fences use backticks for formatting, not execution."
      },
      {
        "title": "False Positive: Weak Cryptographic Algorithm Detection",
        "description": "Scanner flagged 'description' field in test case tuples as 'weak cryptographic algorithm'. This is legitimate test data for email validation testing.",
        "locations": [
          {
            "file": "SKILL.md",
            "line_start": 3,
            "line_end": 3
          },
          {
            "file": "SKILL.md",
            "line_start": 193,
            "line_end": 193
          },
          {
            "file": "SKILL.md",
            "line_start": 200,
            "line_end": 200
          }
        ],
        "verdict": "FALSE_POSITIVE",
        "confidence": 0.98,
        "confidence_reasoning": "Scanner incorrectly identified the word 'description' as a cryptographic algorithm. This is test case metadata in table-driven tests, not crypto code."
      },
      {
        "title": "False Positive: System Reconnaissance Detection",
        "description": "Scanner flagged email test case data as 'system reconnaissance'. These are legitimate test inputs for email validation examples.",
        "locations": [
          {
            "file": "SKILL.md",
            "line_start": 185,
            "line_end": 186
          }
        ],
        "verdict": "FALSE_POSITIVE",
        "confidence": 0.98,
        "confidence_reasoning": "Test case data for email validation table-driven tests. 'test@example.com' and 'user@domain.org' are standard test fixtures, not reconnaissance targets."
      }
    ],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 1,
    "total_lines": 337,
    "audit_model": "claude",
    "audited_at": "2026-01-23T02:37:00.442Z"
  },
  "content": {
    "user_title": "Improve Rust test coverage",
    "value_statement": "Writing comprehensive tests for Rust code can be time-consuming and error-prone. This skill proactively identifies missing test cases for error paths, edge cases, and business logic so you can write better tests faster.",
    "seo_keywords": [
      "test coverage",
      "Rust testing",
      "Claude Code",
      "Claude",
      "Codex",
      "test automation",
      "code quality",
      "unit tests",
      "integration tests",
      "software testing"
    ],
    "actual_capabilities": [
      "Reviews existing test coverage and identifies gaps in error path testing",
      "Suggests specific test cases for edge cases and boundary conditions",
      "Provides ready-to-use Rust test code examples",
      "Recommends table-driven test patterns for multiple similar test cases",
      "Identifies anti-patterns in test code and suggests improvements",
      "Links to Rust coverage tools like cargo-tarpaulin"
    ],
    "limitations": [
      "Only provides guidance for Rust testing patterns",
      "Does not execute tests or modify code directly",
      "Cannot analyze project-specific business logic without user context",
      "Coverage suggestions are based on common patterns, not formal analysis"
    ],
    "use_cases": [
      {
        "title": "Junior developer learning Rust testing",
        "description": "Get guidance on writing comprehensive tests including error cases, edge cases, and proper test organization. Learn testing best practices through concrete examples.",
        "target_user": "Developers new to Rust or testing"
      },
      {
        "title": "Improving legacy test coverage",
        "description": "Identify untested error paths and missing edge cases in existing code. Receive specific suggestions for tests to add with ready-to-use code patterns.",
        "target_user": "Engineers maintaining or improving existing test suites"
      },
      {
        "title": "Code review quality checks",
        "description": "During code reviews, verify that new implementations have adequate test coverage. Point out missing test patterns before merging changes.",
        "target_user": "Team leads and code reviewers"
      }
    ],
    "prompt_templates": [
      {
        "title": "Basic test review request",
        "prompt": "I just wrote a function that returns Result<T, Error>. Can you check if my tests cover all error cases and suggest any missing tests?",
        "scenario": "User wants feedback on error path testing"
      },
      {
        "title": "Edge case identification",
        "prompt": "I'm testing a function that processes a Vec of items. What edge cases should I test for empty collections, single items, and large inputs?",
        "scenario": "User wants to know what edge cases to test"
      },
      {
        "title": "Async function testing",
        "prompt": "I have an async function that makes database queries. What tests should I write for success, not found, and connection error cases?",
        "scenario": "User needs guidance on async testing patterns"
      },
      {
        "title": "Test organization review",
        "prompt": "My test file is getting large and disorganized. Can you suggest how to structure tests using mod blocks and table-driven patterns?",
        "scenario": "User wants to improve test organization"
      }
    ],
    "output_examples": [
      {
        "input": "I wrote a validate_email function that returns Result<(), ValidationError> with Empty and InvalidFormat variants.",
        "output": [
          "I see you're returning Result from validate_email. Here are the tests you should add:",
          "",
          "1. test_validate_email_empty - Test empty string returns ValidationError::Empty",
          "2. test_validate_email_missing_at - Test 'invalid' returns ValidationError::InvalidFormat",
          "3. test_validate_email_no_domain - Test 'test@' returns ValidationError::InvalidFormat",
          "4. test_validate_email_success - Test valid email returns Ok(())",
          "",
          "Consider using a table-driven test for these similar cases."
        ]
      },
      {
        "input": "What should I test for a function that processes a list of up to 1000 items?",
        "output": [
          "Key edge cases to test:",
          "",
          "- Empty list: process_items(vec![]) should return empty result",
          "- Single item: process_items(vec![item]) should return list with one item",
          "- Maximum size: process_items(vec![item; 1000]) should handle max capacity",
          "- Large input: Consider performance testing with 1000+ items",
          "- Nil/None handling if your function uses Option"
        ]
      }
    ],
    "best_practices": [
      "Test error paths explicitly - do not assume success cases cover all scenarios",
      "Use table-driven tests when testing multiple variations of the same behavior",
      "Organize tests using mod blocks: success, errors, and edge_cases modules",
      "Focus tests on public API behavior rather than implementation details"
    ],
    "anti_patterns": [
      "Testing private implementation details instead of public behavior",
      "Writing tests without assertions - what are you actually verifying?",
      "Creating overly complex tests that try to verify too much in one function",
      "Forgetting to test boundary conditions like empty inputs, zero values, and max values"
    ],
    "faq": [
      {
        "question": "What tools does this skill recommend for measuring test coverage?",
        "answer": "The skill references cargo-tarpaulin for HTML coverage reports and cargo-llvm-cov for LLVM-based coverage analysis with HTML output."
      },
      {
        "question": "Can this skill write tests for me?",
        "answer": "No. The skill provides specific test suggestions with code examples, but you must add the tests to your codebase yourself."
      },
      {
        "question": "Does this skill work with testing frameworks other than the standard library?",
        "answer": "Yes. Examples show standard library patterns, but suggestions apply to rstest, proptest, and other Rust testing frameworks."
      },
      {
        "question": "How does this skill detect missing tests?",
        "answer": "The skill analyzes code patterns like Result/Option returns and identifies when corresponding error/None test cases are missing."
      },
      {
        "question": "Can I use this skill for integration tests?",
        "answer": "The skill focuses on unit testing patterns. Integration test guidance is limited to async testing concepts for repository patterns."
      },
      {
        "question": "What Rust version requirements exist?",
        "answer": "Examples use stable Rust patterns. Async tests assume tokio or a compatible async runtime. No specific version requirements."
      }
    ]
  },
  "file_structure": [
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md",
      "lines": 337
    }
  ]
}
