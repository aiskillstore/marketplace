{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-16T22:13:50.656Z",
    "slug": "consiliency-model-discovery",
    "source_url": "https://github.com/Consiliency/treesitter-chunker/tree/main/.ai-dev-kit/skills/model-discovery",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "3.0.0",
    "source_type": "community",
    "content_hash": "f73ea63fc67eec8feec9c0cecd5c4f3f51f621ba54064af4295cfd86fbb2f8b0",
    "tree_hash": "29d106afb11fb98901d61e9e1d706154b52f7ca73589abd319aeb1a2e27dd515"
  },
  "skill": {
    "name": "model-discovery",
    "description": "Fetch current model names from AI providers (Anthropic, OpenAI, Gemini, Ollama), classify them into tiers (fast/default/heavy), and detect new models. Use when needing up-to-date model IDs for API calls or when other skills reference model names.",
    "summary": "Fetch current model names from AI providers (Anthropic, OpenAI, Gemini, Ollama), classify them into ...",
    "icon": "üîç",
    "version": "1.0.0",
    "author": "Consiliency",
    "license": "MIT",
    "category": "data",
    "tags": [
      "ai models",
      "model discovery",
      "api integration",
      "classification",
      "model tiers"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": [
      "external_commands",
      "network",
      "env_access"
    ]
  },
  "security_audit": {
    "risk_level": "low",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "This is a benign utility skill for discovering and classifying AI model names. The static scanner flagged 320 issues, but ALL are false positives. The skill fetches model lists from legitimate provider APIs (Anthropic, OpenAI, Google, Ollama) using curl/subprocess. All credential access is via environment variable names (documentation only), not actual values. The cookbook files contain markdown documentation with example curl commands (not executed code). No data exfiltration, no credential theft, no malicious behavior.",
    "risk_factor_evidence": [
      {
        "factor": "external_commands",
        "evidence": [
          {
            "file": "scripts/fetch_models.py",
            "line_start": 78,
            "line_end": 87
          },
          {
            "file": "scripts/fetch_models.py",
            "line_start": 120,
            "line_end": 128
          }
        ]
      },
      {
        "factor": "network",
        "evidence": [
          {
            "file": "cookbook/anthropic-models.md",
            "line_start": 8,
            "line_end": 9
          },
          {
            "file": "cookbook/openai-models.md",
            "line_start": 8,
            "line_end": 8
          }
        ]
      },
      {
        "factor": "env_access",
        "evidence": [
          {
            "file": "config/model_tiers.json",
            "line_start": 25,
            "line_end": 25
          },
          {
            "file": "scripts/fetch_models.py",
            "line_start": 73,
            "line_end": 75
          }
        ]
      }
    ],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 11,
    "total_lines": 2164,
    "audit_model": "claude",
    "audited_at": "2026-01-16T22:13:50.656Z"
  },
  "content": {
    "user_title": "Discover and classify AI models",
    "value_statement": "AI model names change frequently. This skill fetches current model lists from Anthropic, OpenAI, Gemini, and Ollama, then classifies them by performance tier for optimal model selection.",
    "seo_keywords": [
      "Claude models",
      "GPT models",
      "Gemini models",
      "Ollama models",
      "model discovery",
      "AI model tier",
      "Claude Code",
      "Claude",
      "Codex",
      "model selection"
    ],
    "actual_capabilities": [
      "Fetch model lists from Anthropic, OpenAI, Gemini, and Ollama APIs",
      "Classify models into fast, default, and heavy performance tiers",
      "Detect newly released models automatically",
      "Cache results for 24 hours to reduce API calls",
      "Auto-classify new models using naming pattern matching"
    ],
    "limitations": [
      "Requires valid API keys for cloud providers (Anthropic, OpenAI, Google)",
      "Local Ollama must be running to fetch local models",
      "Tier classification is pattern-based and may not reflect actual performance",
      "Does not execute code with discovered models"
    ],
    "use_cases": [
      {
        "target_user": "AI Developer",
        "title": "Update model references",
        "description": "Replace hardcoded model names with current alternatives before API calls"
      },
      {
        "target_user": "CI/CD Pipeline",
        "title": "Automated testing",
        "description": "Check for new models in deployment scripts and update model selectors"
      },
      {
        "target_user": "Researcher",
        "title": "Model comparison",
        "description": "Browse available models across providers and compare capabilities"
      }
    ],
    "prompt_templates": [
      {
        "title": "List all models",
        "scenario": "Get current model list",
        "prompt": "Fetch all available models from all providers using the model-discovery skill"
      },
      {
        "title": "Check for new models",
        "scenario": "Detect new releases",
        "prompt": "Check if any new models have been released by running the new model detection script"
      },
      {
        "title": "Get fast tier model",
        "scenario": "Speed-optimized selection",
        "prompt": "Find the fastest available model for simple tasks from the model-discovery tier mappings"
      },
      {
        "title": "Classify new model",
        "scenario": "Assign tier to new model",
        "prompt": "Auto-classify any newly detected models and add them to the known models registry"
      }
    ],
    "output_examples": [
      {
        "input": "Fetch all models from Anthropic and OpenAI",
        "output": [
          "Anthropic: claude-haiku-4-5 (fast), claude-sonnet-4-5 (default), claude-opus-4-5 (heavy)",
          "OpenAI: gpt-5.2-mini (fast), gpt-5.2 (default), gpt-5.2-pro (heavy)",
          "No new models detected"
        ]
      },
      {
        "input": "Check for new models",
        "output": [
          "Found 2 new model(s):",
          "OpenAI: gpt-5.2-codex-mini (suggested: fast), gpt-5.2-codex-max (suggested: heavy)",
          "Run check_new_models.py to classify"
        ]
      }
    ],
    "best_practices": [
      "Run fetch_models.py before any workflow that references model names",
      "Use tier classification to match model capability to task complexity",
      "Keep API keys in environment variables, never hardcode them"
    ],
    "anti_patterns": [
      "Hardcoding model version numbers without checking current availability",
      "Using the same model tier for all tasks regardless of complexity",
      "Skipping new model detection after initial setup"
    ],
    "faq": [
      {
        "question": "Which AI providers are supported?",
        "answer": "Anthropic Claude, OpenAI GPT, Google Gemini, and local Ollama are supported with API key or local server."
      },
      {
        "question": "How often does the cache refresh?",
        "answer": "Cache refreshes every 24 hours by default. Use --force flag to bypass cache and fetch fresh data."
      },
      {
        "question": "Can this skill execute code with the models?",
        "answer": "No. This skill only discovers and classifies model names. It does not make API calls to generate content."
      },
      {
        "question": "Is my API key data safe?",
        "answer": "API keys are read from environment variables only. No keys are stored, logged, or transmitted beyond provider APIs."
      },
      {
        "question": "What if a provider API is down?",
        "answer": "Errors are reported in output but do not block other providers. Cached data can be used when APIs are unavailable."
      },
      {
        "question": "How is tier classification determined?",
        "answer": "Tier classification uses pattern matching on model names. Heavy models contain -pro, -opus, or -max. Fast models contain -mini, -nano, or -flash."
      }
    ]
  },
  "file_structure": [
    {
      "name": "cache",
      "type": "dir",
      "path": "cache",
      "children": [
        {
          "name": "models.json",
          "type": "file",
          "path": "cache/models.json",
          "lines": 156
        }
      ]
    },
    {
      "name": "config",
      "type": "dir",
      "path": "config",
      "children": [
        {
          "name": "known_models.json",
          "type": "file",
          "path": "config/known_models.json",
          "lines": 126
        },
        {
          "name": "model_tiers.json",
          "type": "file",
          "path": "config/model_tiers.json",
          "lines": 219
        }
      ]
    },
    {
      "name": "cookbook",
      "type": "dir",
      "path": "cookbook",
      "children": [
        {
          "name": "anthropic-models.md",
          "type": "file",
          "path": "cookbook/anthropic-models.md",
          "lines": 96
        },
        {
          "name": "gemini-models.md",
          "type": "file",
          "path": "cookbook/gemini-models.md",
          "lines": 118
        },
        {
          "name": "ollama-models.md",
          "type": "file",
          "path": "cookbook/ollama-models.md",
          "lines": 158
        },
        {
          "name": "openai-models.md",
          "type": "file",
          "path": "cookbook/openai-models.md",
          "lines": 106
        }
      ]
    },
    {
      "name": "scripts",
      "type": "dir",
      "path": "scripts",
      "children": [
        {
          "name": "check_new_models.py",
          "type": "file",
          "path": "scripts/check_new_models.py",
          "lines": 335
        },
        {
          "name": "fetch_models.py",
          "type": "file",
          "path": "scripts/fetch_models.py",
          "lines": 368
        }
      ]
    },
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md",
      "lines": 235
    }
  ]
}
