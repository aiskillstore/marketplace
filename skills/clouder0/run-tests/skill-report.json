{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-16T22:28:27.574Z",
    "slug": "clouder0-run-tests",
    "source_url": "https://github.com/Clouder0/dotagent/tree/main/.claude/skills/project/run-tests",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "3.0.0",
    "source_type": "community",
    "content_hash": "ba66264c42c6991912a68e4952bca5c3e55f79856c6a6f116e972a01c81573a9",
    "tree_hash": "ecfa4fd0c05939e5bd163f7f7d7ad769ecbedae9df26ffa980745c222eddbe2e"
  },
  "skill": {
    "name": "run-tests",
    "description": "How to run tests in this project. Load when implementing or verifying code.",
    "summary": "How to run tests in this project. Load when implementing or verifying code.",
    "icon": "ðŸ§ª",
    "version": "1.0.1",
    "author": "Clouder0",
    "license": "MIT",
    "category": "coding",
    "tags": [
      "testing",
      "bun",
      "pytest",
      "typescript",
      "python"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": [
      "network",
      "filesystem",
      "external_commands"
    ]
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "This skill is pure documentation containing only test command examples in markdown format. No executable code, no network calls, no file modifications. The static scanner triggered false positives on documentation metadata (URLs, hashes) and markdown code blocks. All findings are dismissible as documentation artifacts, not security risks.",
    "risk_factor_evidence": [
      {
        "factor": "network",
        "evidence": [
          {
            "file": "skill-report.json",
            "line_start": 6,
            "line_end": 6
          }
        ]
      },
      {
        "factor": "filesystem",
        "evidence": [
          {
            "file": "skill-report.json",
            "line_start": 6,
            "line_end": 6
          }
        ]
      },
      {
        "factor": "external_commands",
        "evidence": [
          {
            "file": "SKILL.md",
            "line_start": 13,
            "line_end": 28
          },
          {
            "file": "SKILL.md",
            "line_start": 28,
            "line_end": 32
          },
          {
            "file": "SKILL.md",
            "line_start": 32,
            "line_end": 32
          },
          {
            "file": "SKILL.md",
            "line_start": 32,
            "line_end": 33
          },
          {
            "file": "SKILL.md",
            "line_start": 33,
            "line_end": 37
          },
          {
            "file": "SKILL.md",
            "line_start": 37,
            "line_end": 40
          }
        ]
      }
    ],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 2,
    "total_lines": 125,
    "audit_model": "claude",
    "audited_at": "2026-01-16T22:28:27.574Z"
  },
  "content": {
    "user_title": "Run project tests with Bun or pytest",
    "value_statement": "Writing tests is essential but running them manually wastes time. This skill provides ready-to-use commands for executing test suites with Bun for JavaScript or pytest for Python projects.",
    "seo_keywords": [
      "run tests",
      "bun test",
      "pytest",
      "claude code",
      "test runner",
      "typescript testing",
      "python testing",
      "codex",
      "claude",
      "software testing"
    ],
    "actual_capabilities": [
      "Run all tests in a TypeScript or JavaScript project with Bun",
      "Run all tests in a Python project with pytest",
      "Execute specific test files by path",
      "Run tests matching a pattern or filter",
      "Generate test coverage reports",
      "Display verbose test output"
    ],
    "limitations": [
      "Commands must be customized for each project",
      "Requires Bun installed for JavaScript tests",
      "Requires uv and pytest installed for Python tests",
      "Does not write or modify test files"
    ],
    "use_cases": [
      {
        "target_user": "Frontend developers",
        "title": "Run JS/TS tests",
        "description": "Quickly execute all Bun tests or specific test files for JavaScript projects"
      },
      {
        "target_user": "Python developers",
        "title": "Run Python tests",
        "description": "Run pytest suites with coverage reports for Python projects using uv"
      },
      {
        "target_user": "AI agents",
        "title": "Automated testing",
        "description": "Integrate test execution into development workflows and agent tasks"
      }
    ],
    "prompt_templates": [
      {
        "title": "Basic test run",
        "scenario": "Run all tests",
        "prompt": "Run all tests for this project"
      },
      {
        "title": "Specific test",
        "scenario": "Run one test file",
        "prompt": "Run tests for the Button component"
      },
      {
        "title": "Filtered tests",
        "scenario": "Match test pattern",
        "prompt": "Run tests matching \"user authentication\""
      },
      {
        "title": "With coverage",
        "scenario": "Generate coverage report",
        "prompt": "Run all tests with coverage report"
      }
    ],
    "output_examples": [
      {
        "input": "Run all tests for this project",
        "output": [
          "All tests passed",
          "24 tests passed in 2.5 seconds",
          "Coverage: 85%"
        ]
      },
      {
        "input": "Run tests matching user authentication",
        "output": [
          "7 tests matched the filter",
          "2 passed, 1 failed",
          "Failed: login_with_valid_credentials"
        ]
      },
      {
        "input": "Run tests with coverage report",
        "output": [
          "Test coverage: 78%",
          "Uncovered: src/utils/helper.ts",
          "Lines 15-23 need additional tests"
        ]
      }
    ],
    "best_practices": [
      "Customize the SKILL.md file with your project-specific test commands",
      "Run tests after every code change to catch issues early",
      "Use coverage reports to identify untested code paths"
    ],
    "anti_patterns": [
      "Running tests without checking the exit code",
      "Ignoring test failures and continuing development",
      "Running the entire test suite when a single module was modified"
    ],
    "faq": [
      {
        "question": "Which test frameworks are supported?",
        "answer": "Bun test for JavaScript and pytest for Python. Add your own commands for other frameworks like Jest or Vitest."
      },
      {
        "question": "What do test exit codes mean?",
        "answer": "Exit code 0 means all tests passed. Exit code 1 means one or more tests failed."
      },
      {
        "question": "Can I use other test runners?",
        "answer": "Yes. Edit SKILL.md to add commands for Jest, Vitest, unittest, or any framework you use."
      },
      {
        "question": "Is my data safe when running tests?",
        "answer": "Yes. This skill only executes tests. It does not read, transmit, or store data outside your project."
      },
      {
        "question": "How do I debug failing tests?",
        "answer": "Run tests with verbose mode to see detailed output. Check the specific test file and error messages."
      },
      {
        "question": "How is this skill different from others?",
        "answer": "This skill is project-specific and customizable. It contains the exact commands your project needs."
      }
    ]
  },
  "file_structure": [
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md",
      "lines": 48
    }
  ]
}
