{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-10T09:39:41.348Z",
    "slug": "acskamloops-land-reduction-trespass",
    "source_url": "https://github.com/ACSKamloops/shs-engine/tree/master/.codex/skills/land-reduction-trespass",
    "source_ref": "master",
    "model": "claude",
    "analysis_version": "2.0.0",
    "source_type": "community",
    "content_hash": "cb11c07c31d72ad3954e18cce75ddb0633b0c5f6ab978189a26d10ea8251c9a8",
    "tree_hash": "9754986aa7d6fd3dcb694e362c7ff6b9a411e5285e47cb4f018c8bb1f9ce9693"
  },
  "skill": {
    "name": "land-reduction-trespass",
    "description": "Clerk for reserve reduction, trespass, survey errors, and railway takings; use when processing the Land_Reduction_Trespass queue.",
    "summary": "Clerk for reserve reduction, trespass, survey errors, and railway takings; use when processing the L...",
    "icon": "ðŸ“œ",
    "version": "1.0.0",
    "author": "ACSKamloops",
    "license": "UNLICENSED",
    "category": "documentation",
    "tags": [
      "legal",
      "historical",
      "research",
      "transcription",
      "indexing"
    ],
    "supported_tools": [
      "codex"
    ],
    "risk_factors": []
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "Prompt-only skill containing only AI instructions. No executable code, no network calls, no file system access beyond standard AI tool capabilities. The skill is a documentation/transcription workflow guide.",
    "risk_factor_evidence": [],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 1,
    "total_lines": 163,
    "audit_model": "claude",
    "audited_at": "2026-01-10T09:39:41.348Z"
  },
  "content": {
    "user_title": "Transcribe land reduction evidence",
    "value_statement": "Process historical documents related to reserve reductions, settler encroachment, and railway takings. The skill ensures legal-grade transcription with metadata extraction and provenance verification.",
    "seo_keywords": [
      "Codex skill",
      "land records",
      "historical transcription",
      "reserve reduction",
      "trespass documentation",
      "legal-grade",
      "document indexing",
      "Canadian history",
      "Indigenous land claims",
      "Codex"
    ],
    "actual_capabilities": [
      "Transcribe historical land and trespass documents with legal-grade accuracy",
      "Extract metadata including dates, titles, and document IDs",
      "Verify provenance and document reliability",
      "Identify key evidence quotes from source texts",
      "Flag corrupt, irrelevant, or OCR-failed documents",
      "Follow context refresh protocol to prevent AI hallucination"
    ],
    "limitations": [
      "Requires JSON task input file to function",
      "Cannot access source documents directly; processes provided copies only",
      "Cannot modify original source files (WORM storage compliance)",
      "Does not make legal conclusions or opinions"
    ],
    "use_cases": [
      {
        "target_user": "Historical researchers",
        "title": "Index colonial documents",
        "description": "Process batches of historical records about reserve reductions for academic research and land claims."
      },
      {
        "target_user": "Legal professionals",
        "title": "Prepare evidence transcripts",
        "description": "Create verified transcriptions of historical documents for use in indigenous land claim cases."
      },
      {
        "target_user": "Archive specialists",
        "title": "Classify old records",
        "description": "Sort and categorize historical land survey records by relevance and reliability."
      }
    ],
    "prompt_templates": [
      {
        "title": "Basic transcription",
        "scenario": "Process a single document",
        "prompt": "Read the JSON task file for the Land_Reduction_Trespass queue. Extract all metadata, summarize the document, and identify key evidence quotes. Output to the analysis JSON file."
      },
      {
        "title": "Batch processing",
        "scenario": "Process multiple documents",
        "prompt": "Fetch a batch of tasks from the Land_Reduction_Trespass queue. Analyze each document, apply the legal-grade verbatim protocol, and create analysis JSON for the entire batch."
      },
      {
        "title": "Provenance check",
        "scenario": "Verify document source",
        "prompt": "Check the provenance field in each task. Flag any documents with 'Incoming' or 'Unknown' provenance. Use the flag-task command with reason 'Provenance_Failure'."
      },
      {
        "title": "Quality validation",
        "scenario": "Pre-submission check",
        "prompt": "Before submitting the analysis JSON, validate: check length exceeds 100 chars, remove forbidden words like suggests or likely, verify all metadata fields are populated correctly."
      }
    ],
    "output_examples": [
      {
        "input": "Process this batch of land reduction documents",
        "output": [
          "â€¢ Batch ID: LR-2024-001 - 12 tasks processed",
          "â€¢ High relevance: 8 documents | Medium: 3 | Low: 1",
          "â€¢ Key finding: 1913 letter documents 20-acre reduction from 1878 survey",
          "â€¢ Flagged: 1 OCR failure, 1 provenance issue",
          "â€¢ Submission ready for ManagerReview queue"
        ]
      }
    ],
    "best_practices": [
      "Re-read the instruction file after every 5 tasks to prevent context drift",
      "Quote text directly rather than summarizing with opinion words like suggests or implies",
      "Always verify dates are 4-digit years; Unknown is not acceptable"
    ],
    "anti_patterns": [
      "Using keyword search instead of reading document context",
      "Writing Python scripts to auto-scan document content",
      "Submitting metadata as Unknown when information exists in the text"
    ],
    "faq": [
      {
        "question": "What input format does this skill require?",
        "answer": "JSON task file from the refinement_workflow.py get-task command with Land_Reduction_Trespass theme."
      },
      {
        "question": "How many documents can I process at once?",
        "answer": "Each batch contains up to 40,000 characters of aggregated document text (Super Task format)."
      },
      {
        "question": "Can this skill access original source files?",
        "answer": "No. Source files are in WORM storage; the skill only processes read-only copies."
      },
      {
        "question": "Is my data safe with this skill?",
        "answer": "Yes. This is a prompt-only skill with no external network calls or data exfiltration capabilities."
      },
      {
        "question": "What if OCR fails on a document?",
        "answer": "Use flag-task with reason 'OCR_Failure' to automatically move the source file to Vision Pipeline for reprocessing."
      },
      {
        "question": "How is this different from general document skills?",
        "answer": "This skill follows legal-grade protocols including provenance checks, contradiction logging, and strict factual-only language requirements."
      }
    ]
  },
  "file_structure": [
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md"
    }
  ]
}
