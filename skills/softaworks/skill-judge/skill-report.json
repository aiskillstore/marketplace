{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-26T07:53:42.439Z",
    "slug": "softaworks-skill-judge",
    "source_url": "https://github.com/softaworks/agent-toolkit/tree/main/skills/skill-judge/",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "3.0.0",
    "source_type": "community",
    "content_hash": "7b8e3f1277c3ca04643064037acbc5be2ab7aeee35bf1cf44534b386c0f382f8",
    "tree_hash": "6adfc0d996cacb3107c8101a3be41368295ca2e16e4f06f9021e2b8a6215ad5d"
  },
  "skill": {
    "name": "skill-judge",
    "description": "Evaluate Agent Skill design quality against official specifications and best practices. Use when reviewing, auditing, or improving SKILL.md files and skill packages. Provides multi-dimensional scoring and actionable improvement suggestions.",
    "summary": "Evaluate Agent Skill quality with 8-dimension scoring framework and expert-level improvement suggestions.",
    "icon": "ðŸ“¦",
    "version": "1.0.0",
    "author": "softaworks",
    "license": "MIT",
    "tags": [
      "skill-evaluation",
      "skill-audit",
      "skill-quality",
      "claude-skills",
      "agent-toolkit"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": []
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "All static findings are false positives. This is a documentation-only skill containing markdown files (SKILL.md, README.md) with educational content about skill evaluation. The detected 'Ruby/shell backtick execution' patterns are markdown backticks used for code formatting. The 'weak cryptographic algorithm' patterns are text references in documentation examples. No executable code, scripts, network operations, or file system access exists in this skill.",
    "risk_factor_evidence": [],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 2,
    "total_lines": 999,
    "audit_model": "claude",
    "audited_at": "2026-01-26T08:00:00.000Z"
  },
  "content": {
    "user_title": "Evaluate Agent Skill Quality",
    "value_statement": "Many skills waste tokens on content Claude already knows. This skill provides a systematic 8-dimension framework with 120-point scoring to evaluate skill design quality, identify token waste, and generate actionable improvement suggestions.",
    "seo_keywords": [
      "skill evaluation",
      "claude skills",
      "skill quality",
      "agent toolkit",
      "skill audit",
      "skill design",
      "claude code",
      "knowledge delta",
      "skill assessment",
      "claude"
    ],
    "actual_capabilities": [
      "Evaluate SKILL.md files against official specifications and best practices",
      "Score skills across 8 dimensions with 120-point total framework",
      "Identify token waste from redundant explanations Claude already knows",
      "Detect common failure patterns like tutorials, dumps, and orphan references",
      "Generate structured evaluation reports with specific improvement suggestions"
    ],
    "limitations": [
      "Does not execute or test skill scripts - only evaluates documentation",
      "Does not provide code implementation guidance beyond skill design",
      "Does not evaluate skills against domain-specific requirements",
      "Assessment is based on documented patterns, not runtime behavior"
    ],
    "use_cases": [
      {
        "title": "Review Skills Before Publishing",
        "description": "Evaluate a new or updated skill against best practices to ensure it adds genuine value before publishing to a skill marketplace.",
        "target_user": "Skill authors and maintainers"
      },
      {
        "title": "Audit Existing Skill Collections",
        "description": "Systematically assess all skills in a collection to identify which need improvement and prioritize refactoring efforts.",
        "target_user": "Platform operators and skill curators"
      },
      {
        "title": "Learn Skill Design Patterns",
        "description": "Understand what makes an effective skill by reviewing evaluation criteria and common failure patterns to apply to your own skills.",
        "target_user": "New skill authors learning best practices"
      }
    ],
    "prompt_templates": [
      {
        "title": "Basic Skill Evaluation",
        "prompt": "Evaluate the skill at {path}/SKILL.md using the skill-judge framework. Score it across all 8 dimensions and provide a final grade with specific improvement suggestions.",
        "scenario": "Quick evaluation of a single skill file"
      },
      {
        "title": "Comparative Skill Analysis",
        "prompt": "Compare skills/skill-a and skills/skill-b using the skill-judge framework. Identify which has better design and explain why based on the 8 evaluation dimensions.",
        "scenario": "Comparing two skills to determine which follows best practices better"
      },
      {
        "title": "Knowledge Delta Assessment",
        "prompt": "Focus on the knowledge delta in my skill at {path}/SKILL.md. Identify sections that are redundant (Claude already knows this) versus genuine expert-only knowledge that adds value.",
        "scenario": "Optimizing skill content to reduce token waste"
      },
      {
        "title": "Pattern Identification",
        "prompt": "What pattern does my skill follow (Mindset, Navigation, Philosophy, Process, or Tool)? Is this the right choice for the skills purpose? Evaluate and suggest improvements.",
        "scenario": "Understanding which design pattern a skill uses and if it fits the use case"
      }
    ],
    "output_examples": [
      {
        "input": "Evaluate the skill at skills/my-new-skill/SKILL.md",
        "output": [
          "Total Score: 92/120 (77%) - Grade: C",
          "Pattern: Process (appropriate for multi-step workflow)",
          "Knowledge Ratio: E:A:R = 45:30:25",
          "Top Issue: D5 Progressive Disclosure scored 6/15 - references directory unused",
          "Recommendation: Add explicit MANDATORY loading triggers to workflow steps"
        ]
      },
      {
        "input": "Compare skills/skill-a and skills/skill-b",
        "output": [
          "Skill A: 108/120 (90%) - Grade A",
          "Skill B: 74/120 (62%) - Grade D",
          "Key Difference: Skill A has 70% Expert content vs 35% for Skill B",
          "Skill B fails on D1 (Knowledge Delta) - explains basics Claude knows"
        ]
      }
    ],
    "best_practices": [
      "Always prioritize knowledge delta - every paragraph must earn its tokens by teaching Claude something it would not know otherwise",
      "Use the description field to answer three questions: What does the skill do, When should it be used, and What keywords trigger it",
      "Follow established design patterns (Mindset, Navigation, Philosophy, Process, Tool) based on the skills purpose and complexity",
      "Implement progressive disclosure with loading triggers so references are only loaded when needed"
    ],
    "anti_patterns": [
      "The Tutorial - explaining concepts Claude already knows like what is a PDF or how to write basic code",
      "The Dump - putting everything in a single 800+ line file without progressive disclosure",
      "The Invisible Skill - having great content but a vague description that prevents the Agent from knowing when to activate it"
    ],
    "faq": [
      {
        "question": "What is the knowledge delta concept?",
        "answer": "Knowledge delta measures what a skill adds beyond what Claude already knows. Good skills contain expert-only knowledge - decisions, trade-offs, and anti-patterns that take years of experience to learn. Skills explaining basics waste tokens."
      },
      {
        "question": "How is the score calculated?",
        "answer": "The framework uses 8 dimensions with 120 total points: Knowledge Delta (20), Mindset + Procedures (15), Anti-Pattern Quality (15), Specification Compliance (15), Progressive Disclosure (15), Freedom Calibration (15), Pattern Recognition (10), Practical Usability (15)."
      },
      {
        "question": "What are the five design patterns?",
        "answer": "Mindset (50 lines) for creative tasks, Navigation (30 lines) for multiple scenarios, Philosophy (150 lines) for original creation, Process (200 lines) for complex workflows, Tool (300 lines) for precise format operations."
      },
      {
        "question": "Why is the description field so important?",
        "answer": "The description is the only thing the Agent sees before deciding to load a skill. It must answer What, When, and include Keywords. A skill with perfect content but poor description will never be activated."
      },
      {
        "question": "How do I improve a skills score?",
        "answer": "Focus on the lowest-scoring dimensions first. Common improvements: remove redundant explanations, add specific anti-patterns with reasons, create loading triggers for references, and make the description more specific with trigger scenarios."
      },
      {
        "question": "Does this skill evaluate itself?",
        "answer": "Yes, skill-judge is designed to pass its own evaluation. It provides expert-level evaluation criteria Claude would not generate, follows the Tool pattern appropriately, and has comprehensive documentation."
      }
    ]
  },
  "file_structure": [
    {
      "name": "README.md",
      "type": "file",
      "path": "README.md",
      "lines": 246
    },
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md",
      "lines": 753
    }
  ]
}
