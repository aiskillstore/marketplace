{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-10T14:22:51.325Z",
    "slug": "doyajin174-structured-logging",
    "source_url": "https://github.com/Doyajin174/myskills/tree/main/.public/skills/structured-logging",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "2.0.0",
    "source_type": "community",
    "content_hash": "a8942fd7ce1a372d22ff9b67caef01b5b877d36807be7c0484651df5a38009ab",
    "tree_hash": "c8d6bb759af03f8febb479b2a9a2244f9c03885e84f640338c3cbc34b283802c"
  },
  "skill": {
    "name": "structured-logging",
    "description": "Implement JSON-based structured logging for observability. Use when setting up logging, debugging production issues, or preparing for log aggregation (ELK, Datadog). Covers log levels, context, and best practices.",
    "summary": "Implement JSON-based structured logging for observability. Use when setting up logging, debugging pr...",
    "icon": "ðŸ“‹",
    "version": "1.0.0",
    "author": "Doyajin174",
    "license": "MIT",
    "category": "devops",
    "tags": [
      "logging",
      "observability",
      "debugging",
      "json"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": []
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "Pure documentation skill containing logging best practices and code examples. No executable code, no network calls, no file system access beyond its own content.",
    "risk_factor_evidence": [],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 1,
    "total_lines": 452,
    "audit_model": "claude",
    "audited_at": "2026-01-10T14:22:51.325Z"
  },
  "content": {
    "user_title": "Implement structured JSON logging",
    "value_statement": "Traditional console logs are hard to search and parse. This skill provides patterns and code examples for implementing JSON-structured logging that enables powerful filtering, aggregation, and observability across your services.",
    "seo_keywords": [
      "structured logging",
      "JSON logging",
      "Pino logger",
      "Winston logger",
      "observability",
      "log aggregation",
      "ELK stack",
      "Datadog logging",
      "Claude",
      "Codex",
      "Claude Code"
    ],
    "actual_capabilities": [
      "Implement Pino logger with environment-based configuration",
      "Create Winston logger with JSON formatting",
      "Set up request context propagation using AsyncLocalStorage",
      "Configure sensitive data redaction in logs",
      "Integrate logging with ELK Stack and Datadog",
      "Define appropriate log levels for production and development"
    ],
    "limitations": [
      "Does not install logging libraries - only provides configuration guidance",
      "Does not handle log rotation or log file management",
      "Does not include monitoring or alerting setup",
      "Focused on Node.js/TypeScript implementations"
    ],
    "use_cases": [
      {
        "target_user": "Backend developers",
        "title": "Production logging setup",
        "description": "Configure structured logging for production services with Pino or Winston for better debugging and observability"
      },
      {
        "target_user": "DevOps engineers",
        "title": "Log aggregation pipeline",
        "description": "Set up log shipping to ELK Stack or Datadog with proper trace context propagation"
      },
      {
        "target_user": "Full-stack developers",
        "title": "API request tracking",
        "description": "Implement request ID middleware and context-aware logging to trace requests across microservices"
      }
    ],
    "prompt_templates": [
      {
        "title": "Basic logger setup",
        "scenario": "Getting started with structured logging",
        "prompt": "Set up Pino logger with environment-based log level, service name, and development pretty-print mode"
      },
      {
        "title": "Context propagation",
        "scenario": "Tracing requests across async calls",
        "prompt": "Create AsyncLocalStorage context to propagate requestId and userId across all async operations"
      },
      {
        "title": "Sensitive data redaction",
        "scenario": "Preventing credential leaks in logs",
        "prompt": "Configure Pino redact option to mask passwords, tokens, API keys, and credit card numbers"
      },
      {
        "title": "Log aggregation",
        "scenario": "Shipping logs to external services",
        "prompt": "Create Winston transport that sends JSON logs to Elasticsearch for the ELK Stack"
      }
    ],
    "output_examples": [
      {
        "input": "Set up structured logging for my Node.js API",
        "output": [
          "Create logger.ts with Pino configured for JSON output",
          "Add environment-based log level (info for production, debug for development)",
          "Include base fields: service name, environment, requestId",
          "Use pino-pretty transport for development readability",
          "Configure redact option for sensitive fields"
        ]
      }
    ],
    "best_practices": [
      "Always use ISO 8601 timestamps for consistent log parsing across systems",
      "Include requestId in all logs to enable distributed tracing",
      "Never log sensitive data like passwords, tokens, or credit card numbers",
      "Use appropriate log levels (info for production, debug for development)"
    ],
    "anti_patterns": [
      "Logging unstructured strings with string interpolation instead of JSON objects",
      "Including sensitive credentials or personal data in log output",
      "Excessive debug logging in production causing performance issues",
      "Missing error stack traces that prevent proper debugging"
    ],
    "faq": [
      {
        "question": "Which logging library should I choose?",
        "answer": "Pino is recommended for new projects due to its minimal overhead. Winston offers more plugins and customization options."
      },
      {
        "question": "What log level should I use in production?",
        "answer": "Use 'info' level in production to reduce noise. Enable 'debug' or 'trace' only when troubleshooting specific issues."
      },
      {
        "question": "How do I add context to all log entries?",
        "answer": "Use AsyncLocalStorage to store requestId, userId, and other context. Create a wrapper logger that automatically includes context from storage."
      },
      {
        "question": "Is my sensitive data safe in logs?",
        "answer": "Configure redaction for sensitive fields. Use Pino's redact option or create a sanitization function before logging."
      },
      {
        "question": "Why are my logs not appearing in ELK?",
        "answer": "Ensure your logger outputs JSON format. Check that Filebeat or Logstash can parse the format. Verify network connectivity to Elasticsearch."
      },
      {
        "question": "How does this compare to console.log?",
        "answer": "Structured logging provides searchable, filterable JSON output unlike console.log's unstructured text. Enables aggregation and alerting that console.log cannot provide."
      }
    ]
  },
  "file_structure": [
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md"
    }
  ]
}
