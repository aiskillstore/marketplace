{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-10T14:23:38.288Z",
    "slug": "doyajin174-ml-antipattern-validator",
    "source_url": "https://github.com/Doyajin174/myskills/tree/main/.public/skills/ml-antipattern-validator",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "2.0.0",
    "source_type": "community",
    "content_hash": "8f4a01c090887287c32bbeaef2d727ebbf37233727850516de6df63413c5ff77",
    "tree_hash": "90b2fd4046a6bd22c58a421cd50a76a6e411630e76ba449c8f9e30313fd0b2b7"
  },
  "skill": {
    "name": "ml-antipattern-validator",
    "description": "Prevents 30+ critical AI/ML mistakes including data leakage, evaluation errors, training pitfalls, and deployment issues. Use when working with ML training, testing, model evaluation, or deployment.",
    "summary": "Prevents 30+ critical AI/ML mistakes including data leakage, evaluation errors, training pitfalls, a...",
    "icon": "ðŸ”¬",
    "version": "1.0.0",
    "author": "Doyajin174",
    "license": "MIT",
    "category": "data",
    "tags": [
      "machine-learning",
      "data-quality",
      "evaluation",
      "validation",
      "best-practices"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": [
      "scripts",
      "filesystem"
    ]
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "This is a documentation and static analysis skill with no network access, no credential access, and no command execution capabilities. The Python scripts only read and parse local files for analysis. Behavior matches stated purpose.",
    "risk_factor_evidence": [
      {
        "factor": "scripts",
        "evidence": [
          {
            "file": "scripts/detect_leakage.py",
            "line_start": 1,
            "line_end": 342
          },
          {
            "file": "scripts/validate_split.py",
            "line_start": 1,
            "line_end": 249
          }
        ]
      },
      {
        "factor": "filesystem",
        "evidence": [
          {
            "file": "scripts/detect_leakage.py",
            "line_start": 176,
            "line_end": 177
          },
          {
            "file": "scripts/validate_split.py",
            "line_start": 196,
            "line_end": 197
          }
        ]
      }
    ],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 7,
    "total_lines": 2324,
    "audit_model": "claude",
    "audited_at": "2026-01-10T14:23:38.288Z"
  },
  "content": {
    "user_title": "Validate ML code for antipatterns",
    "value_statement": "ML models often fail in production due to data leakage, improper evaluation, and training mistakes. This skill detects over 30 critical antipatterns and helps prevent invalid results by scanning your code and data splits before training.",
    "seo_keywords": [
      "ML antipattern detection",
      "data leakage prevention",
      "machine learning validation",
      "ML evaluation best practices",
      "train test split validation",
      "Claude Code ML tools",
      "Codex ML validation",
      "ML code quality"
    ],
    "actual_capabilities": [
      "Detect 30+ ML antipatterns in Python code using AST analysis",
      "Validate train/test splits for leakage patterns (temporal, group, sample overlap)",
      "Check evaluation methodology correctness (CV strategies, metric alignment)",
      "Review preprocessing order to prevent scaling leakage",
      "Generate fix recommendations for detected issues"
    ],
    "limitations": [
      "Static analysis only - cannot catch runtime or logic errors",
      "Requires Python files to be syntactically valid",
      "Does not execute your ML code or access external APIs",
      "Cannot verify statistical significance of detected issues"
    ],
    "use_cases": [
      {
        "target_user": "Data scientists",
        "title": "Validate training code",
        "description": "Scan training scripts for leakage before running experiments to ensure valid results"
      },
      {
        "target_user": "ML engineers",
        "title": "Review data splits",
        "description": "Validate train/test CSVs for group leakage, temporal ordering, and class distribution"
      },
      {
        "target_user": "Research teams",
        "title": "Check evaluation methodology",
        "description": "Verify cross-validation setup and metric selection matches the business objective"
      }
    ],
    "prompt_templates": [
      {
        "title": "Quick scan",
        "scenario": "Check a Python file",
        "prompt": "@validate-ml scan my training script at src/train_model.py for data leakage and antipatterns"
      },
      {
        "title": "Check data split",
        "scenario": "Validate CSV splits",
        "prompt": "@check-leakage validate my train.csv and test.csv files for group overlap using user_id column"
      },
      {
        "title": "Review evaluation",
        "scenario": "Check methodology",
        "prompt": "@verify-eval review my evaluation approach - I am using cross_val_score with 5 folds on time series data"
      },
      {
        "title": "Full validation",
        "scenario": "Comprehensive check",
        "prompt": "@validate-ml perform full validation on my ML pipeline - check preprocessing order, data splits, and evaluation setup"
      }
    ],
    "output_examples": [
      {
        "input": "Scan my training script for data leakage issues",
        "output": [
          "CRITICAL: Found fit_transform called before train_test_split (line 45) - preprocessing leakage detected",
          "HIGH: Same user_id appears in both train and test sets - group leakage",
          "MEDIUM: cross_val_score without Pipeline wrapper may cause fold leakage",
          "FIX: Use scaler.fit() on X_train, then transform() on both sets",
          "FIX: Use GroupShuffleSplit with groups=df['user_id'] for proper splitting"
        ]
      }
    ],
    "best_practices": [
      "Always split data BEFORE any preprocessing (fit_transform, imputation, encoding)",
      "Use Pipeline objects to ensure correct preprocessing order in cross-validation",
      "Keep related samples (same user, patient, session) together in train/test splits",
      "Never tune hyperparameters on test data - use a separate validation set"
    ],
    "anti_patterns": [
      "Calling fit_transform on full dataset then splitting - leaks test statistics into training",
      "Using train_test_split with shuffle=True on temporal data - breaks causality",
      "Testing on training data or evaluating model.score(X_train, y_train)",
      "Using accuracy on highly imbalanced datasets without checking per-class metrics"
    ],
    "faq": [
      {
        "question": "Which ML frameworks are supported?",
        "answer": "Works with any Python ML code using scikit-learn, PyTorch, TensorFlow, or custom implementations"
      },
      {
        "question": "What file types can be scanned?",
        "answer": "Python source files (.py) for code analysis and CSV files for data split validation"
      },
      {
        "question": "Can this integrate with CI/CD pipelines?",
        "answer": "The detect_leakage.py script can be run from command line and returns exit codes for CI integration"
      },
      {
        "question": "Is my data sent anywhere?",
        "answer": "No - all analysis runs locally. Files are read from disk but never transmitted externally"
      },
      {
        "question": "What types of leakage are detected?",
        "answer": "Target leakage, temporal leakage, preprocessing leakage, group leakage, and cross-validation fold leakage"
      },
      {
        "question": "How does this compare to pytest or linters?",
        "answer": "This tool focuses specifically on ML antipatterns that general linters cannot detect, such as data leakage patterns"
      }
    ]
  },
  "file_structure": [
    {
      "name": "references",
      "type": "dir",
      "path": "references",
      "children": [
        {
          "name": "deployment_checklist.md",
          "type": "file",
          "path": "references/deployment_checklist.md"
        },
        {
          "name": "evaluation_guidelines.md",
          "type": "file",
          "path": "references/evaluation_guidelines.md"
        },
        {
          "name": "leakage_patterns.md",
          "type": "file",
          "path": "references/leakage_patterns.md"
        },
        {
          "name": "REFERENCE.md",
          "type": "file",
          "path": "references/REFERENCE.md"
        }
      ]
    },
    {
      "name": "scripts",
      "type": "dir",
      "path": "scripts",
      "children": [
        {
          "name": "detect_leakage.py",
          "type": "file",
          "path": "scripts/detect_leakage.py"
        },
        {
          "name": "validate_split.py",
          "type": "file",
          "path": "scripts/validate_split.py"
        }
      ]
    },
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md"
    }
  ]
}
