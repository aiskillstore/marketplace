{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-17T06:55:11.198Z",
    "slug": "eleutherai-logprob-prefill-analysis",
    "source_url": "https://github.com/EleutherAI/rh-indicators/tree/main/.claude/skills/logprob-prefill-analysis",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "3.0.0",
    "source_type": "community",
    "content_hash": "f6fbd31f525edb77952ed360f39fa3825ed4996f684b74bd1ad14ea84bafb067",
    "tree_hash": "37dee1a514b20b4d36f7cdd1a2dd3e028717c4bb1113f3b50bff92a60ec6877d"
  },
  "skill": {
    "name": "logprob-prefill-analysis",
    "description": "Reproduces the full prefill sensitivity analysis pipeline for reward hacking indicators. Use when evaluating how susceptible model checkpoints are to exploit-eliciting prefills, computing token-based trajectories, or comparing logprob vs token-count as predictors of exploitability.",
    "summary": "Reproduces the full prefill sensitivity analysis pipeline for reward hacking indicators. Use when ev...",
    "icon": "ðŸ“Š",
    "version": "1.0.0",
    "author": "EleutherAI",
    "license": "MIT",
    "category": "research",
    "tags": [
      "ai-safety",
      "reward-hacking",
      "model-analysis",
      "prefill-sensitivity",
      "ml-research"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": [
      "network",
      "filesystem",
      "external_commands"
    ]
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "Pure documentation skill containing only SKILL.md markdown file with no executable code. The static analyzer incorrectly flagged documentation examples as security issues. Backticks in code blocks are markdown formatting, not shell execution. Hardcoded URLs in examples are localhost development endpoints. Hash-related terms in metadata are not cryptographic code. The skill documents a legitimate AI safety research pipeline for measuring model susceptibility to reward hacking.",
    "risk_factor_evidence": [
      {
        "factor": "network",
        "evidence": [
          {
            "file": "skill-report.json",
            "line_start": 6,
            "line_end": 6
          },
          {
            "file": "SKILL.md",
            "line_start": 90,
            "line_end": 90
          },
          {
            "file": "SKILL.md",
            "line_start": 123,
            "line_end": 123
          }
        ]
      },
      {
        "factor": "filesystem",
        "evidence": [
          {
            "file": "skill-report.json",
            "line_start": 6,
            "line_end": 6
          }
        ]
      },
      {
        "factor": "external_commands",
        "evidence": [
          {
            "file": "SKILL.md",
            "line_start": 14,
            "line_end": 27
          },
          {
            "file": "SKILL.md",
            "line_start": 27,
            "line_end": 30
          },
          {
            "file": "SKILL.md",
            "line_start": 30,
            "line_end": 53
          },
          {
            "file": "SKILL.md",
            "line_start": 53,
            "line_end": 55
          },
          {
            "file": "SKILL.md",
            "line_start": 55,
            "line_end": 67
          },
          {
            "file": "SKILL.md",
            "line_start": 67,
            "line_end": 82
          },
          {
            "file": "SKILL.md",
            "line_start": 82,
            "line_end": 84
          },
          {
            "file": "SKILL.md",
            "line_start": 84,
            "line_end": 88
          },
          {
            "file": "SKILL.md",
            "line_start": 88,
            "line_end": 95
          },
          {
            "file": "SKILL.md",
            "line_start": 95,
            "line_end": 100
          },
          {
            "file": "SKILL.md",
            "line_start": 100,
            "line_end": 101
          },
          {
            "file": "SKILL.md",
            "line_start": 101,
            "line_end": 102
          },
          {
            "file": "SKILL.md",
            "line_start": 102,
            "line_end": 105
          },
          {
            "file": "SKILL.md",
            "line_start": 105,
            "line_end": 106
          },
          {
            "file": "SKILL.md",
            "line_start": 106,
            "line_end": 110
          },
          {
            "file": "SKILL.md",
            "line_start": 110,
            "line_end": 133
          },
          {
            "file": "SKILL.md",
            "line_start": 133,
            "line_end": 141
          },
          {
            "file": "SKILL.md",
            "line_start": 141,
            "line_end": 146
          },
          {
            "file": "SKILL.md",
            "line_start": 146,
            "line_end": 149
          },
          {
            "file": "SKILL.md",
            "line_start": 149,
            "line_end": 155
          },
          {
            "file": "SKILL.md",
            "line_start": 155,
            "line_end": 163
          },
          {
            "file": "SKILL.md",
            "line_start": 163,
            "line_end": 164
          },
          {
            "file": "SKILL.md",
            "line_start": 164,
            "line_end": 165
          },
          {
            "file": "SKILL.md",
            "line_start": 165,
            "line_end": 175
          },
          {
            "file": "SKILL.md",
            "line_start": 175,
            "line_end": 181
          },
          {
            "file": "SKILL.md",
            "line_start": 181,
            "line_end": 185
          },
          {
            "file": "SKILL.md",
            "line_start": 185,
            "line_end": 190
          },
          {
            "file": "SKILL.md",
            "line_start": 190,
            "line_end": 193
          },
          {
            "file": "SKILL.md",
            "line_start": 193,
            "line_end": 194
          },
          {
            "file": "SKILL.md",
            "line_start": 194,
            "line_end": 195
          },
          {
            "file": "SKILL.md",
            "line_start": 195,
            "line_end": 203
          },
          {
            "file": "SKILL.md",
            "line_start": 203,
            "line_end": 212
          },
          {
            "file": "SKILL.md",
            "line_start": 212,
            "line_end": 215
          },
          {
            "file": "SKILL.md",
            "line_start": 215,
            "line_end": 219
          },
          {
            "file": "SKILL.md",
            "line_start": 219,
            "line_end": 222
          },
          {
            "file": "SKILL.md",
            "line_start": 222,
            "line_end": 223
          },
          {
            "file": "SKILL.md",
            "line_start": 223,
            "line_end": 226
          },
          {
            "file": "SKILL.md",
            "line_start": 226,
            "line_end": 227
          },
          {
            "file": "SKILL.md",
            "line_start": 227,
            "line_end": 228
          },
          {
            "file": "SKILL.md",
            "line_start": 228,
            "line_end": 229
          },
          {
            "file": "SKILL.md",
            "line_start": 229,
            "line_end": 235
          },
          {
            "file": "SKILL.md",
            "line_start": 235,
            "line_end": 236
          },
          {
            "file": "SKILL.md",
            "line_start": 236,
            "line_end": 237
          },
          {
            "file": "SKILL.md",
            "line_start": 237,
            "line_end": 238
          },
          {
            "file": "SKILL.md",
            "line_start": 238,
            "line_end": 240
          },
          {
            "file": "SKILL.md",
            "line_start": 240,
            "line_end": 271
          },
          {
            "file": "SKILL.md",
            "line_start": 271,
            "line_end": 284
          },
          {
            "file": "SKILL.md",
            "line_start": 284,
            "line_end": 284
          },
          {
            "file": "SKILL.md",
            "line_start": 284,
            "line_end": 287
          },
          {
            "file": "SKILL.md",
            "line_start": 287,
            "line_end": 287
          },
          {
            "file": "SKILL.md",
            "line_start": 287,
            "line_end": 296
          },
          {
            "file": "SKILL.md",
            "line_start": 296,
            "line_end": 326
          },
          {
            "file": "SKILL.md",
            "line_start": 326,
            "line_end": 334
          },
          {
            "file": "SKILL.md",
            "line_start": 334,
            "line_end": 334
          },
          {
            "file": "SKILL.md",
            "line_start": 334,
            "line_end": 335
          },
          {
            "file": "SKILL.md",
            "line_start": 335,
            "line_end": 335
          },
          {
            "file": "SKILL.md",
            "line_start": 335,
            "line_end": 335
          },
          {
            "file": "SKILL.md",
            "line_start": 335,
            "line_end": 336
          },
          {
            "file": "SKILL.md",
            "line_start": 336,
            "line_end": 336
          },
          {
            "file": "SKILL.md",
            "line_start": 336,
            "line_end": 337
          },
          {
            "file": "SKILL.md",
            "line_start": 337,
            "line_end": 337
          },
          {
            "file": "SKILL.md",
            "line_start": 337,
            "line_end": 337
          },
          {
            "file": "SKILL.md",
            "line_start": 337,
            "line_end": 338
          },
          {
            "file": "SKILL.md",
            "line_start": 338,
            "line_end": 338
          },
          {
            "file": "SKILL.md",
            "line_start": 338,
            "line_end": 338
          },
          {
            "file": "SKILL.md",
            "line_start": 338,
            "line_end": 339
          },
          {
            "file": "SKILL.md",
            "line_start": 339,
            "line_end": 339
          },
          {
            "file": "SKILL.md",
            "line_start": 339,
            "line_end": 339
          },
          {
            "file": "SKILL.md",
            "line_start": 112,
            "line_end": 112
          },
          {
            "file": "SKILL.md",
            "line_start": 110,
            "line_end": 133
          },
          {
            "file": "SKILL.md",
            "line_start": 111,
            "line_end": 111
          }
        ]
      }
    ],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 2,
    "total_lines": 518,
    "audit_model": "claude",
    "audited_at": "2026-01-17T06:55:11.198Z"
  },
  "content": {
    "user_title": "Analyze model susceptibility to reward hacking",
    "value_statement": "This skill provides documentation for running prefill sensitivity analysis to measure how easily AI models can be manipulated into generating exploit code. Researchers use it to compare token-count versus logprob metrics for predicting reward hacking susceptibility across model checkpoints.",
    "seo_keywords": [
      "reward hacking detection",
      "prefill sensitivity analysis",
      "logprob metrics",
      "AI safety research",
      "model checkpoint evaluation",
      "Claude Code",
      "Claude",
      "Codex",
      "exploit prevention",
      "AI model alignment"
    ],
    "actual_capabilities": [
      "Documents prefill sensitivity evaluation pipeline for measuring model exploitability",
      "Explains token-based trajectory analysis for tracking exploit accessibility over training",
      "Describes logprob computation for measuring how natural exploit reasoning appears to models",
      "Provides integrated analysis comparing token-count versus logprob predictors",
      "Covers experiment context logging for reproducible research runs",
      "Includes troubleshooting guidance for CUDA memory and vLLM server issues"
    ],
    "limitations": [
      "Documentation-only skill - users must run Python scripts described in the documentation",
      "Requires pre-existing model checkpoints and vLLM installation to execute analyses",
      "Does not perform analysis itself - provides commands and configuration guidance",
      "Skill assumes access to SFT checkpoints and prefill source data"
    ],
    "use_cases": [
      {
        "target_user": "AI Safety Researchers",
        "title": "Measure Model Vulnerability",
        "description": "Evaluate how susceptible trained models are to reward hacking by measuring prefill token thresholds and logprob scores across checkpoints"
      },
      {
        "target_user": "ML Engineers",
        "title": "Track Training Progression",
        "description": "Analyze how exploit accessibility changes during SFT training to identify when models become vulnerable"
      },
      {
        "target_user": "Alignment Researchers",
        "title": "Compare Prediction Metrics",
        "description": "Compare R2 values between token-based and logprob-based metrics for predicting when models become exploitable"
      }
    ],
    "prompt_templates": [
      {
        "title": "Run Full Analysis",
        "scenario": "Reproduce complete prefill pipeline",
        "prompt": "How do I run the full prefill sensitivity analysis pipeline using the run_full_prefill_analysis.py script?"
      },
      {
        "title": "Analyze Trajectories",
        "scenario": "Compute token-based metrics",
        "prompt": "What commands do I use to analyze token-based trajectories and compute minimum prefill tokens needed for exploits?"
      },
      {
        "title": "Compute Logprobs",
        "scenario": "Measure logprob-based metrics",
        "prompt": "Show me how to compute prefill logprobs for a model checkpoint and batch process multiple checkpoints"
      },
      {
        "title": "Compare Metrics",
        "scenario": "Integrate and compare results",
        "prompt": "How do I merge token-based and logprob-based metrics to compare their predictive power using integrate_logprob_trajectory.py?"
      }
    ],
    "output_examples": [
      {
        "input": "How do I run the full prefill sensitivity analysis pipeline?",
        "output": [
          "Execute: python scripts/run_full_prefill_analysis.py",
          "The orchestration script automatically discovers checkpoints from config.yaml",
          "Add --dry-run flag to preview execution without running",
          "Add --skip-logprob to run trajectory analysis only",
          "Results are saved to timestamped directories with full experiment context"
        ]
      },
      {
        "input": "How do I analyze token-based trajectories?",
        "output": [
          "Run: python scripts/prefill_trajectory_analysis.py --run-dir results/prefill_sensitivity/{RUN_NAME}",
          "Track minimum prefill tokens needed to trigger exploits across checkpoints",
          "Set threshold (default 10) to define when models are easily exploitable",
          "Output includes accessibility_distribution.png and time_to_threshold.png"
        ]
      },
      {
        "input": "What are the key results from this analysis?",
        "output": [
          "Logprob-based metrics show 66% better R2 than token-based for predicting exploitability",
          "Token threshold fires 16.2 steps earlier on average than logprob threshold",
          "Best practice: use SUM logprob for comparing across different prefill lengths"
        ]
      }
    ],
    "best_practices": [
      "Use experiment context logging (--use-run-context) to capture reproducibility metadata including Git commit, Python version, and environment details",
      "Start with --dry-run to verify configuration before executing long-running analysis pipelines",
      "Use the threshold parameter (default 10) to define when a model is considered easily exploitable based on min_prefill tokens"
    ],
    "anti_patterns": [
      "Running full analysis without first verifying checkpoint availability in config.yaml",
      "Ignoring the distinction between word tokens and subword tokens when interpreting results",
      "Using mean logprob instead of sum logprob when comparing across different prefill lengths"
    ],
    "faq": [
      {
        "question": "What models and frameworks does this analysis support?",
        "answer": "Works with SFT checkpoints served via vLLM. gpt-oss models use Harmony format with thinking field auto-detection."
      },
      {
        "question": "What compute resources are required?",
        "answer": "GPU recommended for logprob computation. CUDA OOM can be addressed with --max-samples 50 or --dtype float16."
      },
      {
        "question": "How long does full analysis take?",
        "answer": "Depends on checkpoint count and prefill levels. The orchestration script processes all checkpoints automatically."
      },
      {
        "question": "Is data saved securely?",
        "answer": "Results written to local results/ directory. No external data transmission occurs during analysis execution."
      },
      {
        "question": "What if vLLM server fails to start?",
        "answer": "Ensure server fully starts before evaluation. Check logs for Uvicorn running message. Use pkill to clean up stuck processes."
      },
      {
        "question": "How does this differ from standard model evaluation?",
        "answer": "Tracks exploit accessibility over training progression, comparing how easily models can be manipulated via prefill tokens."
      }
    ]
  },
  "file_structure": [
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md",
      "lines": 340
    }
  ]
}
