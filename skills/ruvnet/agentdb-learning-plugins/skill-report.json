{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-06T07:26:45.619Z",
    "slug": "ruvnet-agentdb-learning-plugins",
    "source_url": "https://github.com/ruvnet/claude-flow/tree/main/.claude/skills/agentdb-learning",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "2.0.0",
    "source_type": "community",
    "content_hash": "bd886ca826d378916c375045b4540f46a8d86e22619b5d160a6d13c615061ec4",
    "tree_hash": "129e74ee676832f277e2870141ac3afb2a1c7f5dcc90fc28f3d3120103fbc66e"
  },
  "skill": {
    "name": "AgentDB Learning Plugins",
    "description": "Create and train AI learning plugins with AgentDB's 9 reinforcement learning algorithms. Includes Decision Transformer, Q-Learning, SARSA, Actor-Critic, and more. Use when building self-learning agents, implementing RL, or optimizing agent behavior through experience.",
    "summary": "Create and train AI learning plugins with AgentDB's 9 reinforcement learning algorithms. Includes De...",
    "icon": "ðŸ§ ",
    "version": "1.0.0",
    "author": "ruvnet",
    "license": "MIT",
    "category": "data",
    "tags": [
      "machine-learning",
      "reinforcement-learning",
      "ai-agents",
      "training",
      "neural-networks"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": []
  },
  "security_audit": {
    "risk_level": "low",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "This skill contains only documentation (SKILL.md) describing AgentDB learning plugins. No executable code, scripts, or binaries are present. The documented behavior aligns with legitimate ML framework functionality.",
    "risk_factor_evidence": [],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 1,
    "total_lines": 546,
    "audit_model": "claude",
    "audited_at": "2026-01-06T07:26:45.618Z"
  },
  "content": {
    "user_title": "Create AI Learning Plugins with RL Algorithms",
    "value_statement": "Building self-learning AI agents requires implementing complex reinforcement learning algorithms. This skill provides templates and documentation for 9 RL algorithms including Decision Transformer and Q-Learning to accelerate agent development.",
    "seo_keywords": [
      "reinforcement learning",
      "agent training",
      "decision transformer",
      "q-learning",
      "actor-critic",
      "machine learning plugins",
      "AI agent development",
      "Claude",
      "Codex",
      "Claude Code"
    ],
    "actual_capabilities": [
      "Create learning plugins from 9 RL algorithm templates",
      "Train models using Decision Transformer, Q-Learning, SARSA, Actor-Critic",
      "Store and retrieve agent experiences for pattern learning",
      "Implement experience replay and prioritized replay buffers",
      "Configure curriculum learning and multi-task training",
      "Integrate with ReasoningBank for hybrid learning"
    ],
    "limitations": [
      "Requires AgentDB v1.0.7+ and Node.js 18+",
      "Basic understanding of reinforcement learning recommended",
      "No pre-trained models included",
      "Training requires computational resources"
    ],
    "use_cases": [
      {
        "target_user": "ML Engineers",
        "title": "Build Self-Learning Agents",
        "description": "Implement autonomous agents that improve through experience using Q-Learning or Decision Transformer algorithms"
      },
      {
        "target_user": "Research Scientists",
        "title": "Experiment with RL Algorithms",
        "description": "Test and compare different reinforcement learning approaches including Actor-Critic and SARSA"
      },
      {
        "target_user": "AI Developers",
        "title": "Optimize Agent Behavior",
        "description": "Use experience replay and curriculum learning to improve agent decision-making over time"
      }
    ],
    "prompt_templates": [
      {
        "title": "Create Q-Learning Agent",
        "scenario": "Build a simple learning agent",
        "prompt": "Create a Q-Learning plugin named my-agent for discrete action spaces"
      },
      {
        "title": "Decision Transformer Setup",
        "scenario": "Offline RL from logged data",
        "prompt": "Create a Decision Transformer plugin to learn from historical experience data"
      },
      {
        "title": "Multi-Agent Training",
        "scenario": "Coordinate multiple agents",
        "prompt": "Set up multi-agent training with shared experience replay buffer"
      },
      {
        "title": "Curriculum Learning",
        "scenario": "Progressive difficulty training",
        "prompt": "Configure curriculum learning for a complex task with increasing difficulty levels"
      }
    ],
    "output_examples": [
      {
        "input": "Create a Q-Learning plugin for a navigation agent",
        "output": [
          "Created plugin: q-learning/navigation-agent",
          "Algorithm: Q-Learning (off-policy, value-based)",
          "Configuration: { learningRate: 0.001, gamma: 0.99, epsilon: 0.1, epsilonDecay: 0.995 }",
          "Best for: Discrete action spaces, grid worlds, navigation tasks",
          "Next: Train with experience replay using adapter.insertPattern()"
        ]
      }
    ],
    "best_practices": [
      "Start with Q-Learning for simple discrete action tasks before moving to complex algorithms",
      "Use validation split during training to detect overfitting early",
      "Store experiences with TD error as priority for prioritized experience replay"
    ],
    "anti_patterns": [
      "Using continuous action algorithms like Actor-Critic for discrete action spaces without modification",
      "Training without validation split leads to overfitting",
      "Ignoring exploration-exploitation balance causes poor convergence"
    ],
    "faq": [
      {
        "question": "Which algorithm should I start with?",
        "answer": "Q-Learning is recommended for beginners with discrete actions. Decision Transformer is best for offline learning from logged data."
      },
      {
        "question": "What hardware is needed for training?",
        "answer": "CPU training works for basic cases. GPU is recommended for Decision Transformer and larger neural network models."
      },
      {
        "question": "Can I use this with other AI frameworks?",
        "answer": "Yes. AgentDB integrates with ReasoningBank and can combine with any agent framework using the adapter API."
      },
      {
        "question": "Is my training data saved securely?",
        "answer": "Training data is stored locally in .agentdb/learning.db. No data is sent to external servers by default."
      },
      {
        "question": "Why is my training not converging?",
        "answer": "Try reducing learning rate, increasing training epochs, or checking if rewards are properly normalized."
      },
      {
        "question": "How does this compare to other RL frameworks?",
        "answer": "AgentDB focuses on integrating learning with agent memory. Use Stable Baselines3 for pure research or this for production agents."
      }
    ]
  },
  "file_structure": [
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md"
    }
  ]
}
