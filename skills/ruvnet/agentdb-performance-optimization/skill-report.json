{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-17T07:13:33.778Z",
    "slug": "ruvnet-agentdb-performance-optimization",
    "source_url": "https://github.com/ruvnet/claude-flow/tree/main/.claude/skills/agentdb-optimization",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "3.0.0",
    "source_type": "community",
    "content_hash": "2f89515de3a1ad352edc725cbae887e184ac016917bc2757e670be7bf16d4200",
    "tree_hash": "1f4285334d6e17f46aa80a8144bc167a866c31652502a14b37b03b9e5da11ed5"
  },
  "skill": {
    "name": "agentdb-performance-optimization",
    "description": "Optimize AgentDB performance with quantization (4-32x memory reduction), HNSW indexing (150x faster search), caching, and batch operations. Use when optimizing memory usage, improving search speed, or scaling to millions of vectors.",
    "summary": "Optimize AgentDB performance with quantization (4-32x memory reduction), HNSW indexing (150x faster ...",
    "icon": "ðŸš€",
    "version": "1.0.0",
    "author": "ruvnet",
    "license": "MIT",
    "category": "data",
    "tags": [
      "performance",
      "optimization",
      "vector-database",
      "quantization",
      "indexing"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": [
      "network",
      "filesystem",
      "external_commands"
    ]
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "This is a documentation-only skill containing configuration examples for AgentDB performance optimization. All 75 static findings are false positives: markdown code blocks were misidentified as shell commands, quantization terminology was confused with cryptographic algorithms, and documentation URLs were flagged as network operations. No executable code exists.",
    "risk_factor_evidence": [
      {
        "factor": "network",
        "evidence": [
          {
            "file": "skill-report.json",
            "line_start": 6,
            "line_end": 6
          },
          {
            "file": "SKILL.md",
            "line_start": 502,
            "line_end": 502
          },
          {
            "file": "SKILL.md",
            "line_start": 503,
            "line_end": 503
          }
        ]
      },
      {
        "factor": "filesystem",
        "evidence": [
          {
            "file": "skill-report.json",
            "line_start": 6,
            "line_end": 6
          }
        ]
      },
      {
        "factor": "external_commands",
        "evidence": [
          {
            "file": "SKILL.md",
            "line_start": 26,
            "line_end": 35
          },
          {
            "file": "SKILL.md",
            "line_start": 35,
            "line_end": 39
          },
          {
            "file": "SKILL.md",
            "line_start": 39,
            "line_end": 50
          },
          {
            "file": "SKILL.md",
            "line_start": 50,
            "line_end": 61
          },
          {
            "file": "SKILL.md",
            "line_start": 61,
            "line_end": 67
          },
          {
            "file": "SKILL.md",
            "line_start": 67,
            "line_end": 84
          },
          {
            "file": "SKILL.md",
            "line_start": 84,
            "line_end": 90
          },
          {
            "file": "SKILL.md",
            "line_start": 90,
            "line_end": 107
          },
          {
            "file": "SKILL.md",
            "line_start": 107,
            "line_end": 113
          },
          {
            "file": "SKILL.md",
            "line_start": 113,
            "line_end": 130
          },
          {
            "file": "SKILL.md",
            "line_start": 130,
            "line_end": 135
          },
          {
            "file": "SKILL.md",
            "line_start": 135,
            "line_end": 147
          },
          {
            "file": "SKILL.md",
            "line_start": 147,
            "line_end": 157
          },
          {
            "file": "SKILL.md",
            "line_start": 157,
            "line_end": 161
          },
          {
            "file": "SKILL.md",
            "line_start": 161,
            "line_end": 169
          },
          {
            "file": "SKILL.md",
            "line_start": 169,
            "line_end": 191
          },
          {
            "file": "SKILL.md",
            "line_start": 191,
            "line_end": 201
          },
          {
            "file": "SKILL.md",
            "line_start": 201,
            "line_end": 210
          },
          {
            "file": "SKILL.md",
            "line_start": 210,
            "line_end": 218
          },
          {
            "file": "SKILL.md",
            "line_start": 218,
            "line_end": 226
          },
          {
            "file": "SKILL.md",
            "line_start": 226,
            "line_end": 252
          },
          {
            "file": "SKILL.md",
            "line_start": 252,
            "line_end": 256
          },
          {
            "file": "SKILL.md",
            "line_start": 256,
            "line_end": 264
          },
          {
            "file": "SKILL.md",
            "line_start": 264,
            "line_end": 272
          },
          {
            "file": "SKILL.md",
            "line_start": 272,
            "line_end": 286
          },
          {
            "file": "SKILL.md",
            "line_start": 286,
            "line_end": 290
          },
          {
            "file": "SKILL.md",
            "line_start": 290,
            "line_end": 298
          },
          {
            "file": "SKILL.md",
            "line_start": 298,
            "line_end": 302
          },
          {
            "file": "SKILL.md",
            "line_start": 302,
            "line_end": 309
          },
          {
            "file": "SKILL.md",
            "line_start": 309,
            "line_end": 317
          },
          {
            "file": "SKILL.md",
            "line_start": 317,
            "line_end": 328
          },
          {
            "file": "SKILL.md",
            "line_start": 328,
            "line_end": 332
          },
          {
            "file": "SKILL.md",
            "line_start": 332,
            "line_end": 342
          },
          {
            "file": "SKILL.md",
            "line_start": 342,
            "line_end": 350
          },
          {
            "file": "SKILL.md",
            "line_start": 350,
            "line_end": 359
          },
          {
            "file": "SKILL.md",
            "line_start": 359,
            "line_end": 363
          },
          {
            "file": "SKILL.md",
            "line_start": 363,
            "line_end": 372
          },
          {
            "file": "SKILL.md",
            "line_start": 372,
            "line_end": 376
          },
          {
            "file": "SKILL.md",
            "line_start": 376,
            "line_end": 385
          },
          {
            "file": "SKILL.md",
            "line_start": 385,
            "line_end": 389
          },
          {
            "file": "SKILL.md",
            "line_start": 389,
            "line_end": 397
          },
          {
            "file": "SKILL.md",
            "line_start": 397,
            "line_end": 405
          },
          {
            "file": "SKILL.md",
            "line_start": 405,
            "line_end": 411
          },
          {
            "file": "SKILL.md",
            "line_start": 411,
            "line_end": 415
          },
          {
            "file": "SKILL.md",
            "line_start": 415,
            "line_end": 421
          },
          {
            "file": "SKILL.md",
            "line_start": 421,
            "line_end": 425
          },
          {
            "file": "SKILL.md",
            "line_start": 425,
            "line_end": 431
          },
          {
            "file": "SKILL.md",
            "line_start": 431,
            "line_end": 435
          },
          {
            "file": "SKILL.md",
            "line_start": 435,
            "line_end": 442
          },
          {
            "file": "SKILL.md",
            "line_start": 442,
            "line_end": 450
          },
          {
            "file": "SKILL.md",
            "line_start": 450,
            "line_end": 456
          },
          {
            "file": "SKILL.md",
            "line_start": 456,
            "line_end": 460
          },
          {
            "file": "SKILL.md",
            "line_start": 460,
            "line_end": 470
          },
          {
            "file": "SKILL.md",
            "line_start": 470,
            "line_end": 474
          },
          {
            "file": "SKILL.md",
            "line_start": 474,
            "line_end": 480
          }
        ]
      }
    ],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 2,
    "total_lines": 687,
    "audit_model": "claude",
    "audited_at": "2026-01-17T07:13:33.778Z"
  },
  "content": {
    "user_title": "Optimize AgentDB vector database performance 150x faster",
    "value_statement": "AgentDB vector searches slow down as data grows, causing application lag. This skill provides quantization and indexing techniques to achieve 150x faster searches with 4-32x memory reduction while maintaining accuracy.",
    "seo_keywords": [
      "AgentDB optimization",
      "vector database performance",
      "quantization techniques",
      "HNSW indexing",
      "Claude Code skills",
      "memory reduction",
      "search optimization",
      "Claude AI",
      "vector search speed",
      "database scaling"
    ],
    "actual_capabilities": [
      "Configure binary quantization for 32x memory reduction",
      "Implement HNSW indexing for O(log n) search complexity",
      "Set up in-memory caching with LRU eviction",
      "Execute batch operations for 500x faster inserts",
      "Monitor performance with real-time metrics",
      "Apply scaling strategies for millions of vectors"
    ],
    "limitations": [
      "Requires AgentDB v1.0.7+ via agentic-flow",
      "Quantization may cause 2-7% accuracy loss",
      "Binary quantization not suitable for all use cases",
      "Performance gains vary by dataset size and dimension"
    ],
    "use_cases": [
      {
        "target_user": "AI developers building RAG systems",
        "title": "Speed up vector similarity search",
        "description": "Reduce search latency from 15ms to 100Âµs in retrieval-augmented generation systems with HNSW indexing."
      },
      {
        "target_user": "Mobile app developers",
        "title": "Reduce memory usage for edge deployment",
        "description": "Deploy vector databases on mobile devices using binary quantization to shrink 3GB to 96MB."
      },
      {
        "target_user": "Data engineers handling large datasets",
        "title": "Scale to millions of vectors efficiently",
        "description": "Handle million-vector datasets with optimized batch operations and memory-efficient configurations."
      }
    ],
    "prompt_templates": [
      {
        "title": "Basic optimization setup",
        "scenario": "First-time AgentDB optimization",
        "prompt": "Help me set up AgentDB with balanced performance using scalar quantization and standard caching for a 50K vector dataset"
      },
      {
        "title": "Memory-constrained optimization",
        "scenario": "Mobile app with limited memory",
        "prompt": "Configure AgentDB for maximum memory efficiency on a mobile app that needs to store 100K vectors in under 50MB"
      },
      {
        "title": "High-performance search",
        "scenario": "Real-time recommendation system",
        "prompt": "Optimize AgentDB for sub-100Âµs search latency in a recommendation engine with 500K vectors, accepting 5% accuracy loss"
      },
      {
        "title": "Large-scale batch processing",
        "scenario": "Bulk vector ingestion pipeline",
        "prompt": "Set up AgentDB to efficiently ingest 10K vectors per batch with product quantization and monitor performance metrics"
      }
    ],
    "output_examples": [
      {
        "input": "Configure AgentDB for a mobile app with 200K vectors targeting under 100MB memory usage",
        "output": [
          "âœ… Applied binary quantization (32x reduction): 3GB â†’ 96MB",
          "âœ… Set cache size to 500 for mobile constraints",
          "âœ… Configured HNSW with M=8 for fast mobile searches",
          "âœ… Expected performance: <100Âµs search, 95-98% accuracy",
          "âœ… Memory target achieved: 96MB for 200K vectors"
        ]
      },
      {
        "input": "Set up AgentDB for a RAG system with 100K vectors needing 99% accuracy",
        "output": [
          "âœ… Used scalar quantization (4x reduction): retains 98-99% accuracy",
          "âœ… Configured cache size of 2000 patterns for high hit rates",
          "âœ… Set HNSW with M=16 and efSearch=100 for balanced performance",
          "âœ… Expected: <100Âµs search latency with 98-99% accuracy"
        ]
      },
      {
        "input": "Optimize batch insert performance for 10K vectors",
        "output": [
          "âœ… Enabled batch operations for bulk inserts",
          "âœ… Applied product quantization (8x reduction) for memory efficiency",
          "âœ… Configured HNSW with M=32 for faster indexing",
          "âœ… Expected: 2ms for 100 vectors, ~200ms for 10K vectors batch insert"
        ]
      }
    ],
    "best_practices": [
      "Start with scalar quantization for balanced performance, then adjust based on accuracy requirements",
      "Monitor cache hit rates and aim for >80% - increase cache size if below target",
      "Use batch operations for bulk inserts to achieve 500x performance improvement"
    ],
    "anti_patterns": [
      "Do not use binary quantization for high-accuracy requirements - it causes 2-5% accuracy loss",
      "Avoid individual vector inserts in loops - always use batch operations for multiple vectors",
      "Do not skip performance monitoring - cache hit rates below 50% indicate configuration issues"
    ],
    "faq": [
      {
        "question": "Which quantization type should I use?",
        "answer": "Use scalar for balanced performance (98-99% accuracy), binary for maximum memory reduction (95-98% accuracy), or product for high-dimensional vectors (93-97% accuracy)."
      },
      {
        "question": "What is the minimum AgentDB version required?",
        "answer": "AgentDB v1.0.7+ via agentic-flow is required. Install with: npm install agentic-flow"
      },
      {
        "question": "How do I integrate this with my existing Node.js app?",
        "answer": "Import createAgentDBAdapter from 'agentic-flow/reasoningbank' and pass optimization parameters to the constructor."
      },
      {
        "question": "Is my data safe during optimization?",
        "answer": "Yes, optimization techniques only affect storage format and indexing - your original data remains intact and accessible."
      },
      {
        "question": "Why are my searches still slow after optimization?",
        "answer": "Check cache hit rate (>80% target), reduce efSearch parameter for speed, and ensure HNSW indexing is enabled."
      },
      {
        "question": "How does this compare to other vector databases?",
        "answer": "AgentDB with these optimizations achieves <100Âµs search times and 32x memory reduction, outperforming most alternatives for similarity search workloads."
      }
    ]
  },
  "file_structure": [
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md",
      "lines": 510
    }
  ]
}
