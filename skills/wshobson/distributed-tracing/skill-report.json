{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-21T19:17:37.764Z",
    "slug": "wshobson-distributed-tracing",
    "source_url": "https://github.com/wshobson/agents/tree/main/plugins/observability-monitoring/skills/distributed-tracing",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "3.0.0",
    "source_type": "community",
    "content_hash": "f027ee2b349b310b0dd01a45f5e23a2e4f01aaa8395ced10cdeb6fbd8c9a3c56",
    "tree_hash": "9bb0bb5bce32f19275735a6f47686cb14764744fd7e27088e78943ffb2117c71"
  },
  "skill": {
    "name": "distributed-tracing",
    "description": "Implement distributed tracing with Jaeger and Tempo to track requests across microservices and identify performance bottlenecks. Use when debugging microservices, analyzing request flows, or implementing observability for distributed systems.",
    "summary": "Track request flows across microservices using Jaeger and Tempo distributed tracing",
    "icon": "ðŸ“¦",
    "version": "1.0.0",
    "author": "wshobson",
    "license": "MIT",
    "category": "devops",
    "tags": [
      "observability",
      "monitoring",
      "microservices",
      "jaeger",
      "tempo"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": [
      "scripts",
      "network",
      "external_commands"
    ]
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "Static analyzer detected 65 potential security patterns including C2 keywords, weak crypto, and external commands. Manual review confirms all findings are false positives - patterns appear in legitimate documentation and code examples for distributed tracing infrastructure deployment. No security risks identified.",
    "risk_factors": [
      "scripts",
      "network",
      "external_commands"
    ],
    "risk_factor_evidence": [
      {
        "factor": "scripts",
        "evidence": [
          {
            "file": "skill-report.json",
            "line_start": 424,
            "line_end": 424
          },
          {
            "file": "skill-report.json",
            "line_start": 425,
            "line_end": 425
          },
          {
            "file": "SKILL.md",
            "line_start": 191,
            "line_end": 198
          }
        ]
      },
      {
        "factor": "network",
        "evidence": [
          {
            "file": "skill-report.json",
            "line_start": 6,
            "line_end": 6
          },
          {
            "file": "SKILL.md",
            "line_start": 267,
            "line_end": 267
          },
          {
            "file": "SKILL.md",
            "line_start": 405,
            "line_end": 405
          },
          {
            "file": "SKILL.md",
            "line_start": 257,
            "line_end": 257
          },
          {
            "file": "SKILL.md",
            "line_start": 50,
            "line_end": 50
          },
          {
            "file": "SKILL.md",
            "line_start": 65,
            "line_end": 65
          },
          {
            "file": "SKILL.md",
            "line_start": 156,
            "line_end": 156
          },
          {
            "file": "SKILL.md",
            "line_start": 202,
            "line_end": 202
          },
          {
            "file": "SKILL.md",
            "line_start": 257,
            "line_end": 257
          },
          {
            "file": "SKILL.md",
            "line_start": 267,
            "line_end": 267
          }
        ]
      },
      {
        "factor": "external_commands",
        "evidence": [
          {
            "file": "SKILL.md",
            "line_start": 25,
            "line_end": 34
          },
          {
            "file": "SKILL.md",
            "line_start": 34,
            "line_end": 47
          },
          {
            "file": "SKILL.md",
            "line_start": 47,
            "line_end": 69
          },
          {
            "file": "SKILL.md",
            "line_start": 69,
            "line_end": 73
          },
          {
            "file": "SKILL.md",
            "line_start": 73,
            "line_end": 89
          },
          {
            "file": "SKILL.md",
            "line_start": 89,
            "line_end": 91
          },
          {
            "file": "SKILL.md",
            "line_start": 91,
            "line_end": 98
          },
          {
            "file": "SKILL.md",
            "line_start": 98,
            "line_end": 139
          },
          {
            "file": "SKILL.md",
            "line_start": 139,
            "line_end": 142
          },
          {
            "file": "SKILL.md",
            "line_start": 142,
            "line_end": 185
          },
          {
            "file": "SKILL.md",
            "line_start": 185,
            "line_end": 188
          },
          {
            "file": "SKILL.md",
            "line_start": 188,
            "line_end": 236
          },
          {
            "file": "SKILL.md",
            "line_start": 236,
            "line_end": 238
          },
          {
            "file": "SKILL.md",
            "line_start": 238,
            "line_end": 243
          },
          {
            "file": "SKILL.md",
            "line_start": 243,
            "line_end": 246
          },
          {
            "file": "SKILL.md",
            "line_start": 246,
            "line_end": 251
          },
          {
            "file": "SKILL.md",
            "line_start": 251,
            "line_end": 258
          },
          {
            "file": "SKILL.md",
            "line_start": 258,
            "line_end": 261
          },
          {
            "file": "SKILL.md",
            "line_start": 261,
            "line_end": 268
          },
          {
            "file": "SKILL.md",
            "line_start": 268,
            "line_end": 274
          },
          {
            "file": "SKILL.md",
            "line_start": 274,
            "line_end": 326
          },
          {
            "file": "SKILL.md",
            "line_start": 326,
            "line_end": 328
          },
          {
            "file": "SKILL.md",
            "line_start": 328,
            "line_end": 333
          },
          {
            "file": "SKILL.md",
            "line_start": 333,
            "line_end": 338
          },
          {
            "file": "SKILL.md",
            "line_start": 338,
            "line_end": 341
          },
          {
            "file": "SKILL.md",
            "line_start": 341,
            "line_end": 346
          },
          {
            "file": "SKILL.md",
            "line_start": 346,
            "line_end": 349
          },
          {
            "file": "SKILL.md",
            "line_start": 349,
            "line_end": 354
          },
          {
            "file": "SKILL.md",
            "line_start": 354,
            "line_end": 361
          },
          {
            "file": "SKILL.md",
            "line_start": 361,
            "line_end": 364
          },
          {
            "file": "SKILL.md",
            "line_start": 364,
            "line_end": 369
          },
          {
            "file": "SKILL.md",
            "line_start": 369,
            "line_end": 373
          },
          {
            "file": "SKILL.md",
            "line_start": 373,
            "line_end": 399
          },
          {
            "file": "SKILL.md",
            "line_start": 399,
            "line_end": 413
          },
          {
            "file": "SKILL.md",
            "line_start": 413,
            "line_end": 430
          },
          {
            "file": "SKILL.md",
            "line_start": 430,
            "line_end": 431
          },
          {
            "file": "SKILL.md",
            "line_start": 431,
            "line_end": 432
          },
          {
            "file": "SKILL.md",
            "line_start": 432,
            "line_end": 436
          },
          {
            "file": "SKILL.md",
            "line_start": 436,
            "line_end": 437
          },
          {
            "file": "SKILL.md",
            "line_start": 437,
            "line_end": 438
          }
        ]
      }
    ],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 2,
    "total_lines": 1155,
    "audit_model": "claude",
    "audited_at": "2026-01-21T19:17:37.764Z"
  },
  "content": {
    "user_title": "Implement Distributed Tracing with Jaeger and Tempo",
    "value_statement": "Debugging microservices is difficult without visibility into request flows across services. This skill helps you implement distributed tracing with Jaeger and Tempo to track requests, identify bottlenecks, and understand service dependencies.",
    "seo_keywords": [
      "Claude Code",
      "Claude",
      "Codex",
      "distributed tracing",
      "Jaeger",
      "Tempo",
      "OpenTelemetry",
      "microservices observability",
      "request tracing",
      "performance monitoring"
    ],
    "actual_capabilities": [
      "Deploy Jaeger and Tempo tracing infrastructure on Kubernetes or Docker",
      "Instrument applications with OpenTelemetry in Python, Node.js, and Go",
      "Configure context propagation across HTTP service boundaries",
      "Set up sampling strategies for production tracing workloads",
      "Integrate distributed tracing with logging systems",
      "Query and analyze traces to identify performance bottlenecks"
    ],
    "limitations": [
      "Does not provide pre-built dashboards or alerting rules",
      "Requires manual instrumentation of application code",
      "Does not cover advanced sampling strategies or custom exporters",
      "Limited to Jaeger and Tempo backends, does not include other tracing systems"
    ],
    "use_cases": [
      {
        "title": "Debug Microservice Latency Issues",
        "description": "Deploy Jaeger tracing and instrument your Python Flask services to identify which downstream calls are causing slow API responses.",
        "target_user": "Backend Developer"
      },
      {
        "title": "Map Service Dependencies",
        "description": "Set up distributed tracing across your Node.js microservices to visualize service dependency graphs and understand request flow patterns.",
        "target_user": "DevOps Engineer"
      },
      {
        "title": "Implement Production Observability",
        "description": "Configure Tempo with Grafana and implement sampling strategies to track traces in production without performance overhead.",
        "target_user": "Site Reliability Engineer"
      }
    ],
    "prompt_templates": [
      {
        "title": "Set up Jaeger on Kubernetes",
        "prompt": "Help me deploy Jaeger on my Kubernetes cluster with Elasticsearch storage",
        "scenario": "Beginner setting up tracing infrastructure"
      },
      {
        "title": "Instrument Flask Application",
        "prompt": "Add OpenTelemetry instrumentation to my Flask API to send traces to Jaeger",
        "scenario": "Developer adding tracing to existing service"
      },
      {
        "title": "Configure Context Propagation",
        "prompt": "Show me how to propagate trace context when my Node.js service calls downstream APIs",
        "scenario": "Intermediate user connecting multiple services"
      },
      {
        "title": "Optimize Tracing Overhead",
        "prompt": "Help me configure adaptive sampling for my production Go services to reduce tracing overhead while capturing errors",
        "scenario": "Advanced user optimizing production setup"
      }
    ],
    "output_examples": [
      {
        "input": "Help me deploy Jaeger on Kubernetes",
        "output": "I will help you deploy Jaeger on Kubernetes using the Jaeger Operator. First, I will create the observability namespace and deploy the operator. Then I will configure a production Jaeger instance with Elasticsearch storage and enable ingress for the UI."
      },
      {
        "input": "Add tracing to my Flask application",
        "output": "I will instrument your Flask application with OpenTelemetry. I will install the required packages, initialize the tracer provider with Jaeger exporter, and add automatic Flask instrumentation. I will also show you how to create custom spans for database queries."
      },
      {
        "input": "Configure sampling to trace only errors",
        "output": "I will set up a custom sampler that traces all requests with errors while sampling only 1 percent of successful requests. This approach captures all failures for debugging while minimizing overhead from normal operations."
      }
    ],
    "best_practices": [
      "Use sampling rates between 1 and 10 percent in production to minimize performance overhead",
      "Add meaningful tags like user ID and request ID to spans for easier filtering and analysis",
      "Propagate trace context across all service boundaries including message queues and async jobs"
    ],
    "anti_patterns": [
      "Tracing 100 percent of production traffic without sampling leads to high storage costs and performance impact",
      "Creating too many spans for fine-grained operations adds overhead without useful insights",
      "Storing sensitive data like passwords or API keys in span tags violates security best practices"
    ],
    "faq": [
      {
        "question": "What is the difference between Jaeger and Tempo?",
        "answer": "Jaeger is a complete distributed tracing system with its own UI and query capabilities. Tempo is a tracing backend designed to integrate with Grafana for visualization. Tempo uses object storage like S3 for cost-effective trace storage at scale."
      },
      {
        "question": "How much overhead does distributed tracing add?",
        "answer": "With proper sampling, distributed tracing typically adds less than 1 percent CPU overhead. The main cost is network bandwidth to send spans and storage for trace data. Use sampling rates of 1 to 10 percent in production."
      },
      {
        "question": "Can I trace requests across different programming languages?",
        "answer": "Yes. OpenTelemetry provides instrumentation libraries for all major languages and uses standard propagation formats. As long as all services propagate trace context headers, traces work across Python, Node.js, Go, Java, and other languages."
      },
      {
        "question": "How do I correlate traces with logs?",
        "answer": "Extract the trace ID from the current span context and add it to your log entries as a structured field. This allows you to jump from a trace to related logs and vice versa for complete request visibility."
      },
      {
        "question": "What sampling strategy should I use?",
        "answer": "Start with probabilistic sampling at 1 percent for high-traffic services. Use higher rates for low-traffic services. Consider adaptive sampling that always traces errors while sampling successful requests at a lower rate."
      },
      {
        "question": "How long should I retain trace data?",
        "answer": "Most teams retain traces for 7 to 30 days. Traces are useful for recent debugging but become less valuable over time. Configure retention based on your storage budget and compliance requirements."
      }
    ]
  },
  "file_structure": [
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md",
      "lines": 439
    }
  ]
}
