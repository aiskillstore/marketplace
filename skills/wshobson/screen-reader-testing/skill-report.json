{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-04T16:21:26.444Z",
    "slug": "wshobson-screen-reader-testing",
    "source_url": "https://github.com/wshobson/agents/tree/main/plugins/accessibility-compliance/skills/screen-reader-testing",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "2.0.0",
    "source_type": "community",
    "content_hash": "95b6b60814c1bb40049c9a90aea782f71f6c7bbe7d40935fe71dd13117886c96",
    "tree_hash": "daf7aafcf9331e4b8aef615a3a112dc92a42257532063e1de4523de5b0d09345"
  },
  "skill": {
    "name": "screen-reader-testing",
    "description": "Test web applications with screen readers including VoiceOver, NVDA, and JAWS. Use when validating screen reader compatibility, debugging accessibility issues, or ensuring assistive technology support.",
    "summary": "Test web applications with screen readers including VoiceOver, NVDA, and JAWS. Use when validating s...",
    "icon": "ðŸ¦»",
    "version": "1.0.0",
    "author": "wshobson",
    "license": "MIT",
    "category": "documentation",
    "tags": [
      "accessibility",
      "screen reader",
      "testing",
      "a11y",
      "web"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": []
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "Pure documentation skill with instructional content for screen reader testing. Contains no executable code, no file system access, no network calls, and no external command execution. The SKILL.md file only provides guidance, checklists, and example patterns for accessible web development.",
    "risk_factor_evidence": [],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 4,
    "total_lines": 533,
    "audit_model": "claude",
    "audited_at": "2026-01-04T16:21:26.444Z"
  },
  "content": {
    "user_title": "Test screen reader support fast",
    "value_statement": "Screen reader issues are hard to reproduce and validate. This skill gives clear test steps and fixes for VoiceOver, NVDA, JAWS, and TalkBack.",
    "seo_keywords": [
      "screen reader testing",
      "accessibility QA",
      "VoiceOver checklist",
      "NVDA testing",
      "JAWS testing",
      "ARIA validation",
      "Claude",
      "Codex",
      "Claude Code"
    ],
    "actual_capabilities": [
      "Provide platform specific setup steps for VoiceOver, NVDA, JAWS, and TalkBack",
      "Offer command references for navigation, forms, and landmarks",
      "Supply checklists for headings, links, forms, and dynamic content",
      "Show accessible patterns for modals, live regions, and tabs",
      "Include debugging tips for accessible name and state"
    ],
    "limitations": [
      "Does not run screen readers or automate tests",
      "Does not cover every screen reader or browser combination",
      "Does not validate visual design or color contrast",
      "Relies on manual verification by the user"
    ],
    "use_cases": [
      {
        "target_user": "QA tester",
        "title": "Manual regression pass",
        "description": "Run repeatable screen reader checks before a release."
      },
      {
        "target_user": "Frontend developer",
        "title": "Fix ARIA issues",
        "description": "Debug missing announcements and focus behavior in components."
      },
      {
        "target_user": "Accessibility lead",
        "title": "Team test guide",
        "description": "Standardize screen reader testing coverage across teams."
      }
    ],
    "prompt_templates": [
      {
        "title": "Start with VoiceOver",
        "scenario": "First time testing on macOS",
        "prompt": "Create a VoiceOver test checklist for my landing page with headings, landmarks, and forms."
      },
      {
        "title": "NVDA quick audit",
        "scenario": "Validate a new form flow",
        "prompt": "Give me an NVDA script to test a checkout form, including error handling and focus movement."
      },
      {
        "title": "Dynamic content checks",
        "scenario": "SPA updates not announced",
        "prompt": "List steps to verify live region announcements for search results updates."
      },
      {
        "title": "Advanced widget review",
        "scenario": "Custom tabs and modals",
        "prompt": "Review my tab and modal behavior and list the critical screen reader checks to run."
      }
    ],
    "output_examples": [
      {
        "input": "Provide a checklist to test a modal dialog with NVDA.",
        "output": [
          "Confirm the dialog title and description are announced on open",
          "Verify focus moves into the dialog and is trapped inside",
          "Check that Escape closes the dialog and focus returns",
          "Ensure all buttons announce role and state"
        ]
      }
    ],
    "best_practices": [
      "Test with real screen readers on supported platforms",
      "Use semantic HTML before adding ARIA",
      "Verify keyboard only flow before screen reader tests"
    ],
    "anti_patterns": [
      "Relying on a single screen reader for approval",
      "Testing only happy paths without errors",
      "Ignoring mobile screen reader behavior"
    ],
    "faq": [
      {
        "question": "Is this compatible with Claude, Codex, and Claude Code?",
        "answer": "Yes, it is plain guidance and works in Claude, Codex, and Claude Code."
      },
      {
        "question": "What are the main limits of this skill?",
        "answer": "It is manual guidance and does not run tests or automate screen readers."
      },
      {
        "question": "Can it integrate with my test pipeline?",
        "answer": "It provides steps and checklists you can adapt into your QA process."
      },
      {
        "question": "Does it access or store my data?",
        "answer": "No, it only provides instructions and sample patterns."
      },
      {
        "question": "What if NVDA or VoiceOver results are inconsistent?",
        "answer": "Verify browser, mode, and focus behavior, then retest with the listed commands."
      },
      {
        "question": "How does it compare to automated a11y tools?",
        "answer": "It covers real screen reader behavior that automated tools cannot fully detect."
      }
    ]
  },
  "file_structure": [
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md"
    }
  ]
}
