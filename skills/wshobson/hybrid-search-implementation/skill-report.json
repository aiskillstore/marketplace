{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-21T19:22:39.130Z",
    "slug": "wshobson-hybrid-search-implementation",
    "source_url": "https://github.com/wshobson/agents/tree/main/plugins/llm-application-dev/skills/hybrid-search-implementation",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "3.0.0",
    "source_type": "community",
    "content_hash": "c71cedb27c6a3c4624e848b8605709c19ff8610e6e13ebfd15620360bd1a8a2c",
    "tree_hash": "ff8cd0f73e07939078c05cb8851c30f99d170483a77dd74b7535da1798814d67"
  },
  "skill": {
    "name": "hybrid-search-implementation",
    "description": "Combine vector and keyword search for improved retrieval. Use when implementing RAG systems, building search engines, or when neither approach alone provides sufficient recall.",
    "summary": "Combine vector and keyword search for improved retrieval. Use when implementing RAG systems, building search engines, or when neither approach alone provides sufficient recall.",
    "icon": "üîç",
    "version": "1.0.0",
    "author": "wshobson",
    "license": "MIT",
    "tags": [
      "hybrid-search",
      "vector-search",
      "rag",
      "information-retrieval",
      "semantic-search"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": [
      "scripts",
      "filesystem"
    ]
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "All static findings are false positives. The skill contains documentation templates for hybrid search algorithms (RRF, linear fusion) with PostgreSQL, Elasticsearch, and custom RAG pipelines. Static scanner misidentified mathematical formulas as crypto operations, markdown code fences as command execution, and benign terminology as security risks. No malicious code or credential exfiltration present.",
    "risk_factor_evidence": [
      {
        "factor": "scripts",
        "evidence": [
          {
            "file": "SKILL.md",
            "line_start": 41,
            "line_end": 110
          }
        ]
      },
      {
        "factor": "filesystem",
        "evidence": [
          {
            "file": "SKILL.md",
            "line_start": 1,
            "line_end": 569
          }
        ]
      }
    ],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 2,
    "total_lines": 1169,
    "audit_model": "claude",
    "audited_at": "2026-01-21T19:22:39.130Z",
    "risk_factors": [
      "scripts",
      "filesystem"
    ]
  },
  "content": {
    "user_title": "Implement Hybrid Search for RAG",
    "value_statement": "Pure vector search misses exact matches while keyword search fails on semantic queries. This skill provides ready-to-use templates for combining both approaches using RRF fusion, linear combination, and cross-encoder reranking.",
    "seo_keywords": [
      "hybrid search",
      "vector search",
      "semantic search",
      "RAG implementation",
      "Reciprocal Rank Fusion",
      "information retrieval",
      "search fusion",
      "dense vector search",
      "Claude",
      "Codex",
      "Claude Code"
    ],
    "actual_capabilities": [
      "Implement Reciprocal Rank Fusion (RRF) for combining vector and keyword results",
      "Build PostgreSQL hybrid search with pgvector and full-text search",
      "Create Elasticsearch hybrid search with kNN and BM25",
      "Develop custom hybrid RAG pipelines with parallel search execution",
      "Apply cross-encoder reranking for improved result quality",
      "Tune fusion weights for optimal vector-to-keyword balance"
    ],
    "limitations": [
      "Requires separate vector store and keyword store implementations",
      "Does not include embedding model or vector database setup",
      "Performance depends on underlying search backends",
      "Reranking adds latency and requires cross-encoder model"
    ],
    "use_cases": [
      {
        "title": "Build RAG Systems with Better Recall",
        "description": "Combine semantic understanding with exact matching to improve document retrieval for LLM context. Handle queries that need both conceptual similarity and specific terminology.",
        "target_user": "ML Engineers building RAG applications"
      },
      {
        "title": "Implement Enterprise Search",
        "description": "Create search systems that find both semantically related content and documents containing exact terms like product codes, names, or identifiers.",
        "target_user": "Search Engineers and Backend Developers"
      },
      {
        "title": "Improve Search Quality Metrics",
        "description": "Apply fusion techniques like RRF to boost recall without sacrificing precision. Log individual scores to debug and tune search quality.",
        "target_user": "Data Scientists and Search Engineers"
      }
    ],
    "prompt_templates": [
      {
        "title": "Basic RRF Fusion",
        "prompt": "Help me implement Reciprocal Rank Fusion to combine vector and keyword search results. I have two lists of (doc_id, score) tuples. Show me how to fuse them.",
        "scenario": "Starting hybrid search implementation"
      },
      {
        "title": "PostgreSQL Setup",
        "prompt": "Show me how to set up a PostgreSQL table with pgvector for embeddings and tsvector for full-text search. Include the HNSW and GIN index definitions.",
        "scenario": "Setting up PostgreSQL hybrid search"
      },
      {
        "title": "Elasticsearch kNN",
        "prompt": "Help me write an Elasticsearch hybrid search query that combines dense vector kNN with BM25 text matching using the RRF rank feature.",
        "scenario": "Building Elasticsearch hybrid index"
      },
      {
        "title": "Custom RAG Pipeline",
        "prompt": "Create a complete HybridRAGPipeline class that executes vector and keyword searches in parallel, fuses results with configurable methods (RRF or linear), and optionally reranks with a cross-encoder.",
        "scenario": "Building production RAG pipeline"
      }
    ],
    "output_examples": [
      {
        "input": "How do I combine vector and keyword search results?",
        "output": [
          "Use Reciprocal Rank Fusion (RRF):",
          "1. Run both searches to get ranked lists",
          "2. For each result, calculate score = sum(weight / (k + rank))",
          "3. Fuse by sorting combined scores",
          "",
          "Example:",
          "  vector_results = [('doc1', 0.9), ('doc2', 0.8)]",
          "  keyword_results = [('doc2', 0.95), ('doc3', 0.7)]",
          "  fused = rrf_fusion([vector_results, keyword_results])",
          "  # Returns [('doc2', 0.03), ('doc1', 0.016), ('doc3', 0.016)]"
        ]
      },
      {
        "input": "What's the difference between RRF and linear fusion?",
        "output": [
          "RRF (Reciprocal Rank Fusion):",
          "  - Score = sum(1 / (k + rank))",
          "  - Rank-based, no score normalization needed",
          "  - k=60 is standard constant",
          "  - Works well without tuning",
          "",
          "Linear Combination:",
          "  - Score = alpha * vector_score + (1-alpha) * keyword_score",
          "  - Requires score normalization to [0,1]",
          "  - Alpha needs empirical tuning per dataset",
          "  - More controllable but requires tuning"
        ]
      },
      {
        "input": "Should I add reranking to my hybrid search?",
        "output": [
          "Yes, reranking improves quality significantly:",
          "",
          "1. Fetch more candidates from hybrid search (50-100)",
          "2. Use cross-encoder to score query-document pairs",
          "3. Return top-k reranked results",
          "",
          "Trade-offs:",
          "  - + Better precision and relevance",
          "  - - Additional latency (cross-encoder inference)",
          "  - Model: cross-encoder/ms-marco-MiniLM-L-6-v2 is a good starting point"
        ]
      }
    ],
    "best_practices": [
      "Start with RRF fusion as it works well without parameter tuning. Use k=60 as the standard constant.",
      "Fetch more candidates from individual searches (3x the final limit) before fusion to ensure good recall.",
      "Log both vector and keyword scores separately during development. This helps debug when results are missing.",
      "Use cross-encoder reranking for production systems. The quality improvement is significant."
    ],
    "anti_patterns": [
      "Don't assume a single fusion weight works for all queries. Some queries need more semantic matching while others need keyword matching.",
      "Don't skip keyword search entirely. Exact term matching handles names, codes, and specific phrases better than vectors.",
      "Don't over-fetch candidates. Balance recall needs against latency. 50-100 candidates before reranking is usually sufficient."
    ],
    "faq": [
      {
        "question": "What fusion method should I start with?",
        "answer": "Start with Reciprocal Rank Fusion (RRF). It performs well without tuning and is the default in many production systems. Use k=60 as the constant. Switch to linear combination only if you need explicit control over vector-to-keyword balance."
      },
      {
        "question": "How do I handle different score ranges between vector and keyword search?",
        "answer": "Normalize scores to [0, 1] before combining. For vectors, use min-max normalization. For BM25, scores are already somewhat normalized. Linear combination requires normalization; RRF does not because it uses ranks instead of raw scores."
      },
      {
        "question": "What vector dimensions should I use?",
        "answer": "Common choices are 768 (Sentence Transformers), 1024 (large models), or 1536 (OpenAI ada-002). Match your embedding model. PostgreSQL pgvector and Elasticsearch both support configurable dimensions."
      },
      {
        "question": "How do I choose the vector-to-keyword weight (alpha)?",
        "answer": "Start with alpha=0.5 (equal weighting). Test on your specific queries and adjust based on whether you need more semantic recall or exact matching. Some queries need alpha=0.7-0.8, others need 0.3-0.4."
      },
      {
        "question": "Can I use hybrid search without a reranker?",
        "answer": "Yes, hybrid search without reranking works well for many use cases. The fusion step (RRF or linear) already combines results intelligently. Add reranking when you need the highest quality results and can tolerate additional latency."
      },
      {
        "question": "What databases support hybrid search?",
        "answer": "PostgreSQL with pgvector extension, Elasticsearch 8.x (native kNN + RRF), Vespa, Milvus, Qdrant, and Weaviate all support hybrid search patterns. The choice depends on your existing infrastructure and scaling requirements."
      }
    ]
  },
  "file_structure": [
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md",
      "lines": 569
    }
  ]
}
