{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-21T15:43:27.335Z",
    "slug": "c0ntr0lledcha0s-analyzing-docs",
    "source_url": "https://github.com/C0ntr0lledCha0s/claude-code-plugin-automations/tree/main/documents-manager/skills/analyzing-docs",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "3.0.0",
    "source_type": "community",
    "content_hash": "4271c047ac72c5a40a06f44525d6984b902ffbe853cd68b9206cc06951ff3eb3",
    "tree_hash": "15869264b829291d1514ac493b6a9341527ab41ce78b61ca81d9f602f141c857"
  },
  "skill": {
    "name": "analyzing-docs",
    "description": "Expert at analyzing documentation quality, coverage, and completeness. Auto-invokes when evaluating documentation health, checking documentation coverage, auditing existing docs, assessing documentation quality metrics, or analyzing how well code is documented. Provides frameworks for measuring documentation effectiveness.\n",
    "summary": "Expert at analyzing documentation quality, coverage, and completeness. Auto-invokes when evaluating ...",
    "icon": "ðŸ“¦",
    "version": "1.0.0",
    "author": "C0ntr0lledCha0s",
    "license": "MIT",
    "tags": [
      "documentation",
      "code-analysis",
      "documentation-audit",
      "quality-metrics",
      "code-coverage"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": [
      "filesystem",
      "external_commands"
    ]
  },
  "security_audit": {
    "risk_level": "low",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "Static analysis flagged 32 potential issues, all evaluated as false positives. The 'network' detection is a legitimate GitHub source URL. 'External_commands' detections are Markdown code fence delimiters, not shell execution. C2 keywords and cryptographic algorithm flags are documentation text misinterpreted by pattern matching. The skill only uses Read, Glob, Grep tools for safe documentation analysis.",
    "risk_factor_evidence": [
      {
        "factor": "filesystem",
        "evidence": [
          {
            "file": "SKILL.md",
            "line_start": 1,
            "line_end": 212
          }
        ]
      },
      {
        "factor": "external_commands",
        "evidence": [
          {
            "file": "SKILL.md",
            "line_start": 106,
            "line_end": 127
          }
        ]
      }
    ],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 2,
    "total_lines": 560,
    "audit_model": "claude",
    "audited_at": "2026-01-21T16:00:00.000Z",
    "risk_factors": [
      "filesystem",
      "external_commands"
    ]
  },
  "content": {
    "user_title": "Analyze documentation quality and coverage",
    "value_statement": "Documentation gaps and quality issues slow down team productivity and onboarding. This skill provides automated documentation analysis with measurable coverage metrics, quality scoring frameworks, and actionable improvement recommendations.",
    "seo_keywords": [
      "Claude",
      "Codex",
      "Claude Code",
      "documentation analysis",
      "documentation quality",
      "code documentation",
      "doc coverage",
      "technical writing",
      "API documentation",
      "documentation audit"
    ],
    "actual_capabilities": [
      "Calculates documentation coverage metrics across functions, classes, modules, and files",
      "Scores documentation quality across completeness, accuracy, clarity, and usefulness dimensions",
      "Identifies documentation gaps with specific file and function locations",
      "Generates comprehensive markdown reports with executive summaries and recommendations",
      "Provides language-specific patterns for JavaScript, TypeScript, Python, and Go codebases",
      "Tracks documentation health over time with prioritized improvement recommendations"
    ],
    "limitations": [
      "Does not generate or write documentation (use writing-docs skill for that)",
      "Cannot access private repositories or authenticated documentation sources",
      "Analysis is based on static code inspection, not runtime behavior",
      "Quality scoring relies on sampling for large codebases, not exhaustive review"
    ],
    "use_cases": [
      {
        "title": "Onboard new developers faster",
        "description": "New team members need clear documentation to understand codebases quickly. This skill identifies what is documented and where gaps exist, enabling focused documentation efforts that reduce onboarding time and support queries.",
        "target_user": "Engineering managers and team leads"
      },
      {
        "title": "Maintain documentation quality standards",
        "description": "Teams struggle to maintain documentation as code evolves. Regular documentation audits surface outdated examples, missing parameters, and deprecated content before they cause confusion or bugs.",
        "target_user": "Technical writers and documentation owners"
      },
      {
        "title": "Assess project health for acquisition or migration",
        "description": "Due diligence on codebases requires understanding their documentation maturity. This skill provides objective metrics and reports that help evaluate documentation quality across large codebases efficiently.",
        "target_user": "DevOps engineers and technical auditors"
      }
    ],
    "prompt_templates": [
      {
        "title": "Quick documentation health check",
        "prompt": "Analyze the documentation health of this codebase. What percentage of functions and classes are documented? What are the most critical documentation gaps?",
        "scenario": "When you want a fast overview of documentation status"
      },
      {
        "title": "Detailed coverage report",
        "prompt": "Generate a full documentation coverage report for this project. Include coverage percentages for functions, classes, modules, and files. Identify the top 5 files with the worst documentation coverage.",
        "scenario": "When you need comprehensive metrics for planning"
      },
      {
        "title": "Quality assessment",
        "prompt": "Evaluate the quality of existing documentation in this codebase. Score completeness, accuracy, clarity, and usefulness. Provide specific examples of both excellent and poor documentation.",
        "scenario": "When you want to understand documentation quality beyond just coverage"
      },
      {
        "title": "Remediation roadmap",
        "prompt": "Based on the documentation analysis, create a prioritized roadmap for improving documentation. Group items by priority and provide specific file paths and function names for each recommendation.",
        "scenario": "When you need actionable next steps for documentation improvement"
      }
    ],
    "output_examples": [
      {
        "input": "Analyze documentation coverage in this Python project",
        "output": [
          "Documentation Coverage Summary",
          "- Functions: 145 documented / 210 total (69%)",
          "- Classes: 23 documented / 28 total (82%)",
          "- Modules: 15 documented / 18 total (83%)",
          "",
          "Overall Coverage: 71%",
          "",
          "Critical Gaps:",
          "- src/api/client.py: Missing docstrings for 8 functions",
          "- src/utils/validation.py: Outdated parameter types in 5 functions",
          "- src/models/user.py: Missing error condition documentation"
        ]
      },
      {
        "input": "Generate a quality assessment report",
        "output": [
          "Documentation Quality Assessment",
          "",
          "Quality Scores:",
          "- Completeness: 6/10 - Most APIs documented but many lack parameter details",
          "- Accuracy: 7/10 - Documentation mostly matches code, some outdated examples",
          "- Clarity: 8/10 - Well-written and organized, consistent terminology",
          "- Usefulness: 5/10 - Few practical examples, missing troubleshooting info",
          "",
          "Overall Quality Score: 6.5/10 (Acceptable)"
        ]
      }
    ],
    "best_practices": [
      "Run documentation analysis early in projects to establish baseline metrics and track improvement over time",
      "Use the quality scoring framework to prioritize which documentation areas need the most attention",
      "Combine this skill with writing-docs to create a complete documentation improvement workflow"
    ],
    "anti_patterns": [
      "Avoid analyzing documentation without reviewing the output - automated tools may miss context-specific quality issues",
      "Do not rely solely on coverage percentages; high coverage with poor quality is worse than lower coverage with excellent docs",
      "Avoid ignoring documentation debt; it compounds over time and becomes harder to address later"
    ],
    "faq": [
      {
        "question": "What programming languages does this skill support?",
        "answer": "The skill provides analysis patterns for JavaScript, TypeScript, Python, and Go. It can analyze documentation in any language by examining docstrings, comments, and documentation files."
      },
      {
        "question": "How does this skill differ from writing-docs?",
        "answer": "This skill analyzes and measures existing documentation. The writing-docs skill generates new documentation. Use both together: analyze to find gaps, then write to fill them."
      },
      {
        "question": "Can this skill analyze documentation in private repositories?",
        "answer": "No. The skill operates on repositories accessible through standard Read, Glob, and Grep tools. Private repositories require appropriate authentication which is handled by the calling context."
      },
      {
        "question": "How accurate is the quality scoring?",
        "answer": "Quality scoring samples documentation for assessment on larger codebases. For small projects, it can review all documentation. Scores are subjective guidelines, not definitive assessments."
      },
      {
        "question": "Does this skill modify any files?",
        "answer": "No. This skill is read-only. It only analyzes existing documentation and generates reports. It does not create, modify, or delete any files."
      },
      {
        "question": "How long does analysis take for large codebases?",
        "answer": "Analysis time depends on repository size and tool availability. A typical project of a few thousand files completes in seconds. Very large repositories may take longer."
      }
    ]
  },
  "file_structure": [
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md",
      "lines": 212
    }
  ]
}
