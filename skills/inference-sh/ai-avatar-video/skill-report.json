{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-02-04T08:53:54.667Z",
    "slug": "inference-sh-ai-avatar-video",
    "source_url": "https://github.com/inference-sh/skills/tree/main/skills/ai-avatar-video/",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "3.0.0",
    "source_type": "community",
    "content_hash": "6f61b8291b13610840ef0ee3420c0ae1aba5dd8c46b9519fd1a23fe8b90f236a",
    "tree_hash": "45878509fdc77df94e0dfea73a1e64f52b0711fbb9c87d1857a382a7a2a59970"
  },
  "skill": {
    "name": "ai-avatar-video",
    "description": "Create AI avatar and talking head videos with OmniHuman, Fabric, PixVerse via inference.sh CLI. Models: OmniHuman 1.5, OmniHuman 1.0, Fabric 1.0, PixVerse Lipsync. Capabilities: audio-driven avatars, lipsync videos, talking head generation, virtual presenters. Use for: AI presenters, explainer videos, virtual influencers, dubbing, marketing videos.",
    "summary": "Generate talking head videos with AI avatars using OmniHuman, Fabric, and PixVerse models through the inference.sh CLI platform.",
    "icon": "ðŸŽ¥",
    "version": "1.0.0",
    "author": "inference-sh",
    "license": "MIT",
    "category": "productivity",
    "tags": [
      "AI video",
      "avatar",
      "lipsync",
      "talking head",
      "video generation"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": [
      "network"
    ]
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "Documentation file containing example CLI commands. Static scanner misidentified markdown code blocks as code execution patterns. No actual security vulnerabilities found.",
    "risk_factor_evidence": [
      {
        "factor": "network",
        "evidence": [
          {
            "file": "SKILL.md",
            "line_start": 16,
            "line_end": 16
          },
          {
            "file": "SKILL.md",
            "line_start": 21,
            "line_end": 21
          },
          {
            "file": "SKILL.md",
            "line_start": 25,
            "line_end": 25
          },
          {
            "file": "SKILL.md",
            "line_start": 26,
            "line_end": 26
          },
          {
            "file": "SKILL.md",
            "line_start": 53,
            "line_end": 53
          },
          {
            "file": "SKILL.md",
            "line_start": 54,
            "line_end": 54
          },
          {
            "file": "SKILL.md",
            "line_start": 64,
            "line_end": 64
          },
          {
            "file": "SKILL.md",
            "line_start": 65,
            "line_end": 65
          },
          {
            "file": "SKILL.md",
            "line_start": 73,
            "line_end": 73
          },
          {
            "file": "SKILL.md",
            "line_start": 74,
            "line_end": 74
          },
          {
            "file": "SKILL.md",
            "line_start": 90,
            "line_end": 90
          },
          {
            "file": "SKILL.md",
            "line_start": 99,
            "line_end": 99
          },
          {
            "file": "SKILL.md",
            "line_start": 108,
            "line_end": 108
          },
          {
            "file": "SKILL.md",
            "line_start": 151,
            "line_end": 151
          },
          {
            "file": "SKILL.md",
            "line_start": 152,
            "line_end": 152
          },
          {
            "file": "SKILL.md",
            "line_start": 153,
            "line_end": 153
          }
        ]
      }
    ],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 1,
    "total_lines": 154,
    "audit_model": "claude",
    "audited_at": "2026-02-04T08:53:54.667Z"
  },
  "content": {
    "user_title": "Generate AI Talking Head Videos",
    "value_statement": "Create professional talking head videos with AI avatars using text, audio, or images. Perfect for product demos, tutorials, and virtual presenters without filming.",
    "seo_keywords": [
      "AI avatar",
      "talking head video",
      "lipsync",
      "virtual presenter",
      "AI spokesperson",
      "video avatar",
      "HeyGen alternative",
      "Synthesia alternative",
      "Claude Code",
      "video generation"
    ],
    "actual_capabilities": [
      "Generate talking head videos from static images and audio files",
      "Create lipsync videos where static images speak to your audio",
      "Support for multiple AI models: OmniHuman 1.5, OmniHuman 1.0, Fabric 1.0, PixVerse",
      "Multi-character avatar generation with OmniHuman 1.5",
      "Dub existing videos into different languages with new audio",
      "Integrate with text-to-speech apps for complete video workflows"
    ],
    "limitations": [
      "Requires login to inference.sh CLI platform",
      "Works with external APIs - requires internet connection",
      "Avatar quality depends on input image quality and lighting",
      "Processing time varies by model and complexity",
      "Only supports images that can be publicly accessed via URL",
      "Limited to models available through inference.sh platform"
    ],
    "use_cases": [
      {
        "title": "Product Demo Videos",
        "description": "Create professional product demonstrations with AI presenters without filming. Ideal for SaaS companies showcasing features.",
        "target_user": "Marketing teams, product managers"
      },
      {
        "title": "Educational Content",
        "description": "Generate consistent explainer videos and tutorials. Perfect for online courses and educational platforms.",
        "target_user": "Teachers, content creators, educators"
      },
      {
        "title": "Multilingual Content",
        "description": "Dub existing videos into multiple languages with AI avatars speaking the new language. Expand your global audience.",
        "target_user": "Localization teams, international brands"
      }
    ],
    "prompt_templates": [
      {
        "title": "Create Basic Avatar Video",
        "prompt": "Generate a talking head video from this image: [IMAGE_URL] using the specified audio: [AUDIO_URL]. Use the OmniHuman 1.5 model for best quality.",
        "scenario": "Beginner: Simple avatar video creation"
      },
      {
        "title": "Create Lipsync Video",
        "prompt": "Create a lipsync video where this static image speaks the provided audio. Use the PixVerse Lipsync model for realistic lip movements.",
        "scenario": "Intermediate: Lipsync with static images"
      },
      {
        "title": "Create Multi-Language Dub",
        "prompt": "Create a dubbed version of this video in English: [VIDEO_URL] using these translated subtitles as audio: [TRANSLATED_AUDIO_URL]. Use LatentSync for video-to-audio sync.",
        "scenario": "Advanced: Video dubbing and localization"
      },
      {
        "title": "Create TTS + Avatar Workflow",
        "prompt": "First generate speech from this text: [TEXT] using kokoro-tts. Then create a talking head video from this image: [IMAGE_URL] with the generated speech as audio.",
        "scenario": "Advanced: Complete text-to-video workflow"
      }
    ],
    "output_examples": [
      {
        "input": "Generate a talking head video from a portrait photo with a voice-over explaining a product feature.",
        "output": "Uses infsh app run bytedance/omnihuman-1-5 --input '{\"image_url\": \"https://portrait.jpg\", \"audio_url\": \"https://speech.mp3\"}' to create the video. Result: The AI avatar from portrait.jpg speaks the audio track with synchronized lip movements."
      },
      {
        "input": "Create a dubbed version of an educational video in a new language.",
        "output": "1. Transcribe original video with infsh/fast-whisper-large-v3. 2. Generate speech in new language with kokoro-tts. 3. Sync to original video with latentsync-1-6. Result: Original video with AI avatars speaking the new language."
      }
    ],
    "best_practices": [
      "Use high-quality front-facing portrait photos with good lighting for best avatar results",
      "Ensure audio is clear with minimal background noise for accurate lipsync",
      "Use Claude Code's multi-step workflow for complex video generation tasks",
      "Verify URL accessibility before using images or audio in commands",
      "Test with small segments before generating full-length videos"
    ],
    "anti_patterns": [
      "Don't use low-quality images with poor lighting - avatar quality will be poor",
      "Avoid using copyrighted images for commercial avatar videos without permission",
      "Don't mix languages in the same video without proper dubbing workflow",
      "Don't forget to save output files immediately after generation",
      "Avoid using very long audio tracks without testing lip sync quality"
    ],
    "faq": [
      {
        "question": "What is inference.sh and why do I need it?",
        "answer": "Inference.sh is a cloud platform that provides AI model APIs. The inference.sh CLI allows you to run these AI models locally without managing infrastructure. You need it to access OmniHuman, Fabric, and PixVerse models for avatar video generation."
      },
      {
        "question": "Which model should I use for my avatar videos?",
        "answer": "Use OmniHuman 1.5 for multi-character videos and best quality. Use Fabric 1.0 for static images that need to speak. Use PixVerse Lipsync for highly realistic lip sync on existing images."
      },
      {
        "question": "Can I create videos in languages other than English?",
        "answer": "Yes, you can create videos in any language supported by the kokoro-tts text-to-speech model. Use the dubbing workflow to create multilingual versions of existing videos."
      },
      {
        "question": "How do I authenticate with inference.sh?",
        "answer": "Run infsh login in your terminal. You'll need to authenticate with your inference.sh account credentials. This provides access to all available AI models."
      },
      {
        "question": "What image formats work best for avatar videos?",
        "answer": "Use high-resolution portrait photos (400x400 or larger) with front-facing orientation. JPG and PNG formats work well. Good lighting and neutral background produce better results."
      },
      {
        "question": "Can I use this skill with Claude Code?",
        "answer": "Yes, this skill is compatible with Claude, Codex, and Claude Code. You can use the command examples in SKILL.md with Claude Code to build automated video generation workflows."
      }
    ]
  },
  "file_structure": [
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md",
      "lines": 154
    }
  ]
}
