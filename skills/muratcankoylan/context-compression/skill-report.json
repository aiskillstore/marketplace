{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-17T06:44:13.633Z",
    "slug": "muratcankoylan-context-compression",
    "source_url": "https://github.com/muratcankoylan/Agent-Skills-for-Context-Engineering/tree/main/skills/context-compression",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "3.0.0",
    "source_type": "community",
    "content_hash": "bc398950888ae73df9651f44f2fb51acea9409362d736592c771e38d236022ae",
    "tree_hash": "6c092dd70710be7702f7809a48bde0db1ee692eee6cd4b5e4c15733ba5e769db"
  },
  "skill": {
    "name": "context-compression",
    "description": "This skill should be used when the user asks to \"compress context\", \"summarize conversation history\", \"implement compaction\", \"reduce token usage\", or mentions context compression, structured summarization, tokens-per-task optimization, or long-running agent sessions exceeding context limits.",
    "summary": "This skill should be used when the user asks to \"compress context\", \"summarize conversation history\"...",
    "icon": "ðŸ“¦",
    "version": "1.1.0",
    "author": "muratcankoylan",
    "license": "MIT",
    "category": "coding",
    "tags": [
      "context",
      "compression",
      "tokens",
      "summarization",
      "conversation"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": [
      "external_commands",
      "network"
    ]
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "This skill contains documentation and Python evaluation utilities. All static findings are false positives. The scanner misinterpreted markdown code fences as shell commands, AI model names as cryptographic algorithms, and evaluation criteria names as system reconnaissance. No actual dangerous patterns exist in the codebase.",
    "risk_factor_evidence": [
      {
        "factor": "external_commands",
        "evidence": [
          {
            "file": "references/evaluation-framework.md",
            "line_start": 12,
            "line_end": 16
          },
          {
            "file": "references/evaluation-framework.md",
            "line_start": 16,
            "line_end": 28
          },
          {
            "file": "references/evaluation-framework.md",
            "line_start": 28,
            "line_end": 32
          },
          {
            "file": "references/evaluation-framework.md",
            "line_start": 32,
            "line_end": 44
          },
          {
            "file": "references/evaluation-framework.md",
            "line_start": 44,
            "line_end": 48
          },
          {
            "file": "references/evaluation-framework.md",
            "line_start": 48,
            "line_end": 60
          },
          {
            "file": "references/evaluation-framework.md",
            "line_start": 60,
            "line_end": 64
          },
          {
            "file": "references/evaluation-framework.md",
            "line_start": 64,
            "line_end": 121
          },
          {
            "file": "references/evaluation-framework.md",
            "line_start": 121,
            "line_end": 131
          },
          {
            "file": "references/evaluation-framework.md",
            "line_start": 131,
            "line_end": 135
          },
          {
            "file": "references/evaluation-framework.md",
            "line_start": 135,
            "line_end": 143
          },
          {
            "file": "references/evaluation-framework.md",
            "line_start": 143,
            "line_end": 147
          },
          {
            "file": "references/evaluation-framework.md",
            "line_start": 147,
            "line_end": 166
          },
          {
            "file": "scripts/compression_evaluator.py",
            "line_start": 358,
            "line_end": 367
          },
          {
            "file": "SKILL.md",
            "line_start": 55,
            "line_end": 76
          },
          {
            "file": "SKILL.md",
            "line_start": 76,
            "line_end": 187
          },
          {
            "file": "SKILL.md",
            "line_start": 187,
            "line_end": 208
          }
        ]
      },
      {
        "factor": "network",
        "evidence": [
          {
            "file": "skill-report.json",
            "line_start": 6,
            "line_end": 6
          }
        ]
      }
    ],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 4,
    "total_lines": 1362,
    "audit_model": "claude",
    "audited_at": "2026-01-17T06:44:13.633Z"
  },
  "content": {
    "user_title": "Compress conversation context",
    "value_statement": "Long agent sessions generate millions of tokens that exceed context limits. This skill provides structured compression strategies that reduce token usage while preserving file paths, error messages, and decisions so agents can continue working without re-fetching information.",
    "seo_keywords": [
      "context compression",
      "Claude",
      "Codex",
      "Claude Code",
      "token optimization",
      "conversation summarization",
      "structured summarization",
      "anchored iterative summarization",
      "context window limits",
      "tokens per task"
    ],
    "actual_capabilities": [
      "Implement anchored iterative summarization with explicit sections for files, decisions, and next steps",
      "Generate structured summaries that preserve file paths, error messages, and technical details",
      "Evaluate compression quality using probe-based assessment across six dimensions",
      "Apply three-phase compression workflow for large codebases (research, planning, implementation)",
      "Track artifact trail integrity separately from general summarization",
      "Configure compression triggers based on context utilization thresholds"
    ],
    "limitations": [
      "Does not automatically compress context during conversations (requires manual implementation)",
      "Quality of compression depends on the summarization model used",
      "Opaque compression methods sacrifice interpretability for higher compression ratios"
    ],
    "use_cases": [
      {
        "target_user": "AI developers",
        "title": "Build compression pipelines",
        "description": "Implement context compression in agent frameworks to handle long-running coding sessions efficiently."
      },
      {
        "target_user": "Engineering teams",
        "title": "Evaluate compression quality",
        "description": "Use probe-based evaluation to measure whether compressed context preserves critical information."
      },
      {
        "target_user": "LLM practitioners",
        "title": "Optimize token usage",
        "description": "Apply structured summarization strategies to reduce tokens-per-task without losing technical details."
      }
    ],
    "prompt_templates": [
      {
        "title": "Enable compression",
        "scenario": "Activate context compression",
        "prompt": "Enable context compression for this session using anchored iterative summarization with explicit sections for session intent, files modified, decisions made, current state, and next steps."
      },
      {
        "title": "Summarize history",
        "scenario": "Compress conversation so far",
        "prompt": "Compress our conversation history into a structured summary. Include the original error or issue, all files modified with their changes, key decisions made, current test status, and actionable next steps."
      },
      {
        "title": "Track artifacts",
        "scenario": "Preserve file tracking",
        "prompt": "After compressing context, generate an artifact trail that lists which files were created, modified, and read during this session. Include function names and error messages that were discussed."
      },
      {
        "title": "Evaluate quality",
        "scenario": "Test compression fidelity",
        "prompt": "Evaluate our compression quality using probe-based assessment. Test recall of the original error, artifact knowledge of modified files, continuation awareness of next steps, and decision retention of why we chose specific solutions."
      }
    ],
    "output_examples": [
      {
        "input": "Compress our debugging session into a structured summary",
        "output": [
          "## Session Intent",
          "Debug 401 Unauthorized error on /api/auth/login endpoint despite valid credentials.",
          "## Files Modified",
          "- config/redis.ts: Fixed connection pooling configuration",
          "- services/session.service.ts: Added retry logic for transient failures",
          "## Decisions Made",
          "- Using Redis connection pool instead of per-request connections",
          "- Retry logic with exponential backoff for transient failures",
          "## Current State",
          "14 passing, 2 failing (mock setup issues)",
          "## Next Steps",
          "1. Fix remaining test failures",
          "2. Run full test suite",
          "3. Deploy to staging"
        ]
      },
      {
        "input": "How do I implement anchored iterative summarization?",
        "output": [
          "Define explicit summary sections matching your needs: Session Intent, Files Modified, Files Read, Decisions Made, Current State, Next Steps.",
          "On first compression, summarize truncated history into each section.",
          "On subsequent compressions, summarize only new content and merge into existing sections.",
          "Track which information came from which compression cycle for debugging."
        ]
      },
      {
        "input": "What triggers should I use for compression?",
        "output": [
          "Fixed threshold: Trigger at 70-80% context utilization. Simple but may compress early.",
          "Sliding window: Keep last N turns plus summary. Predictable context size.",
          "Task-boundary: Compress at logical task completions. Clean summaries but unpredictable timing.",
          "For most cases, sliding window with structured summaries provides best balance."
        ]
      }
    ],
    "best_practices": [
      "Use structured summaries with explicit sections to prevent silent loss of file paths and decisions",
      "Optimize for tokens-per-task, not just tokens-per-request, to account for re-fetching costs",
      "Test compression quality with probe-based evaluation before deploying to production"
    ],
    "anti_patterns": [
      "Using aggressive compression that loses error codes, file paths, and function names",
      "Triggering compression at 100% context utilization instead of 70-80%",
      "Regenerating full summaries on each compression instead of incremental merging"
    ],
    "faq": [
      {
        "question": "Which AI platforms support this skill?",
        "answer": "This skill works with Claude, Codex, and Claude Code for AI-assisted coding tasks."
      },
      {
        "question": "What is the maximum compression ratio?",
        "answer": "Opaque compression achieves 99.3% but sacrifices interpretability. Structured approaches achieve 98.6% with better quality retention."
      },
      {
        "question": "How does this integrate with agent frameworks?",
        "answer": "The skill provides Python utilities for evaluation and documentation for implementing compression in your agent scaffolding."
      },
      {
        "question": "Is my conversation data safe?",
        "answer": "All processing is local to the AI session. No conversation data is sent to external services beyond the AI model itself."
      },
      {
        "question": "Why do agents forget modified files?",
        "answer": "Artifact trail integrity scores 2.2-2.5 out of 5.0 across all methods. Consider separate file-state tracking outside compression."
      },
      {
        "question": "How is this different from simple summarization?",
        "answer": "Structured summarization uses explicit sections to force preservation of file paths, decisions, and technical details that generic summarization loses."
      }
    ]
  },
  "file_structure": [
    {
      "name": "references",
      "type": "dir",
      "path": "references",
      "children": [
        {
          "name": "evaluation-framework.md",
          "type": "file",
          "path": "references/evaluation-framework.md",
          "lines": 214
        }
      ]
    },
    {
      "name": "scripts",
      "type": "dir",
      "path": "scripts",
      "children": [
        {
          "name": "compression_evaluator.py",
          "type": "file",
          "path": "scripts/compression_evaluator.py",
          "lines": 659
        }
      ]
    },
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md",
      "lines": 266
    }
  ]
}
