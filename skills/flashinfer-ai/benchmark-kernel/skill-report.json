{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-17T05:24:49.983Z",
    "slug": "flashinfer-ai-benchmark-kernel",
    "source_url": "https://github.com/flashinfer-ai/flashinfer/tree/main/.claude/skills/benchmark-kernel",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "3.0.0",
    "source_type": "community",
    "content_hash": "87ba341e412c819522e61fe3f9391c922ac1e3cb8c7dee409f1cc19b5cb87ff9",
    "tree_hash": "e9e1c8c5e0688bede60485a26a650f32bc4414f5cedff36f8248f536882da348"
  },
  "skill": {
    "name": "benchmark-kernel",
    "description": "Guide for benchmarking FlashInfer kernels with CUPTI timing",
    "summary": "Guide for benchmarking FlashInfer kernels with CUPTI timing",
    "icon": "ðŸ“Š",
    "version": "1.0.0",
    "author": "flashinfer-ai",
    "license": "MIT",
    "category": "coding",
    "tags": [
      "benchmarking",
      "gpu",
      "cuda",
      "performance",
      "profiling"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": [
      "network",
      "filesystem",
      "external_commands"
    ]
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "Documentation-only skill containing tutorial instructions for GPU kernel benchmarking. No executable code, network calls, or file system access. Static findings are false positives caused by the analyzer incorrectly flagging documentation strings and bash command examples as security vulnerabilities.",
    "risk_factor_evidence": [
      {
        "factor": "network",
        "evidence": [
          {
            "file": "skill-report.json",
            "line_start": 6,
            "line_end": 6
          }
        ]
      },
      {
        "factor": "filesystem",
        "evidence": [
          {
            "file": "skill-report.json",
            "line_start": 6,
            "line_end": 6
          }
        ]
      },
      {
        "factor": "external_commands",
        "evidence": [
          {
            "file": "SKILL.md",
            "line_start": 24,
            "line_end": 24
          },
          {
            "file": "SKILL.md",
            "line_start": 38,
            "line_end": 40
          },
          {
            "file": "SKILL.md",
            "line_start": 40,
            "line_end": 47
          },
          {
            "file": "SKILL.md",
            "line_start": 47,
            "line_end": 56
          },
          {
            "file": "SKILL.md",
            "line_start": 56,
            "line_end": 56
          },
          {
            "file": "SKILL.md",
            "line_start": 56,
            "line_end": 56
          },
          {
            "file": "SKILL.md",
            "line_start": 56,
            "line_end": 56
          },
          {
            "file": "SKILL.md",
            "line_start": 56,
            "line_end": 57
          },
          {
            "file": "SKILL.md",
            "line_start": 57,
            "line_end": 57
          },
          {
            "file": "SKILL.md",
            "line_start": 57,
            "line_end": 57
          },
          {
            "file": "SKILL.md",
            "line_start": 57,
            "line_end": 57
          },
          {
            "file": "SKILL.md",
            "line_start": 57,
            "line_end": 58
          },
          {
            "file": "SKILL.md",
            "line_start": 58,
            "line_end": 58
          },
          {
            "file": "SKILL.md",
            "line_start": 58,
            "line_end": 58
          },
          {
            "file": "SKILL.md",
            "line_start": 58,
            "line_end": 58
          },
          {
            "file": "SKILL.md",
            "line_start": 58,
            "line_end": 64
          },
          {
            "file": "SKILL.md",
            "line_start": 64,
            "line_end": 83
          },
          {
            "file": "SKILL.md",
            "line_start": 83,
            "line_end": 87
          },
          {
            "file": "SKILL.md",
            "line_start": 87,
            "line_end": 101
          },
          {
            "file": "SKILL.md",
            "line_start": 101,
            "line_end": 106
          },
          {
            "file": "SKILL.md",
            "line_start": 106,
            "line_end": 110
          },
          {
            "file": "SKILL.md",
            "line_start": 110,
            "line_end": 116
          },
          {
            "file": "SKILL.md",
            "line_start": 116,
            "line_end": 126
          },
          {
            "file": "SKILL.md",
            "line_start": 126,
            "line_end": 128
          },
          {
            "file": "SKILL.md",
            "line_start": 128,
            "line_end": 132
          },
          {
            "file": "SKILL.md",
            "line_start": 132,
            "line_end": 136
          },
          {
            "file": "SKILL.md",
            "line_start": 136,
            "line_end": 142
          },
          {
            "file": "SKILL.md",
            "line_start": 142,
            "line_end": 144
          },
          {
            "file": "SKILL.md",
            "line_start": 144,
            "line_end": 150
          },
          {
            "file": "SKILL.md",
            "line_start": 150,
            "line_end": 151
          },
          {
            "file": "SKILL.md",
            "line_start": 151,
            "line_end": 152
          },
          {
            "file": "SKILL.md",
            "line_start": 152,
            "line_end": 153
          },
          {
            "file": "SKILL.md",
            "line_start": 153,
            "line_end": 154
          },
          {
            "file": "SKILL.md",
            "line_start": 154,
            "line_end": 155
          },
          {
            "file": "SKILL.md",
            "line_start": 155,
            "line_end": 156
          },
          {
            "file": "SKILL.md",
            "line_start": 156,
            "line_end": 157
          },
          {
            "file": "SKILL.md",
            "line_start": 157,
            "line_end": 158
          },
          {
            "file": "SKILL.md",
            "line_start": 158,
            "line_end": 166
          },
          {
            "file": "SKILL.md",
            "line_start": 166,
            "line_end": 196
          },
          {
            "file": "SKILL.md",
            "line_start": 196,
            "line_end": 202
          },
          {
            "file": "SKILL.md",
            "line_start": 202,
            "line_end": 204
          },
          {
            "file": "SKILL.md",
            "line_start": 204,
            "line_end": 207
          },
          {
            "file": "SKILL.md",
            "line_start": 207,
            "line_end": 210
          },
          {
            "file": "SKILL.md",
            "line_start": 210,
            "line_end": 213
          },
          {
            "file": "SKILL.md",
            "line_start": 213,
            "line_end": 217
          },
          {
            "file": "SKILL.md",
            "line_start": 217,
            "line_end": 221
          },
          {
            "file": "SKILL.md",
            "line_start": 221,
            "line_end": 238
          },
          {
            "file": "SKILL.md",
            "line_start": 238,
            "line_end": 244
          },
          {
            "file": "SKILL.md",
            "line_start": 244,
            "line_end": 251
          },
          {
            "file": "SKILL.md",
            "line_start": 251,
            "line_end": 253
          },
          {
            "file": "SKILL.md",
            "line_start": 253,
            "line_end": 257
          },
          {
            "file": "SKILL.md",
            "line_start": 257,
            "line_end": 267
          },
          {
            "file": "SKILL.md",
            "line_start": 267,
            "line_end": 269
          },
          {
            "file": "SKILL.md",
            "line_start": 269,
            "line_end": 272
          },
          {
            "file": "SKILL.md",
            "line_start": 272,
            "line_end": 274
          },
          {
            "file": "SKILL.md",
            "line_start": 274,
            "line_end": 277
          },
          {
            "file": "SKILL.md",
            "line_start": 277,
            "line_end": 279
          },
          {
            "file": "SKILL.md",
            "line_start": 279,
            "line_end": 282
          },
          {
            "file": "SKILL.md",
            "line_start": 282,
            "line_end": 284
          },
          {
            "file": "SKILL.md",
            "line_start": 284,
            "line_end": 288
          },
          {
            "file": "SKILL.md",
            "line_start": 288,
            "line_end": 294
          },
          {
            "file": "SKILL.md",
            "line_start": 294,
            "line_end": 296
          },
          {
            "file": "SKILL.md",
            "line_start": 296,
            "line_end": 301
          },
          {
            "file": "SKILL.md",
            "line_start": 301,
            "line_end": 303
          },
          {
            "file": "SKILL.md",
            "line_start": 303,
            "line_end": 307
          },
          {
            "file": "SKILL.md",
            "line_start": 307,
            "line_end": 309
          },
          {
            "file": "SKILL.md",
            "line_start": 309,
            "line_end": 309
          },
          {
            "file": "SKILL.md",
            "line_start": 309,
            "line_end": 314
          },
          {
            "file": "SKILL.md",
            "line_start": 314,
            "line_end": 316
          },
          {
            "file": "SKILL.md",
            "line_start": 316,
            "line_end": 319
          },
          {
            "file": "SKILL.md",
            "line_start": 319,
            "line_end": 321
          },
          {
            "file": "SKILL.md",
            "line_start": 321,
            "line_end": 324
          },
          {
            "file": "SKILL.md",
            "line_start": 324,
            "line_end": 326
          },
          {
            "file": "SKILL.md",
            "line_start": 326,
            "line_end": 329
          },
          {
            "file": "SKILL.md",
            "line_start": 329,
            "line_end": 331
          },
          {
            "file": "SKILL.md",
            "line_start": 331,
            "line_end": 334
          },
          {
            "file": "SKILL.md",
            "line_start": 334,
            "line_end": 336
          },
          {
            "file": "SKILL.md",
            "line_start": 336,
            "line_end": 339
          },
          {
            "file": "SKILL.md",
            "line_start": 339,
            "line_end": 341
          },
          {
            "file": "SKILL.md",
            "line_start": 341,
            "line_end": 344
          },
          {
            "file": "SKILL.md",
            "line_start": 344,
            "line_end": 346
          },
          {
            "file": "SKILL.md",
            "line_start": 346,
            "line_end": 351
          },
          {
            "file": "SKILL.md",
            "line_start": 351,
            "line_end": 359
          },
          {
            "file": "SKILL.md",
            "line_start": 359,
            "line_end": 362
          },
          {
            "file": "SKILL.md",
            "line_start": 362,
            "line_end": 372
          },
          {
            "file": "SKILL.md",
            "line_start": 372,
            "line_end": 375
          },
          {
            "file": "SKILL.md",
            "line_start": 375,
            "line_end": 383
          },
          {
            "file": "SKILL.md",
            "line_start": 383,
            "line_end": 386
          },
          {
            "file": "SKILL.md",
            "line_start": 386,
            "line_end": 397
          },
          {
            "file": "SKILL.md",
            "line_start": 397,
            "line_end": 404
          },
          {
            "file": "SKILL.md",
            "line_start": 404,
            "line_end": 413
          },
          {
            "file": "SKILL.md",
            "line_start": 413,
            "line_end": 413
          },
          {
            "file": "SKILL.md",
            "line_start": 413,
            "line_end": 414
          },
          {
            "file": "SKILL.md",
            "line_start": 414,
            "line_end": 420
          },
          {
            "file": "SKILL.md",
            "line_start": 420,
            "line_end": 421
          },
          {
            "file": "SKILL.md",
            "line_start": 283,
            "line_end": 283
          }
        ]
      }
    ],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 2,
    "total_lines": 595,
    "audit_model": "claude",
    "audited_at": "2026-01-17T05:24:49.983Z"
  },
  "content": {
    "user_title": "Benchmark GPU kernels with CUPTI timing",
    "value_statement": "Accurate GPU kernel benchmarking is challenging due to measurement overhead. This skill provides step-by-step instructions for using CUPTI hardware profiling to get precise kernel execution times. Compare different backends like FlashAttention and cuDNN to find the fastest implementation for your workload.",
    "seo_keywords": [
      "GPU benchmarking",
      "CUPTI profiling",
      "CUDA performance",
      "FlashInfer kernels",
      "Claude Code",
      "kernel timing",
      "hardware profiling",
      "GPU optimization",
      "attention kernels",
      "performance profiling"
    ],
    "actual_capabilities": [
      "Provides tutorial for CUPTI hardware-level GPU profiling",
      "Includes command-line examples for FlashInfer benchmarks",
      "Shows Python API usage with bench_gpu_time() function",
      "Documents timing accuracy differences between CUPTI and CUDA events",
      "Explains how to compare multiple backend implementations"
    ],
    "limitations": [
      "Requires CUDA 13+ for CUPTI installation",
      "Documentation only - no automated execution",
      "Specific to FlashInfer kernel library"
    ],
    "use_cases": [
      {
        "target_user": "GPU kernel developers",
        "title": "Measure kernel performance accurately",
        "description": "Use CUPTI hardware profiling to get precise GPU execution times without host overhead"
      },
      {
        "target_user": "ML performance engineers",
        "title": "Compare attention kernel backends",
        "description": "Benchmark different attention implementations to find the fastest for your workload"
      },
      {
        "target_user": "CUDA optimization specialists",
        "title": "Profile FP8 GEMM operations",
        "description": "Measure performance of mixed-precision matrix multiplication kernels"
      }
    ],
    "prompt_templates": [
      {
        "title": "Basic kernel timing",
        "scenario": "Timing a simple kernel",
        "prompt": "Help me benchmark my CUDA kernel using bench_gpu_time() with 30 iterations and 5 warmup runs"
      },
      {
        "title": "Compare backends",
        "scenario": "Testing multiple implementations",
        "prompt": "Show me how to benchmark BatchDecodeWithPagedKVCacheWrapper with fa2, cudnn, and cutlass backends"
      },
      {
        "title": "Batch benchmarks",
        "scenario": "Running multiple configurations",
        "prompt": "Create a test list file to benchmark different batch sizes and sequence lengths"
      },
      {
        "title": "Custom Python benchmarking",
        "scenario": "Integrating into research code",
        "prompt": "Write a Python script that benchmarks my custom attention kernel with CUPTI timing"
      }
    ],
    "output_examples": [
      {
        "input": "Benchmark decode attention with different backends",
        "output": [
          "fa2: median 0.145ms, 125.3 TFLOPS",
          "fa2_tc: median 0.138ms, 131.5 TFLOPS",
          "cudnn: median 0.142ms, 127.8 TFLOPS",
          "Best: fa2_tc with 131.5 TFLOPS throughput"
        ]
      },
      {
        "input": "How do I install CUPTI for accurate benchmarking",
        "output": [
          "Install with: pip install -U cupti-python",
          "Requires CUDA 13 or higher",
          "Framework auto-detects and uses CUPTI when available",
          "Falls back to CUDA events if CUPTI not installed"
        ]
      },
      {
        "input": "Why are my benchmark results inconsistent",
        "output": [
          "Increase warmup iterations (try 10 dry_run_iters)",
          "Increase measurement iterations (try 50 num_iters)",
          "Use cold L2 cache option to reduce cache effects",
          "Check for thermal throttling on your GPU"
        ]
      }
    ],
    "best_practices": [
      "Install CUPTI for hardware-level accuracy when possible",
      "Use reference checking to verify kernel correctness during benchmarking",
      "Run sufficient iterations (30+) for statistical significance"
    ],
    "anti_patterns": [
      "Benchmarking without warmup iterations",
      "Using only CUDA events when CUPTI is available",
      "Comparing backends without verifying output correctness"
    ],
    "faq": [
      {
        "question": "Do I need CUPTI installed?",
        "answer": "No, the framework automatically falls back to CUDA events if CUPTI is unavailable"
      },
      {
        "question": "What is the minimum CUDA version?",
        "answer": "CUPTI requires CUDA 13+, but CUDA events work with any CUDA version"
      },
      {
        "question": "Can I benchmark non-FlashInfer kernels?",
        "answer": "Yes, use bench_gpu_time() with any CUDA kernel function in your Python code"
      },
      {
        "question": "Is my data safe during benchmarking?",
        "answer": "Yes, benchmarking only measures execution time without accessing your input data"
      },
      {
        "question": "Why are my benchmark results inconsistent?",
        "answer": "Increase warmup and measurement iterations, and check for thermal throttling on your GPU"
      },
      {
        "question": "How accurate is CUPTI compared to CUDA events?",
        "answer": "CUPTI is more accurate for fast kernels under 50 microseconds, difference is negligible for longer kernels"
      }
    ]
  },
  "file_structure": [
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md",
      "lines": 423
    }
  ]
}
