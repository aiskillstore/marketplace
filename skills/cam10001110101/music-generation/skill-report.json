{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-16T20:20:51.282Z",
    "slug": "cam10001110101-music-generation",
    "source_url": "https://github.com/Cam10001110101/claude-skills-base/tree/main/mnt/skills/examples/music-generation",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "3.0.0",
    "source_type": "community",
    "content_hash": "a303d13eaf8346f05041faf180251c67bd86b145940a2a5989a9b006cc885166",
    "tree_hash": "32ed38b0f1195f69e87f07f18e71d094e09010048ac367d90e48559edcfe24cc"
  },
  "skill": {
    "name": "music-generation",
    "description": "Tools, patterns, and utilities for generating professional music with realistic instrument sounds. Write custom compositions using music21 or learn from existing MIDI files.",
    "summary": "Tools, patterns, and utilities for generating professional music with realistic instrument sounds. W...",
    "icon": "ðŸŽµ",
    "version": "2.0.0",
    "author": "Cam10001110101",
    "license": "MIT",
    "category": "data",
    "tags": [
      "music",
      "midi",
      "audio",
      "composition",
      "synthesis"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": [
      "scripts",
      "filesystem",
      "external_commands"
    ]
  },
  "security_audit": {
    "risk_level": "low",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "Legitimate music generation skill with no malicious behavior. Static scanner flagged audio synthesis terminology (attack, decay, sustain, oscillator, filter) as C2 keywords and weak crypto - these are false positives. All subprocess calls use hardcoded paths for audio rendering pipelines. Filesystem access is limited to user-specified output directories for MIDI/audio files.",
    "risk_factor_evidence": [
      {
        "factor": "scripts",
        "evidence": [
          {
            "file": "install.sh",
            "line_start": 1,
            "line_end": 66
          }
        ]
      },
      {
        "factor": "filesystem",
        "evidence": [
          {
            "file": "scripts/midi_utils.py",
            "line_start": 1,
            "line_end": 120
          }
        ]
      },
      {
        "factor": "external_commands",
        "evidence": [
          {
            "file": "SKILL.md",
            "line_start": 146,
            "line_end": 156
          }
        ]
      }
    ],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [
      {
        "title": "Subprocess usage for script execution",
        "description": "The skill uses subprocess.run() to execute Python scripts for rendering MIDI to audio. This is standard practice for audio processing pipelines. Arguments use hardcoded script paths with user-provided file paths. Path normalization via Path.resolve() mitigates injection risk.",
        "locations": [
          {
            "file": "SKILL.md",
            "line_start": 146,
            "line_end": 156
          }
        ]
      }
    ],
    "dangerous_patterns": [],
    "files_scanned": 14,
    "total_lines": 4764,
    "audit_model": "claude",
    "audited_at": "2026-01-16T20:20:51.282Z"
  },
  "content": {
    "user_title": "Generate Professional Music with MIDI",
    "value_statement": "Create original music compositions and convert MIDI files to MP3 or WAV audio files. Uses music21 library for intelligent composition and supports both orchestral and electronic music generation with realistic instrument sounds.",
    "seo_keywords": [
      "music generation",
      "MIDI to MP3",
      "audio synthesis",
      "Claude Code",
      "Claude",
      "Codex",
      "music composition",
      "electronic music",
      "orchestral music",
      "audio rendering"
    ],
    "actual_capabilities": [
      "Generate original compositions using music21 library with algorithmic note generation",
      "Convert MIDI files to downloadable MP3 or WAV audio files",
      "Create electronic music with real-time synthesis (808-style drums, synth bass, pads, leads)",
      "Extract and analyze musical structure from existing MIDI files",
      "Apply transformations to MIDI compositions (transpose, tempo change, instrument swap)",
      "Validate audio file quality and detect issues like clipping or excessive silence"
    ],
    "limitations": [
      "Instrumental music only - cannot generate lyrics or vocals",
      "MIDI-based synthesis quality depends on SoundFont files used",
      "Requires installation of system dependencies (FluidSynth, FFmpeg) for full functionality",
      "No real-time playback - audio must be rendered before listening"
    ],
    "use_cases": [
      {
        "target_user": "Content creators",
        "title": "Background music for videos",
        "description": "Generate original royalty-free music for YouTube videos, podcasts, or presentations"
      },
      {
        "target_user": "Music producers",
        "title": "MIDI to audio conversion",
        "description": "Convert MIDI compositions to high-quality MP3 files with realistic instrument sounds"
      },
      {
        "target_user": "Educators",
        "title": "Music theory examples",
        "description": "Create educational examples demonstrating chord progressions, scales, and musical structures"
      }
    ],
    "prompt_templates": [
      {
        "title": "Simple melody",
        "scenario": "Create a basic melody",
        "prompt": "Generate a 16-bar melody in C major at 120 BPM using piano. Save the output as /mnt/user-data/outputs/piano_melody.mp3"
      },
      {
        "title": "Electronic track",
        "scenario": "Create an electronic house track",
        "prompt": "Create a 32-bar deep house track with four-on-the-floor drums, synth bass on A1, and atmospheric pads. Render using the electronic pipeline with deep_house preset. Save to /mnt/user-data/outputs/deep_house.mp3"
      },
      {
        "title": "Orchestral piece",
        "scenario": "Compose orchestral music",
        "prompt": "Compose a 24-bar orchestral piece with violin, cello, and trumpet sections. Use a I-IV-V-I progression. Export to /mnt/user-data/outputs/orchestral.mp3"
      },
      {
        "title": "MIDI transformation",
        "scenario": "Transform existing MIDI",
        "prompt": "Take the MIDI file at /mnt/user-data/inputs/song.mid, transpose it up by 2 semitones, change tempo to 1.2x, and render the result to /mnt/user-data/outputs/transformed.mp3"
      }
    ],
    "output_examples": [
      {
        "input": "Generate a 16-bar ambient piece with soft pads and subtle percussion at 80 BPM",
        "output": [
          "Created: /mnt/user-data/outputs/ambient_piece.mp3",
          "Duration: 24 seconds (16 bars at 80 BPM)",
          "Pipeline: Electronic synthesis with ambient preset",
          "Instruments: Soft pads (synth), subtle percussion, atmospheric effects"
        ]
      },
      {
        "input": "Create a 32-bar reggae track with one-drop drum pattern and walking bass",
        "output": [
          "Created: /mnt/user-data/outputs/reggae_track.mp3",
          "Duration: 46 seconds (32 bars at 85 BPM)",
          "Drums: One-drop pattern with offbeat hats",
          "Bass: Walking bass pattern with syncopated rhythm"
        ]
      },
      {
        "input": "Compose a jazz piece with ii-V-I progressions and walking bass",
        "output": [
          "Created: /mnt/user-data/outputs/jazz_piece.mp3",
          "Duration: 90 seconds",
          "Chords: Extended 7th, 9th, and 13th chords",
          "Instruments: Piano, walking bass, brushed snare"
        ]
      }
    ],
    "best_practices": [
      "Always use .insert() with explicit timing offsets for layered compositions instead of .append()",
      "Set appropriate MIDI velocities for each instrument role (lead: 90-105, background: 50-65)",
      "Choose the correct rendering pipeline based on genre (traditional for orchestral, electronic for EDM/house)"
    ],
    "anti_patterns": [
      "Using .append() for drum patterns - creates sequential rather than layered notes",
      "Setting all instruments to the same velocity - causes poor mix balance",
      "Using orchestral SoundFont for electronic music - results in poor quality synthetic sounds"
    ],
    "faq": [
      {
        "question": "Which rendering pipeline should I use?",
        "answer": "Use the traditional pipeline (FluidSynth) for orchestral, classical, or acoustic music. Use the electronic pipeline (real-time synthesis) for house, techno, trance, or any synth-heavy music."
      },
      {
        "question": "What is the maximum duration for generated music?",
        "answer": "There is no hard limit, but rendering time increases with duration. Practical limits are around 10-15 minutes for complex compositions."
      },
      {
        "question": "How do I set specific instruments in my composition?",
        "answer": "For orchestral instruments, use music21 instrument classes like instrument.Violin(). For electronic instruments, use mido to insert program_change messages after MIDI export."
      },
      {
        "question": "Is my data safe when using this skill?",
        "answer": "Yes. This skill processes audio locally on your machine. No audio data is sent to external servers. All output files are written to directories you specify."
      },
      {
        "question": "Why does the audio sound different from professional productions?",
        "answer": "MIDI synthesis cannot match studio-quality recordings. Sound quality depends on SoundFont files and synthesis parameters. For best results, use appropriate presets and velocity settings."
      },
      {
        "question": "How does this compare to other music generation tools?",
        "answer": "Unlike AI-based generators that create audio directly, this skill uses MIDI synthesis for controllable, theory-based composition. It gives you precise control over every note and instrument."
      }
    ]
  },
  "file_structure": [
    {
      "name": "scripts",
      "type": "dir",
      "path": "scripts",
      "children": [
        {
          "name": "__init__.py",
          "type": "file",
          "path": "scripts/__init__.py",
          "lines": 1
        },
        {
          "name": "audio_validate.py",
          "type": "file",
          "path": "scripts/audio_validate.py",
          "lines": 208
        },
        {
          "name": "drum_synthesizer.py",
          "type": "file",
          "path": "scripts/drum_synthesizer.py",
          "lines": 277
        },
        {
          "name": "melodic_synthesizer.py",
          "type": "file",
          "path": "scripts/melodic_synthesizer.py",
          "lines": 437
        },
        {
          "name": "midi_inventory.py",
          "type": "file",
          "path": "scripts/midi_inventory.py",
          "lines": 204
        },
        {
          "name": "midi_render.py",
          "type": "file",
          "path": "scripts/midi_render.py",
          "lines": 203
        },
        {
          "name": "midi_transform.py",
          "type": "file",
          "path": "scripts/midi_transform.py",
          "lines": 237
        },
        {
          "name": "midi_utils.py",
          "type": "file",
          "path": "scripts/midi_utils.py",
          "lines": 121
        },
        {
          "name": "render_electronic.py",
          "type": "file",
          "path": "scripts/render_electronic.py",
          "lines": 514
        },
        {
          "name": "synthesis_presets.py",
          "type": "file",
          "path": "scripts/synthesis_presets.py",
          "lines": 498
        }
      ]
    },
    {
      "name": "install.sh",
      "type": "file",
      "path": "install.sh",
      "lines": 66
    },
    {
      "name": "requirements.txt",
      "type": "file",
      "path": "requirements.txt",
      "lines": 7
    },
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md",
      "lines": 1670
    }
  ]
}
