{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-21T16:47:13.097Z",
    "slug": "cjharmath-postgres-performance",
    "source_url": "https://github.com/CJHarmath/claude-agents-skills/tree/main/skills/postgres-performance",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "3.0.0",
    "source_type": "community",
    "content_hash": "a9d3b1a51f621c8423720a8a95bda5c1ded938920d247baee3b504183e0ab608",
    "tree_hash": "3609eb55c543d16994aa17cb143da7d0b9943c80f89ffc87b00b1e9361370465"
  },
  "skill": {
    "name": "postgres-performance",
    "description": "High-performance PostgreSQL patterns. Use when optimizing queries, designing for scale, or debugging performance issues.",
    "summary": "High-performance PostgreSQL patterns for query optimization, indexing strategies, and database scaling.",
    "icon": "ðŸ“¦",
    "version": "1.0.0",
    "author": "CJHarmath",
    "license": "MIT",
    "tags": [
      "postgresql",
      "database-optimization",
      "query-performance",
      "sql",
      "database-engineering"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": []
  },
  "security_audit": {
    "risk_level": "low",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "Static analysis flagged 78 potential issues but all are false positives. The scanner misidentified SQL keywords as cryptographic code and markdown code fences as shell execution. This is a legitimate PostgreSQL performance optimization skill containing documentation and example queries. Risk factors are standard for documentation skills that include code examples.",
    "risk_factor_evidence": [],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 2,
    "total_lines": 1166,
    "audit_model": "claude",
    "audited_at": "2026-01-21T16:47:13.097Z"
  },
  "content": {
    "user_title": "Optimize PostgreSQL Query Performance",
    "value_statement": "Database performance issues slow down applications and frustrate users. This skill provides proven patterns for PostgreSQL optimization including indexing strategies, query tuning, and scalable architecture patterns.",
    "seo_keywords": [
      "PostgreSQL performance optimization",
      "PostgreSQL query tuning",
      "database indexing",
      "SQL performance",
      "PostgreSQL scaling",
      "query optimization",
      "database performance",
      "Claude",
      "Codex",
      "Claude Code"
    ],
    "actual_capabilities": [
      "Analyze slow queries using pg_stat_statements and EXPLAIN",
      "Design effective indexes including covering indexes for index-only scans",
      "Implement cursor-based pagination for large datasets",
      "Optimize batch processing with FOR UPDATE SKIP LOCKED",
      "Configure connection pooling for serverless and long-running applications",
      "Set up read replicas for query load distribution"
    ],
    "limitations": [
      "Does not execute queries or modify database schema",
      "Cannot access actual database statistics without connection",
      "Cannot replace proper database monitoring and observability tools",
      "Patterns are general guidance, not specific to every workload"
    ],
    "use_cases": [
      {
        "title": "Debug Slow Application Queries",
        "description": "Identify and fix performance bottlenecks in application queries using PostgreSQL diagnostic tools and EXPLAIN analysis.",
        "target_user": "Backend developers troubleshooting production performance issues"
      },
      {
        "title": "Design Scalable Database Schema",
        "description": "Apply indexing strategies, partitioning, and denormalization patterns for high-throughput database workloads.",
        "target_user": "Database engineers designing new systems or refactoring existing schemas"
      },
      {
        "title": "Optimize Batch Operations",
        "description": "Process large datasets efficiently without locking or causing timeouts using batch patterns with SKIP LOCKED.",
        "target_user": "Data engineers building ETL pipelines and data processing jobs"
      }
    ],
    "prompt_templates": [
      {
        "title": "Quick Query Analysis",
        "prompt": "My PostgreSQL query is slow. Analyze and optimize it:\n\n```sql\nSELECT * FROM orders WHERE user_id = ? AND status = 'pending' ORDER BY created_at DESC LIMIT 20;\n```\n\nHow can I improve this query?",
        "scenario": "Getting started with query optimization"
      },
      {
        "title": "Index Strategy Design",
        "prompt": "I need to optimize these frequently-run queries on a table with 10M+ rows:\n\n1. SELECT * FROM products WHERE category_id = ? AND in_stock = true\n2. SELECT id, name, price FROM products WHERE category_id = ? ORDER BY price ASC\n3. SELECT COUNT(*) FROM products WHERE category_id = ?\n\nDesign an optimal index strategy.",
        "scenario": "Designing indexes for specific query patterns"
      },
      {
        "title": "Pagination Migration",
        "prompt": "Our API uses OFFSET pagination and it is slow for deep pages:\n\n```python\n# Current implementation\ndef get_events(page: int, limit: int = 20):\n    offset = (page - 1) * limit\n    return db.execute(\"SELECT * FROM events ORDER BY created_at DESC LIMIT ? OFFSET ?\", limit, offset)\n```\n\nConvert this to cursor-based pagination with example code.",
        "scenario": "Migrating from OFFSET to cursor pagination"
      },
      {
        "title": "Connection Pool Configuration",
        "prompt": "Configure PostgreSQL connection pooling for our use case:\n\n- Serverless Python API on Lambda (spiky traffic, ~1000 req/min)\n- We see connection errors during traffic spikes\n- Database has 16GB RAM, shared_buffers = 4GB\n\nWhat pool settings do you recommend?",
        "scenario": "Optimizing connection handling for specific deployment"
      }
    ],
    "output_examples": [
      {
        "input": "My query SELECT * FROM events WHERE user_id = 'abc-123' ORDER BY created_at DESC LIMIT 10 is slow on a table with 5M rows.",
        "output": "The query likely performs a sequential scan on the large events table. Here is the optimization approach:\n\n**Problem:** Missing index for the filter and ORDER BY columns.\n\n**Solution:** Create a covering index:\n```sql\nCREATE INDEX CONCURRENTLY ix_events_user_created \nON events (user_id, created_at DESC);\n```\n\nThis index allows:\n1. Filtering by user_id directly from the index\n2. Sorting by created_at DESC using the index order\n3. Index-only scan if you select only indexed columns\n\n**Verification:**\n```sql\nEXPLAIN (ANALYZE, BUFFERS)\nSELECT * FROM events \nWHERE user_id = 'abc-123' \nORDER BY created_at DESC \nLIMIT 10;\n```\n\nLook for \"Index Scan\" instead of \"Seq Scan\" in the plan."
      },
      {
        "input": "How should I implement pagination for a high-traffic API endpoint?",
        "output": "Avoid OFFSET-based pagination for large datasets. Use cursor-based (keyset) pagination instead.\n\n**Why OFFSET is slow:**\n```sql\nSELECT * FROM events ORDER BY created_at DESC LIMIT 20 OFFSET 10000;\n-- Must scan and discard 10,000 rows before returning results\n```\n\n**Cursor-based approach:**\n```sql\nSELECT * FROM events \nWHERE created_at < '2024-01-15T10:30:00Z'\nORDER BY created_at DESC \nLIMIT 20;\n-- Jumps directly to the right place via index\n```\n\n**Python implementation:**\n```python\nasync def get_events_page(session, cursor_time=None, limit=20):\n    query = select(Event).order_by(Event.created_at.desc())\n    if cursor_time:\n        query = query.where(Event.created_at < cursor_time)\n    return await session.execute(query.limit(limit))\n```\n\n**Trade-offs:**\n- Cannot jump to arbitrary page numbers\n- Requires passing cursor to client\n- Much faster for deep pagination"
      }
    ],
    "best_practices": [
      "Always verify query improvements with EXPLAIN (ANALYZE, BUFFERS) before and after changes",
      "Use covering indexes (INCLUDE clause) to avoid heap fetches for frequent queries",
      "Implement cursor-based pagination instead of OFFSET for any table over 100K rows"
    ],
    "anti_patterns": [
      "Using SELECT * in performance-critical queries - specify only needed columns",
      "Running large UPDATE or DELETE operations without batching - causes locks and timeouts",
      "Skipping the FOR UPDATE SKIP LOCKED pattern in concurrent batch processing"
    ],
    "faq": [
      {
        "question": "Does this skill execute queries against my database?",
        "answer": "No. This skill provides patterns, code examples, and guidance. You must execute any SQL commands yourself after reviewing the recommendations."
      },
      {
        "question": "How do I identify which queries are slow in production?",
        "answer": "Enable the pg_stat_statements extension and query it to find your slowest queries by average execution time. The skill includes the exact SQL to use."
      },
      {
        "question": "What is the difference between CREATE INDEX and CREATE INDEX CONCURRENTLY?",
        "answer": "CONCURRENTLY creates the index without blocking writes to the table. Use it in production. Regular CREATE INDEX locks the table for writes during index build."
      },
      {
        "question": "When should I use table partitioning?",
        "answer": "Partition when tables exceed 10M rows and you have natural partition keys (dates, categories). Partitioning improves query performance and makes deleting old data much faster."
      },
      {
        "question": "How do I choose between read replicas and caching?",
        "answer": "Use read replicas to scale query throughput across multiple connections. Use caching for frequently-read, rarely-changed data. Both strategies complement each other."
      },
      {
        "question": "What connection pool settings work best for serverless?",
        "answer": "For serverless/Lambda with no persistent connections, use NullPool (new connection per request). For long-running services, use AsyncAdaptedQueuePool with appropriate pool_size and max_overflow values."
      }
    ]
  },
  "file_structure": [
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md",
      "lines": 441
    }
  ]
}
