{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-07T01:15:42.853Z",
    "slug": "davila7-vaex",
    "source_url": "https://github.com/davila7/claude-code-templates/tree/main/cli-tool/components/skills/scientific/vaex",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "2.0.0",
    "source_type": "community",
    "content_hash": "c6b43bf868735e6a807e50b01ea0ea0c097343d9753b042e956aa7b6f44f3147",
    "tree_hash": "cd95637ee3c99bd55655f1e34a430ebb6576a48338e548ea2f1c24191b7be349"
  },
  "skill": {
    "name": "vaex",
    "description": "Use this skill for processing and analyzing large tabular datasets (billions of rows) that exceed available RAM. Vaex excels at out-of-core DataFrame operations, lazy evaluation, fast aggregations, efficient visualization of big data, and machine learning on large datasets. Apply when users need to work with large CSV/HDF5/Arrow/Parquet files, perform fast statistics on massive datasets, create visualizations of big data, or build ML pipelines that don't fit in memory.",
    "summary": "Use this skill for processing and analyzing large tabular datasets (billions of rows) that exceed av...",
    "icon": "üìä",
    "version": "1.0.0",
    "author": "davila7",
    "license": "MIT",
    "category": "data",
    "tags": [
      "data-science",
      "big-data",
      "dataframes",
      "performance",
      "machine-learning"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": []
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "This is a pure documentation skill containing only reference guides and Python code examples for the Vaex library. No executable scripts, network operations, file system access, or environment variableËØªÂèñ were found. The content describes legitimate data processing operations using a well-known open-source library.",
    "risk_factor_evidence": [],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 7,
    "total_lines": 3720,
    "audit_model": "claude",
    "audited_at": "2026-01-07T01:15:42.853Z"
  },
  "content": {
    "user_title": "Process billion-row datasets efficiently",
    "value_statement": "Working with large datasets that exceed RAM causes memory errors and slow performance. Vaex uses lazy evaluation and memory-mapping to process billions of rows instantly without loading data into memory.",
    "seo_keywords": [
      "Vaex",
      "big data processing",
      "billion rows",
      "out-of-core DataFrame",
      "lazy evaluation",
      "memory efficient",
      "data science",
      "Claude Code",
      "Codex",
      "large dataset analysis"
    ],
    "actual_capabilities": [
      "Load and process datasets larger than available RAM using memory-mapping",
      "Perform fast statistical aggregations on billion-row datasets",
      "Create virtual columns without memory overhead",
      "Build machine learning pipelines with sklearn, XGBoost, and LightGBM integration",
      "Visualize large datasets with heatmaps and histograms"
    ],
    "limitations": [
      "Not a drop-in replacement for pandas in all scenarios",
      "Requires converting data to HDF5 or Arrow format for optimal performance",
      "Some pandas operations not available in Vaex",
      "May require code changes when migrating from pandas"
    ],
    "use_cases": [
      {
        "target_user": "Data scientists",
        "title": "Analyze massive datasets",
        "description": "Explore and analyze datasets with billions of rows without memory errors or sampling."
      },
      {
        "target_user": "ML engineers",
        "title": "Train models on big data",
        "description": "Build and deploy ML pipelines on datasets too large for traditional tools."
      },
      {
        "target_user": "Financial analysts",
        "title": "Process time-series data",
        "description": "Work with large financial time-series data for risk analysis and forecasting."
      }
    ],
    "prompt_templates": [
      {
        "title": "Load large dataset",
        "scenario": "Opening massive files",
        "prompt": "Load a large HDF5/Parquet file with Vaex and show basic statistics and column info."
      },
      {
        "title": "Filter and aggregate",
        "scenario": "Computing statistics",
        "prompt": "Filter the dataset by condition and compute groupby aggregations efficiently."
      },
      {
        "title": "Create visualizations",
        "scenario": "Big data plots",
        "prompt": "Create a heatmap or histogram visualization of the large dataset."
      },
      {
        "title": "Build ML pipeline",
        "scenario": "Training on big data",
        "prompt": "Preprocess features using Vaex ML transformers and train an XGBoost model."
      }
    ],
    "output_examples": [
      {
        "input": "Load my 10GB sales data file and show the distribution of revenue by region",
        "output": [
          "Dataset shape: 150,000,000 rows √ó 25 columns",
          "Memory usage: 0 bytes (memory-mapped HDF5)",
          "Revenue by region:",
          "  ‚Ä¢ North: $12.5B (mean: $245)",
          "  ‚Ä¢ South: $8.3B (mean: $198)",
          "  ‚Ä¢ East: $15.1B (mean: $312)",
          "  ‚Ä¢ West: $10.7B (mean: $267)"
        ]
      }
    ],
    "best_practices": [
      "Convert CSV files to HDF5 or Arrow format for instant loading",
      "Use virtual columns instead of materializing data to save memory",
      "Batch multiple operations with delay=True for single-pass computation",
      "Leverage selections instead of creating new DataFrames for filtering"
    ],
    "anti_patterns": [
      "Using .to_pandas_df() on large datasets defeats Vaex's purpose",
      "Converting data to NumPy arrays with .values when not needed",
      "Exporting to CSV repeatedly instead of using HDF5/Arrow",
      "Materializing virtual columns without good reason"
    ],
    "faq": [
      {
        "question": "How does Vaex handle datasets larger than RAM?",
        "answer": "Vaex memory-maps files, keeping data on disk and reading only accessed portions into memory."
      },
      {
        "question": "What file formats work best with Vaex?",
        "answer": "HDF5 and Apache Arrow provide instant loading. CSV is slow for large files."
      },
      {
        "question": "Can I use Vaex with pandas code?",
        "answer": "Vaex has similar API to pandas but some operations differ. Full pandas compatibility is not guaranteed."
      },
      {
        "question": "Is my data safe when using Vaex?",
        "answer": "Vaex never modifies source files. All transformations create virtual columns or new exports."
      },
      {
        "question": "Why are my operations running slowly?",
        "answer": "Check that you are using HDF5/Arrow format, not CSV. Use delay=True for multiple aggregations."
      },
      {
        "question": "How does Vaex compare to Dask or Polars?",
        "answer": "Vaex excels at billion-row datasets with minimal memory. Dask handles distributed computing, Polars is faster for in-memory data."
      }
    ]
  },
  "file_structure": [
    {
      "name": "references",
      "type": "dir",
      "path": "references",
      "children": [
        {
          "name": "core_dataframes.md",
          "type": "file",
          "path": "references/core_dataframes.md"
        },
        {
          "name": "data_processing.md",
          "type": "file",
          "path": "references/data_processing.md"
        },
        {
          "name": "io_operations.md",
          "type": "file",
          "path": "references/io_operations.md"
        },
        {
          "name": "machine_learning.md",
          "type": "file",
          "path": "references/machine_learning.md"
        },
        {
          "name": "performance.md",
          "type": "file",
          "path": "references/performance.md"
        },
        {
          "name": "visualization.md",
          "type": "file",
          "path": "references/visualization.md"
        }
      ]
    },
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md"
    }
  ]
}
