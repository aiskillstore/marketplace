{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-07T01:07:47.929Z",
    "slug": "davila7-polars",
    "source_url": "https://github.com/davila7/claude-code-templates/tree/main/cli-tool/components/skills/scientific/polars",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "2.0.0",
    "source_type": "community",
    "content_hash": "388a31513ad88d121c6f16257f9a6fb4f3084771d1123070a246279fb9321dd6",
    "tree_hash": "e092a054f65d9c8743e625bfbd6dba6ccec08f8e8d958a4a25a5dcdfa06abe87"
  },
  "skill": {
    "name": "polars",
    "description": "Fast DataFrame library (Apache Arrow). Select, filter, group_by, joins, lazy evaluation, CSV/Parquet I/O, expression API, for high-performance data analysis workflows.",
    "summary": "Fast DataFrame library (Apache Arrow). Select, filter, group_by, joins, lazy evaluation, CSV/Parquet...",
    "icon": "⚡",
    "version": "1.0.0",
    "author": "davila7",
    "license": "MIT",
    "category": "data",
    "tags": [
      "data-analysis",
      "dataframes",
      "python",
      "performance"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": []
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "This is a pure documentation skill containing educational content about the Polars DataFrame library. No executable code, scripts, network calls, or file system access beyond its own markdown files. All code examples demonstrate legitimate data analysis operations using the Polars library.",
    "risk_factor_evidence": [],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 7,
    "total_lines": 2379,
    "audit_model": "claude",
    "audited_at": "2026-01-07T01:07:47.928Z"
  },
  "content": {
    "user_title": "Process data with fast Polars DataFrames",
    "value_statement": "Working with large datasets in pandas is slow and memory-intensive. Polars provides a high-performance alternative built on Apache Arrow with lazy evaluation, parallel execution, and an expression-based API for efficient data analysis.",
    "seo_keywords": [
      "Polars",
      "DataFrame",
      "Python",
      "data analysis",
      "Apache Arrow",
      "lazy evaluation",
      "Claude Code",
      "Codex",
      "data processing",
      "pandas alternative"
    ],
    "actual_capabilities": [
      "Create and manipulate DataFrames with expression-based API",
      "Filter rows and select columns using Polars expressions",
      "Perform group-by aggregations and window functions",
      "Join and concatenate multiple DataFrames",
      "Read and write CSV, Parquet, JSON, Excel, and database formats",
      "Use lazy evaluation for query optimization with large datasets"
    ],
    "limitations": [
      "Does not include index-based operations like pandas",
      "Requires explicit type handling for type conversions",
      "Some advanced pandas features have no direct Polars equivalent",
      "Complex custom functions may require map_elements with performance trade-offs"
    ],
    "use_cases": [
      {
        "target_user": "Data Engineers",
        "title": "Build ETL Pipelines",
        "description": "Create efficient data pipelines with lazy evaluation and streaming for large datasets."
      },
      {
        "target_user": "Data Scientists",
        "title": "Analyze Large Datasets",
        "description": "Process millions of rows faster than pandas with parallel execution."
      },
      {
        "target_user": "Python Developers",
        "title": "Replace Pandas Code",
        "description": "Migrate existing pandas workflows to Polars for better performance."
      }
    ],
    "prompt_templates": [
      {
        "title": "Basic DataFrame",
        "scenario": "Creating and exploring DataFrames",
        "prompt": "Show me how to create a Polars DataFrame from a dictionary, select specific columns, and filter rows where a column value meets a condition."
      },
      {
        "title": "Aggregation",
        "scenario": "Grouping and summarizing data",
        "prompt": "Write Polars code to group data by one or more columns and compute multiple aggregations like sum, mean, and count."
      },
      {
        "title": "Lazy Mode",
        "scenario": "Optimizing large data queries",
        "prompt": "Explain lazy evaluation in Polars. Show how to use scan_csv, build a query plan with filter and select operations, and collect the results."
      },
      {
        "title": "Migration",
        "scenario": "Converting from pandas",
        "prompt": "Help me migrate this pandas code to Polars: show equivalent operations for df['col'], df[df['col'] > 10], df.groupby('cat').agg(), and df.assign(new_col=lambda x: x['old'] * 2)."
      }
    ],
    "output_examples": [
      {
        "input": "Load a CSV file, filter to rows where age is greater than 25, calculate the average salary by department, and save the result to Parquet format.",
        "output": [
          "• Lazy read the CSV with scan_csv for better performance",
          "• Filter using pl.col('age') > 25 expression",
          "• Group by department and aggregate with mean salary",
          "• Collect the result and write to compressed Parquet"
        ]
      }
    ],
    "best_practices": [
      "Use lazy evaluation with scan_csv and scan_parquet for datasets larger than memory to enable query optimization.",
      "Filter and select columns early in your pipeline to maximize predicate and projection pushdown benefits.",
      "Prefer native Polars expressions over Python lambda functions to maintain parallel execution."
    ],
    "anti_patterns": [
      "Iterating over rows with iter_rows() - always use vectorized operations instead.",
      "Using read_csv instead of scan_csv for large files - loses lazy evaluation benefits.",
      "Mixing pandas and Polars unnecessarily - convert once at boundaries with from_pandas or to_pandas."
    ],
    "faq": [
      {
        "question": "How does Polars differ from pandas?",
        "answer": "Polars uses columnar Arrow format instead of row-oriented NumPy arrays. It offers lazy evaluation with query optimization, parallel execution by default, and a strict type system without silent conversions."
      },
      {
        "question": "When should I use lazy mode vs eager mode?",
        "answer": "Use lazy mode (scan_csv, scan_parquet) for large datasets, complex queries, and when you want query optimization. Use eager mode (read_csv) for small data and interactive exploration."
      },
      {
        "question": "Can I use Polars with my existing pandas code?",
        "answer": "Yes, convert between formats with pl.from_pandas() and df.to_pandas(). Use this at integration boundaries rather than mixing APIs throughout your code."
      },
      {
        "question": "Is my data safe when using Polars?",
        "answer": "Polars is a local data processing library. It does not send data to external servers. All file I/O and transformations happen locally on your machine."
      },
      {
        "question": "Why is my Polars code slower than expected?",
        "answer": "Common causes include using Python functions in map_elements, not using lazy mode, filtering after selecting all columns, or having inefficient data types. Check your query plan with lf.explain()."
      },
      {
        "question": "Should I switch from pandas to Polars?",
        "answer": "Switch when performance is critical, working with large datasets, or starting a new project. Keep pandas for small data, when you need complex index operations, or when ecosystem compatibility is essential."
      }
    ]
  },
  "file_structure": [
    {
      "name": "references",
      "type": "dir",
      "path": "references",
      "children": [
        {
          "name": "best_practices.md",
          "type": "file",
          "path": "references/best_practices.md"
        },
        {
          "name": "core_concepts.md",
          "type": "file",
          "path": "references/core_concepts.md"
        },
        {
          "name": "io_guide.md",
          "type": "file",
          "path": "references/io_guide.md"
        },
        {
          "name": "operations.md",
          "type": "file",
          "path": "references/operations.md"
        },
        {
          "name": "pandas_migration.md",
          "type": "file",
          "path": "references/pandas_migration.md"
        },
        {
          "name": "transformations.md",
          "type": "file",
          "path": "references/transformations.md"
        }
      ]
    },
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md"
    }
  ]
}
