{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-17T02:03:22.612Z",
    "slug": "davila7-get-available-resources",
    "source_url": "https://github.com/davila7/claude-code-templates/tree/main/cli-tool/components/skills/scientific/get-available-resources",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "3.0.0",
    "source_type": "community",
    "content_hash": "e51562f2070cd450dd4a67cd2a55995f6596458714a9d9a01c7f008a21de6a7f",
    "tree_hash": "ae35613c034fa2450ea1126f52dc3ba153765304f820d35cf280b9e3f93df753"
  },
  "skill": {
    "name": "get-available-resources",
    "description": "This skill should be used at the start of any computationally intensive scientific task to detect and report available system resources (CPU cores, GPUs, memory, disk space). It creates a JSON file with resource information and strategic recommendations that inform computational approach decisions such as whether to use parallel processing (joblib, multiprocessing), out-of-core computing (Dask, Zarr), GPU acceleration (PyTorch, JAX), or memory-efficient strategies. Use this skill before running analyses, training models, processing large datasets, or any task where resource constraints matter.",
    "summary": "This skill should be used at the start of any computationally intensive scientific task to detect an...",
    "icon": "ðŸ”¬",
    "version": "1.0.0",
    "author": "davila7",
    "license": "MIT",
    "category": "data",
    "tags": [
      "scientific-computing",
      "resource-detection",
      "gpu",
      "optimization"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": [
      "external_commands",
      "filesystem",
      "scripts"
    ]
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "This is a legitimate system resource detection script for scientific computing. All subprocess calls use hardcoded command names (nvidia-smi, rocm-smi, sysctl, system_profiler) to standard system utilities with list arguments (no shell injection risk). File write at line 267 outputs to a predictable local JSON file for resource data storage. No network calls, data exfiltration, credential access, or persistence mechanisms found. The static findings are false positives triggered by pattern matching on subprocess and file operations without semantic context.",
    "risk_factor_evidence": [
      {
        "factor": "external_commands",
        "evidence": [
          {
            "file": "scripts/detect_resources.py",
            "line_start": 87,
            "line_end": 93
          },
          {
            "file": "scripts/detect_resources.py",
            "line_start": 122,
            "line_end": 127
          },
          {
            "file": "scripts/detect_resources.py",
            "line_start": 156,
            "line_end": 161
          },
          {
            "file": "scripts/detect_resources.py",
            "line_start": 177,
            "line_end": 182
          }
        ]
      },
      {
        "factor": "filesystem",
        "evidence": [
          {
            "file": "scripts/detect_resources.py",
            "line_start": 267,
            "line_end": 268
          }
        ]
      },
      {
        "factor": "scripts",
        "evidence": [
          {
            "file": "scripts/detect_resources.py",
            "line_start": 255,
            "line_end": 255
          }
        ]
      }
    ],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 3,
    "total_lines": 864,
    "audit_model": "claude",
    "audited_at": "2026-01-17T02:03:22.612Z"
  },
  "content": {
    "user_title": "Detect system resources for scientific computing",
    "value_statement": "Scientific computing tasks require appropriate hardware resources to run efficiently. This skill automatically detects CPU cores, GPU availability, memory, and disk space to recommend optimal computational strategies and library choices.",
    "seo_keywords": [
      "Claude Code skill",
      "scientific computing",
      "GPU detection",
      "resource monitoring",
      "parallel processing",
      "CUDA",
      "Metal",
      "ROCm",
      "system resources",
      "data science tools"
    ],
    "actual_capabilities": [
      "Detect CPU cores, architecture, and frequency using psutil",
      "Identify NVIDIA GPUs via nvidia-smi with VRAM and compute capability",
      "Detect AMD GPUs via rocm-smi for ROCm backend",
      "Detect Apple Silicon GPUs (M1-M4) via system_profiler",
      "Measure RAM and swap memory availability",
      "Generate recommendations for parallel processing, memory strategy, and GPU acceleration"
    ],
    "limitations": [
      "Requires psutil Python package installation",
      "GPU detection depends on installed driver utilities (nvidia-smi, rocm-smi)",
      "Memory readings are snapshots that change over time",
      "Does not monitor resources continuously"
    ],
    "use_cases": [
      {
        "target_user": "Data scientists",
        "title": "Analyze large datasets",
        "description": "Determine if datasets fit in memory or require Dask, Zarr, or out-of-core processing"
      },
      {
        "target_user": "ML engineers",
        "title": "Train neural networks",
        "description": "Check GPU availability and select appropriate backend for PyTorch, TensorFlow, or JAX"
      },
      {
        "target_user": "Researchers",
        "title": "Run simulations",
        "description": "Identify optimal worker count for parallel processing with joblib or multiprocessing"
      }
    ],
    "prompt_templates": [
      {
        "title": "Basic resource check",
        "scenario": "Quick system scan",
        "prompt": "Use the get-available-resources skill to detect available CPU, GPU, memory, and disk resources"
      },
      {
        "title": "Dataset planning",
        "scenario": "Before large data work",
        "prompt": "Run get-available-resources and recommend whether I should use Dask, Zarr, or in-memory processing"
      },
      {
        "title": "GPU optimization",
        "scenario": "ML workload setup",
        "prompt": "Use get-available-resources to check GPU availability and suggest optimal libraries for my hardware"
      },
      {
        "title": "Parallel scaling",
        "scenario": "Performance tuning",
        "prompt": "Run resource detection and determine the optimal number of parallel workers for processing"
      }
    ],
    "output_examples": [
      {
        "input": "Detect available system resources",
        "output": [
          "CPU: 8 cores (arm64 architecture)",
          "Memory: 16 GB total, 8.5 GB available",
          "GPU: Apple M2 detected with Metal backend",
          "Recommendation: Use high parallelism with 6 workers",
          "Recommendation: GPU acceleration available via PyTorch-MPS"
        ]
      },
      {
        "input": "Check if I can train a model locally",
        "output": [
          "NVIDIA GPU detected with 8GB VRAM",
          "Backend: CUDA available",
          "Suggested libraries: PyTorch, TensorFlow, JAX",
          "Memory: 32 GB RAM available - sufficient for most datasets",
          "Parallel workers recommended: 6"
        ]
      }
    ],
    "best_practices": [
      "Run resource detection at the start of each project session",
      "Re-run before scaling up parallel workers or data sizes",
      "Save the .claude_resources.json file in project directories for documentation"
    ],
    "anti_patterns": [
      "Running resource detection once and ignoring changing resource availability",
      "Assuming GPU availability without checking (nvidia-smi may not be installed)",
      "Using all available cores for parallel processing without leaving headroom for system operations"
    ],
    "faq": [
      {
        "question": "Which platforms are supported?",
        "answer": "Full support for macOS (including Apple Silicon), Linux (NVIDIA and AMD GPUs), and Windows (NVIDIA GPUs)."
      },
      {
        "question": "What Python packages are required?",
        "answer": "Only psutil is required. All other functionality uses Python standard library modules."
      },
      {
        "question": "How accurate are memory readings?",
        "answer": "Memory readings are snapshots at execution time. Available memory changes constantly as processes run."
      },
      {
        "question": "Can I use this skill in CI/CD pipelines?",
        "answer": "Yes, but GPU detection will fail without GPU utilities installed. The script handles missing tools gracefully."
      },
      {
        "question": "How do I detect multiple GPUs?",
        "answer": "The script queries nvidia-smi for all GPUs and reports VRAM, compute capability, and driver version for each."
      },
      {
        "question": "What libraries are recommended for GPU acceleration?",
        "answer": "NVIDIA: PyTorch, TensorFlow, JAX, CuPy. AMD: PyTorch-ROCm, TensorFlow-ROCm. Apple Silicon: PyTorch-MPS, TensorFlow-Metal."
      }
    ]
  },
  "file_structure": [
    {
      "name": "scripts",
      "type": "dir",
      "path": "scripts",
      "children": [
        {
          "name": "detect_resources.py",
          "type": "file",
          "path": "scripts/detect_resources.py",
          "lines": 402
        }
      ]
    },
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md",
      "lines": 272
    }
  ]
}
