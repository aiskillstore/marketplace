{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-17T00:26:11.568Z",
    "slug": "davila7-deepchem",
    "source_url": "https://github.com/davila7/claude-code-templates/tree/main/cli-tool/components/skills/scientific/deepchem",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "3.0.0",
    "source_type": "community",
    "content_hash": "48f4c2f916dc30174d2285f320a07648b4188a708196fb059caee07c2e3aab94",
    "tree_hash": "d163749ee3c2268d21408a92aef3ec9012f4a33014931e8406d51a9c2a2e84ac"
  },
  "skill": {
    "name": "deepchem",
    "description": "Molecular machine learning toolkit. Property prediction (ADMET, toxicity), GNNs (GCN, MPNN), MoleculeNet benchmarks, pretrained models, featurization, for drug discovery ML.",
    "summary": "Molecular machine learning toolkit. Property prediction (ADMET, toxicity), GNNs (GCN, MPNN), Molecul...",
    "icon": "ðŸ§ª",
    "version": "1.0.0",
    "author": "davila7",
    "license": "MIT",
    "category": "scientific",
    "tags": [
      "machine-learning",
      "chemistry",
      "drug-discovery",
      "molecular"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": [
      "scripts",
      "network",
      "filesystem",
      "external_commands"
    ]
  },
  "security_audit": {
    "risk_level": "low",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "Legitimate molecular ML toolkit with standard ML library behaviors. Downloads pretrained models from HuggingFace and saves checkpoints locally. No suspicious network endpoints, credential access, or code execution patterns. Static findings are false positives from markdown documentation parsing.",
    "risk_factor_evidence": [
      {
        "factor": "scripts",
        "evidence": [
          {
            "file": "scripts/predict_solubility.py",
            "line_start": 1,
            "line_end": 225
          },
          {
            "file": "scripts/transfer_learning.py",
            "line_start": 1,
            "line_end": 376
          },
          {
            "file": "scripts/graph_neural_network.py",
            "line_start": 1,
            "line_end": 339
          }
        ]
      },
      {
        "factor": "network",
        "evidence": [
          {
            "file": "scripts/transfer_learning.py",
            "line_start": 59,
            "line_end": 66
          }
        ]
      },
      {
        "factor": "filesystem",
        "evidence": [
          {
            "file": "scripts/transfer_learning.py",
            "line_start": 121,
            "line_end": 126
          },
          {
            "file": "scripts/graph_neural_network.py",
            "line_start": 191,
            "line_end": 191
          }
        ]
      },
      {
        "factor": "external_commands",
        "evidence": [
          {
            "file": "scripts/predict_solubility.py",
            "line_start": 14,
            "line_end": 16
          },
          {
            "file": "scripts/transfer_learning.py",
            "line_start": 13,
            "line_end": 15
          },
          {
            "file": "scripts/graph_neural_network.py",
            "line_start": 14,
            "line_end": 16
          }
        ]
      }
    ],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [
      {
        "title": "Pretrained model downloads from HuggingFace",
        "description": "The transfer_learning.py script downloads pretrained models from HuggingFace (line 61: model_id='seyonec/ChemBERTa-zinc-base-v1'). Standard ML library behavior for transfer learning workflows.",
        "locations": [
          {
            "file": "scripts/transfer_learning.py",
            "line_start": 59,
            "line_end": 66
          }
        ]
      }
    ],
    "low_findings": [
      {
        "title": "Model checkpoint storage to local directories",
        "description": "Scripts save model checkpoints to local directories (line 125: model_dir='./grover_pretrained'). Standard ML practice for model persistence.",
        "locations": [
          {
            "file": "scripts/transfer_learning.py",
            "line_start": 121,
            "line_end": 126
          }
        ]
      }
    ],
    "dangerous_patterns": [],
    "files_scanned": 7,
    "total_lines": 2639,
    "audit_model": "claude",
    "audited_at": "2026-01-17T00:26:11.568Z"
  },
  "content": {
    "user_title": "Predict molecular properties for drug discovery",
    "value_statement": "Drug discovery requires predicting molecular properties like solubility and toxicity. DeepChem provides pretrained models and graph neural networks to predict these properties from molecular structures.",
    "seo_keywords": [
      "DeepChem",
      "molecular machine learning",
      "drug discovery",
      "property prediction",
      "graph neural networks",
      "ADMET prediction",
      "toxicity prediction",
      "solubility prediction",
      "MoleculeNet",
      "ChemBERTa"
    ],
    "actual_capabilities": [
      "Predict molecular properties including solubility, toxicity, and binding affinity",
      "Train and use graph neural networks (GCN, GAT, MPNN, AttentiveFP)",
      "Apply transfer learning with pretrained models (ChemBERTa, GROVER, MolFormer)",
      "Load and process MoleculeNet benchmark datasets",
      "Convert molecules to ML-ready features (fingerprints, graphs, descriptors)",
      "Generate novel molecules using GAN-based molecular generation"
    ],
    "limitations": [
      "Requires DeepChem installation and ML dependencies (deepchem, pytorch, transformers)",
      "Performance depends on dataset size and quality of chemical data",
      "Models trained from scratch need substantial computational resources"
    ],
    "use_cases": [
      {
        "target_user": "Computational chemists",
        "title": "Screen compound libraries",
        "description": "Predict ADMET properties for large compound libraries to prioritize candidates for synthesis."
      },
      {
        "target_user": "Drug discovery researchers",
        "title": "Build predictive models",
        "description": "Train custom property prediction models using your proprietary chemical data."
      },
      {
        "target_user": "Materials scientists",
        "title": "Predict material properties",
        "description": "Apply crystal graph neural networks to predict bandgap, formation energy, and other materials properties."
      }
    ],
    "prompt_templates": [
      {
        "title": "Basic solubility prediction",
        "scenario": "Predict solubility for small molecules",
        "prompt": "Use DeepChem to predict aqueous solubility for these SMILES: CCO, CC(=O)O, c1ccccc1, CN1C=NC2=C1C(=O)N(C(=O)N2C)C"
      },
      {
        "title": "Train property model",
        "scenario": "Train on custom molecular dataset",
        "prompt": "Train a GCN model on my molecules.csv file to predict activity. The SMILES column is 'smiles' and target column is 'target'. Use ScaffoldSplitter for data splitting."
      },
      {
        "title": "Transfer learning",
        "scenario": "Fine-tune pretrained model",
        "prompt": "Fine-tune ChemBERTa on the BBBP dataset using DeepChem. Use scaffold splitting and evaluate with ROC-AUC score."
      },
      {
        "title": "Benchmark evaluation",
        "scenario": "Evaluate model on MoleculeNet",
        "prompt": "Evaluate GCN, GAT, and AttentiveFP models on Tox21 dataset using DeepChem. Compare ROC-AUC scores and report the best performing architecture."
      }
    ],
    "output_examples": [
      {
        "input": "Predict solubility for caffeine using DeepChem",
        "output": [
          "Predicted solubility for CN1C=NC2=C1C(=O)N(C(=O)N2C)C: -1.190 log(mol/L)",
          "Model: MultitaskRegressor with CircularFingerprint featurizer",
          "Dataset: Delaney benchmark, RÂ²=0.89 on test set"
        ]
      },
      {
        "input": "Train a GCN model on Tox21 dataset",
        "output": [
          "Training GCN on 12 toxicity prediction tasks",
          "Using scaffold splitting to prevent data leakage",
          "Test ROC-AUC: 0.782 average across all tasks"
        ]
      }
    ],
    "best_practices": [
      "Use ScaffoldSplitter for molecular data to prevent data leakage from similar structures",
      "Apply normalization transformers to features and targets for better model convergence",
      "Start with simpler models (Random Forest + CircularFingerprint) before scaling to deep learning"
    ],
    "anti_patterns": [
      "Using random splitting for molecular datasets causes data leakage from similar compounds",
      "Training deep neural networks on small datasets (<1000 samples) leads to overfitting",
      "Skipping data normalization reduces model performance and training stability"
    ],
    "faq": [
      {
        "question": "Which featurizer should I use?",
        "answer": "Use CircularFingerprint for small datasets and traditional ML. Use MolGraphConvFeaturizer for large datasets and graph neural networks."
      },
      {
        "question": "What compute resources do I need?",
        "answer": "Graph neural networks require GPU for training. Traditional ML (Random Forest, XGBoost) runs efficiently on CPU with smaller datasets."
      },
      {
        "question": "How do I install DeepChem?",
        "answer": "Run: uv pip install deepchem. For PyTorch models: uv pip install deepchem[torch]. For all features: uv pip install deepchem[all]."
      },
      {
        "question": "Is my data safe when using pretrained models?",
        "answer": "Yes. Your data is processed locally. Pretrained model weights are downloaded from HuggingFace but your data never leaves your environment."
      },
      {
        "question": "Why is my model underperforming?",
        "answer": "Common issues: insufficient data, wrong featurizer choice, data leakage from random splitting, or insufficient training epochs. Use ScaffoldSplitter and start with simpler baselines."
      },
      {
        "question": "How does this compare to other ML frameworks?",
        "answer": "DeepChem specializes in molecular data with built-in loaders, featurizers, and benchmarks. For general ML, use scikit-learn or PyTorch directly."
      }
    ]
  },
  "file_structure": [
    {
      "name": "references",
      "type": "dir",
      "path": "references",
      "children": [
        {
          "name": "api_reference.md",
          "type": "file",
          "path": "references/api_reference.md",
          "lines": 304
        },
        {
          "name": "workflows.md",
          "type": "file",
          "path": "references/workflows.md",
          "lines": 492
        }
      ]
    },
    {
      "name": "scripts",
      "type": "dir",
      "path": "scripts",
      "children": [
        {
          "name": "graph_neural_network.py",
          "type": "file",
          "path": "scripts/graph_neural_network.py",
          "lines": 339
        },
        {
          "name": "predict_solubility.py",
          "type": "file",
          "path": "scripts/predict_solubility.py",
          "lines": 225
        },
        {
          "name": "transfer_learning.py",
          "type": "file",
          "path": "scripts/transfer_learning.py",
          "lines": 376
        }
      ]
    },
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md",
      "lines": 592
    }
  ]
}
