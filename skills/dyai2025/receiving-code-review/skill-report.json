{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-17T04:40:42.442Z",
    "slug": "dyai2025-receiving-code-review",
    "source_url": "https://github.com/DYAI2025/Stoppclock-page/tree/main/stoppclock_speckit/.claude/commands/skills/receiving-code-review",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "3.0.0",
    "source_type": "community",
    "content_hash": "2f6114025609bed0dcf13a9b4a583f625c9f27b91052c9c90a8833af9a83c804",
    "tree_hash": "cfa94ccff5e668b9f2f25e2b272b7e4c3885296b882ef9320339ac756719e210"
  },
  "skill": {
    "name": "receiving-code-review",
    "description": "Use when receiving code review feedback, before implementing suggestions, especially if feedback seems unclear or technically questionable - requires technical rigor and verification, not performative agreement or blind implementation",
    "summary": "Use when receiving code review feedback, before implementing suggestions, especially if feedback see...",
    "icon": "üîç",
    "version": "1.0.0",
    "author": "DYAI2025",
    "license": "MIT",
    "category": "coding",
    "tags": [
      "code-review",
      "development",
      "quality",
      "verification",
      "technical"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": [
      "network",
      "filesystem",
      "external_commands"
    ]
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "This is a documentation-only skill providing guidelines for code review feedback handling. All static findings are false positives: the scanner misinterpreted source URL metadata as network issues, backtick-delimited documentation blocks as shell execution, and JSON field names mentioning cryptographic terms as actual algorithm implementations. No executable code, no data access, no network calls, no file system operations. Pure instructional content.",
    "risk_factor_evidence": [
      {
        "factor": "network",
        "evidence": [
          {
            "file": "skill-report.json",
            "line_start": 6,
            "line_end": 6
          }
        ]
      },
      {
        "factor": "filesystem",
        "evidence": [
          {
            "file": "skill-report.json",
            "line_start": 6,
            "line_end": 6
          }
        ]
      },
      {
        "factor": "external_commands",
        "evidence": [
          {
            "file": "SKILL.md",
            "line_start": 16,
            "line_end": 25
          },
          {
            "file": "SKILL.md",
            "line_start": 25,
            "line_end": 42
          },
          {
            "file": "SKILL.md",
            "line_start": 42,
            "line_end": 48
          },
          {
            "file": "SKILL.md",
            "line_start": 48,
            "line_end": 51
          },
          {
            "file": "SKILL.md",
            "line_start": 51,
            "line_end": 57
          },
          {
            "file": "SKILL.md",
            "line_start": 57,
            "line_end": 68
          },
          {
            "file": "SKILL.md",
            "line_start": 68,
            "line_end": 84
          },
          {
            "file": "SKILL.md",
            "line_start": 84,
            "line_end": 90
          },
          {
            "file": "SKILL.md",
            "line_start": 90,
            "line_end": 96
          },
          {
            "file": "SKILL.md",
            "line_start": 96,
            "line_end": 102
          },
          {
            "file": "SKILL.md",
            "line_start": 102,
            "line_end": 111
          },
          {
            "file": "SKILL.md",
            "line_start": 111,
            "line_end": 134
          },
          {
            "file": "SKILL.md",
            "line_start": 134,
            "line_end": 144
          },
          {
            "file": "SKILL.md",
            "line_start": 144,
            "line_end": 153
          },
          {
            "file": "SKILL.md",
            "line_start": 153,
            "line_end": 160
          },
          {
            "file": "SKILL.md",
            "line_start": 160,
            "line_end": 179
          },
          {
            "file": "SKILL.md",
            "line_start": 179,
            "line_end": 182
          },
          {
            "file": "SKILL.md",
            "line_start": 182,
            "line_end": 185
          },
          {
            "file": "SKILL.md",
            "line_start": 185,
            "line_end": 188
          },
          {
            "file": "SKILL.md",
            "line_start": 188,
            "line_end": 191
          },
          {
            "file": "SKILL.md",
            "line_start": 191,
            "line_end": 194
          },
          {
            "file": "SKILL.md",
            "line_start": 194,
            "line_end": 197
          },
          {
            "file": "SKILL.md",
            "line_start": 197,
            "line_end": 201
          }
        ]
      }
    ],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 2,
    "total_lines": 394,
    "audit_model": "claude",
    "audited_at": "2026-01-17T04:40:42.442Z"
  },
  "content": {
    "user_title": "Handle code reviews with technical rigor",
    "value_statement": "Many developers blindly implement code review feedback without verification. This skill ensures you evaluate feedback technically before implementation. It promotes code quality and prevents unnecessary changes.",
    "seo_keywords": [
      "code review",
      "Claude",
      "Codex",
      "Claude Code",
      "technical verification",
      "code quality",
      "development process",
      "peer review",
      "software engineering",
      "code review best practices"
    ],
    "actual_capabilities": [
      "Provides structured approach to evaluating code review feedback",
      "Prevents blind implementation of suggestions without verification",
      "Includes specific guidelines for handling unclear feedback",
      "Teaches technical pushback when suggestions are incorrect",
      "Promotes YAGNI principle for avoiding unnecessary features",
      "Emphasizes testing each fix individually before moving on"
    ],
    "limitations": [
      "Requires technical knowledge to properly evaluate suggestions",
      "May slow down initial implementation while building verification habits",
      "Works best when combined with existing test coverage"
    ],
    "use_cases": [
      {
        "target_user": "Software developers",
        "title": "Evaluate peer review feedback",
        "description": "Systematically assess code review comments before implementation to ensure technical soundness."
      },
      {
        "target_user": "Senior engineers",
        "title": "Train junior developers",
        "description": "Establish code review culture focused on technical correctness over performative agreement."
      },
      {
        "target_user": "Open source contributors",
        "title": "Handle external reviewer suggestions",
        "description": "Navigate code review from project maintainers with appropriate skepticism and verification."
      }
    ],
    "prompt_templates": [
      {
        "title": "Basic review handling",
        "scenario": "Simple code review with minor changes",
        "prompt": "I received code review feedback asking to fix variable naming and add error handling. Help me evaluate these suggestions before implementing."
      },
      {
        "title": "Complex architectural feedback",
        "scenario": "Major refactoring suggestions from senior developer",
        "prompt": "A senior developer suggested refactoring our entire authentication system. How should I evaluate this feedback?"
      },
      {
        "title": "Unclear review comments",
        "scenario": "Review feedback is vague or incomplete",
        "prompt": "My reviewer said 'Fix the performance issues' but didn't specify which ones. How do I handle this unclear feedback?"
      },
      {
        "title": "Conflicting suggestions",
        "scenario": "Multiple reviewers give contradictory advice",
        "prompt": "Two reviewers gave opposite suggestions about database optimization. One says use indexes, another says denormalize. How do I evaluate?"
      }
    ],
    "output_examples": [
      {
        "input": "Review feedback: 'Remove this legacy code, it's not needed anymore'",
        "output": [
          "Checking codebase for usage of legacy code...",
          "Found 3 references in authentication module",
          "Code handles edge case for IE11 compatibility",
          "Response: 'This code handles IE11 edge cases. Remove it and drop IE11 support, or keep it for compatibility?'"
        ]
      },
      {
        "input": "Review feedback: 'Implement proper metrics tracking with database, date filters, CSV export'",
        "output": [
          "Grepping codebase for endpoint usage...",
          "No calls found to this metrics endpoint",
          "Endpoint appears unused in current codebase",
          "Response: 'Nothing calls this endpoint. Remove it (YAGNI)? Or is there usage I missed?'"
        ]
      },
      {
        "input": "Review feedback: 'Fix items 1-6'",
        "output": [
          "Reviewing items 1-6 for clarity",
          "Items 1, 2, 3, 6 are clear",
          "Items 4 and 5 need clarification",
          "Response: 'Understand 1,2,3,6. Need clarification on 4 and 5 before implementing.'"
        ]
      }
    ],
    "best_practices": [
      "Always verify suggestions against actual codebase usage before implementing",
      "Ask clarifying questions when feedback is unclear rather than making assumptions",
      "Test each fix individually rather than batching multiple changes together"
    ],
    "anti_patterns": [
      "Blindly implementing suggestions without verification or understanding",
      "Using performative agreement like 'Great point!' or 'You're absolutely right!'",
      "Implementing partial feedback when some items are unclear"
    ],
    "faq": [
      {
        "question": "Is this compatible with all code review tools?",
        "answer": "Yes, the principles apply regardless of platform - GitHub, GitLab, Bitbucket, or internal tools."
      },
      {
        "question": "What if the reviewer gets upset when I push back?",
        "answer": "Use technical reasoning, not defensiveness. Good reviewers appreciate thorough evaluation."
      },
      {
        "question": "How do I integrate this with existing review processes?",
        "answer": "Apply verification steps mentally before responding. No process changes needed."
      },
      {
        "question": "Is my data safe when using this approach?",
        "answer": "Yes, this skill doesn't access or transmit data. It's purely a methodology guide."
      },
      {
        "question": "What if I can't verify a suggestion without significant investigation?",
        "answer": "State the limitation: 'I can't verify this without [X]. Should I investigate or proceed differently?'"
      },
      {
        "question": "How does this compare to other code review approaches?",
        "answer": "This emphasizes technical verification over social niceties, preventing incorrect suggestions."
      }
    ]
  },
  "file_structure": [
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md",
      "lines": 210
    },
    {
      "name": "SKILL.zip",
      "type": "file",
      "path": "SKILL.zip"
    }
  ]
}
