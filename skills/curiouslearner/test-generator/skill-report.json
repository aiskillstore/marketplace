{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-16T23:46:34.846Z",
    "slug": "curiouslearner-test-generator",
    "source_url": "https://github.com/CuriousLearner/devkit/tree/main/skills/test-generator",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "3.0.0",
    "source_type": "community",
    "content_hash": "b8e90f43d366f4897e5bafd53b44ae9a91e82d6a289a0d0b5065a290e4b863e3",
    "tree_hash": "7d995b82d4904ec323aaaa00cfb424c3db42d5fda16198edbf6026abd895fc7d"
  },
  "skill": {
    "name": "test-generator",
    "description": "Generate unit tests based on existing code patterns and testing frameworks.",
    "summary": "Generate unit tests based on existing code patterns and testing frameworks.",
    "icon": "ðŸ§ª",
    "version": "1.0.0",
    "author": "CuriousLearner",
    "license": "MIT",
    "category": "coding",
    "tags": [
      "testing",
      "unit-tests",
      "code-generation",
      "development"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": [
      "network",
      "external_commands"
    ]
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "This is a prompt-based skill containing only instructions for generating test code. The static findings are false positives: the analyzer misidentified metadata URLs as network calls, test-related terminology as cryptographic issues, and code examples as executable commands. No executable code, network access, file system access, or environment variable access exists.",
    "risk_factor_evidence": [
      {
        "factor": "network",
        "evidence": [
          {
            "file": "skill-report.json",
            "line_start": 6,
            "line_end": 6
          }
        ]
      },
      {
        "factor": "external_commands",
        "evidence": [
          {
            "file": "SKILL.md",
            "line_start": 50,
            "line_end": 55
          },
          {
            "file": "SKILL.md",
            "line_start": 55,
            "line_end": 69
          },
          {
            "file": "SKILL.md",
            "line_start": 69,
            "line_end": 85
          }
        ]
      }
    ],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 2,
    "total_lines": 262,
    "audit_model": "claude",
    "audited_at": "2026-01-16T23:46:34.846Z"
  },
  "content": {
    "user_title": "Generate Unit Tests Automatically",
    "value_statement": "Writing comprehensive unit tests is time-consuming and often incomplete. This skill analyzes your code and generates complete test suites with edge cases, error handling, and proper mocking.",
    "seo_keywords": [
      "unit test generator",
      "automated testing",
      "Claude Code testing",
      "Codex test generation",
      "JavaScript testing",
      "Python tests",
      "Jest tests",
      "pytest",
      "test automation",
      "code coverage"
    ],
    "actual_capabilities": [
      "Analyzes existing code patterns and function signatures",
      "Detects testing framework (Jest, pytest, JUnit, etc.)",
      "Generates comprehensive test cases with edge cases",
      "Creates mocks for external dependencies",
      "Follows project-specific naming conventions"
    ],
    "limitations": [
      "Requires existing code to analyze",
      "Cannot run tests - only generates code",
      "May need manual adjustment for complex logic"
    ],
    "use_cases": [
      {
        "target_user": "Software developers",
        "title": "Legacy Code Test Coverage",
        "description": "Add tests to untested legacy codebases to improve reliability and enable refactoring."
      },
      {
        "target_user": "Development teams",
        "title": "New Feature Testing",
        "description": "Generate initial test suites for new features following team conventions."
      },
      {
        "target_user": "Open source contributors",
        "title": "Contribution Requirements",
        "description": "Create tests required for pull requests in projects with strict testing policies."
      }
    ],
    "prompt_templates": [
      {
        "title": "Basic Test Generation",
        "scenario": "Generate tests for a simple function",
        "prompt": "@test-generator src/utils/calculator.js"
      },
      {
        "title": "Coverage Focus",
        "scenario": "Generate tests with coverage requirements",
        "prompt": "@test-generator --coverage src/api/userService.ts"
      },
      {
        "title": "Watch Mode",
        "scenario": "Generate tests in watch mode for TDD",
        "prompt": "@test-generator --watch src/components/Button.jsx"
      },
      {
        "title": "Complex Module",
        "scenario": "Generate tests for a module with dependencies",
        "prompt": "@test-generator src/services/PaymentProcessor.py"
      }
    ],
    "output_examples": [
      {
        "input": "@test-generator src/utils/validator.js",
        "output": [
          "Creates validator.test.js with:",
          "Tests for valid inputs",
          "Tests for invalid inputs",
          "Edge case tests (null, undefined, empty strings)",
          "Tests for each validation rule",
          "Mocked dependency tests"
        ]
      },
      {
        "input": "@test-generator --coverage src/api/userService.ts",
        "output": [
          "Generates userService.test.ts",
          "Includes coverage reporting setup",
          "Tests all public methods",
          "Adds integration test stubs"
        ]
      },
      {
        "input": "@test-generator src/services/PaymentProcessor.py",
        "output": [
          "Creates test_payment_processor.py",
          "Mocks external payment gateway",
          "Tests success and failure scenarios",
          "Validates error handling paths"
        ]
      }
    ],
    "best_practices": [
      "Review generated tests to ensure they match your testing philosophy",
      "Add custom edge cases specific to your domain",
      "Use the generated tests as a starting point, not the final version"
    ],
    "anti_patterns": [
      "Blindly committing generated tests without review",
      "Using generated tests as a substitute for thinking about test design",
      "Generating tests for code that should be refactored first"
    ],
    "faq": [
      {
        "question": "Which testing frameworks are supported?",
        "answer": "Jest, Mocha, Vitest, pytest, unittest, Go testing, JUnit, TestNG, RSpec, and Minitest."
      },
      {
        "question": "Can it generate integration tests?",
        "answer": "Yes, it can generate integration tests where appropriate, following your project's patterns."
      },
      {
        "question": "How does it handle external dependencies?",
        "answer": "It automatically creates mocks for external dependencies like APIs, databases, and file systems."
      },
      {
        "question": "Will it overwrite existing tests?",
        "answer": "No, it preserves existing tests and only adds new ones for untested code."
      },
      {
        "question": "Can I customize the test generation?",
        "answer": "Yes, use flags like --coverage or --watch to control generation behavior."
      },
      {
        "question": "Is the generated code production-ready?",
        "answer": "The code follows best practices but always review and adjust for your specific needs."
      }
    ]
  },
  "file_structure": [
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md",
      "lines": 86
    }
  ]
}
