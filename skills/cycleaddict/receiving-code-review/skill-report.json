{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-21T16:52:45.318Z",
    "slug": "cycleaddict-receiving-code-review",
    "source_url": "https://github.com/Cycleaddict/generic-superpowers/tree/main/skills/receiving-code-review",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "3.0.0",
    "source_type": "community",
    "content_hash": "cbf580a8b2b65fba03646a47223264654d7037c8b1901236c1f485a005fb64df",
    "tree_hash": "ee299e61fd46ec51890fa07a3ea9e8efe2ddd0579f286112c196b77f24b23635"
  },
  "skill": {
    "name": "receiving-code-review",
    "description": "Guides AI agents through technical evaluation of code review feedback with emphasis on verification before implementation and technical rigor over performative agreement.",
    "summary": "Handle code review feedback with technical rigor and verification instead of blind implementation.",
    "icon": "ðŸ“¦",
    "version": "1.0.0",
    "author": "Cycleaddict",
    "license": "MIT",
    "category": "coding",
    "tags": [
      "code-review",
      "feedback-handling",
      "technical-evaluation",
      "verification",
      "best-practices"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": []
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "This is a pure documentation skill providing guidance on code review feedback handling. All 36 static findings are false positives: C2 keywords are movie quotes, cryptographic patterns are markdown file extensions, backticks are documentation code blocks, and URLs are legitimate GitHub references. No actual code execution or network access.",
    "risk_factor_evidence": [],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 2,
    "total_lines": 652,
    "audit_model": "claude",
    "audited_at": "2026-01-21T16:52:45.318Z"
  },
  "content": {
    "user_title": "Handle Code Review Feedback with Technical Rigor",
    "value_statement": "Code review feedback requires technical verification, not blind implementation. This skill guides AI agents through evaluating feedback critically, asking clarifying questions, and pushing back when necessary with technical reasoning.",
    "seo_keywords": [
      "Claude",
      "Codex",
      "Claude Code",
      "code review",
      "peer review",
      "feedback handling",
      "technical verification",
      "development workflow",
      "code quality",
      "pull requests"
    ],
    "actual_capabilities": [
      "Provides structured framework for evaluating code review feedback before implementation",
      "Guides technical verification of suggestions against actual codebase reality",
      "Teaches appropriate pushback strategies when feedback conflicts with technical requirements",
      "Distinguishes handling trusted partner feedback versus external reviewer suggestions",
      "Enforces YAGNI principle by verifying actual feature usage before implementing suggestions",
      "Prevents performative agreement in favor of technical acknowledgment"
    ],
    "limitations": [
      "Requires human judgment to determine when technical pushback is appropriate",
      "Does not provide automated code analysis or testing capabilities",
      "Guidance is framework-only and requires agent to execute verification steps",
      "Cannot resolve architectural conflicts without human partner involvement"
    ],
    "use_cases": [
      {
        "title": "External Pull Request Review",
        "description": "Evaluate suggestions from external contributors by checking technical correctness, compatibility with existing architecture, and potential breaking changes before accepting changes.",
        "target_user": "Open source maintainers using Claude Code to process community contributions"
      },
      {
        "title": "Team Code Review Processing",
        "description": "Handle multi-item feedback from team reviews by clarifying unclear items first, verifying technical feasibility, and implementing changes in priority order with individual testing.",
        "target_user": "Development teams collaborating on shared codebases with AI assistance"
      },
      {
        "title": "YAGNI Enforcement",
        "description": "Challenge feature expansion suggestions by verifying actual usage in the codebase and pushing back on implementing unused functionality that violates YAGNI principles.",
        "target_user": "Technical leads maintaining lean codebases and preventing scope creep"
      }
    ],
    "prompt_templates": [
      {
        "title": "Basic Review Acknowledgment",
        "prompt": "I received code review feedback suggesting to extract this function into a utility module. Verify if this pattern is used elsewhere in the codebase before implementing.",
        "scenario": "Single suggestion from team member requiring verification"
      },
      {
        "title": "Multi-Item Review Processing",
        "prompt": "Pull request has 8 review comments. Items 1-3 and 7-8 are clear. Need clarification on items 4, 5, and 6 regarding the database migration approach before proceeding with any implementation.",
        "scenario": "Complex review with mix of clear and unclear feedback"
      },
      {
        "title": "Technical Pushback",
        "prompt": "Reviewer suggests removing backward compatibility code for iOS 12. Check deployment targets and actual device support before implementing - we may still need this for enterprise customers.",
        "scenario": "External suggestion that may conflict with requirements"
      },
      {
        "title": "YAGNI Verification",
        "prompt": "Code review suggests implementing comprehensive error reporting with database logging, email notifications, and dashboard UI. Grep the codebase to verify if this error handler is actually called anywhere before building all this infrastructure.",
        "scenario": "Feature expansion suggestion requiring usage verification"
      }
    ],
    "output_examples": [
      {
        "input": "Reviewer says to add TypeScript strict mode to this file",
        "output": "Checking tsconfig.json... Project uses strict:false globally. Enabling strict mode for one file creates inconsistency and may break existing type assumptions. Should we enable strict mode project-wide or keep current configuration?"
      },
      {
        "input": "Fix items 1-5 from the code review",
        "output": "Understand items 1, 2, and 5. Need clarification on items 3 and 4: Item 3 mentions refactoring the auth flow but does not specify which approach. Item 4 references a shared utility that does not exist in the codebase. Please clarify before proceeding."
      },
      {
        "input": "Implement proper pagination with cursor-based navigation",
        "output": [
          "Grepped codebase for calls to this endpoint... No usage found.",
          "This is an unused API route. Remove it per YAGNI principle?",
          "Or is there planned usage I am missing?"
        ]
      }
    ],
    "best_practices": [
      "Always verify feedback against actual codebase state before implementing changes",
      "Clarify all unclear items in multi-item reviews before starting any implementation",
      "Use technical reasoning and specific evidence when pushing back on suggestions"
    ],
    "anti_patterns": [
      "Responding with performative agreement like absolutely right or great point without verification",
      "Implementing suggestions immediately without checking for breaking changes or conflicts",
      "Proceeding with partial implementation when some feedback items are unclear"
    ],
    "faq": [
      {
        "question": "How does this skill differ from accepting all review feedback?",
        "answer": "This skill teaches critical evaluation of feedback through technical verification rather than blind acceptance. It emphasizes checking suggestions against codebase reality and pushing back with technical reasoning when appropriate."
      },
      {
        "question": "When should I push back on code review feedback?",
        "answer": "Push back when suggestions break existing functionality, violate YAGNI for unused features, lack full context, conflict with architectural decisions, or are technically incorrect for your stack. Always use technical reasoning, not defensiveness."
      },
      {
        "question": "What if I cannot verify a suggestion easily?",
        "answer": "State the limitation explicitly and ask for direction. For example: I cannot verify this without access to production logs. Should I investigate locally, ask the team, or proceed based on the suggestion?"
      },
      {
        "question": "How do I handle unclear items in multi-item reviews?",
        "answer": "Stop and clarify all unclear items before implementing anything. Items may be related, and partial understanding leads to wrong implementation. State which items you understand and which need clarification."
      },
      {
        "question": "What is the YAGNI check mentioned in this skill?",
        "answer": "YAGNI means You Aren't Gonna Need It. Before implementing suggested features, grep the codebase for actual usage. If the code is unused, consider removing it instead of enhancing it to avoid building unnecessary functionality."
      },
      {
        "question": "Does this skill work with GitHub pull request workflows?",
        "answer": "Yes, this skill includes guidance for replying to inline review comments in GitHub threads and processing multi-item PR feedback systematically. It handles both trusted team feedback and external contributor suggestions."
      }
    ]
  },
  "file_structure": [
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md",
      "lines": 214
    }
  ]
}
