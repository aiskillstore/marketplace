{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-21T16:49:53.498Z",
    "slug": "cycleaddict-verification-before-completion",
    "source_url": "https://github.com/Cycleaddict/generic-superpowers/tree/main/skills/verification-before-completion",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "3.0.0",
    "source_type": "community",
    "content_hash": "963f6b63d58d88e029181126528a1c720f76c4f8cfaec3532ece14795aef5b77",
    "tree_hash": "5e28449c44a200b29c1299bd5f333662f94ce7dd54a3fd9f59a721e2cd342612"
  },
  "skill": {
    "name": "verification-before-completion",
    "description": "Enforces verification before making completion claims by requiring fresh command output and exit codes before commits or PRs",
    "summary": "Evidence-based verification workflow that prevents premature completion claims",
    "icon": "✅",
    "version": "1.0.0",
    "author": "Cycleaddict",
    "license": "MIT",
    "category": "productivity",
    "tags": [
      "verification",
      "testing",
      "quality-assurance",
      "workflow",
      "best-practices"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": []
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "This skill is safe. All static findings are false positives. The skill contains only markdown documentation providing verification workflow guidelines with no executable code, network requests, or file system operations.",
    "risk_factor_evidence": [],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 2,
    "total_lines": 469,
    "audit_model": "claude",
    "audited_at": "2026-01-21T16:49:53.498Z"
  },
  "content": {
    "user_title": "Verify Work Before Claiming Completion",
    "value_statement": "Prevents premature completion claims by requiring fresh verification evidence before commits or pull requests. This skill teaches Claude Code to always run verification commands and check output before making any success claims.",
    "seo_keywords": [
      "Claude",
      "Codex",
      "Claude Code",
      "verification",
      "testing",
      "quality assurance",
      "test driven development",
      "TDD",
      "CI/CD",
      "code quality"
    ],
    "actual_capabilities": [
      "Guides Claude Code to run verification commands before making completion claims",
      "Enforces evidence-based workflow requiring fresh test output and exit codes",
      "Provides structured patterns for test verification, build checks, and requirement validation",
      "Prevents premature commits and pull requests without proper verification",
      "Teaches red-green-refactor cycle verification for regression tests"
    ],
    "limitations": [
      "Does not execute verification commands itself, only provides guidelines for when to run them",
      "Requires Claude Code to interpret and follow the documented workflow patterns",
      "Cannot prevent verification bypass if Claude Code ignores the guidelines"
    ],
    "use_cases": [
      {
        "title": "Test-Driven Development Workflow",
        "description": "Use this skill when practicing TDD to ensure Claude Code verifies the red-green cycle before claiming a test passes. The skill enforces running tests after writing them, reverting the fix to confirm failure, then restoring to verify success.",
        "target_user": "Developers using TDD methodology"
      },
      {
        "title": "Pre-Commit Quality Gates",
        "description": "Apply this skill before creating commits or pull requests to ensure Claude Code runs all verification commands including tests, linters, and builds. It prevents commits based on assumptions without fresh evidence.",
        "target_user": "Teams enforcing quality standards"
      },
      {
        "title": "Agent Delegation Verification",
        "description": "Use when delegating work to AI agents to ensure Claude Code independently verifies agent success claims by checking version control diffs and running verification commands rather than trusting agent reports.",
        "target_user": "Users working with multiple AI agents"
      }
    ],
    "prompt_templates": [
      {
        "title": "Basic Test Verification",
        "prompt": "I need to verify that all tests pass before committing my changes",
        "scenario": "Simple test verification before commit"
      },
      {
        "title": "Red-Green Cycle Validation",
        "prompt": "I wrote a regression test for the bug fix. Verify it follows proper red-green-refactor cycle",
        "scenario": "Ensuring new tests actually catch the bug"
      },
      {
        "title": "Pre-PR Complete Verification",
        "prompt": "I am ready to create a pull request. Run all verification steps including tests, linting, and build",
        "scenario": "Comprehensive verification before pull request"
      },
      {
        "title": "Requirement Completion Check",
        "prompt": "Verify that all requirements from the original task are met with evidence",
        "scenario": "Advanced verification against requirement checklist"
      }
    ],
    "output_examples": [
      {
        "input": "I need to verify tests pass before committing",
        "output": "Running test command to verify: npm test\n\nTest Results:\n✓ 34 tests passed\n✓ 0 tests failed\n✓ Exit code: 0\n\nVerification complete. All tests pass. Evidence confirmed before proceeding with commit."
      },
      {
        "input": "Verify the regression test catches the bug",
        "output": "Step 1: Running test with fix in place\n✓ Test passes\n\nStep 2: Reverting fix to verify test catches bug\n✓ Test fails as expected\n\nStep 3: Restoring fix\n✓ Test passes again\n\nRed-green cycle verified. The regression test correctly catches the bug."
      }
    ],
    "best_practices": [
      "Always run the full verification command fresh in the current session before making completion claims",
      "Check exit codes and count failures in test output rather than relying on partial verification",
      "For regression tests, verify the red-green cycle by confirming tests fail without the fix"
    ],
    "anti_patterns": [
      "Using words like should, probably, or seems to when making completion claims without verification",
      "Trusting agent success reports or previous test runs without fresh verification",
      "Making completion claims based on partial verification such as linter passing but build not run"
    ],
    "faq": [
      {
        "question": "Does this skill automatically run verification commands?",
        "answer": "No. This skill provides guidelines and patterns for Claude Code to follow. Claude Code still needs to execute the verification commands based on these guidelines."
      },
      {
        "question": "What types of verification does this skill cover?",
        "answer": "The skill covers test verification, build checks, linting, regression test validation, requirement checklists, and agent delegation verification."
      },
      {
        "question": "Can I use this skill with any testing framework?",
        "answer": "Yes. The skill provides framework-agnostic verification patterns that work with any testing, linting, or build system."
      },
      {
        "question": "How does this prevent premature completion claims?",
        "answer": "The skill teaches Claude Code to recognize red flags like using words such as should or probably, and requires fresh command output with exit codes before making any success claims."
      },
      {
        "question": "What is the red-green cycle verification?",
        "answer": "Red-green cycle verification ensures regression tests actually catch bugs by running the test with the fix, reverting to confirm failure, then restoring to confirm success."
      },
      {
        "question": "Does this skill work for pull request creation?",
        "answer": "Yes. The skill includes patterns for comprehensive pre-PR verification including tests, builds, linting, and requirement validation before creating pull requests."
      }
    ]
  },
  "file_structure": [
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md",
      "lines": 140
    }
  ]
}
