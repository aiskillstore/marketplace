{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-16T13:03:48.303Z",
    "slug": "89jobrien-golang-performance",
    "source_url": "https://github.com/89jobrien/steve/tree/main/steve/skills/golang-performance",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "3.0.0",
    "source_type": "community",
    "content_hash": "8d07c6e762b73946c51be1981ca42895d35e50df970591635ddad954e23ca4be",
    "tree_hash": "0a8dea21cd618d7d2e7a2641b7a8d90365ab9329ae16e30e245a0cc2b5e4001f"
  },
  "skill": {
    "name": "golang-performance",
    "description": "Go performance optimization techniques including profiling with pprof, memory optimization, concurrency patterns, and escape analysis.",
    "summary": "Go performance optimization techniques including profiling with pprof, memory optimization, concurre...",
    "icon": "âš¡",
    "version": "1.0.1",
    "author": "Joseph OBrien",
    "license": "UNLICENSED",
    "category": "coding",
    "tags": [
      "go",
      "performance",
      "optimization",
      "profiling",
      "concurrency"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": [
      "network",
      "scripts",
      "external_commands"
    ]
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "Pure documentation skill containing educational Go code examples for performance optimization. Contains no executable code, no network calls to external endpoints, no file system operations, and no command execution capabilities. All static findings are false positives triggered by documentation patterns rather than actual security risks.",
    "risk_factor_evidence": [
      {
        "factor": "network",
        "evidence": [
          {
            "file": "skill-report.json",
            "line_start": 6,
            "line_end": 6
          },
          {
            "file": "SKILL.md",
            "line_start": 49,
            "line_end": 49
          },
          {
            "file": "SKILL.md",
            "line_start": 61,
            "line_end": 61
          },
          {
            "file": "SKILL.md",
            "line_start": 64,
            "line_end": 64
          }
        ]
      },
      {
        "factor": "scripts",
        "evidence": [
          {
            "file": "SKILL.md",
            "line_start": 30,
            "line_end": 33
          },
          {
            "file": "SKILL.md",
            "line_start": 74,
            "line_end": 77
          }
        ]
      },
      {
        "factor": "external_commands",
        "evidence": [
          {
            "file": "SKILL.md",
            "line_start": 29,
            "line_end": 43
          },
          {
            "file": "SKILL.md",
            "line_start": 43,
            "line_end": 47
          },
          {
            "file": "SKILL.md",
            "line_start": 47,
            "line_end": 55
          },
          {
            "file": "SKILL.md",
            "line_start": 55,
            "line_end": 59
          },
          {
            "file": "SKILL.md",
            "line_start": 59,
            "line_end": 69
          },
          {
            "file": "SKILL.md",
            "line_start": 69,
            "line_end": 73
          },
          {
            "file": "SKILL.md",
            "line_start": 73,
            "line_end": 96
          },
          {
            "file": "SKILL.md",
            "line_start": 96,
            "line_end": 102
          },
          {
            "file": "SKILL.md",
            "line_start": 102,
            "line_end": 120
          },
          {
            "file": "SKILL.md",
            "line_start": 120,
            "line_end": 124
          },
          {
            "file": "SKILL.md",
            "line_start": 124,
            "line_end": 142
          },
          {
            "file": "SKILL.md",
            "line_start": 142,
            "line_end": 146
          },
          {
            "file": "SKILL.md",
            "line_start": 146,
            "line_end": 164
          },
          {
            "file": "SKILL.md",
            "line_start": 164,
            "line_end": 168
          },
          {
            "file": "SKILL.md",
            "line_start": 168,
            "line_end": 180
          },
          {
            "file": "SKILL.md",
            "line_start": 180,
            "line_end": 184
          },
          {
            "file": "SKILL.md",
            "line_start": 184,
            "line_end": 190
          },
          {
            "file": "SKILL.md",
            "line_start": 190,
            "line_end": 194
          },
          {
            "file": "SKILL.md",
            "line_start": 194,
            "line_end": 212
          },
          {
            "file": "SKILL.md",
            "line_start": 212,
            "line_end": 218
          },
          {
            "file": "SKILL.md",
            "line_start": 218,
            "line_end": 253
          },
          {
            "file": "SKILL.md",
            "line_start": 253,
            "line_end": 257
          },
          {
            "file": "SKILL.md",
            "line_start": 257,
            "line_end": 263
          },
          {
            "file": "SKILL.md",
            "line_start": 263,
            "line_end": 267
          },
          {
            "file": "SKILL.md",
            "line_start": 267,
            "line_end": 301
          },
          {
            "file": "SKILL.md",
            "line_start": 301,
            "line_end": 305
          },
          {
            "file": "SKILL.md",
            "line_start": 305,
            "line_end": 320
          },
          {
            "file": "SKILL.md",
            "line_start": 320,
            "line_end": 326
          },
          {
            "file": "SKILL.md",
            "line_start": 326,
            "line_end": 340
          },
          {
            "file": "SKILL.md",
            "line_start": 340,
            "line_end": 344
          },
          {
            "file": "SKILL.md",
            "line_start": 344,
            "line_end": 362
          },
          {
            "file": "SKILL.md",
            "line_start": 362,
            "line_end": 366
          },
          {
            "file": "SKILL.md",
            "line_start": 366,
            "line_end": 397
          },
          {
            "file": "SKILL.md",
            "line_start": 397,
            "line_end": 401
          },
          {
            "file": "SKILL.md",
            "line_start": 401,
            "line_end": 404
          },
          {
            "file": "SKILL.md",
            "line_start": 404,
            "line_end": 410
          },
          {
            "file": "SKILL.md",
            "line_start": 410,
            "line_end": 435
          },
          {
            "file": "SKILL.md",
            "line_start": 435,
            "line_end": 439
          },
          {
            "file": "SKILL.md",
            "line_start": 439,
            "line_end": 449
          },
          {
            "file": "SKILL.md",
            "line_start": 449,
            "line_end": 454
          },
          {
            "file": "SKILL.md",
            "line_start": 454,
            "line_end": 455
          }
        ]
      }
    ],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 2,
    "total_lines": 639,
    "audit_model": "claude",
    "audited_at": "2026-01-16T13:03:48.303Z"
  },
  "content": {
    "user_title": "Optimize Go Performance with Profiling",
    "value_statement": "Go applications often suffer from hidden performance bottlenecks in memory allocations and concurrency patterns. This skill provides proven techniques to identify bottlenecks using pprof, reduce allocations with sync.Pool, and implement efficient worker patterns that scale.",
    "seo_keywords": [
      "go performance optimization",
      "golang profiling",
      "pprof tutorial",
      "go memory optimization",
      "golang concurrency patterns",
      "escape analysis go",
      "go benchmarking",
      "Claude Code performance",
      "Claude optimization",
      "Codex go performance"
    ],
    "actual_capabilities": [
      "Profile CPU and memory usage with Go pprof tool",
      "Optimize memory allocations using sync.Pool and pre-allocation",
      "Implement efficient worker pool and concurrency patterns",
      "Analyze escape analysis to reduce heap allocations",
      "Write benchmarks and measure performance improvements",
      "Optimize data structures for memory alignment and cache efficiency"
    ],
    "limitations": [
      "Does not execute or modify your code directly",
      "Cannot profile running applications remotely",
      "Does not install or configure Go tools automatically",
      "Limited to providing guidance and code examples"
    ],
    "use_cases": [
      {
        "target_user": "Backend Engineers",
        "title": "Optimize API Services",
        "description": "Reduce latency and improve throughput in high-traffic Go microservices and API servers."
      },
      {
        "target_user": "DevOps Engineers",
        "title": "Debug Production Issues",
        "description": "Diagnose memory leaks and CPU bottlenecks in production Go applications using pprof."
      },
      {
        "target_user": "Performance Engineers",
        "title": "Establish Performance Baselines",
        "description": "Set up benchmarking pipelines and track performance metrics across code changes."
      }
    ],
    "prompt_templates": [
      {
        "title": "Basic Profiling",
        "scenario": "Getting started with pprof",
        "prompt": "How do I enable pprof in my Go HTTP server and collect a CPU profile to identify performance bottlenecks?"
      },
      {
        "title": "Memory Optimization",
        "scenario": "Reducing allocations",
        "prompt": "Show me how to use sync.Pool to reuse buffers and reduce garbage collection pressure in my Go application."
      },
      {
        "title": "Concurrency Patterns",
        "scenario": "Worker pool design",
        "prompt": "What is the best pattern for implementing a worker pool in Go that efficiently processes items from a channel?"
      },
      {
        "title": "Advanced Benchmarking",
        "scenario": "Measuring improvements",
        "prompt": "How do I write Go benchmarks that compare two implementations and report memory allocations to validate optimization improvements?"
      }
    ],
    "output_examples": [
      {
        "input": "How do I enable pprof in my Go HTTP server and collect a CPU profile?",
        "output": [
          "Add the pprof import to enable profiling endpoints",
          "Start a separate server on localhost for profiling",
          "Collect profile using go tool pprof with seconds parameter",
          "Use top10 to see functions by CPU usage",
          "Use list FunctionName to see line-by-line timing"
        ]
      },
      {
        "input": "My Go service has high memory usage. How can I identify what's causing it?",
        "output": [
          "Enable heap profiling to see allocation sites",
          "Collect a heap profile from the /debug/pprof/heap endpoint",
          "Use the pprof tool to identify top memory consumers",
          "Look for unexpected allocations in hot paths",
          "Consider using sync.Pool for frequently allocated objects"
        ]
      },
      {
        "input": "How do I write a Go benchmark that compares two implementations?",
        "output": [
          "Use b.Run with names to compare implementations",
          "Report allocations with b.ReportAllocs for memory comparison",
          "Run with extended benchtime for more accurate results",
          "Use b.ResetTimer to exclude setup overhead",
          "Analyze statistical significance of benchmark results"
        ]
      }
    ],
    "best_practices": [
      "Profile before optimizing to identify actual bottlenecks rather than guessing",
      "Pre-allocate slices with known capacity to reduce dynamic array growth",
      "Use sync.Pool for frequently allocated objects to reduce GC pressure"
    ],
    "anti_patterns": [
      "Using defer inside hot loops causes deferred call stack buildup",
      "String concatenation in loops creates quadratic allocations",
      "Returning slices that reference backing arrays can cause memory leaks"
    ],
    "faq": [
      {
        "question": "Which Go versions support pprof?",
        "answer": "Pprof is available in all Go versions since Go 1.5. The net/http/pprof package provides standard profiling endpoints."
      },
      {
        "question": "How long should I collect CPU profiles?",
        "answer": "A 30-second profile captures enough data for most applications. For variable workloads, extend to 60-90 seconds to cover all code paths."
      },
      {
        "question": "Can I use these techniques with frameworks like Gin or Echo?",
        "answer": "Yes, pprof works with any Go HTTP framework. Add the import and start the pprof server alongside your main application router."
      },
      {
        "question": "Is my production data safe when profiling?",
        "answer": "Profiles only contain stack traces and timing data, not request body content. Pprof endpoints should remain localhost-only in production."
      },
      {
        "question": "Why are my benchmarks showing inconsistent results?",
        "answer": "Run benchmarks multiple times and use -benchtime to extend duration. Avoid benchmark pollution by resetting state with b.ResetTimer()."
      },
      {
        "question": "How is this different from other Go optimization tools?",
        "answer": "This skill focuses on Go-specific patterns like goroutines, channels, and the Go memory model. External profilers may not understand Go's concurrency model."
      }
    ]
  },
  "file_structure": [
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md",
      "lines": 461
    }
  ]
}
