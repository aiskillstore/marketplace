{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-10T11:41:16.452Z",
    "slug": "byronwilliamscpa-testing",
    "source_url": "https://github.com/ByronWilliamsCPA/fragrance-rater/tree/main/.claude/skills/testing",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "2.0.0",
    "source_type": "community",
    "content_hash": "406516e9b9a3928dc988c1c427747aabec2795881bcec1d43e911761fa1d6c38",
    "tree_hash": "5a42a32ea2583306c29644cd7a981a6405e3dc5b01c9475578a96bc7a65f7ff3"
  },
  "skill": {
    "name": "Testing Skill",
    "description": "Automated test generation, review, and execution for pytest-based projects.",
    "summary": "Automated test generation, review, and execution for pytest-based projects.",
    "icon": "ðŸ§ª",
    "version": "1.0.0",
    "author": "ByronWilliamsCPA",
    "license": "MIT",
    "category": "coding",
    "tags": [
      "testing",
      "pytest",
      "coverage",
      "test-automation"
    ],
    "supported_tools": [
      "claude-code"
    ],
    "risk_factors": []
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "Pure prompt-based skill containing only documentation and testing guidance. No executable code, network calls, filesystem access, or external command execution capabilities.",
    "risk_factor_evidence": [],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 1,
    "total_lines": 93,
    "audit_model": "claude",
    "audited_at": "2026-01-10T11:41:16.452Z"
  },
  "content": {
    "user_title": "Generate and Review pytest Tests",
    "value_statement": "Writing tests manually is time-consuming and error-prone. This skill automates test generation, review, and execution for pytest projects with built-in coverage standards.",
    "seo_keywords": [
      "testing skill",
      "pytest",
      "test generation",
      "code coverage",
      "Claude Code",
      "test automation",
      "unit testing",
      "integration testing",
      "e2e testing",
      "test review"
    ],
    "actual_capabilities": [
      "Generate unit and integration tests for Python code",
      "Review existing tests for quality and coverage gaps",
      "Execute pytest with coverage reporting",
      "Run mutation testing to verify test effectiveness",
      "Apply AAA pattern and fixture-based testing",
      "Organize tests by category (unit, integration, e2e, security)"
    ],
    "limitations": [
      "Limited to pytest-based Python projects",
      "Cannot execute tests outside the project directory",
      "Does not modify production code directly",
      "Coverage enforcement is informational only"
    ],
    "use_cases": [
      {
        "target_user": "Python Developers",
        "title": "Automate Test Creation",
        "description": "Generate comprehensive test suites from existing code automatically"
      },
      {
        "target_user": "QA Engineers",
        "title": "Review Test Coverage",
        "description": "Analyze test quality and identify gaps in existing test suites"
      },
      {
        "target_user": "DevOps Teams",
        "title": "Run CI Test Suites",
        "description": "Execute tests with coverage reports for continuous integration"
      }
    ],
    "prompt_templates": [
      {
        "title": "Basic Test Request",
        "scenario": "Generate unit tests",
        "prompt": "Generate unit tests for the function [function_name] in [file_path] using the AAA pattern"
      },
      {
        "title": "Coverage Analysis",
        "scenario": "Check test coverage",
        "prompt": "Run coverage analysis on [module_name] and identify untested branches"
      },
      {
        "title": "Integration Tests",
        "scenario": "Create integration tests",
        "prompt": "Create integration tests for [feature_name] including edge cases and error handling"
      },
      {
        "title": "Test Review",
        "scenario": "Review test quality",
        "prompt": "Review tests in [test_file] for coverage, mocking quality, and assertion completeness"
      }
    ],
    "output_examples": [
      {
        "input": "Generate unit tests for the calculate_total function in src/utils/financial.py",
        "output": [
          "âœ“ Generated 5 test cases covering normal inputs, edge cases, and error conditions",
          "âœ“ Applied AAA pattern with proper fixture setup",
          "âœ“ Coverage: 100% on calculate_total function",
          "âœ“ Included property-based tests using Hypothesis"
        ]
      }
    ],
    "best_practices": [
      "Write tests before code (TDD) for better design",
      "Aim for meaningful coverage, not just high percentages",
      "Use fixtures to share setup code across tests",
      "Test edge cases and failure paths, not just happy paths"
    ],
    "anti_patterns": [
      "Avoid testing implementation details instead of behavior",
      "Do not skip tests without documenting why",
      "Avoid hardcoded values in assertions without variables",
      "Do not make tests depend on execution order"
    ],
    "faq": [
      {
        "question": "What test frameworks does this skill support?",
        "answer": "This skill focuses on pytest but concepts apply to unittest and other Python testing frameworks."
      },
      {
        "question": "What is the minimum coverage requirement?",
        "answer": "The skill enforces 80% minimum coverage with branch coverage enabled for all projects."
      },
      {
        "question": "Can this skill integrate with CI/CD pipelines?",
        "answer": "Yes. The skill generates pytest commands compatible with GitHub Actions, GitLab CI, and other CI systems."
      },
      {
        "question": "Is my test data safe?",
        "answer": "Yes. All testing happens locally in your project. No test data is sent to external services."
      },
      {
        "question": "Why are my tests failing after generation?",
        "answer": "Generated tests may need adjustment for complex dependencies. Review the test and add any missing mocks or fixtures."
      },
      {
        "question": "How is this different from other testing tools?",
        "answer": "This skill uses Claude Code's context awareness to generate contextually appropriate tests for your specific codebase."
      }
    ]
  },
  "file_structure": [
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md"
    }
  ]
}
