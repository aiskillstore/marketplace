{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-10T09:55:09.913Z",
    "slug": "ancplua-verification-before-completion",
    "source_url": "https://github.com/ANcpLua/ancplua-claude-plugins/tree/main/plugins/metacognitive-guard/skills/verification-before-completion",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "2.0.0",
    "source_type": "community",
    "content_hash": "e0bb72e05554f904bec693057f6bfae96454a9149dd323300dc2d6bc13248a9b",
    "tree_hash": "284892807d1898c806bef86e8c1e2ef14ebd39be9cc5f1f579a9a4862e9f0e9d"
  },
  "skill": {
    "name": "verification-before-completion",
    "description": "Force verification before claiming success or completion. Prevents false \"it works\" claims.\nTriggers when about to say \"done\", \"complete\", \"works\", \"fixed\", or \"the implementation is ready\".\nRequires actually running builds/tests and showing output before claiming success.\n",
    "summary": "Force verification before claiming success or completion. Prevents false \"it works\" claims.\nTriggers...",
    "icon": "üõ°Ô∏è",
    "version": "1.0.0",
    "author": "ANcpLua",
    "license": "MIT",
    "category": "productivity",
    "tags": [
      "verification",
      "quality-assurance",
      "testing",
      "workflow",
      "best-practices"
    ],
    "supported_tools": [
      "claude",
      "claude-code"
    ],
    "risk_factors": []
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "Pure markdown-based skill with no executable code. Contains only behavioral guidelines for AI verification workflows. No scripts, network calls, filesystem access, or external command execution capabilities.",
    "risk_factor_evidence": [],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 1,
    "total_lines": 165,
    "audit_model": "claude",
    "audited_at": "2026-01-10T09:55:09.913Z"
  },
  "content": {
    "user_title": "Verify Before Claiming Completion",
    "value_statement": "AI agents often claim work is complete without actual verification. This skill ensures builds run, tests pass, and outputs are shown before any completion claim. Prevents false 'it works' statements.",
    "seo_keywords": [
      "claude code skill",
      "verification workflow",
      "test before completion",
      "code quality",
      "build verification",
      "claude code",
      "claude",
      "ai testing",
      "software quality",
      "development workflow"
    ],
    "actual_capabilities": [
      "Triggers on completion keywords like 'done', 'complete', 'fixed', or 'ready'",
      "Requires dotnet build to pass with no errors before claiming success",
      "Requires dotnet test execution with pass or explicit skip reason",
      "Demands actual code execution and output demonstration",
      "Forces verification against assertions.yaml for factual claims",
      "Prevents unverified bug fix claims without reproduction steps"
    ],
    "limitations": [
      "Does not execute commands itself - requires the AI to run them",
      "Does not verify external APIs or services are reachable",
      "Does not guarantee the fix addresses the root cause",
      "Does not automatically run regression tests"
    ],
    "use_cases": [
      {
        "target_user": "Software Developers",
        "title": "Build and Test Verification",
        "description": "Ensure code changes compile and tests pass before claiming feature implementation complete."
      },
      {
        "target_user": "QA Engineers",
        "title": "Bug Fix Validation",
        "description": "Require reproduction, fix application, and verification steps before marking bugs as resolved."
      },
      {
        "target_user": "AI Assistants",
        "title": "Factual Claim Checking",
        "description": "Verify claims about versions, dates, or status through WebSearch before stating them as facts."
      }
    ],
    "prompt_templates": [
      {
        "title": "Basic Completion Check",
        "scenario": "After implementing a feature",
        "prompt": "Use the verification-before-completion skill to confirm the implementation is actually ready."
      },
      {
        "title": "Bug Fix Verification",
        "scenario": "After fixing a reported bug",
        "prompt": "Apply verification-before-completion to demonstrate the bug is resolved."
      },
      {
        "title": "Build Verification",
        "scenario": "Before marking code as ready",
        "prompt": "Run dotnet build and dotnet test using the verification-before-completion skill."
      },
      {
        "title": "Quality Gate",
        "scenario": "Final review before submission",
        "prompt": "Act as final checkpoint. Apply verification-before-completion to ensure nothing is missed."
      }
    ],
    "output_examples": [
      {
        "input": "I've implemented the user authentication feature. It is complete.",
        "output": [
          "## Verification Checklist",
          "- dotnet build: PASS",
          "- dotnet test: PASS (24/24 tests)",
          "- No new warnings introduced",
          "- Verified against assertions.yaml",
          "- Edge cases tested: null user, expired token, invalid credentials",
          "- Confidence: HIGH - All verification steps passed"
        ]
      }
    ],
    "best_practices": [
      "Run the full build pipeline before claiming any code change is complete",
      "Show actual test output including pass/fail counts to the user",
      "Test edge cases and demonstrate the output, do not just assume correctness",
      "Always reproduce a bug before claiming it is fixed"
    ],
    "anti_patterns": [
      "Claiming 'it works' without running the code or showing output",
      "Saying 'the fix is complete' without running the build or tests",
      "Making version or date claims without WebSearch verification",
      "Assuming tests pass without actually running them"
    ],
    "faq": [
      {
        "question": "Which AI tools support this skill?",
        "answer": "This skill works with Claude and Claude Code. It is designed for Claude Code workflows."
      },
      {
        "question": "What happens if tests fail?",
        "answer": "You must NOT claim completion. Show the failure output, fix the issues, and re-run verification."
      },
      {
        "question": "Can I skip verification for small changes?",
        "answer": "No. The skill requires verification for ALL completion claims regardless of change size."
      },
      {
        "question": "Does this skill run commands automatically?",
        "answer": "No. The skill provides guidelines. You must manually execute build, test, and verification commands."
      },
      {
        "question": "How do I handle skipped tests?",
        "answer": "Provide an explicit reason for skipping in the verification output. Do not skip silently."
      },
      {
        "question": "What if the project uses a different build system?",
        "answer": "Replace dotnet build/test with your equivalent commands. The skill framework remains the same."
      }
    ]
  },
  "file_structure": [
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md"
    }
  ]
}
