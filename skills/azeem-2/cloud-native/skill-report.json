{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-21T16:59:35.299Z",
    "slug": "azeem-2-cloud-native",
    "source_url": "https://github.com/Azeem-2/HackthonII/tree/master/.claude/skills/cloud-native",
    "source_ref": "master",
    "model": "claude",
    "analysis_version": "3.0.0",
    "source_type": "community",
    "content_hash": "cb48597f7818f07c0afc9d193a2ebe8c56763e3383fa5f4b1e550d132b99b6ff",
    "tree_hash": "b9245dd9e85e327ae7311e63a169e94d557728887702514d586e70777d7c0a67"
  },
  "skill": {
    "name": "cloud-native",
    "description": "Generic Cloud-Native Deployment and Infrastructure as Code patterns for 2025. Provides comprehensive implementation strategies for multi-cloud deployments, GitOps workflows, progressive delivery, and platform engineering. Framework-agnostic approach supporting any cloud provider, deployment tool, and orchestration platform.",
    "summary": "Comprehensive cloud-native deployment patterns for multi-cloud IaC, GitOps, and progressive delivery",
    "icon": "ðŸ“¦",
    "version": "1.0.0",
    "author": "Azeem-2",
    "license": "MIT",
    "category": "devops",
    "tags": [
      "infrastructure-as-code",
      "gitops",
      "kubernetes",
      "multi-cloud",
      "deployment"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": [
      "scripts",
      "network",
      "filesystem",
      "external_commands"
    ]
  },
  "security_audit": {
    "risk_level": "low",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "This skill provides educational Infrastructure as Code patterns for cloud-native deployments. Static analysis detected 61 patterns, predominantly false positives. The code demonstrates legitimate IaC operations including file generation for Terraform and Pulumi configurations, external command execution for infrastructure tooling like kubectl and terraform, and network operations for GitOps integrations. All detected patterns are appropriate for an infrastructure automation skill. The implementation includes proper async command execution patterns with error handling. No malicious intent or security vulnerabilities identified.",
    "risk_factor_evidence": [
      {
        "factor": "scripts",
        "evidence": [
          {
            "file": "SKILL.md",
            "line_start": 498,
            "line_end": 500
          }
        ]
      },
      {
        "factor": "network",
        "evidence": [
          {
            "file": "SKILL.md",
            "line_start": 771,
            "line_end": 771
          },
          {
            "file": "SKILL.md",
            "line_start": 840,
            "line_end": 840
          },
          {
            "file": "SKILL.md",
            "line_start": 856,
            "line_end": 856
          }
        ]
      },
      {
        "factor": "filesystem",
        "evidence": [
          {
            "file": "SKILL.md",
            "line_start": 208,
            "line_end": 233
          },
          {
            "file": "SKILL.md",
            "line_start": 442,
            "line_end": 447
          }
        ]
      },
      {
        "factor": "external_commands",
        "evidence": [
          {
            "file": "SKILL.md",
            "line_start": 123,
            "line_end": 124
          },
          {
            "file": "SKILL.md",
            "line_start": 237,
            "line_end": 250
          },
          {
            "file": "SKILL.md",
            "line_start": 838,
            "line_end": 846
          },
          {
            "file": "SKILL.md",
            "line_start": 1024,
            "line_end": 1040
          }
        ]
      }
    ],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [
      {
        "title": "Pipe to Shell Pattern in Installation Command",
        "description": "The Flux installation command at SKILL.md:856 uses a pipe to shell pattern which could be vulnerable if the remote script is compromised. This is standard for tool installation but should be executed with caution in production environments. The pattern is used in educational context demonstrating GitOps setup procedures.",
        "locations": [
          {
            "file": "SKILL.md",
            "line_start": 855,
            "line_end": 857
          }
        ]
      },
      {
        "title": "External Command Execution for Infrastructure Tools",
        "description": "The skill executes external commands for infrastructure tools including terraform, pulumi, kubectl, and argocd. This is the expected and necessary behavior for an Infrastructure as Code skill. All commands use proper async subprocess execution with controlled arguments and error handling. No command injection vulnerabilities detected as arguments are properly structured.",
        "locations": [
          {
            "file": "SKILL.md",
            "line_start": 123,
            "line_end": 124
          },
          {
            "file": "SKILL.md",
            "line_start": 237,
            "line_end": 250
          }
        ]
      }
    ],
    "dangerous_patterns": [],
    "files_scanned": 2,
    "total_lines": 2083,
    "audit_model": "claude",
    "audited_at": "2026-01-21T16:59:35.299Z"
  },
  "content": {
    "user_title": "Deploy Cloud Infrastructure with Modern IaC Patterns",
    "value_statement": "Managing cloud infrastructure across multiple providers is complex and error-prone. This skill provides production-ready patterns for Infrastructure as Code, GitOps workflows, and progressive delivery strategies that work with any cloud provider or deployment tool.",
    "seo_keywords": [
      "Claude",
      "Claude Code",
      "Codex",
      "infrastructure as code",
      "terraform",
      "kubernetes deployment",
      "gitops automation",
      "multi-cloud strategy",
      "canary deployment",
      "cloud native patterns"
    ],
    "actual_capabilities": [
      "Generate Infrastructure as Code configurations for Terraform, Pulumi, and CDK with provider abstraction layers",
      "Implement GitOps workflows with ArgoCD and Flux for declarative deployment management",
      "Create multi-cloud deployment strategies with automated failover and state synchronization",
      "Build progressive delivery pipelines with canary analysis and blue-green deployment patterns",
      "Design platform engineering abstractions for developer self-service infrastructure provisioning",
      "Implement policy as code and compliance automation for cloud resources"
    ],
    "limitations": [
      "Provides code patterns and architecture guidance only, does not execute actual infrastructure deployments",
      "Requires existing cloud provider accounts and authentication credentials configured separately",
      "Code examples need adaptation for specific organizational policies and security requirements",
      "Does not include cloud-specific pricing optimization or cost management logic"
    ],
    "use_cases": [
      {
        "title": "Multi-Cloud Infrastructure Management",
        "description": "Platform engineers can use this skill to design and implement infrastructure that spans AWS, Azure, and GCP with unified management interfaces and automated failover capabilities.",
        "target_user": "Platform Engineers"
      },
      {
        "title": "GitOps Deployment Automation",
        "description": "DevOps teams can implement declarative deployment workflows where infrastructure and application changes are managed through Git repositories with automated sync and rollback capabilities.",
        "target_user": "DevOps Teams"
      },
      {
        "title": "Progressive Delivery Implementation",
        "description": "SRE teams can build canary deployment systems with automated metric analysis and traffic shifting to minimize deployment risk and enable rapid rollback when issues are detected.",
        "target_user": "Site Reliability Engineers"
      }
    ],
    "prompt_templates": [
      {
        "title": "Create Basic Infrastructure Configuration",
        "prompt": "Help me create a Terraform configuration for a web application with a load balancer, auto-scaling group, and RDS database in AWS us-east-1",
        "scenario": "Starting with infrastructure as code for a simple web application"
      },
      {
        "title": "Setup GitOps Workflow",
        "prompt": "Guide me through setting up ArgoCD for GitOps deployment of my microservices application. I want automatic sync from my main branch and manual approval for production",
        "scenario": "Implementing GitOps for continuous deployment"
      },
      {
        "title": "Implement Canary Deployment",
        "prompt": "Create a canary deployment strategy for my API service that gradually increases traffic from 10% to 50% while monitoring error rates and latency. Roll back automatically if error rate exceeds 1%",
        "scenario": "Setting up progressive delivery with automated rollback"
      },
      {
        "title": "Design Multi-Cloud Architecture",
        "prompt": "Design a multi-cloud deployment strategy where my primary workload runs on AWS with automatic failover to GCP. Include DNS routing, state synchronization, and health checking logic",
        "scenario": "Building resilient multi-cloud infrastructure"
      }
    ],
    "output_examples": [
      {
        "input": "Create a Terraform module for an S3 bucket with versioning and lifecycle policies",
        "output": "I will create a Terraform module with the following structure:\n\nModule includes resource definitions for S3 bucket with versioning enabled, lifecycle rules for transitioning objects to Glacier after 90 days and expiring old versions after 365 days, bucket policy for secure access, and outputs for bucket name and ARN.\n\nThe module uses variables for bucket name prefix, environment tag, and lifecycle configuration allowing reuse across multiple environments."
      },
      {
        "input": "Setup a canary deployment with 20% traffic split and automatic rollback",
        "output": "I will implement a canary deployment strategy using the following approach:\n\nCreate two deployments: baseline running your current version and canary running the new version. Configure traffic splitting at 20% canary and 80% baseline using Istio VirtualService or similar traffic management tool. Set up Prometheus queries to monitor error rate, latency p99, and request success rate. If canary metrics degrade by more than 10% compared to baseline, automatically trigger rollback and restore 100% traffic to baseline.\n\nIncludes health check configuration and notification webhooks for deployment status updates."
      }
    ],
    "best_practices": [
      "Always implement state backends for Infrastructure as Code to enable team collaboration and prevent configuration drift",
      "Use GitOps workflows to maintain audit trails of all infrastructure changes and enable easy rollback through Git history",
      "Start progressive delivery with small traffic percentages and automated analysis before full promotion to production"
    ],
    "anti_patterns": [
      "Avoid manual infrastructure changes that bypass your Infrastructure as Code configuration and create state drift",
      "Do not deploy directly to production without progressive delivery or blue-green strategies that enable safe rollback",
      "Never hardcode cloud credentials or secrets in Infrastructure as Code files, use secret management services instead"
    ],
    "faq": [
      {
        "question": "Can this skill deploy actual infrastructure to my cloud account?",
        "answer": "No, this skill provides code patterns and architectural guidance. You need to execute the generated Infrastructure as Code configurations using tools like Terraform or Pulumi with appropriate cloud credentials."
      },
      {
        "question": "Which cloud providers are supported?",
        "answer": "The patterns are designed to be cloud-agnostic and work with AWS, Azure, GCP, DigitalOcean, and on-premises infrastructure. The abstraction layer allows switching between providers without rewriting application logic."
      },
      {
        "question": "Do I need Kubernetes to use these patterns?",
        "answer": "No, while many examples use Kubernetes for deployment orchestration, the Infrastructure as Code patterns work with any compute platform including VMs, containers, or serverless functions."
      },
      {
        "question": "How does canary analysis determine when to rollback?",
        "answer": "The canary analyzer compares metrics between baseline and canary deployments using configurable thresholds. If error rates increase, latency degrades, or custom metrics fail criteria, automatic rollback is triggered."
      },
      {
        "question": "Can I use this with existing infrastructure?",
        "answer": "Yes, you can import existing resources into Infrastructure as Code state and then manage them declaratively. The patterns support incremental adoption without requiring complete infrastructure replacement."
      },
      {
        "question": "What is the difference between GitOps and traditional CI/CD?",
        "answer": "GitOps uses Git as the single source of truth for infrastructure and applications. Changes are automatically synced from Git to your environment, providing declarative configuration, version control, and easy rollback through Git operations."
      }
    ]
  },
  "file_structure": [
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md",
      "lines": 1534
    }
  ]
}
