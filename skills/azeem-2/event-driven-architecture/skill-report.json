{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-16T18:49:43.465Z",
    "slug": "azeem-2-event-driven-architecture",
    "source_url": "https://github.com/Azeem-2/HackthonII/tree/master/.claude/skills/event-driven-architecture",
    "source_ref": "master",
    "model": "claude",
    "analysis_version": "3.0.0",
    "source_type": "community",
    "content_hash": "5e518aca319301994038ca0bc382235215801c6dc8cdb34860fffd0c83cbaeb9",
    "tree_hash": "8bcc1f7f1fec20768e5d97b40c75f48bce3c816a51dfdf0a971482034fa1a72e"
  },
  "skill": {
    "name": "event-driven-architecture",
    "description": "Generic Event-Driven Architecture patterns with Kafka, Dapr, and modern messaging systems. Provides reusable patterns for building scalable, resilient event-driven microservices. Framework-agnostic implementation supporting multiple message brokers, state stores, and event patterns. Follows 2025 best practices for distributed systems.",
    "summary": "Generic Event-Driven Architecture patterns with Kafka, Dapr, and modern messaging systems. Provides ...",
    "icon": "ðŸ“¡",
    "version": "1.0.0",
    "author": "Azeem-2",
    "license": "MIT",
    "category": "coding",
    "tags": [
      "event-driven",
      "microservices",
      "distributed-systems",
      "kafka",
      "dapr"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": [
      "network",
      "filesystem",
      "external_commands",
      "env_access"
    ]
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "Documentation-only skill containing Python code patterns for event-driven architecture. No executable code, no network calls to external endpoints, no file system access beyond configuration, no credential handling. Purely instructional content aligned with stated purpose. All 109 static findings are false positives - the scanner misinterpreted code examples, documentation placeholders, and metadata as security issues.",
    "risk_factor_evidence": [
      {
        "factor": "network",
        "evidence": [
          {
            "file": "skill-report.json",
            "line_start": 6,
            "line_end": 6
          },
          {
            "file": "SKILL.md",
            "line_start": 1543,
            "line_end": 1543
          },
          {
            "file": "SKILL.md",
            "line_start": 1407,
            "line_end": 1407
          },
          {
            "file": "SKILL.md",
            "line_start": 1814,
            "line_end": 1814
          }
        ]
      },
      {
        "factor": "filesystem",
        "evidence": [
          {
            "file": "skill-report.json",
            "line_start": 6,
            "line_end": 6
          }
        ]
      },
      {
        "factor": "external_commands",
        "evidence": [
          {
            "file": "SKILL.md",
            "line_start": 28,
            "line_end": 170
          },
          {
            "file": "SKILL.md",
            "line_start": 170,
            "line_end": 174
          },
          {
            "file": "SKILL.md",
            "line_start": 174,
            "line_end": 472
          },
          {
            "file": "SKILL.md",
            "line_start": 472,
            "line_end": 478
          },
          {
            "file": "SKILL.md",
            "line_start": 478,
            "line_end": 859
          },
          {
            "file": "SKILL.md",
            "line_start": 859,
            "line_end": 865
          },
          {
            "file": "SKILL.md",
            "line_start": 865,
            "line_end": 1101
          },
          {
            "file": "SKILL.md",
            "line_start": 1101,
            "line_end": 1105
          },
          {
            "file": "SKILL.md",
            "line_start": 1105,
            "line_end": 1380
          },
          {
            "file": "SKILL.md",
            "line_start": 1380,
            "line_end": 1386
          },
          {
            "file": "SKILL.md",
            "line_start": 1386,
            "line_end": 1797
          },
          {
            "file": "SKILL.md",
            "line_start": 1797,
            "line_end": 1803
          },
          {
            "file": "SKILL.md",
            "line_start": 1803,
            "line_end": 1888
          },
          {
            "file": "SKILL.md",
            "line_start": 1888,
            "line_end": 1890
          },
          {
            "file": "SKILL.md",
            "line_start": 1890,
            "line_end": 1974
          },
          {
            "file": "SKILL.md",
            "line_start": 1974,
            "line_end": 1978
          },
          {
            "file": "SKILL.md",
            "line_start": 1978,
            "line_end": 1987
          }
        ]
      },
      {
        "factor": "env_access",
        "evidence": [
          {
            "file": "SKILL.md",
            "line_start": 731,
            "line_end": 731
          },
          {
            "file": "SKILL.md",
            "line_start": 732,
            "line_end": 732
          },
          {
            "file": "SKILL.md",
            "line_start": 732,
            "line_end": 732
          },
          {
            "file": "SKILL.md",
            "line_start": 740,
            "line_end": 740
          },
          {
            "file": "SKILL.md",
            "line_start": 856,
            "line_end": 856
          },
          {
            "file": "SKILL.md",
            "line_start": 856,
            "line_end": 856
          }
        ]
      }
    ],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 2,
    "total_lines": 2165,
    "audit_model": "claude",
    "audited_at": "2026-01-16T18:49:43.465Z"
  },
  "content": {
    "user_title": "Build Event-Driven Microservices",
    "value_statement": "Building distributed systems with event-driven patterns requires understanding messaging patterns, saga coordination, and broker integration. This skill provides ready-to-use patterns for Kafka, Dapr, Redis, and pub/sub architectures.",
    "seo_keywords": [
      "event-driven architecture",
      "Kafka patterns",
      "Dapr integration",
      "microservices",
      "pub/sub",
      "CQRS pattern",
      "saga pattern",
      "event sourcing",
      "Claude",
      "Codex",
      "Claude Code"
    ],
    "actual_capabilities": [
      "Implement event schemas with versioning, priorities, and correlation tracking",
      "Build message broker abstractions for Kafka, Redis, RabbitMQ, and cloud services",
      "Create saga orchestrations with compensation and retry policies",
      "Apply CQRS patterns with command and query buses",
      "Integrate with Dapr for state management, pub/sub, and workflows",
      "Deploy event-driven services on Kubernetes with Dapr sidecar"
    ],
    "limitations": [
      "Does not provision or configure message broker infrastructure",
      "Requires understanding of distributed systems concepts",
      "Does not include monitoring or observability implementations",
      "Assumes existing Dapr runtime for Dapr-related patterns"
    ],
    "use_cases": [
      {
        "target_user": "Backend Developers",
        "title": "Implement Event Sourcing",
        "description": "Build audit trails and recover system state from immutable event streams"
      },
      {
        "target_user": "Solutions Architects",
        "title": "Design Distributed Transactions",
        "description": "Coordinate multi-service operations with saga patterns and compensation"
      },
      {
        "target_user": "Platform Engineers",
        "title": "Deploy with Dapr",
        "description": "Configure Dapr components for state, pub/sub, and service invocation"
      }
    ],
    "prompt_templates": [
      {
        "title": "Basic Event Schema",
        "scenario": "Create an event type",
        "prompt": "Create a custom DomainEvent for user registration with event_type, aggregate_id, and event_data fields"
      },
      {
        "title": "Pub/Sub Setup",
        "scenario": "Configure message broker",
        "prompt": "Set up a KafkaBroker connecting to bootstrap-servers:9092 and create a topic for order events"
      },
      {
        "title": "Saga Orchestration",
        "scenario": "Coordinate distributed transaction",
        "prompt": "Create a Saga with three steps: reserve inventory, process payment, and ship order, with compensation actions"
      },
      {
        "title": "CQRS Implementation",
        "scenario": "Separate read and write models",
        "prompt": "Implement a CommandBus with CreateTaskCommand and a QueryBus with GetTaskQuery for task management"
      }
    ],
    "output_examples": [
      {
        "input": "Create an event schema for order placed with order_id, customer_id, and items",
        "output": [
          "DomainEvent: order.placed with aggregate_id=order_id",
          "Event data includes: order_id, customer_id, items list, total_amount",
          "Correlation tracking via correlation_id for distributed tracing",
          "Priority level: normal (can be set to high for time-sensitive orders)"
        ]
      },
      {
        "input": "Set up a saga for order processing with inventory reservation and payment",
        "output": [
          "Saga: order-processing with compensation rollback on failure",
          "Step 1: Reserve inventory (compensate: release inventory)",
          "Step 2: Process payment (compensate: refund payment)",
          "Step 3: Ship order (compensate: cancel shipment)",
          "Retry policy: 3 attempts with exponential backoff"
        ]
      },
      {
        "input": "Configure Dapr pub/sub for publishing events to multiple subscribers",
        "output": [
          "DaprClient connected to localhost:3500 sidecar",
          "Publish event to pubsub component with topic name",
          "Supports metadata for custom routing and filtering",
          "Works with Kafka, Redis, RabbitMQ backends"
        ]
      }
    ],
    "best_practices": [
      "Use explicit event versioning to support schema evolution",
      "Design idempotent event handlers to handle duplicate processing",
      "Leverage broker-level features like Kafka consumer groups for scaling"
    ],
    "anti_patterns": [
      "Avoid synchronous request-response patterns in event handlers",
      "Do not couple event producers directly to specific consumers",
      "Avoid storing sensitive data in event payloads without encryption"
    ],
    "faq": [
      {
        "question": "Which AI tools support this skill?",
        "answer": "Compatible with Claude, Codex, and Claude Code. Framework-agnostic Python patterns work in any Python environment."
      },
      {
        "question": "What message brokers are supported?",
        "answer": "Kafka, Redis, RabbitMQ, AWS SQS, Azure Service Bus, GCP Pub/Sub, NATS, and EMQX via abstract broker interface."
      },
      {
        "question": "Does this skill provision infrastructure?",
        "answer": "No. This skill provides code patterns only. Infrastructure must be configured separately via Kubernetes, Helm, or cloud tools."
      },
      {
        "question": "Is my data safe with this skill?",
        "answer": "Safe. This is documentation-only content. No data is collected, stored, or transmitted. All processing occurs in your environment."
      },
      {
        "question": "Why use event-driven over REST APIs?",
        "answer": "Event-driven systems achieve loose coupling, better scalability, and enable real-time updates. Sagas coordinate distributed transactions reliably."
      },
      {
        "question": "How does this compare to RPC frameworks?",
        "answer": "Event-driven uses async messaging instead of synchronous calls. This improves resilience and enables pattern complexity like CQRS and sagas."
      }
    ]
  },
  "file_structure": [
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md",
      "lines": 1987
    }
  ]
}
