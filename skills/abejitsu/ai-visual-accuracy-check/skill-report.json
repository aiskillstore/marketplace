{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-16T14:35:48.662Z",
    "slug": "abejitsu-ai-visual-accuracy-check",
    "source_url": "https://github.com/AbeJitsu/Game-Settings-Panel/tree/main/.claude/skills/calypso/ai-visual-accuracy-check",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "3.0.0",
    "source_type": "community",
    "content_hash": "af6460dfb11fcfadead920952cc5575380b6579c0c5265c8ee191466e73adcf4",
    "tree_hash": "8f25948ec70f9cf368fa6b7501653bf7e88c7c18c8dd3912a757192f22c92171"
  },
  "skill": {
    "name": "ai-visual-accuracy-check",
    "description": "Use AI to compare rendered HTML to original PDF page. AI makes contextual judgment about visual accuracy with explainable reasoning. BLOCKING quality gate - stops pipeline if score below 85%.",
    "summary": "Use AI to compare rendered HTML to original PDF page. AI makes contextual judgment about visual accu...",
    "icon": "üëÅÔ∏è",
    "version": "1.0.0",
    "author": "AbeJitsu",
    "license": "MIT",
    "category": "quality",
    "tags": [
      "visual-validation",
      "quality-assurance",
      "html-comparison",
      "ai-testing",
      "blocking-gate"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": [
      "network",
      "filesystem",
      "external_commands"
    ]
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "Pure prompt-based skill with no executable code. All 37 static findings are false positives: markdown backtick formatting was misidentified as shell execution, documentation references as file access, and API image attachment as malicious upload. This is a legitimate visual accuracy validation tool that sends images to Claude API for comparison.",
    "risk_factor_evidence": [
      {
        "factor": "network",
        "evidence": [
          {
            "file": "skill-report.json",
            "line_start": 6,
            "line_end": 6
          }
        ]
      },
      {
        "factor": "filesystem",
        "evidence": [
          {
            "file": "skill-report.json",
            "line_start": 6,
            "line_end": 6
          }
        ]
      },
      {
        "factor": "external_commands",
        "evidence": [
          {
            "file": "SKILL.md",
            "line_start": 29,
            "line_end": 29
          },
          {
            "file": "SKILL.md",
            "line_start": 30,
            "line_end": 30
          },
          {
            "file": "SKILL.md",
            "line_start": 50,
            "line_end": 50
          },
          {
            "file": "SKILL.md",
            "line_start": 59,
            "line_end": 66
          },
          {
            "file": "SKILL.md",
            "line_start": 66,
            "line_end": 70
          },
          {
            "file": "SKILL.md",
            "line_start": 70,
            "line_end": 127
          },
          {
            "file": "SKILL.md",
            "line_start": 127,
            "line_end": 159
          },
          {
            "file": "SKILL.md",
            "line_start": 159,
            "line_end": 166
          },
          {
            "file": "SKILL.md",
            "line_start": 166,
            "line_end": 170
          },
          {
            "file": "SKILL.md",
            "line_start": 170,
            "line_end": 206
          },
          {
            "file": "SKILL.md",
            "line_start": 206,
            "line_end": 210
          },
          {
            "file": "SKILL.md",
            "line_start": 210,
            "line_end": 212
          },
          {
            "file": "SKILL.md",
            "line_start": 212,
            "line_end": 243
          },
          {
            "file": "SKILL.md",
            "line_start": 243,
            "line_end": 267
          },
          {
            "file": "SKILL.md",
            "line_start": 267,
            "line_end": 275
          },
          {
            "file": "SKILL.md",
            "line_start": 275,
            "line_end": 340
          },
          {
            "file": "SKILL.md",
            "line_start": 340,
            "line_end": 361
          },
          {
            "file": "SKILL.md",
            "line_start": 361,
            "line_end": 371
          }
        ]
      }
    ],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 2,
    "total_lines": 565,
    "audit_model": "claude",
    "audited_at": "2026-01-16T14:35:48.662Z"
  },
  "content": {
    "user_title": "Validate HTML visual accuracy against PDF source",
    "value_statement": "Manually comparing generated HTML to PDF source is slow and error-prone. This AI-powered skill provides automated visual validation with contextual understanding, scoring layout, hierarchy, and typography to ensure quality before deployment.",
    "seo_keywords": [
      "AI visual accuracy check",
      "HTML PDF comparison",
      "Claude Code visual validation",
      "visual quality gate",
      "automated testing HTML",
      "PDF to HTML validation",
      "visual regression testing",
      "AI-powered QA tool",
      "Claude visual comparison",
      "multi-modal AI testing"
    ],
    "actual_capabilities": [
      "Compares rendered HTML screenshots against original PDF page images using AI",
      "Scores visual accuracy across four criteria: layout, hierarchy, positioning, typography",
      "Provides contextual pass/fail decisions with configurable 85% threshold",
      "Generates detailed JSON reports with scoring rationale and specific differences",
      "Supports multi-page chapter validation with averaged scores across pages",
      "Blocks deployment pipeline when visual accuracy fails threshold"
    ],
    "limitations": [
      "Requires pre-rendered PNG images of both HTML and PDF for comparison",
      "Cannot run without Claude API access and headless browser for rendering",
      "Quality gate stops pipeline but does not automatically fix visual issues",
      "Cannot compare complex interactive content or JavaScript-dependent elements"
    ],
    "use_cases": [
      {
        "target_user": "Documentation teams",
        "title": "Validate PDF-to-HTML Conversion",
        "description": "Ensure technical documentation maintains visual accuracy when converting from PDF to HTML format."
      },
      {
        "target_user": "Publishing workflows",
        "title": "Automated Visual QA Gate",
        "description": "Integrate into CI/CD pipelines to automatically verify chapter content before publication."
      },
      {
        "target_user": "Web developers",
        "title": "Compare Design Implementations",
        "description": "Check if rendered HTML pages accurately match design mockups or source documents."
      }
    ],
    "prompt_templates": [
      {
        "title": "Basic Visual Comparison",
        "scenario": "Compare HTML to PDF page",
        "prompt": "Compare the original PDF page image to the rendered HTML screenshot. Score layout match, visual hierarchy, content positioning, and typography on 0-100 scale. Return JSON with overall score, criteria breakdown, and pass/fail recommendation at 85% threshold."
      },
      {
        "title": "Multi-Page Chapter Check",
        "scenario": "Validate entire chapter accuracy",
        "prompt": "Compare this chapter across pages {start_page}-{end_page}. Score each page separately against its PDF source. Provide per-page scores and overall chapter assessment as JSON."
      },
      {
        "title": "Spot-Check Specific Elements",
        "scenario": "Focus on critical sections",
        "prompt": "Focus on comparing heading hierarchy, table formatting, and figure placement between the PDF and rendered HTML. Score these three elements specifically and identify any issues that would confuse readers."
      },
      {
        "title": "Detailed Visual Report",
        "scenario": "Generate full analysis with explanation",
        "prompt": "Perform comprehensive visual comparison. Return detailed JSON with: overall_score, threshold, recommendation, criteria_analysis (layout_match, visual_hierarchy, content_positioning, typography_styling), differences_noted array, visual_fidelity_assessment, confidence_level, explanation, and pass_fail_verdict."
      }
    ],
    "output_examples": [
      {
        "input": "Compare chapter_05.html rendered against page_05.png from the original PDF",
        "output": [
          "Overall Score: 91.5% (PASS)",
          "Layout Match: 94/100 - Page structure matches well",
          "Visual Hierarchy: 90/100 - Headings clearly distinguished",
          "Content Positioning: 92/100 - Elements aligned correctly",
          "Typography: 88/100 - Text styling preserved",
          "Key Differences: Paragraph spacing 1.6 vs 1.5 (acceptable)",
          "Verdict: PASS - Ready for deployment"
        ]
      },
      {
        "input": "Validate chapter 3 across pages 16-29 against the original PDF",
        "output": [
          "Average Score: 87.3% (PASS)",
          "Page 16-19: 89/100 - Excellent consistency",
          "Page 20-24: 86/100 - Minor spacing differences",
          "Page 25-29: 86/100 - Acceptable variations",
          "Critical Issues: None detected",
          "Recommendation: PASS with minor CSS review"
        ]
      },
      {
        "input": "Check if the heading hierarchy and table formatting match between PDF and HTML",
        "output": [
          "Heading Hierarchy: 92/100 - All levels correctly distinguished",
          "Table Formatting: 85/100 - Border styling differs, alignment correct",
          "Figure Placement: 95/100 - Position and caption match",
          "Issues Found: Table borders need CSS adjustment",
          "Verdict: FAIL - Tables require CSS fix before deployment"
        ]
      }
    ],
    "best_practices": [
      "Run the visual accuracy check as a blocking gate before deployment to catch issues early in the pipeline",
      "Use high-resolution PNG screenshots for both HTML and PDF to ensure accurate visual comparison",
      "Review failed assessments to understand what visual differences the AI detected before making changes"
    ],
    "anti_patterns": [
      "Running visual accuracy checks on interactive pages with JavaScript-dependent content that changes dynamically",
      "Skipping the quality gate and deploying HTML without completing visual validation",
      "Ignoring failed checks without reviewing the detailed differences report and explanation"
    ],
    "faq": [
      {
        "question": "What AI models does this skill support?",
        "answer": "Works with Claude 3.5 Sonnet and newer multi-modal models that support image input and structured JSON output."
      },
      {
        "question": "What happens if visual accuracy fails?",
        "answer": "The pipeline stops with exit code 1. A detailed report shows which criteria failed and specific visual differences."
      },
      {
        "question": "Can I integrate this with my CI/CD pipeline?",
        "answer": "Yes. Configure as a blocking step. Returns exit code 0 for pass and 1 for fail, suitable for GitHub Actions or GitLab CI."
      },
      {
        "question": "Is my data sent to external servers?",
        "answer": "Images are sent to Claude API for analysis. No data is stored elsewhere. Review your API provider privacy policy."
      },
      {
        "question": "Why does AI compare better than pixel-diff tools?",
        "answer": "Pixel-diff tools flag every pixel difference. AI understands context: web fonts can differ from PDF but hierarchy remains correct."
      },
      {
        "question": "What image format and resolution are required?",
        "answer": "Use PNG format at reasonable resolution (at least 1200px width). Full-page screenshots capture complete layout for comparison."
      }
    ]
  },
  "file_structure": [
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md",
      "lines": 385
    }
  ]
}
