{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-10T14:31:02.616Z",
    "slug": "dowwie-control-loop-extraction",
    "source_url": "https://github.com/Dowwie/agent_framework_study/tree/main/.claude/skills/control-loop-extraction",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "2.0.0",
    "source_type": "community",
    "content_hash": "d622d37807fc6f8d5ecb6f880ee80c216212a2c06b60a67084ec13361256eb84",
    "tree_hash": "4d5d3fb50327101aacb06f3a9d482165c1f33653dbc05c1f29ef18bcb7d23263"
  },
  "skill": {
    "name": "control-loop-extraction",
    "description": "Extract and analyze agent reasoning loops, step functions, and termination conditions. Use when needing to (1) understand how an agent framework implements reasoning (ReAct, Plan-and-Solve, Reflection, etc.), (2) locate the core decision-making logic, (3) analyze loop mechanics and termination conditions, (4) document the step-by-step execution flow of an agent, or (5) compare reasoning patterns across frameworks.",
    "summary": "Extract and analyze agent reasoning loops, step functions, and termination conditions. Use when need...",
    "icon": "ðŸ”„",
    "version": "1.0.0",
    "author": "Dowwie",
    "license": "MIT",
    "category": "research",
    "tags": [
      "agent-frameworks",
      "reasoning-patterns",
      "code-analysis",
      "documentation",
      "architecture"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": []
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "This is a prompt-based documentation skill containing only markdown content with reasoning pattern definitions and analysis templates. No executable code, scripts, network operations, or file system access. The skill provides instructional guidance for manual code analysis - it does not perform any automated file reading, writing, or code execution.",
    "risk_factor_evidence": [],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 1,
    "total_lines": 154,
    "audit_model": "claude",
    "audited_at": "2026-01-10T14:31:02.616Z"
  },
  "content": {
    "user_title": "Extract agent reasoning loops from code",
    "value_statement": "Understanding how agent frameworks implement reasoning requires tracing complex control flows. This skill provides pattern signatures and extraction methods to identify reasoning topologies like ReAct, Plan-and-Solve, Reflection, and Tree-of-Thoughts from framework source code.",
    "seo_keywords": [
      "control loop extraction",
      "agent reasoning patterns",
      "ReAct analysis",
      "Plan-and-Solve documentation",
      "agent framework architecture",
      "step function analysis",
      "termination conditions",
      "Claude Code",
      "Claude",
      "Codex"
    ],
    "actual_capabilities": [
      "Identify reasoning patterns (ReAct, Plan-and-Solve, Reflection, Tree-of-Thoughts)",
      "Locate the main agent execution loop in source code",
      "Extract step function components (input assembly, LLM call, output parsing, dispatch)",
      "Catalog termination conditions and exit guards",
      "Document reasoning topology with code references",
      "Compare reasoning patterns across different frameworks"
    ],
    "limitations": [
      "Does not automatically read or parse source files - requires user to provide code context",
      "Does not execute or modify any code",
      "Does not provide runtime analysis of agent behavior",
      "Requires prerequisite skill (codebase-mapping) to identify agent files first"
    ],
    "use_cases": [
      {
        "target_user": "AI Researchers",
        "title": "Compare reasoning architectures",
        "description": "Analyze how different agent frameworks implement reasoning loops to inform research decisions"
      },
      {
        "target_user": "Framework Developers",
        "title": "Document control flow logic",
        "description": "Extract and document the core decision-making logic from agent implementation files"
      },
      {
        "target_user": "Security Auditors",
        "title": "Trace termination conditions",
        "description": "Identify all loop exit conditions to assess agent runaway risk and safety guarantees"
      }
    ],
    "prompt_templates": [
      {
        "title": "Identify Pattern",
        "scenario": "Find reasoning pattern in unknown framework",
        "prompt": "Use control-loop-extraction to analyze this agent code. Identify the reasoning pattern (ReAct, Plan-and-Solve, Reflection, or Tree-of-Thoughts). Locate the main loop and document the step function flow."
      },
      {
        "title": "Extract Step Function",
        "scenario": "Document atomic execution unit",
        "prompt": "Extract the step function from this agent. Document: 1) How input context is assembled, 2) The LLM invocation method, 3) Output parsing logic, 4) Action dispatch routing."
      },
      {
        "title": "Catalog Terminations",
        "scenario": "List all exit conditions",
        "prompt": "Find and catalog every termination condition in this agent loop. Include code references for step limits, token limits, explicit finish signals, timeouts, and error thresholds."
      },
      {
        "title": "Full Loop Analysis",
        "scenario": "Complete framework documentation",
        "prompt": "Perform a complete control loop analysis. Include: reasoning topology classification, loop location with line numbers, step function breakdown, termination condition catalog, and loop detection method."
      }
    ],
    "output_examples": [
      {
        "input": "Analyze the control loop in this agent framework code",
        "output": [
          "Reasoning Topology: ReAct (Thought â†’ Action â†’ Observation cycle)",
          "Loop Location: src/agent.py:45-120",
          "Step Function: Input assembly via _build_messages(), LLM call via invoke(), parsing via _parse_response(), dispatch to _execute_tool() or AgentFinish",
          "Termination Conditions: Step limit at max_steps=100, explicit finish action type, timeout after 300 seconds",
          "Loop Detection: None implemented - relies on step counter only"
        ]
      }
    ],
    "best_practices": [
      "Always combine with codebase-mapping to first locate agent files before analysis",
      "Verify termination conditions include both explicit guards (finish action) and implicit limits (step/token counters)",
      "Document the reasoning topology before attempting comparative analysis with other frameworks"
    ],
    "anti_patterns": [
      "Analyzing without first identifying which reasoning pattern the framework uses",
      "Assuming termination guards exist without verifying loop exit conditions",
      "Skipping the step function breakdown when documenting agent behavior"
    ],
    "faq": [
      {
        "question": "Which reasoning patterns does this skill identify?",
        "answer": "It identifies ReAct, Plan-and-Solve, Reflection, Tree-of-Thoughts, and hybrid combinations of these patterns."
      },
      {
        "question": "What is the step function in an agent?",
        "answer": "The step function is the atomic unit of agent execution: input assembly, LLM call, output parsing, and action dispatch."
      },
      {
        "question": "Does this skill read files automatically?",
        "answer": "No. This skill provides patterns and templates. Use codebase-mapping first to identify files, then apply these extraction methods."
      },
      {
        "question": "Is my code data safe when using this skill?",
        "answer": "Yes. This skill only provides documentation templates. It never reads, writes, or executes any code."
      },
      {
        "question": "Why does the skill require codebase-mapping first?",
        "answer": "codebase-mapping identifies agent files in the repository. control-loop-extraction then analyzes the specific loop patterns within those files."
      },
      {
        "question": "How does this differ from execution-engine-analysis?",
        "answer": "control-loop-extraction focuses on reasoning patterns and decision logic. execution-engine-analysis focuses on async patterns, concurrency, and event architecture."
      }
    ]
  },
  "file_structure": [
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md"
    }
  ]
}
