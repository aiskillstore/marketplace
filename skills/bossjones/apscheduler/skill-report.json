{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-16T19:36:12.265Z",
    "slug": "bossjones-apscheduler",
    "source_url": "https://github.com/bossjones/logging-lab/tree/main/.claude/skills/apscheduler",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "3.0.0",
    "source_type": "community",
    "content_hash": "106d6c936395d1de4b678531a323a68a894797b5fb0f84fa0803c2487f401f99",
    "tree_hash": "d896a7887d23c930f2e400ff401e2253f3033bf91d6a71c3b3e751d5e3b9002c"
  },
  "skill": {
    "name": "apscheduler",
    "description": "Advanced Python Scheduler - Task scheduling and job queue system",
    "summary": "Advanced Python Scheduler - Task scheduling and job queue system",
    "icon": "‚è∞",
    "version": "1.0.0",
    "author": "bossjones",
    "license": "MIT",
    "category": "productivity",
    "tags": [
      "scheduling",
      "background-jobs",
      "cron",
      "async",
      "task-queue"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": [
      "external_commands"
    ]
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "This is a documentation-only skill containing code examples for the APScheduler Python library. All 82 static findings are FALSE POSITIVES. The analyzer misinterpreted markdown code fences (backticks) as shell command execution, placeholder URLs as hardcoded endpoints, standard Python keywords as cryptographic algorithms, and job scheduling patterns as system reconnaissance. No actual executable code, network calls, or file operations exist in this skill. It is safe for publication.",
    "risk_factor_evidence": [
      {
        "factor": "external_commands",
        "evidence": [
          {
            "file": "SKILL.md",
            "line_start": 16,
            "line_end": 372
          }
        ]
      }
    ],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 3,
    "total_lines": 1272,
    "audit_model": "claude",
    "audited_at": "2026-01-16T19:36:12.265Z"
  },
  "content": {
    "user_title": "Schedule background tasks with APScheduler",
    "value_statement": "Automate recurring tasks and background jobs in Python applications. APScheduler provides cron-style, interval-based, and date-based scheduling with support for async execution and multiple persistence backends.",
    "seo_keywords": [
      "APScheduler",
      "Python task scheduler",
      "cron scheduling",
      "background jobs",
      "periodic tasks",
      "async scheduler",
      "task queue",
      "Claude Code",
      "Claude",
      "Codex"
    ],
    "actual_capabilities": [
      "Schedule Python functions with cron, interval, and date triggers",
      "Run jobs synchronously or asynchronously with FastAPI integration",
      "Persist schedules across application restarts with SQL databases",
      "Distribute work across scheduler and worker nodes",
      "Manage job results and handle job events",
      "Configure thread pool and process pool executors"
    ],
    "limitations": [
      "Requires Python 3.9 or higher for async features",
      "Memory-based scheduler loses jobs on application restart",
      "Does not provide built-in task deduplication",
      "Monitoring and metrics require custom implementation"
    ],
    "use_cases": [
      {
        "target_user": "Backend developers",
        "title": "Automated report generation",
        "description": "Schedule daily, weekly, or monthly report generation jobs that run without manual intervention"
      },
      {
        "target_user": "API developers",
        "title": "Periodic data sync",
        "description": "Sync data from external APIs or databases at regular intervals with configurable triggers"
      },
      {
        "target_user": "DevOps engineers",
        "title": "Health check monitoring",
        "description": "Run background monitoring tasks that check system health and trigger alerts"
      }
    ],
    "prompt_templates": [
      {
        "title": "Basic scheduling",
        "scenario": "Run a function every minute",
        "prompt": "Use APScheduler to run my cleanup function every minute with an interval trigger"
      },
      {
        "title": "Cron scheduling",
        "scenario": "Schedule daily at specific time",
        "prompt": "Schedule a function to run at 9 AM every weekday using cron trigger"
      },
      {
        "title": "With persistence",
        "scenario": "Save schedules across restarts",
        "prompt": "Set up AsyncScheduler with PostgreSQL persistence so jobs survive application restarts"
      },
      {
        "title": "Distributed workers",
        "scenario": "Scale job execution",
        "prompt": "Create a distributed APScheduler setup with separate scheduler and worker nodes using AsyncpgEventBroker"
      }
    ],
    "output_examples": [
      {
        "input": "Schedule my send_daily_report function to run every day at 9 AM",
        "output": [
          "Added schedule 'send_daily_report' with CronTrigger (hour=9, minute=0)",
          "Next run time: tomorrow at 09:00:00",
          "Job will execute: send_daily_report()",
          "Scheduler is running in background"
        ]
      },
      {
        "input": "Add a job that runs refresh_cache() every 30 minutes",
        "output": [
          "Added schedule with ID: cache_refresh",
          "Trigger: interval, every 30 minutes",
          "Job executor: threadpool (default)",
          "Next run: [calculated next fire time]"
        ]
      }
    ],
    "best_practices": [
      "Use persistent data stores in production to survive application restarts",
      "Set appropriate misfire_grace_time to handle system delays gracefully",
      "Subscribe to job events for monitoring and alerting on job failures"
    ],
    "anti_patterns": [
      "Storing credentials directly in job kwargs - use environment variables instead",
      "Scheduling very short intervals without proper coalesce configuration",
      "Ignoring job exceptions without error handling or retry policies"
    ],
    "faq": [
      {
        "question": "How does APScheduler compare to Celery?",
        "answer": "APScheduler is lighter and simpler for single-application scheduling. Celery is better for complex distributed task queues."
      },
      {
        "question": "Can I run APScheduler in FastAPI?",
        "answer": "Yes, use the lifespan pattern with AsyncScheduler to run the scheduler alongside your FastAPI application."
      },
      {
        "question": "What happens to jobs when the app restarts?",
        "answer": "With in-memory storage, jobs are lost. Use SQLAlchemyDataStore or MongoDBDataStore to persist jobs across restarts."
      },
      {
        "question": "How do I run jobs in the background?",
        "answer": "Call scheduler.start_in_background() after adding your schedules. This runs the scheduler loop without blocking."
      },
      {
        "question": "Can I pass arguments to scheduled functions?",
        "answer": "Yes, use args for positional arguments and kwargs for named arguments in add_schedule or add_job."
      },
      {
        "question": "What executors are available?",
        "answer": "ThreadPoolExecutor (default, good for I/O tasks) and ProcessPoolExecutor (good for CPU-intensive tasks)."
      }
    ]
  },
  "file_structure": [
    {
      "name": "evaluation.json",
      "type": "file",
      "path": "evaluation.json",
      "lines": 471
    },
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md",
      "lines": 372
    }
  ]
}
