{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-16T14:10:39.530Z",
    "slug": "1gy-running-tests",
    "source_url": "https://github.com/1gy/jpp/tree/main/.claude/skills/running-tests",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "3.0.0",
    "source_type": "community",
    "content_hash": "13e3f5b089947d500db33fb990f778d34196e83fc87964e7d1cde4b7684d2880",
    "tree_hash": "779698ca576fcc86a7695040325ed3e79ab2d4969c8817e1e2759d5776a0c73d"
  },
  "skill": {
    "name": "running-tests",
    "description": "Runs tests and handles failures. Triggered when: test execution, verification, test failures, CI checks.\n",
    "summary": "Runs tests and handles failures. Triggered when: test execution, verification, test failures, CI che...",
    "icon": "ðŸ§ª",
    "version": "1.0.0",
    "author": "1gy",
    "license": "MIT",
    "category": "coding",
    "tags": [
      "testing",
      "development",
      "CI/CD",
      "quality assurance"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": [
      "external_commands",
      "filesystem"
    ]
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "All 20 static findings are false positives. The scanner incorrectly flagged markdown formatting (backticks), metadata hashes (SHA-256 checksum), and YAML frontmatter as security threats. This is a legitimate test runner skill that uses the Bash tool to execute test commands. No network calls, no credential access, no persistence mechanisms.",
    "risk_factor_evidence": [
      {
        "factor": "external_commands",
        "evidence": [
          {
            "file": "SKILL.md",
            "line_start": 16,
            "line_end": 21
          }
        ]
      },
      {
        "factor": "filesystem",
        "evidence": [
          {
            "file": "SKILL.md",
            "line_start": 1,
            "line_end": 52
          }
        ]
      }
    ],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 2,
    "total_lines": 252,
    "audit_model": "claude",
    "audited_at": "2026-01-16T14:10:39.530Z"
  },
  "content": {
    "user_title": "Run Tests and Fix Failures",
    "value_statement": "Manually running tests and analyzing failures is time-consuming. This skill automates test execution across different project types, detects the correct test command, runs tests, and handles failures by implementing fixes.",
    "seo_keywords": [
      "test runner",
      "automated testing",
      "CI/CD",
      "Claude",
      "Codex",
      "Claude Code",
      "test automation",
      "development tools",
      "quality assurance",
      "continuous integration"
    ],
    "actual_capabilities": [
      "Detects test commands by checking project files like package.json, Cargo.toml, justfile, Makefile, pyproject.toml, and go.mod",
      "Runs test suites and reports pass or fail status with test counts",
      "Identifies failed test names and extracts error messages",
      "Analyzes failure causes to determine if the issue is an implementation bug, test bug, or environment problem",
      "Implements fixes for implementation bugs and test bugs",
      "Re-runs tests after fixes to confirm all tests pass"
    ],
    "limitations": [
      "Does not modify complex multi-file test configurations",
      "Cannot resolve external dependencies that tests require",
      "Limited to projects with standard test command patterns"
    ],
    "use_cases": [
      {
        "target_user": "Software Developers",
        "title": "Run Project Test Suites",
        "description": "Execute project tests automatically with the correct command for your project type without manual setup"
      },
      {
        "target_user": "DevOps Engineers",
        "title": "Validate CI Test Execution",
        "description": "Test your code in CI environments and diagnose failures quickly to keep pipelines running"
      },
      {
        "target_user": "Code Reviewers",
        "title": "Verify Test Coverage",
        "description": "Run tests to verify code changes pass all quality checks before approving merges"
      }
    ],
    "prompt_templates": [
      {
        "title": "Run All Tests",
        "scenario": "Execute project test suite",
        "prompt": "Run the tests for this project and tell me how many tests passed or failed"
      },
      {
        "title": "Debug Failures",
        "scenario": "Investigate test failures",
        "prompt": "Run the tests, identify any failures, and explain what is causing them"
      },
      {
        "title": "Fix and Verify",
        "scenario": "Fix test failures and verify",
        "prompt": "Run the tests, fix any failures, and confirm all tests pass afterward"
      },
      {
        "title": "Prepare for CI",
        "scenario": "Get code ready for CI",
        "prompt": "Run the full test suite and fix any issues so the code is ready for CI checks"
      }
    ],
    "output_examples": [
      {
        "input": "Run the tests for this project",
        "output": [
          "Test suite completed: 42 tests passed, 3 failed",
          "Failed tests: test_user_authentication, test_payment_processing, test_data_export",
          "Root cause: test_payment_processing has a mock configuration issue",
          "Fix applied: Updated payment mock to use correct API endpoint",
          "All tests now passing after fix"
        ]
      },
      {
        "input": "Run the tests and tell me what is failing",
        "output": [
          "Running pytest on the project",
          "Results: 156 passed, 2 failed",
          "Failed test 1: tests/api/test_users.py::test_get_user_invalid_id",
          "Error: AssertionError - expected status 404, got 200",
          "Failed test 2: tests/api/test_users.py::test_create_user_missing_field",
          "Error: KeyError - 'email' field not found in request body"
        ]
      },
      {
        "input": "Run tests, fix failures, and commit",
        "output": [
          "Test run: 28 passed, 1 failed",
          "Failed: test_payment_calculation in tests/core/test_math.py",
          "Analysis: Implementation bug - discount calculation missing percentage conversion",
          "Fix applied: Changed discount = amount * (1 - percent / 100)",
          "All tests passing after fix",
          "Changes committed: 'Fix discount calculation to properly convert percentage'"
        ]
      }
    ],
    "best_practices": [
      "Run tests frequently during development to catch issues early before they compound",
      "Use specific test commands when you need targeted testing of particular files",
      "Review failure analysis to understand root causes before applying automatic fixes"
    ],
    "anti_patterns": [
      "Running tests without first checking if the project has a test configuration",
      "Ignoring test failures and committing broken code to the repository",
      "Applying automatic fixes without understanding the root cause of the failure"
    ],
    "faq": [
      {
        "question": "What test frameworks are supported?",
        "answer": "Supports npm test, cargo test, pytest, go test, make test, and just test commands. Auto-detects based on project files."
      },
      {
        "question": "Can it run specific test files?",
        "answer": "The skill runs the default test command. You can ask for specific test filtering in your prompt for targeted testing."
      },
      {
        "question": "Does it work with CI systems?",
        "answer": "Yes, the skill works with any project that has standard test commands configured for CI environments."
      },
      {
        "question": "What data does this skill access?",
        "answer": "Only project files needed to detect test commands. No sensitive data, credentials, or private information is accessed."
      },
      {
        "question": "What if tests fail due to environment issues?",
        "answer": "The skill distinguishes between bugs and environment issues. Environment problems are reported to you for manual resolution."
      },
      {
        "question": "How does it compare to manual test running?",
        "answer": "This skill automates finding the right test command, running tests, and diagnosing failures. It saves time on setup and analysis."
      }
    ]
  },
  "file_structure": [
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md",
      "lines": 52
    }
  ]
}
