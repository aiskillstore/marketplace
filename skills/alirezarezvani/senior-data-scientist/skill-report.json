{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-16T16:55:02.770Z",
    "slug": "alirezarezvani-senior-data-scientist",
    "source_url": "https://github.com/alirezarezvani/claude-skills/tree/main/engineering-team/senior-data-scientist",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "3.0.0",
    "source_type": "community",
    "content_hash": "a2ad70e3e730d5915a27472f0413f524ac96e4cf7fd1474a39e14a178c87170d",
    "tree_hash": "35e5869149c34dd8b44043365a609c0e8bed6549b8c1c1fa4bdb462076f9f63d"
  },
  "skill": {
    "name": "senior-data-scientist",
    "description": "World-class data science skill for statistical modeling, experimentation, causal inference, and advanced analytics. Expertise in Python (NumPy, Pandas, Scikit-learn), R, SQL, statistical methods, A/B testing, time series, and business intelligence. Includes experiment design, feature engineering, model evaluation, and stakeholder communication. Use when designing experiments, building predictive models, performing causal analysis, or driving data-driven decisions.",
    "summary": "World-class data science skill for statistical modeling, experimentation, causal inference, and adva...",
    "icon": "ðŸ“Š",
    "version": "1.0.0",
    "author": "alirezarezvani",
    "license": "MIT",
    "category": "data",
    "tags": [
      "data-science",
      "machine-learning",
      "statistics"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": [
      "network",
      "external_commands"
    ]
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "All 74 static findings are false positives. Scanner misinterpreted markdown headings (# symbol) as weak cryptographic algorithms, bash code examples as command injection, and documentation references as C2/network reconnaissance. The skill contains legitimate data science documentation and Python boilerplate for experiment design, feature engineering, and model evaluation. No actual cryptographic implementations, subprocess calls, or network operations exist.",
    "risk_factor_evidence": [
      {
        "factor": "network",
        "evidence": [
          {
            "file": "skill-report.json",
            "line_start": 6,
            "line_end": 6
          }
        ]
      },
      {
        "factor": "external_commands",
        "evidence": [
          {
            "file": "SKILL.md",
            "line_start": 14,
            "line_end": 23
          },
          {
            "file": "SKILL.md",
            "line_start": 23,
            "line_end": 54
          },
          {
            "file": "SKILL.md",
            "line_start": 54,
            "line_end": 65
          },
          {
            "file": "SKILL.md",
            "line_start": 65,
            "line_end": 75
          },
          {
            "file": "SKILL.md",
            "line_start": 75,
            "line_end": 167
          },
          {
            "file": "SKILL.md",
            "line_start": 167,
            "line_end": 185
          },
          {
            "file": "SKILL.md",
            "line_start": 185,
            "line_end": 189
          },
          {
            "file": "SKILL.md",
            "line_start": 189,
            "line_end": 190
          },
          {
            "file": "SKILL.md",
            "line_start": 190,
            "line_end": 191
          },
          {
            "file": "SKILL.md",
            "line_start": 191,
            "line_end": 192
          }
        ]
      }
    ],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 8,
    "total_lines": 1027,
    "audit_model": "claude",
    "audited_at": "2026-01-16T16:55:02.770Z"
  },
  "content": {
    "user_title": "Design experiments and build predictive models",
    "value_statement": "Design rigorous A/B tests and experiments with proper statistical power analysis. Build production-ready predictive models using proven feature engineering techniques and machine learning frameworks.",
    "seo_keywords": [
      "data science",
      "experiment design",
      "A/B testing",
      "statistical analysis",
      "feature engineering",
      "predictive modeling",
      "machine learning",
      "Claude Code",
      "claude",
      "codex"
    ],
    "actual_capabilities": [
      "Design A/B tests with statistical power analysis and sample size calculations",
      "Perform feature engineering with automated generation and selection techniques",
      "Evaluate machine learning models using industry-standard metrics and validation methods",
      "Conduct causal inference analysis for business decision making",
      "Build time series forecasting models for trend analysis",
      "Create production-ready ML pipelines with monitoring and retraining strategies"
    ],
    "limitations": [
      "Does not execute Python code or interact with external data sources directly",
      "Does not provide pre-trained models or datasets",
      "Requires user to provide their own data and computational environment"
    ],
    "use_cases": [
      {
        "target_user": "Product Managers",
        "title": "Design A/B Tests",
        "description": "Design statistically valid experiments to measure product changes and feature releases."
      },
      {
        "target_user": "Data Scientists",
        "title": "Build ML Pipelines",
        "description": "Create production-ready feature engineering workflows and model evaluation frameworks."
      },
      {
        "target_user": "Business Analysts",
        "title": "Analyze Results",
        "description": "Interpret statistical results and communicate findings to stakeholders clearly."
      }
    ],
    "prompt_templates": [
      {
        "title": "Design Experiment",
        "scenario": "New A/B test",
        "prompt": "Help me design an A/B test for my product feature. I need to determine sample size, success metrics, and statistical power requirements."
      },
      {
        "title": "Feature Engineering",
        "scenario": "Prepare features",
        "prompt": "Review my dataset and suggest feature engineering techniques for my prediction target. Include handling missing values and categorical variables."
      },
      {
        "title": "Model Evaluation",
        "scenario": "Assess model",
        "prompt": "Evaluate my machine learning model trained on my data. Suggest appropriate metrics, cross-validation strategies, and potential improvements."
      },
      {
        "title": "Causal Analysis",
        "scenario": "Understand impact",
        "prompt": "Analyze my business scenario to determine causal relationships. Identify confounding variables and recommend appropriate inference methods."
      }
    ],
    "output_examples": [
      {
        "input": "Help me design an A/B test for a new checkout flow",
        "output": [
          "Sample size: 10,000 users per variant at 80% power and 5% significance",
          "Primary metric: Conversion rate to completed purchase",
          "Secondary metrics: Average order value and cart abandonment rate",
          "Recommended duration: 2 weeks with full traffic allocation"
        ]
      },
      {
        "input": "How do I engineer features for customer churn prediction?",
        "output": [
          "Recency-Frequency-Monetary (RFM) features from transaction history",
          "Time-based features: Days since last purchase and account age",
          "Behavioral features: Login frequency and feature usage patterns",
          "Use target encoding for high-cardinality categorical variables"
        ]
      },
      {
        "input": "What metrics should I track in my A/B test?",
        "output": [
          "Define one primary metric directly aligned with business goals",
          "Add 2-3 secondary metrics to catch unintended effects",
          "Include guard metrics to prevent metric manipulation",
          "Consider leading indicators for early signals"
        ]
      }
    ],
    "best_practices": [
      "Always define success metrics and secondary metrics before starting any experiment",
      "Use stratified sampling to ensure balanced treatment groups across key segments",
      "Document all assumptions and conduct sensitivity analysis on power calculations"
    ],
    "anti_patterns": [
      "Running experiments without proper power analysis leads to inconclusive results",
      "Using multiple success metrics without adjusting for false discovery rate",
      "Ignoring novelty effects or seasonal patterns in experiment timing"
    ],
    "faq": [
      {
        "question": "What sample size do I need for my A/B test?",
        "answer": "Calculate using statistical power analysis based on expected effect size, baseline conversion rate, desired power (typically 80%), and significance level (typically 5%)."
      },
      {
        "question": "How do I handle categorical features with high cardinality?",
        "answer": "Use target encoding, frequency encoding, or embedding-based methods. Avoid one-hot encoding for variables with many unique values."
      },
      {
        "question": "What metrics should I track in an A/B test?",
        "answer": "Define one primary metric aligned with business goals plus 2-3 secondary metrics. Guard against metric manipulation and false discovery."
      },
      {
        "question": "When should I use causal inference vs correlation analysis?",
        "answer": "Use causal inference when understanding true intervention effects. Correlation analysis works for prediction but does not establish causality."
      },
      {
        "question": "How do I prevent data leakage in feature engineering?",
        "answer": "Apply transformations separately to training and test sets. Compute statistics like mean only on training data before transforming test data."
      },
      {
        "question": "How long should I run my A/B test?",
        "answer": "Run until reaching calculated sample size and consider full business cycles (typically 1-2 weeks) to account for day-of-week effects."
      }
    ]
  },
  "file_structure": [
    {
      "name": "references",
      "type": "dir",
      "path": "references",
      "children": [
        {
          "name": "experiment_design_frameworks.md",
          "type": "file",
          "path": "references/experiment_design_frameworks.md",
          "lines": 81
        },
        {
          "name": "feature_engineering_patterns.md",
          "type": "file",
          "path": "references/feature_engineering_patterns.md",
          "lines": 81
        },
        {
          "name": "statistical_methods_advanced.md",
          "type": "file",
          "path": "references/statistical_methods_advanced.md",
          "lines": 81
        }
      ]
    },
    {
      "name": "scripts",
      "type": "dir",
      "path": "scripts",
      "children": [
        {
          "name": "experiment_designer.py",
          "type": "file",
          "path": "scripts/experiment_designer.py",
          "lines": 101
        },
        {
          "name": "feature_engineering_pipeline.py",
          "type": "file",
          "path": "scripts/feature_engineering_pipeline.py",
          "lines": 101
        },
        {
          "name": "model_evaluation_suite.py",
          "type": "file",
          "path": "scripts/model_evaluation_suite.py",
          "lines": 101
        }
      ]
    },
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md",
      "lines": 227
    }
  ]
}
