{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-15T11:41:12.101Z",
    "slug": "alirezarezvani-senior-data-scientist",
    "source_url": "https://github.com/alirezarezvani/claude-skills/tree/main/engineering-team/senior-data-scientist",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "3.0.0",
    "source_type": "community",
    "content_hash": "a2ad70e3e730d5915a27472f0413f524ac96e4cf7fd1474a39e14a178c87170d",
    "tree_hash": "730e0442f0878f0c2aa2c8bd270f9ad367a9d47b566fc62ae1c4246d460ec16c"
  },
  "skill": {
    "name": "senior-data-scientist",
    "description": "World-class data science skill for statistical modeling, experimentation, causal inference, and advanced analytics. Expertise in Python (NumPy, Pandas, Scikit-learn), R, SQL, statistical methods, A/B testing, time series, and business intelligence. Includes experiment design, feature engineering, model evaluation, and stakeholder communication. Use when designing experiments, building predictive models, performing causal analysis, or driving data-driven decisions.",
    "summary": "World-class data science skill for statistical modeling, experimentation, causal inference, and adva...",
    "icon": "ðŸ“Š",
    "version": "1.0.0",
    "author": "alirezarezvani",
    "license": "MIT",
    "category": "data",
    "tags": [
      "data-science",
      "machine-learning",
      "statistics"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": [
      "scripts"
    ]
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "All 48 static findings are false positives. Scanner misinterpreted documentation about security practices as cryptographic code and markdown code block syntax as command execution. No actual cryptographic implementations, subprocess calls, or network operations exist in the codebase.",
    "risk_factor_evidence": [
      {
        "factor": "scripts",
        "evidence": [
          {
            "file": "scripts/experiment_designer.py",
            "line_start": 1,
            "line_end": 100
          },
          {
            "file": "scripts/feature_engineering_pipeline.py",
            "line_start": 1,
            "line_end": 100
          },
          {
            "file": "scripts/model_evaluation_suite.py",
            "line_start": 1,
            "line_end": 100
          }
        ]
      }
    ],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 7,
    "total_lines": 773,
    "audit_model": "claude",
    "audited_at": "2026-01-15T11:41:12.101Z"
  },
  "content": {
    "user_title": "Design experiments and build predictive models",
    "value_statement": "Design rigorous A/B tests and experiments with proper statistical power analysis. Build production-ready predictive models using proven feature engineering techniques and machine learning frameworks.",
    "seo_keywords": [
      "data science",
      "experiment design",
      "A/B testing",
      "statistical analysis",
      "feature engineering",
      "predictive modeling",
      "machine learning",
      "Claite Code",
      "Claude"
    ],
    "actual_capabilities": [
      "Design A/B tests with statistical power analysis and sample size calculations",
      "Perform feature engineering with automated generation and selection techniques",
      "Evaluate machine learning models using industry-standard metrics and validation methods",
      "Conduct causal inference analysis for business decision making"
    ],
    "limitations": [
      "Does not execute Python code or interact with external data sources directly",
      "Does not provide pre-trained models or datasets",
      "Requires user to provide their own data and computational environment"
    ],
    "use_cases": [
      {
        "target_user": "Product Managers",
        "title": "Design A/B Tests",
        "description": "Design statistically valid experiments to measure product changes and feature releases."
      },
      {
        "target_user": "Data Scientists",
        "title": "Build ML Pipelines",
        "description": "Create production-ready feature engineering workflows and model evaluation frameworks."
      },
      {
        "target_user": "Business Analysts",
        "title": "Analyze Experiment Results",
        "description": "Interpret statistical results and communicate findings to stakeholders clearly."
      }
    ],
    "prompt_templates": [
      {
        "title": "Design Experiment",
        "scenario": "New A/B test",
        "prompt": "Help me design an A/B test for [product feature]. I need to determine the sample size, success metrics, and statistical power requirements."
      },
      {
        "title": "Feature Engineering",
        "scenario": "Prepare features",
        "prompt": "Review my dataset and suggest feature engineering techniques for [prediction target]. Include handling missing values and categorical variables."
      },
      {
        "title": "Model Evaluation",
        "scenario": "Assess model",
        "prompt": "Evaluate my [model type] model trained on [data]. Suggest appropriate metrics, cross-validation strategies, and potential improvements."
      },
      {
        "title": "Causal Analysis",
        "scenario": "Understand impact",
        "prompt": "Analyze [business scenario] to determine causal relationships. Identify confounding variables and recommend appropriate inference methods."
      }
    ],
    "output_examples": [
      {
        "input": "Help me design an A/B test for a new checkout flow",
        "output": [
          "Sample size: 10,000 users per variant (80% power, 5% significance)",
          "Primary metric: Conversion rate to completed purchase",
          "Secondary metrics: Average order value, cart abandonment rate",
          "Duration: 2 weeks with full traffic allocation"
        ]
      },
      {
        "input": "How do I engineer features for customer churn prediction?",
        "output": [
          "Recency-Frequency-Monetary (RFM) features from transaction history",
          "Time-based features: Days since last purchase, account age",
          "Behavioral features: Login frequency, feature usage patterns",
          "Encode categorical variables using target encoding for high-cardinality fields"
        ]
      }
    ],
    "best_practices": [
      "Always define success metrics and secondary metrics before starting any experiment",
      "Use stratified sampling to ensure balanced treatment groups across key segments",
      "Document all assumptions and conduct sensitivity analysis on power calculations"
    ],
    "anti_patterns": [
      "Running experiments without proper power analysis leads to inconclusive results",
      "Using multiple success metrics without adjusting for false discovery rate",
      "Ignoring novelty effects or seasonal patterns in experiment timing"
    ],
    "faq": [
      {
        "question": "What sample size do I need for my A/B test?",
        "answer": "Calculate using statistical power analysis based on expected effect size, baseline conversion rate, desired power (typically 80%), and significance level (typically 5%)."
      },
      {
        "question": "How do I handle categorical features with high cardinality?",
        "answer": "Use target encoding, frequency encoding, or embedding-based methods. Avoid one-hot encoding for variables with many unique values."
      },
      {
        "question": "What metrics should I track in an A/B test?",
        "answer": "Define one primary metric aligned with business goals, plus 2-3 secondary metrics to catch unintended effects. Guard against metric manipulation."
      },
      {
        "question": "When should I use causal inference vs correlation analysis?",
        "answer": "Use causal inference when you need to understand the true effect of an intervention. Correlation analysis is appropriate for prediction but does not establish causality."
      },
      {
        "question": "How do I prevent data leakage in feature engineering?",
        "answer": "Apply transformations separately to training and test sets. Compute statistics like mean and standard deviation only on training data before transforming test data."
      },
      {
        "question": "How long should I run my A/B test?",
        "answer": "Run until you reach the calculated sample size, but also consider full business cycles (typically 1-2 weeks) to account for day-of-week effects."
      }
    ]
  },
  "file_structure": [
    {
      "name": "references",
      "type": "dir",
      "path": "references",
      "children": [
        {
          "name": "experiment_design_frameworks.md",
          "type": "file",
          "path": "references/experiment_design_frameworks.md",
          "lines": 81
        },
        {
          "name": "feature_engineering_patterns.md",
          "type": "file",
          "path": "references/feature_engineering_patterns.md",
          "lines": 81
        },
        {
          "name": "statistical_methods_advanced.md",
          "type": "file",
          "path": "references/statistical_methods_advanced.md",
          "lines": 81
        }
      ]
    },
    {
      "name": "scripts",
      "type": "dir",
      "path": "scripts",
      "children": [
        {
          "name": "experiment_designer.py",
          "type": "file",
          "path": "scripts/experiment_designer.py",
          "lines": 101
        },
        {
          "name": "feature_engineering_pipeline.py",
          "type": "file",
          "path": "scripts/feature_engineering_pipeline.py",
          "lines": 101
        },
        {
          "name": "model_evaluation_suite.py",
          "type": "file",
          "path": "scripts/model_evaluation_suite.py",
          "lines": 101
        }
      ]
    },
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md",
      "lines": 227
    }
  ]
}
