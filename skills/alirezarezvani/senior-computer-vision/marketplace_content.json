{
  "skill": {
    "name": "Senior Computer Vision Engineer",
    "description": "World-class computer vision skill for image/video processing, object detection, segmentation, and visual AI systems. Expertise in PyTorch, OpenCV, YOLO, SAM, diffusion models, and vision transformers. Includes 3D vision, video analysis, real-time processing, and production deployment.",
    "summary": "Build production computer vision systems with object detection, segmentation, and real-time AI models",
    "icon": "üëÅÔ∏è",
    "version": "1.0.0",
    "author": "Claude Skills",
    "license": "MIT",
    "category": "data",
    "tags": ["computer-vision", "machine-learning", "image-processing", "deep-learning", "production-ai"],
    "supported_tools": ["claude", "codex", "claude-code"]
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "All 36 static findings are false positives. The scanner flagged documentation keywords (encryption, algorithm, SAM) and markdown code blocks without understanding context. The Python scripts are legitimate computer vision tooling with no cryptographic operations, network calls, or malicious code.",
    "static_findings_evaluation": [
      {
        "finding": "[HIGH] blocker: Weak cryptographic algorithm at references/computer_vision_architectures.md:9,11,17,62",
        "verdict": "false_positive",
        "confidence": "high",
        "reasoning": "These are markdown documentation files. The scanner detected the word 'encryption' in security documentation (line 29: 'Data encryption'). There is no actual cryptographic code - only documentation about security best practices."
      },
      {
        "finding": "[LOW] blocker: Network reconnaissance at references/computer_vision_architectures.md:21",
        "verdict": "false_positive",
        "confidence": "high",
        "reasoning": "Line 21 discusses 'Resource awareness' in the context of computing resources (CPU, memory). This is a performance optimization topic, not network reconnaissance."
      },
      {
        "finding": "[HIGH] blocker: Weak cryptographic algorithm at references/object_detection_optimization.md:9,11,17,62",
        "verdict": "false_positive",
        "confidence": "high",
        "reasoning": "Same pattern as computer_vision_architectures.md. Documentation about security practices (line 29: 'Data encryption') contains no actual cryptographic code."
      },
      {
        "finding": "[LOW] blocker: Network reconnaissance at references/object_detection_optimization.md:21",
        "verdict": "false_positive",
        "confidence": "high",
        "reasoning": "Line 21 discusses 'Resource awareness' for performance optimization, not network reconnaissance."
      },
      {
        "finding": "[HIGH] blocker: Weak cryptographic algorithm at references/production_vision_systems.md:9,11,17,62",
        "verdict": "false_positive",
        "confidence": "high",
        "reasoning": "Same pattern as other reference files. Documentation about security best practices (line 29: 'Data encryption') contains no cryptographic code."
      },
      {
        "finding": "[LOW] blocker: Network reconnaissance at references/production_vision_systems.md:21",
        "verdict": "false_positive",
        "confidence": "high",
        "reasoning": "Line 21 discusses 'Resource awareness' for performance optimization, not network reconnaissance."
      },
      {
        "finding": "[HIGH] blocker: Weak cryptographic algorithm at scripts/dataset_pipeline_builder.py:71",
        "verdict": "false_positive",
        "confidence": "high",
        "reasoning": "Line 71 is argparse configuration for command-line arguments. The Python scripts contain no cryptographic operations whatsoever. Scanner incorrectly flagged argument parsing code."
      },
      {
        "finding": "[HIGH] blocker: Weak cryptographic algorithm at scripts/inference_optimizer.py:71",
        "verdict": "false_positive",
        "confidence": "high",
        "reasoning": "Line 71 is argparse configuration. No cryptographic code exists in this script - it is a standard CLI argument parser."
      },
      {
        "finding": "[HIGH] blocker: Weak cryptographic algorithm at scripts/vision_model_trainer.py:71",
        "verdict": "false_positive",
        "confidence": "high",
        "reasoning": "Line 71 is argparse configuration. This is a legitimate model training CLI tool with no cryptographic operations."
      },
      {
        "finding": "[MEDIUM] external_commands: Ruby/shell backtick execution at SKILL.md:14,23,54,65,75,167,185,189,190,191",
        "verdict": "false_positive",
        "confidence": "high",
        "reasoning": "SKILL.md is a markdown documentation file. Backticks are used for markdown code formatting (inline and code blocks). There is no actual shell or Ruby execution - these are example commands shown to users."
      },
      {
        "finding": "[CRITICAL] sensitive: Windows SAM database at SKILL.md:3",
        "verdict": "false_positive",
        "confidence": "high",
        "reasoning": "Line 3 contains skill description mentioning 'SAM' which stands for Segment Anything Model - a legitimate computer vision architecture. Scanner incorrectly flagged this as Windows SAM database."
      },
      {
        "finding": "[HIGH] blocker: Weak cryptographic algorithm at SKILL.md:3,30,68,69,77,90",
        "verdict": "false_positive",
        "confidence": "high",
        "reasoning": "SKILL.md is documentation. Line 3 mentions 'security', line 30 discusses 'Scalable system design', lines 68-77 are tech stack listings, line 90 mentions 'Security & Compliance'. No cryptographic algorithms exist in this markdown file."
      }
    ],
    "risk_factor_evidence": [],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 7,
    "total_lines": 773
  },
  "content": {
    "user_title": "Build production computer vision AI systems",
    "value_statement": "Create enterprise-grade computer vision solutions with object detection, image segmentation, and real-time video analysis. This skill provides expert guidance on PyTorch, OpenCV, YOLO, and vision transformers for production deployment.",
    "seo_keywords": ["claude computer vision", "claude code object detection", "claude codex image segmentation", "yolo model training", "pytorch vision models", "opencv computer vision", "vision transformers", "real-time video analysis", "ml computer vision", "deep learning vision"],
    "actual_capabilities": [
      "Design and train custom object detection models using YOLO and Faster R-CNN architectures",
      "Build image segmentation pipelines with semantic and instance segmentation techniques",
      "Optimize inference pipelines for real-time performance using TensorRT and ONNX export",
      "Implement video processing workflows with frame extraction and object tracking",
      "Deploy production vision systems with Docker, Kubernetes, and cloud monitoring",
      "Apply transfer learning with pre-trained vision models like SAM and ViT"
    ],
    "limitations": [
      "Requires user to provide compute resources and GPU infrastructure for training",
      "Does not include pre-trained model weights - users must download or train their own",
      "Focuses on 2D vision - specialized expertise needed for 3D reconstruction and LiDAR"
    ],
    "use_cases": [
      {
        "target_user": "ML Engineers",
        "title": "Train custom vision models",
        "description": "Build and deploy object detection models tailored to your dataset with production-ready training pipelines"
      },
      {
        "target_user": "Data Scientists",
        "title": "Optimize inference pipelines",
        "description": "Reduce latency and increase throughput for vision models using quantization and model optimization"
      },
      {
        "target_user": "Product Teams",
        "title": "Design vision AI products",
        "description": "Plan and architect computer vision features for products with scalability and cost considerations"
      }
    ],
    "prompt_templates": [
      {
        "title": "Basic object detection",
        "scenario": "Getting started with detection",
        "prompt": "Help me set up a YOLO object detection pipeline for [USE_CASE]. What steps do I need to prepare my dataset and train a model?"
      },
      {
        "title": "Segmentation workflow",
        "scenario": "Image segmentation project",
        "prompt": "Create a step-by-step plan for implementing semantic segmentation using [FRAMEWORK] for a [USE_CASE] application."
      },
      {
        "title": "Production deployment",
        "scenario": "Deploying vision models",
        "prompt": "Design a production deployment architecture for real-time object detection that handles [THROUGHPUT] requests per second with latency under [LATENCY]ms."
      },
      {
        "title": "Performance optimization",
        "scenario": "Optimizing vision pipelines",
        "prompt": "Analyze and optimize my computer vision inference pipeline. Current setup: [DESCRIBE_ARCHITECTURE]. Target: reduce latency by 50% while maintaining accuracy."
      }
    ],
    "output_examples": [
      {
        "input": "How do I set up a training pipeline for detecting custom objects in images?",
        "output": [
          "‚Ä¢ Prepare dataset in YOLO format (one .txt file per image with bounding box coordinates)",
          "‚Ä¢ Use Ultralytics YOLO CLI or PyTorch DataLoader with custom augmentations",
          "‚Ä¢ Start with pretrained YOLOv8 weights and fine-tune for 50-100 epochs",
          "‚Ä¢ Validate using mAP@0.5 and confusion matrix analysis",
          "‚Ä¢ Export to ONNX or TensorRT for production inference"
        ]
      },
      {
        "input": "What architecture should I use for real-time video analysis at 30 FPS?",
        "output": [
          "‚Ä¢ Consider YOLOv8n or YOLOv9 for best speed-accuracy tradeoff",
          "‚Ä¢ Use frame batching to maximize GPU utilization",
          "‚Ä¢ Implement model quantization (INT8) for 2-3x speedup",
          "‚Ä¢ Deploy with TensorRT on NVIDIA GPUs for optimal performance",
          "‚Ä¢ Add asynchronous processing with separate inference and post-processing threads"
        ]
      },
      {
        "input": "How do I optimize a vision model for edge deployment?",
        "output": [
          "‚Ä¢ Apply post-training quantization to INT8 using TensorRT or ONNX Runtime",
          "‚Ä¢ Use model pruning to remove redundant channels and layers",
          "‚Ä¢ Consider knowledge distillation to transfer accuracy to smaller model",
          "‚Ä¢ Test on target hardware early to validate performance targets",
          "‚Ä¢ Profile with torch.cuda.memory_stats() to identify bottlenecks"
        ]
      }
    ],
    "best_practices": [
      "Always start with pre-trained models and fine-tune rather than training from scratch to reduce data requirements and improve convergence",
      "Implement comprehensive data augmentation including random flips, color jitter, and mosaic augmentation for robust models",
      "Use version control for datasets, models, and training configurations to ensure reproducible experiments"
    ],
    "anti_patterns": [
      "Training from random initialization without using transfer learning - this wastes compute and requires massive datasets",
      "Skipping data quality validation - mislabeled images or inconsistent annotations severely degrade model performance",
      "Deploying models without proper monitoring for data drift and concept drift in production environments"
    ],
    "faq": [
      {
        "question": "What frameworks does this skill support?",
        "answer": "PyTorch, TensorFlow, OpenCV, Ultralytics YOLO, Detectron2, and segmentation models like SAM."
      },
      {
        "question": "Can this skill help with video analysis?",
        "answer": "Yes. The skill covers frame extraction, object tracking, and scene detection for video processing pipelines."
      },
      {
        "question": "Do I need a GPU for training?",
        "answer": "A GPU is recommended for training. For inference, CPU deployment is possible with quantized models on edge devices."
      },
      {
        "question": "How do I handle imbalanced datasets?",
        "answer": "Use class-weighted loss functions, oversampling minority classes, and focal loss to address class imbalance."
      },
      {
        "question": "What accuracy metrics should I track?",
        "answer": "mAP@0.5, mAP@0.5:0.95 for detection, IoU for segmentation, and confusion matrix for class performance."
      },
      {
        "question": "Can I deploy on cloud platforms?",
        "answer": "Yes. The skill covers deployment on AWS, GCP, Azure with Kubernetes, SageMaker, and Vertex AI integration."
      }
    ]
  }
}
