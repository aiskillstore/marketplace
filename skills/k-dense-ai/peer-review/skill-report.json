{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-21T17:36:33.523Z",
    "slug": "k-dense-ai-peer-review",
    "source_url": "https://github.com/K-Dense-AI/claude-scientific-skills/tree/main/scientific-skills/peer-review",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "3.0.0",
    "source_type": "community",
    "content_hash": "37858ec2ae061f0f55e14133387046d9eb4526376915448c3e836209a7502e54",
    "tree_hash": "9a043b9df96f4ec1b19e29cfcffa849ba98f7a95346d44fd86706246e10188e0"
  },
  "skill": {
    "name": "peer-review",
    "description": "Structured manuscript/grant review with checklist-based evaluation. Use when writing formal peer reviews with specific criteria methodology assessment, statistical validity, reporting standards compliance (CONSORT/STROBE), and constructive feedback. Best for actual review writing, manuscript revision. For evaluating claims/evidence quality use scientific-critical-thinking; for quantitative scoring frameworks use scholar-evaluation.",
    "summary": "Structured manuscript/grant review with checklist-based evaluation for scientific writing",
    "icon": "ðŸ“¦",
    "version": "1.0.0",
    "author": "K-Dense-AI",
    "license": "MIT license",
    "tags": [
      "peer-review",
      "scientific-writing",
      "methodology",
      "statistics",
      "research"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": [
      "network",
      "external_commands"
    ]
  },
  "security_audit": {
    "risk_level": "low",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "All 106 static findings are false positives. The skill is a scientific peer review documentation tool. Detected 'C2 keywords' are false positives from legitimate terms like 'command-line'. 'Weak cryptographic algorithm' references are educational content in reference materials for evaluating manuscript methodology. Backtick patterns are markdown code formatting in documentation examples. No actual malicious code execution patterns exist.",
    "risk_factor_evidence": [
      {
        "factor": "network",
        "evidence": [
          {
            "file": "references/reporting_standards.md",
            "line_start": 20,
            "line_end": 20
          },
          {
            "file": "references/reporting_standards.md",
            "line_start": 36,
            "line_end": 36
          },
          {
            "file": "references/reporting_standards.md",
            "line_start": 53,
            "line_end": 53
          },
          {
            "file": "references/reporting_standards.md",
            "line_start": 64,
            "line_end": 64
          },
          {
            "file": "references/reporting_standards.md",
            "line_start": 78,
            "line_end": 78
          },
          {
            "file": "references/reporting_standards.md",
            "line_start": 100,
            "line_end": 100
          },
          {
            "file": "references/reporting_standards.md",
            "line_start": 116,
            "line_end": 116
          },
          {
            "file": "references/reporting_standards.md",
            "line_start": 140,
            "line_end": 140
          },
          {
            "file": "references/reporting_standards.md",
            "line_start": 156,
            "line_end": 156
          },
          {
            "file": "references/reporting_standards.md",
            "line_start": 172,
            "line_end": 172
          },
          {
            "file": "references/reporting_standards.md",
            "line_start": 187,
            "line_end": 187
          },
          {
            "file": "references/reporting_standards.md",
            "line_start": 203,
            "line_end": 203
          },
          {
            "file": "references/reporting_standards.md",
            "line_start": 217,
            "line_end": 217
          },
          {
            "file": "skill-report.json",
            "line_start": 6,
            "line_end": 6
          }
        ]
      },
      {
        "factor": "external_commands",
        "evidence": [
          {
            "file": "SKILL.md",
            "line_start": 39,
            "line_end": 41
          },
          {
            "file": "SKILL.md",
            "line_start": 41,
            "line_end": 197
          },
          {
            "file": "SKILL.md",
            "line_start": 197,
            "line_end": 401
          },
          {
            "file": "SKILL.md",
            "line_start": 401,
            "line_end": 404
          },
          {
            "file": "SKILL.md",
            "line_start": 404,
            "line_end": 410
          },
          {
            "file": "SKILL.md",
            "line_start": 410,
            "line_end": 413
          },
          {
            "file": "SKILL.md",
            "line_start": 413,
            "line_end": 500
          },
          {
            "file": "SKILL.md",
            "line_start": 500,
            "line_end": 505
          },
          {
            "file": "SKILL.md",
            "line_start": 505,
            "line_end": 527
          },
          {
            "file": "SKILL.md",
            "line_start": 527,
            "line_end": 539
          }
        ]
      }
    ],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 4,
    "total_lines": 2229,
    "audit_model": "claude",
    "audited_at": "2026-01-21T17:36:33.523Z"
  },
  "content": {
    "user_title": "Review Scientific Manuscripts with Structured Checklists",
    "value_statement": "Researchers need systematic tools to evaluate manuscripts against rigorous methodological and reporting standards. This skill provides structured peer review workflows with checklist-based assessment for statistical rigor, reproducibility, and compliance with discipline-specific guidelines.",
    "seo_keywords": [
      "Claude",
      "Codex",
      "Claude Code",
      "peer review",
      "scientific manuscript review",
      "methodology assessment",
      "statistical validation",
      "research evaluation",
      "grant review",
      "reporting standards"
    ],
    "actual_capabilities": [
      "Conduct structured manuscript review across seven stages from initial assessment to ethical verification",
      "Evaluate statistical methods including power analysis, assumption checking, and multiple comparison corrections",
      "Assess reproducibility through data availability, code sharing, and methodological transparency",
      "Verify compliance with discipline-specific reporting guidelines (CONSORT, PRISBE, PRISMA, ARRIVE)",
      "Provide constructive feedback organized by major issues, minor issues, and line-by-line comments",
      "Review scientific presentations with visual inspection workflow"
    ],
    "limitations": [
      "Does not access external databases or verify citations in real-time",
      "Cannot evaluate image data or perform image integrity analysis",
      "Does not replace domain expert judgment for highly specialized fields",
      "Relies on provided manuscript content without access to supplementary materials"
    ],
    "use_cases": [
      {
        "title": "Journal Manuscript Review",
        "description": "Evaluate original research submissions for peer-reviewed journals. Assess methodology rigor, statistical validity, figure quality, and compliance with reporting guidelines. Generate structured review reports with major and minor comments.",
        "target_user": "Academic researchers and journal editors"
      },
      {
        "title": "Grant Proposal Assessment",
        "description": "Review grant applications for funding agencies. Evaluate innovation, methodology soundness, feasibility, and statistical power. Provide feedback on weaknesses and required clarifications before submission.",
        "target_user": "Grant reviewers and funding agency staff"
      },
      {
        "title": "Preprint Quality Check",
        "description": "Assess preprint manuscripts for methodological quality and reproducibility concerns. Identify statistical issues, missing controls, and potential problems before formal journal submission.",
        "target_user": "Researchers reviewing preprints on platforms like bioRxiv"
      }
    ],
    "prompt_templates": [
      {
        "title": "Basic Manuscript Review",
        "prompt": "Review this manuscript using the peer-review skill. Evaluate the Introduction for clarity and literature context, Methods for reproducibility and statistical rigor, Results for appropriate presentation, and Discussion for balanced conclusions. Provide a summary statement with overall recommendation and list major and minor comments.",
        "scenario": "Initial manuscript evaluation for journal submission"
      },
      {
        "title": "Statistical Methods Audit",
        "prompt": "Focus the peer review on statistical methods only. Check sample size justification, assumption verification, appropriate test selection, multiple comparison correction, and effect size reporting. List any statistical concerns with specific recommendations.",
        "scenario": "Detailed statistical validation of research methods"
      },
      {
        "title": "Reporting Standards Compliance",
        "prompt": "Review this manuscript for compliance with [CONSORT/STROBE/PRISMA/ARRIVE] reporting guidelines. Check that all required elements are present and adequately described. Note any missing or incomplete checklist items.",
        "scenario": "Verification of discipline-specific reporting standards"
      },
      {
        "title": "Comprehensive Multi-Stage Review",
        "prompt": "Conduct a full peer review following all seven stages: Initial Assessment, Detailed Section Review, Methodological Rigor, Reproducibility Assessment, Figure Evaluation, Ethical Review, and Writing Quality. Provide a complete structured report with summary, major comments, minor comments, and author questions.",
        "scenario": "Complete manuscript evaluation with all review stages"
      }
    ],
    "output_examples": [
      {
        "input": "Review a methods paper on a new CRISPR protocol",
        "output": [
          "SUMMARY: This manuscript describes a novel CRISPR-Cas9 protocol with improved specificity. The method is well-characterized and includes appropriate controls. Recommend: Minor Revisions.",
          "MAJOR COMMENTS:",
          "1. Power analysis for sample size justification is missing in Methods.",
          "2. Comparison to existing gold-standard methods should be included.",
          "MINOR COMMENTS: Figure 3 legend should define error bars (SD vs SEM)."
        ]
      },
      {
        "input": "Review a clinical trial report for CONSORT compliance",
        "output": [
          "CONSORT COMPLIANCE CHECK:",
          "- Trial design described: YES",
          "- Sample size calculation: PARTIAL (missing effect size assumption)",
          "- Participant flow diagram: MISSING",
          "- Baseline characteristics: COMPLETE",
          "- Adverse events: NOT ADDRESSED",
          "Key recommendation: Add CONSORT flow diagram and adverse events section."
        ]
      },
      {
        "input": "Review a neuroscience fMRI study",
        "output": [
          "METHODOLOGY ASSESSMENT:",
          "Strengths: Pre-registration documented, blinding implemented, multiple comparison correction applied (FDR).",
          "Concerns: Scanner sequence parameters not fully specified, no sample size justification, raw data not deposited.",
          "RECOMMENDATION: Major revisions required before publication."
        ]
      }
    ],
    "best_practices": [
      "Always verify statistical assumptions rather than accepting reported p-values at face value. Request raw data when necessary to confirm proper analysis.",
      "Distinguish between major issues affecting validity and minor issues affecting clarity. Prioritize feedback to help authors improve rather than simply criticize.",
      "Use reporting guidelines (CONSORT, STROBE, PRISMA) as checklists to ensure comprehensive evaluation and consistent standards across reviews."
    ],
    "anti_patterns": [
      "Avoid vague criticism without specific examples. Always reference specific sections, figures, or line numbers to make feedback actionable.",
      "Do not request additional experiments beyond the scope of the study without clear justification for how they would change conclusions.",
      "Avoid personal judgments about the authors. Focus evaluation on the science, methodology, and reporting quality only."
    ],
    "faq": [
      {
        "question": "What manuscript types can this skill review?",
        "answer": "This skill supports original research articles, reviews and meta-analyses, methods papers, short reports, preprints, and grant proposals across scientific disciplines."
      },
      {
        "question": "Does this skill verify citations or check for plagiarism?",
        "answer": "No. This skill evaluates methodology, statistics, and reporting standards. Citation verification and plagiarism detection require access to external databases not available here."
      },
      {
        "question": "Can this skill review specialized fields like clinical trials or genomics?",
        "answer": "Yes. The skill includes reference materials for discipline-specific guidelines including CONSORT for trials, STROBE for observational studies, and MIAME/MINSEQE for genomics."
      },
      {
        "question": "How does this skill handle statistical expertise?",
        "answer": "The skill provides structured checklists for common statistical issues but cannot replace domain expert judgment for highly specialized analyses."
      },
      {
        "question": "Does this skill access external data repositories?",
        "answer": "No. The skill reviews only the manuscript content provided. Data availability statements are evaluated but not verified against actual repositories."
      },
      {
        "question": "What reporting guidelines are supported?",
        "answer": "The skill references CONSORT (trials), STROBE (observational), PRISMA (reviews), ARRIVE (animal research), MIAME (microarrays), MINSEQE (sequencing), and others in the reporting standards reference."
      }
    ]
  },
  "file_structure": [
    {
      "name": "references",
      "type": "dir",
      "path": "references",
      "children": [
        {
          "name": "common_issues.md",
          "type": "file",
          "path": "references/common_issues.md",
          "lines": 553
        },
        {
          "name": "reporting_standards.md",
          "type": "file",
          "path": "references/reporting_standards.md",
          "lines": 291
        }
      ]
    },
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md",
      "lines": 571
    }
  ]
}
