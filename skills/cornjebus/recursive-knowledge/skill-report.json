{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-16T23:14:40.273Z",
    "slug": "cornjebus-recursive-knowledge",
    "source_url": "https://github.com/Cornjebus/rlm-replication-study/tree/main/recursive-knowledge/",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "3.0.0",
    "source_type": "community",
    "content_hash": "b40c2d5b2aade8f97818ed96a133d3fdc87dd922559e1d172eafadfae0c7986a",
    "tree_hash": "2feb63c3512d8ba3aabb595476b2ed74cd0f46e25b5b5a3ffc9c9684f5f398c2"
  },
  "skill": {
    "name": "recursive-knowledge",
    "description": "Process large document corpora (1000+ docs, millions of tokens) through knowledge graph construction and stateful multi-hop reasoning. Use when (1) User provides a large corpus exceeding context limits, (2) Questions require connections across multiple documents, (3) Multi-hop reasoning needed for complex queries, (4) User wants persistent queryable knowledge from documents. Replaces brute-force document stuffing with intelligent graph traversal.",
    "summary": "Process large document corpora (1000+ docs, millions of tokens) through knowledge graph construction...",
    "icon": "ðŸ”—",
    "version": "1.0.0",
    "author": "Cornjebus",
    "license": "MIT",
    "category": "data",
    "tags": [
      "knowledge-graph",
      "document-analysis",
      "multi-hop-reasoning",
      "corpus-processing",
      "entity-extraction"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": [
      "scripts",
      "filesystem"
    ]
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "Legitimate knowledge graph processing skill. Static findings are false positives triggered by markdown formatting (backticks), SHA-256 for ID generation, and standard filesystem operations. No network calls by default. LLM integration requires explicit USE_LLM=1 opt-in. All operations are appropriate for document corpus analysis.",
    "risk_factor_evidence": [
      {
        "factor": "scripts",
        "evidence": [
          {
            "file": "scripts/index_corpus.py",
            "line_start": 1,
            "line_end": 476
          },
          {
            "file": "scripts/query.py",
            "line_start": 1,
            "line_end": 439
          },
          {
            "file": "scripts/graph_ops.py",
            "line_start": 1,
            "line_end": 246
          }
        ]
      },
      {
        "factor": "filesystem",
        "evidence": [
          {
            "file": "scripts/index_corpus.py",
            "line_start": 35,
            "line_end": 39
          },
          {
            "file": "scripts/graph_ops.py",
            "line_start": 171,
            "line_end": 195
          }
        ]
      }
    ],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 8,
    "total_lines": 1925,
    "audit_model": "claude",
    "audited_at": "2026-01-16T23:14:40.273Z"
  },
  "content": {
    "user_title": "Build Knowledge Graphs from Documents",
    "value_statement": "Large document sets exceed context limits. Process corpora into knowledge graphs for efficient multi-hop reasoning and persistent querying across thousands of documents.",
    "seo_keywords": [
      "recursive knowledge",
      "knowledge graph",
      "multi-hop reasoning",
      "entity extraction",
      "document corpus",
      "Claude",
      "Codex",
      "Claude Code",
      "relationship extraction",
      "graph traversal"
    ],
    "actual_capabilities": [
      "Extract entities and relationships from document collections",
      "Build persistent knowledge graphs in JSON format",
      "Execute multi-hop queries with stateful traversal",
      "Track confidence scores for query results",
      "Prevent redundant exploration with visited node tracking",
      "Synthesize answers from multiple corroborating sources"
    ],
    "limitations": [
      "Does not perform OCR on scanned images",
      "Requires documents to be in text format (txt, md, json)",
      "Does not index new documents automatically after initial indexing",
      "Limited entity extraction quality without LLM integration"
    ],
    "use_cases": [
      {
        "target_user": "Researchers",
        "title": "Analyze Academic Papers",
        "description": "Build searchable knowledge bases from research collections to trace ideas across publications."
      },
      {
        "target_user": "Legal Professionals",
        "title": "Connect Case Documents",
        "description": "Map relationships between entities across large case files for comprehensive discovery."
      },
      {
        "target_user": "Technical Writers",
        "title": "Cross-Reference Documentation",
        "description": "Index product documentation to find connections across thousands of markdown files."
      }
    ],
    "prompt_templates": [
      {
        "title": "Basic Indexing",
        "scenario": "Index new documents",
        "prompt": "Index the documents in /path/to/docs into a knowledge graph. Use python3 scripts/index_corpus.py --input /path/to/docs --output /path/to/graph.json --verbose"
      },
      {
        "title": "Entity Query",
        "scenario": "Find specific entities",
        "prompt": "Find all entities of type person in the knowledge graph. Query the graph using python3 scripts/query.py --graph graph.json --query \"Who are the key people mentioned?\""
      },
      {
        "title": "Multi-Hop Query",
        "scenario": "Trace relationships",
        "prompt": "Find who created the concept mentioned in document A and trace connections to organizations. Use multi-hop traversal with depth 4."
      },
      {
        "title": "Confidence Filtering",
        "scenario": "Filter high-confidence answers",
        "prompt": "Query the knowledge graph with confidence threshold 0.85 and minimum 3 corroborating sources. Return only high-confidence findings."
      }
    ],
    "output_examples": [
      {
        "input": "Query the knowledge graph: Who worked with John Smith on Project Alpha?",
        "output": [
          "Alice appears in both paths: John Smith â†’ works_with â†’ Alice and Project Alpha â†’ has_member â†’ Alice",
          "Confidence: 92% (3 corroborating sources)",
          "Sources: doc_abc123, doc_def456, doc_ghi789"
        ]
      }
    ],
    "best_practices": [
      "Index documents in text format (txt, md, json) for best extraction results",
      "Use confidence thresholds appropriate to your accuracy requirements",
      "Run verbose mode during initial indexing to monitor progress",
      "Update graphs incrementally when adding new documents to preserve existing knowledge"
    ],
    "anti_patterns": [
      "Do not use for single documents under 50k tokens where direct context would work",
      "Avoid queries that require real-time data rather than static corpus analysis",
      "Do not ignore confidence scores when making decisions based on results",
      "Avoid querying without sufficient corroborating sources for critical questions"
    ],
    "faq": [
      {
        "question": "What document formats are supported?",
        "answer": "Plain text files (.txt), Markdown (.md), and JSON (.json) files are supported for indexing."
      },
      {
        "question": "How many documents can this process?",
        "answer": "Designed for 1000+ documents and millions of tokens. Performance depends on available memory for graph storage."
      },
      {
        "question": "Can I use this with Claude API for extraction?",
        "answer": "Set USE_LLM=1 environment variable to enable Claude API calls for improved entity and relationship extraction."
      },
      {
        "question": "Is my data sent to external servers?",
        "answer": "No network calls are made by default. LLM integration requires explicit configuration via environment variable."
      },
      {
        "question": "Why do queries stop before exploring all nodes?",
        "answer": "Query engine uses confidence thresholds and corroboration requirements for early termination. Adjust parameters if more exploration is needed."
      },
      {
        "question": "How does this differ from simple search?",
        "answer": "Knowledge graphs capture relationships between entities, enabling multi-hop queries that connect information across multiple documents."
      }
    ]
  },
  "file_structure": [
    {
      "name": "references",
      "type": "dir",
      "path": "references",
      "children": [
        {
          "name": "graph-schema.md",
          "type": "file",
          "path": "references/graph-schema.md",
          "lines": 74
        },
        {
          "name": "state-management.md",
          "type": "file",
          "path": "references/state-management.md",
          "lines": 162
        },
        {
          "name": "traversal-patterns.md",
          "type": "file",
          "path": "references/traversal-patterns.md",
          "lines": 153
        }
      ]
    },
    {
      "name": "scripts",
      "type": "dir",
      "path": "scripts",
      "children": [
        {
          "name": "graph_ops.py",
          "type": "file",
          "path": "scripts/graph_ops.py",
          "lines": 246
        },
        {
          "name": "index_corpus.py",
          "type": "file",
          "path": "scripts/index_corpus.py",
          "lines": 476
        },
        {
          "name": "query.py",
          "type": "file",
          "path": "scripts/query.py",
          "lines": 439
        }
      ]
    },
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md",
      "lines": 114
    }
  ]
}
