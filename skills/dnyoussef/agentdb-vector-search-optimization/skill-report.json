{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-17T04:33:06.271Z",
    "slug": "dnyoussef-agentdb-vector-search-optimization",
    "source_url": "https://github.com/DNYoussef/ai-chrome-extension/tree/main/.claude/skills/agentdb/when-optimizing-vector-search-use-agentdb-optimization",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "3.0.0",
    "source_type": "community",
    "content_hash": "32a2b070dd0f8afffd87442e60ef97f7d64fe4c93620faf7b5d12915de0f1985",
    "tree_hash": "c8212017ee47b83423b6da9d006ad682093b0d9fef1340b6ca1369f0ed77519d"
  },
  "skill": {
    "name": "agentdb-vector-search-optimization",
    "description": "Optimize AgentDB vector search performance using quantization for 4-32x memory reduction, HNSW indexing for 150x faster search, caching, and batch operations for scaling to millions of vectors.",
    "summary": "Optimize AgentDB vector search performance using quantization for 4-32x memory reduction, HNSW index...",
    "icon": "ðŸš€",
    "version": "1.0.0",
    "author": "DNYoussef",
    "license": "MIT",
    "category": "agentdb",
    "tags": [
      "agentdb",
      "optimization",
      "vector-search",
      "quantization",
      "performance"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": [
      "external_commands",
      "network",
      "filesystem"
    ]
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "Documentation-only skill containing process guides and code examples. No executable code, network calls, file system access, or external commands detected. All 24 static findings are false positives - the scanner misidentified TypeScript template literals as shell backticks, SHA256 hashes as C2 keywords, and URL strings as network calls.",
    "risk_factor_evidence": [
      {
        "factor": "external_commands",
        "evidence": [
          {
            "file": "PROCESS.md",
            "line_start": 5,
            "line_end": 22
          },
          {
            "file": "PROCESS.md",
            "line_start": 22,
            "line_end": 26
          },
          {
            "file": "PROCESS.md",
            "line_start": 26,
            "line_end": 36
          },
          {
            "file": "PROCESS.md",
            "line_start": 36,
            "line_end": 40
          },
          {
            "file": "PROCESS.md",
            "line_start": 40,
            "line_end": 49
          },
          {
            "file": "PROCESS.md",
            "line_start": 49,
            "line_end": 53
          },
          {
            "file": "PROCESS.md",
            "line_start": 53,
            "line_end": 59
          },
          {
            "file": "PROCESS.md",
            "line_start": 59,
            "line_end": 63
          },
          {
            "file": "PROCESS.md",
            "line_start": 63,
            "line_end": 71
          },
          {
            "file": "README.md",
            "line_start": 14,
            "line_end": 17
          },
          {
            "file": "SKILL.md",
            "line_start": 80,
            "line_end": 103
          }
        ]
      },
      {
        "factor": "network",
        "evidence": [
          {
            "file": "skill-report.json",
            "line_start": 6,
            "line_end": 6
          },
          {
            "file": "SKILL.md",
            "line_start": 132,
            "line_end": 132
          }
        ]
      },
      {
        "factor": "filesystem",
        "evidence": [
          {
            "file": "skill-report.json",
            "line_start": 6,
            "line_end": 6
          }
        ]
      }
    ],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 5,
    "total_lines": 474,
    "audit_model": "claude",
    "audited_at": "2026-01-17T04:33:06.271Z"
  },
  "content": {
    "user_title": "Optimize AgentDB vector search performance",
    "value_statement": "Vector search becomes slow and memory-intensive at scale. This skill provides a systematic 5-phase approach to achieve 4-32x memory reduction and 150x faster search using quantization, HNSW indexing, and intelligent caching.",
    "seo_keywords": [
      "AgentDB optimization",
      "vector search",
      "quantization",
      "HNSW indexing",
      "Claude Code",
      "Claude",
      "Codex",
      "performance tuning",
      "vector database",
      "embedding search"
    ],
    "actual_capabilities": [
      "Measure baseline performance metrics including latency, throughput, and memory usage",
      "Apply product, scalar, or binary quantization for 4-32x memory reduction",
      "Implement HNSW indexing for 150x faster search speed",
      "Configure query caching with LRU and TTL eviction policies",
      "Validate accuracy remains above 95% after optimization",
      "Generate performance benchmarks comparing before and after results"
    ],
    "limitations": [
      "Requires AgentDB installation and basic familiarity with vector databases",
      "Binary quantization at 32x compression may reduce search precision",
      "HNSW index building requires memory overhead during construction phase",
      "Optimal parameters depend on specific dataset characteristics and require tuning"
    ],
    "use_cases": [
      {
        "target_user": "ML Engineers",
        "title": "Scale vector databases",
        "description": "Optimize production vector databases to handle millions of embeddings efficiently with reduced infrastructure costs."
      },
      {
        "target_user": "AI Application Developers",
        "title": "Speed up RAG systems",
        "description": "Accelerate retrieval-augmented generation systems with faster vector similarity search and caching layers."
      },
      {
        "target_user": "Data Infrastructure Teams",
        "title": "Reduce memory costs",
        "description": "Achieve significant memory reduction while maintaining search quality for large-scale vector workloads."
      }
    ],
    "prompt_templates": [
      {
        "title": "Quick Optimization",
        "scenario": "Start basic optimization",
        "prompt": "When optimizing vector search, apply quantization and HNSW indexing to reduce memory by 4x and speed up search by 10x."
      },
      {
        "title": "Measure Baseline",
        "scenario": "Establish performance baseline",
        "prompt": "When optimizing vector search, first measure baseline metrics including p95 latency, memory usage, and throughput for 1000 queries."
      },
      {
        "title": "Configure Quantization",
        "scenario": "Apply compression",
        "prompt": "When optimizing vector search, configure product quantization with codebook size 256 and 8 subvectors to achieve 4x compression while maintaining accuracy above 95%."
      },
      {
        "title": "Full Optimization",
        "scenario": "Complete optimization workflow",
        "prompt": "When optimizing vector search for production, execute the full 5-phase workflow: baseline measurement, quantization, HNSW indexing, caching setup, and comprehensive benchmarking with before-after comparison."
      }
    ],
    "output_examples": [
      {
        "input": "Optimize my AgentDB vector database with 1M embeddings of 1536 dimensions",
        "output": [
          "Phase 1: Baseline - Measured 45ms p95 latency, 64GB memory usage",
          "Phase 2: Quantization - Applied 4x compression, accuracy 96.2%",
          "Phase 3: HNSW Index - Built index with M=16, efConstruction=200",
          "Phase 4: Caching - Configured LRU cache with 10K entries, 1hr TTL",
          "Phase 5: Results - 16GB memory (4x reduction), 0.3ms latency (150x faster), 72% cache hit rate"
        ]
      },
      {
        "input": "My RAG system with 10M embeddings is running slowly",
        "output": [
          "Identified bottleneck: Search latency 120ms p95",
          "Applied scalar quantization: 4x memory reduction",
          "Built HNSW index: 85x speedup achieved",
          "Added query caching: 68% hit rate",
          "Final result: 15ms latency, 75% memory reduction"
        ]
      }
    ],
    "best_practices": [
      "Always measure baseline performance before applying optimizations to establish improvement benchmarks",
      "Start with product quantization (4x compression) before trying aggressive binary quantization to balance memory savings and accuracy",
      "Monitor cache hit rates and adjust TTL/eviction policies based on query patterns for optimal performance"
    ],
    "anti_patterns": [
      "Skipping baseline measurement makes it impossible to validate improvement claims or detect regressions",
      "Applying aggressive 32x binary quantization without accuracy validation destroys search quality",
      "Ignoring cache warm-up period after deployment causes cold-start latency spikes for initial queries"
    ],
    "faq": [
      {
        "question": "Which quantization method should I start with?",
        "answer": "Start with product quantization for 4x compression and minimal accuracy loss. Move to binary quantization only if you need extreme compression."
      },
      {
        "question": "What HNSW parameters optimize speed?",
        "answer": "Increase M (16-64) for higher recall and efSearch (100-500) for faster queries. Higher values increase memory but improve accuracy."
      },
      {
        "question": "How do I integrate with existing AgentDB code?",
        "answer": "Import Quantization and QueryCache from agentdb-optimization package and apply before creating your index or querying."
      },
      {
        "question": "Is my data safe during optimization?",
        "answer": "Yes. Quantization creates compressed copies. Original vectors remain intact until you explicitly replace them."
      },
      {
        "question": "Why is accuracy dropping after optimization?",
        "answer": "Check compression ratio (lower is more accurate), validate codebook training on representative data, and adjust subvector count."
      },
      {
        "question": "How does this compare to other vector databases?",
        "answer": "AgentDB optimization achieves comparable results to specialized solutions. HNSW indexing provides similar speedups as pgvector and Milvus."
      }
    ]
  },
  "file_structure": [
    {
      "name": "process-diagram.gv",
      "type": "file",
      "path": "process-diagram.gv",
      "lines": 20
    },
    {
      "name": "PROCESS.md",
      "type": "file",
      "path": "PROCESS.md",
      "lines": 78
    },
    {
      "name": "README.md",
      "type": "file",
      "path": "README.md",
      "lines": 50
    },
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md",
      "lines": 133
    }
  ]
}
