{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-17T04:40:52.518Z",
    "slug": "dnyoussef-when-reviewing-code-comprehensively-use-code-review-assistant",
    "source_url": "https://github.com/DNYoussef/ai-chrome-extension/tree/main/.claude/skills/testing-quality/when-reviewing-code-comprehensively-use-code-review-assistant",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "3.0.0",
    "source_type": "community",
    "content_hash": "e6b0aa011f58aa9d0ab51e8465010a9254f1c36266a345fd73db3076b9c28c0a",
    "tree_hash": "c8ce96b68a1a79ba455bb6b068a9f2d6bf53a3bc18cd5872f9e38fc554e00c41"
  },
  "skill": {
    "name": "when-reviewing-code-comprehensively-use-code-review-assistant",
    "description": "Comprehensive PR review with multi-agent swarm specialization for security, performance, style, tests, and documentation",
    "summary": "Comprehensive PR review with multi-agent swarm specialization for security, performance, style, test...",
    "icon": "üîç",
    "version": "1.0.0",
    "author": "DNYoussef",
    "license": "MIT",
    "category": "testing-quality",
    "tags": [
      "code-review",
      "multi-agent",
      "security",
      "performance",
      "testing"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": [
      "scripts",
      "network",
      "filesystem",
      "env_access",
      "external_commands"
    ]
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "Documentation-only skill describing code review process. All 307 static findings are false positives - backticks are markdown code formatting, not shell execution. Shell commands documented are legitimate tooling (eslint, npm audit, gitleaks). The skill orchestrates security scanning, performance analysis, style validation, and test coverage review using claude-flow.",
    "risk_factor_evidence": [
      {
        "factor": "scripts",
        "evidence": []
      },
      {
        "factor": "network",
        "evidence": []
      },
      {
        "factor": "filesystem",
        "evidence": []
      },
      {
        "factor": "env_access",
        "evidence": []
      },
      {
        "factor": "external_commands",
        "evidence": []
      }
    ],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 5,
    "total_lines": 2140,
    "audit_model": "claude",
    "audited_at": "2026-01-17T04:40:52.518Z"
  },
  "content": {
    "user_title": "Review code with multi-agent swarm",
    "value_statement": "Manual code reviews are slow and inconsistent. This skill orchestrates 4 specialized AI agents that analyze pull requests in parallel for security vulnerabilities, performance bottlenecks, code style issues, test coverage gaps, and documentation completeness with merge readiness scoring.",
    "seo_keywords": [
      "code review assistant",
      "multi-agent code review",
      "Claude Code",
      "Claude",
      "Codex",
      "security review",
      "performance analysis",
      "test coverage",
      "pull request review",
      "automated code review"
    ],
    "actual_capabilities": [
      "Orchestrates 4 specialized agents for security, performance, style, testing, and documentation review",
      "Detects OWASP Top 10 vulnerabilities, SQL injection, XSS, and hardcoded secrets",
      "Identifies performance bottlenecks including N+1 queries and blocking operations",
      "Validates ESLint, Prettier, and TypeScript compliance with auto-fix suggestions",
      "Measures test coverage against configurable thresholds and reports quality metrics",
      "Calculates merge readiness score and generates actionable fix recommendations"
    ],
    "limitations": [
      "Requires claude-flow and npm tooling installed to execute commands",
      "Cannot fix complex issues automatically (only style violations are auto-fixable)",
      "Review quality depends on code complexity and testability of the codebase",
      "External security tools (npm audit, gitleaks) required for comprehensive scans"
    ],
    "use_cases": [
      {
        "target_user": "Engineering teams",
        "title": "PR quality gate",
        "description": "Run automated reviews on every pull request to catch issues before manual review"
      },
      {
        "target_user": "Security engineers",
        "title": "Vulnerability detection",
        "description": "Scan code for OWASP violations, hardcoded secrets, and authentication issues"
      },
      {
        "target_user": "Tech leads",
        "title": "Code quality tracking",
        "description": "Track test coverage, lint errors, and documentation completeness across releases"
      }
    ],
    "prompt_templates": [
      {
        "title": "Quick PR review",
        "scenario": "Review a specific PR",
        "prompt": "Use the code-review-assistant skill to review PR #123 for security issues, performance problems, and test coverage gaps"
      },
      {
        "title": "Full analysis",
        "scenario": "Comprehensive review",
        "prompt": "Run a comprehensive code review on this pull request covering all 5 dimensions. Report the merge readiness score and any blocking issues"
      },
      {
        "title": "Security focus",
        "scenario": "Security audit",
        "prompt": "Run only the security review phase. Check for OWASP violations, hardcoded secrets, SQL injection, and authentication issues"
      },
      {
        "title": "CI integration",
        "scenario": "Automated CI review",
        "prompt": "Execute the full code review swarm with CI/CD integration. Generate the merge readiness report and fail the build if score is below 80"
      }
    ],
    "output_examples": [
      {
        "input": "Review PR #456 with the code-review-assistant skill",
        "output": [
          "Overall Score: 73.5/100 - Changes Required",
          "Security: 68/100 (2 critical, 4 high issues)",
          "Performance: 72/100 (2 P0 bottlenecks)",
          "Style: 85/100 (23 auto-fixable violations)",
          "Testing: 65/100 (15% below coverage target)",
          "Documentation: 78/100 (4 undocumented endpoints)",
          "Merge Approved: No - 4 blocking issues must be fixed first"
        ]
      },
      {
        "input": "Run a quick security scan on this branch",
        "output": [
          "Security Scan Results",
          "Critical: 0 issues found",
          "High: 1 hardcoded API key in config/production.js:12",
          "Medium: 3 insecure dependency versions",
          "Auto-fix available: Move API key to environment variable"
        ]
      }
    ],
    "best_practices": [
      "Run reviews early in the PR cycle to catch issues before manual review",
      "Apply auto-fixes first (style violations) then address complex issues manually",
      "Set appropriate thresholds based on project criticality (80 for critical systems, 70 for utilities)",
      "Integrate with CI/CD to make reviews mandatory before merge"
    ],
    "anti_patterns": [
      "Waiting until merge time to run reviews - catch issues early in the PR cycle",
      "Ignoring low scores without investigating root causes or adjusting thresholds",
      "Using default thresholds for all projects without considering criticality",
      "Not integrating with CI/CD - reviews become optional and inconsistently applied"
    ],
    "faq": [
      {
        "question": "What AI tools support this skill?",
        "answer": "Compatible with Claude, Claude Code, and Codex for orchestrating multi-agent code reviews."
      },
      {
        "question": "How is the merge readiness score calculated?",
        "answer": "Weighted average: Security 30%, Performance 25%, Style 15%, Testing 20%, Docs 10%. Merge approved when score is 80+ with zero blocking issues."
      },
      {
        "question": "Can this skill integrate with CI/CD pipelines?",
        "answer": "Yes. Includes GitHub Actions workflow example that runs on pull requests and fails the build if score falls below the threshold."
      },
      {
        "question": "Is my code data sent to external services?",
        "answer": "Code analysis runs locally using your existing tools. No code is sent beyond your configured AI tool and local development environment."
      },
      {
        "question": "Why did the review time out on my large PR?",
        "answer": "Large PRs may exceed default timeout. Increase REVIEW_TIMEOUT environment variable or review specific paths using the --files flag."
      },
      {
        "question": "How is this different from standard linting tools?",
        "answer": "Linting checks syntax and style. This skill provides comprehensive analysis including security vulnerabilities, performance bottlenecks, test coverage gaps, and documentation completeness with agent-powered insights."
      }
    ]
  },
  "file_structure": [
    {
      "name": "process-diagram.gv",
      "type": "file",
      "path": "process-diagram.gv",
      "lines": 195
    },
    {
      "name": "PROCESS.md",
      "type": "file",
      "path": "PROCESS.md",
      "lines": 661
    },
    {
      "name": "README.md",
      "type": "file",
      "path": "README.md",
      "lines": 102
    },
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md",
      "lines": 985
    }
  ]
}
