{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-17T05:22:16.567Z",
    "slug": "dnyoussef-sop-code-review",
    "source_url": "https://github.com/DNYoussef/ai-chrome-extension/tree/main/.claude/skills/sop-code-review",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "3.0.0",
    "source_type": "community",
    "content_hash": "5ebbd7d541a1601b8a3f5c9ca8d93e7930453487591ccdd3bf571272e9de4895",
    "tree_hash": "ce7cf579be4846bf33919b1385191070747eb0938b734e49073b78d070b76653"
  },
  "skill": {
    "name": "sop-code-review",
    "description": "Comprehensive code review workflow coordinating quality, security, performance, and documentation reviewers. 4-hour timeline for thorough multi-agent review.",
    "summary": "Comprehensive code review workflow coordinating quality, security, performance, and documentation re...",
    "icon": "üîç",
    "version": "1.0.0",
    "author": "DNYoussef",
    "license": "MIT",
    "category": "coding",
    "tags": [
      "code-review",
      "quality-assurance",
      "security",
      "multi-agent",
      "workflow"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": [
      "network",
      "filesystem",
      "external_commands"
    ]
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "Pure documentation skill containing only workflow instructions and prompt templates. No executable code, scripts, file system access, network calls, or command execution capabilities. The static findings are all false positives: JavaScript template literals were misidentified as shell backticks, metadata fields were flagged as hardcoded URLs, and documentation text was misclassified as cryptographic algorithms.",
    "risk_factor_evidence": [
      {
        "factor": "network",
        "evidence": [
          {
            "file": "skill-report.json",
            "line_start": 6,
            "line_end": 6
          }
        ]
      },
      {
        "factor": "filesystem",
        "evidence": [
          {
            "file": "skill-report.json",
            "line_start": 6,
            "line_end": 6
          }
        ]
      },
      {
        "factor": "external_commands",
        "evidence": [
          {
            "file": "SKILL.md",
            "line_start": 26,
            "line_end": 36
          },
          {
            "file": "SKILL.md",
            "line_start": 44,
            "line_end": 46
          },
          {
            "file": "SKILL.md",
            "line_start": 54,
            "line_end": 56
          },
          {
            "file": "SKILL.md",
            "line_start": 64,
            "line_end": 66
          },
          {
            "file": "SKILL.md",
            "line_start": 74,
            "line_end": 79
          },
          {
            "file": "SKILL.md",
            "line_start": 84,
            "line_end": 87
          },
          {
            "file": "SKILL.md",
            "line_start": 87,
            "line_end": 102
          },
          {
            "file": "SKILL.md",
            "line_start": 102,
            "line_end": 105
          },
          {
            "file": "SKILL.md",
            "line_start": 128,
            "line_end": 130
          },
          {
            "file": "SKILL.md",
            "line_start": 153,
            "line_end": 155
          },
          {
            "file": "SKILL.md",
            "line_start": 178,
            "line_end": 180
          },
          {
            "file": "SKILL.md",
            "line_start": 203,
            "line_end": 205
          },
          {
            "file": "SKILL.md",
            "line_start": 227,
            "line_end": 231
          },
          {
            "file": "SKILL.md",
            "line_start": 246,
            "line_end": 247
          },
          {
            "file": "SKILL.md",
            "line_start": 247,
            "line_end": 262
          },
          {
            "file": "SKILL.md",
            "line_start": 262,
            "line_end": 264
          },
          {
            "file": "SKILL.md",
            "line_start": 273,
            "line_end": 276
          },
          {
            "file": "SKILL.md",
            "line_start": 285,
            "line_end": 288
          },
          {
            "file": "SKILL.md",
            "line_start": 296,
            "line_end": 299
          },
          {
            "file": "SKILL.md",
            "line_start": 309,
            "line_end": 310
          },
          {
            "file": "SKILL.md",
            "line_start": 310,
            "line_end": 326
          },
          {
            "file": "SKILL.md",
            "line_start": 326,
            "line_end": 328
          },
          {
            "file": "SKILL.md",
            "line_start": 351,
            "line_end": 354
          },
          {
            "file": "SKILL.md",
            "line_start": 363,
            "line_end": 367
          },
          {
            "file": "SKILL.md",
            "line_start": 375,
            "line_end": 377
          },
          {
            "file": "SKILL.md",
            "line_start": 385,
            "line_end": 387
          },
          {
            "file": "SKILL.md",
            "line_start": 395,
            "line_end": 397
          },
          {
            "file": "SKILL.md",
            "line_start": 397,
            "line_end": 493
          },
          {
            "file": "SKILL.md",
            "line_start": 493,
            "line_end": 498
          },
          {
            "file": "SKILL.md",
            "line_start": 503,
            "line_end": 504
          }
        ]
      }
    ],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 2,
    "total_lines": 690,
    "audit_model": "claude",
    "audited_at": "2026-01-17T05:22:16.567Z"
  },
  "content": {
    "user_title": "Review code with specialized agents",
    "value_statement": "Manual code reviews are time-consuming and inconsistent. This workflow coordinates multiple specialized AI agents to perform thorough reviews across quality, security, performance, architecture, and documentation in parallel.",
    "seo_keywords": [
      "code review",
      "Claude Code",
      "quality assurance",
      "security review",
      "multi-agent",
      "automated review",
      "Codex",
      "software testing",
      "static analysis",
      "developer tools"
    ],
    "actual_capabilities": [
      "Runs automated checks (linting, tests, coverage, build validation)",
      "Spawns parallel specialized reviewers (quality, security, performance, architecture, docs)",
      "Aggregates findings and categorizes by severity",
      "Generates final review summary with approval recommendations",
      "Notifies PR authors with actionable feedback"
    ],
    "limitations": [
      "Requires MCP servers for agent orchestration (ruv-swarm)",
      "Cannot directly modify code or merge pull requests",
      "Reviews are limited to code patterns, not runtime behavior",
      "Depends on existing test suites for coverage analysis"
    ],
    "use_cases": [
      {
        "target_user": "Development teams",
        "title": "PR code review",
        "description": "Automate comprehensive reviews for pull requests before merge"
      },
      {
        "target_user": "Security engineers",
        "title": "Security vulnerability scan",
        "description": "Identify OWASP Top 10 vulnerabilities and security issues in code"
      },
      {
        "target_user": "Tech leads",
        "title": "Architecture assessment",
        "description": "Evaluate code changes for design consistency and scalability"
      }
    ],
    "prompt_templates": [
      {
        "title": "Quick PR review",
        "scenario": "Review a single pull request",
        "prompt": "Run sop-code-review on PR #123 in repository my-org/backend-api. Focus on security and performance."
      },
      {
        "title": "Security audit",
        "scenario": "Focus on security issues only",
        "prompt": "Execute the security review phase of sop-code-review for the authentication module. Check for OWASP vulnerabilities."
      },
      {
        "title": "Full integration review",
        "scenario": "Complete review with all specialists",
        "prompt": "Run the full sop-code-review workflow on PR #456. Include integration testing and deployment impact assessment."
      },
      {
        "title": "Architecture review",
        "scenario": "Deep architecture analysis",
        "prompt": "Run the architecture review phase for the microservices refactoring PR. Assess scalability and dependency patterns."
      }
    ],
    "output_examples": [
      {
        "input": "Review PR #789 which adds user authentication",
        "output": [
          "Automated checks: All passing (100% tests, 92% coverage)",
          "Quality Review: 4/5 stars - Clean code, minor naming suggestions",
          "Security: 2 medium issues found (input validation needed)",
          "Performance: No issues detected",
          "Architecture: Clean integration with existing auth module",
          "Documentation: 100% complete for new APIs",
          "Recommendation: Approve with changes requested"
        ]
      }
    ],
    "best_practices": [
      "Run automated checks first to filter obviously broken PRs before manual review",
      "Use parallel specialized reviewers to complete comprehensive review within 4 hours",
      "Categorize findings by severity (blocking, high, medium, low) for clear action items"
    ],
    "anti_patterns": [
      "Skipping automated checks and going straight to manual review",
      "Reviewing only one aspect (like security) without quality or performance checks",
      "Merging without addressing blocking issues identified in the review"
    ],
    "faq": [
      {
        "question": "What AI tools support this skill?",
        "answer": "Compatible with Claude, Codex, and Claude Code. Requires ruv-swarm MCP server for agent orchestration."
      },
      {
        "question": "How long does a full review take?",
        "answer": "The complete workflow runs approximately 4 hours with automated checks in 30 minutes and specialized reviews in 2 hours."
      },
      {
        "question": "Can I run only specific review phases?",
        "answer": "Yes, individual phases can be invoked separately. The workflow supports running security-only or performance-only reviews."
      },
      {
        "question": "Is my code data sent externally?",
        "answer": "No code leaves your environment. All processing happens through local AI tools and MCP servers you control."
      },
      {
        "question": "What if automated checks fail?",
        "answer": "The workflow stops and requests fixes from the PR author before proceeding with manual review phases."
      },
      {
        "question": "How is this different from single-agent review?",
        "answer": "Multiple specialized agents review different aspects simultaneously, providing deeper coverage than a single generalist agent."
      }
    ]
  },
  "file_structure": [
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md",
      "lines": 511
    }
  ]
}
