{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-17T04:31:31.026Z",
    "slug": "dnyoussef-agentdb-vector-search",
    "source_url": "https://github.com/DNYoussef/ai-chrome-extension/tree/main/.claude/skills/agentdb-vector-search",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "3.0.0",
    "source_type": "community",
    "content_hash": "1f08f3bae5dab450a7196f77063ae41dbe86589c5753b90745e1096db8c558ed",
    "tree_hash": "f0977061fd819b9e23641d07e5c4d0b3b32483b78bda4b20e1b1fa52ec6524af"
  },
  "skill": {
    "name": "agentdb-vector-search",
    "description": "Implement semantic vector search with AgentDB for intelligent document retrieval, similarity matching, and context-aware querying. Use when building RAG systems, semantic search engines, or intelligent knowledge bases.",
    "summary": "Implement semantic vector search with AgentDB for intelligent document retrieval, similarity matchin...",
    "icon": "üîç",
    "version": "1.0.0",
    "author": "DNYoussef",
    "license": "MIT",
    "category": "data",
    "tags": [
      "vector-search",
      "semantic-search",
      "rag",
      "ai",
      "database"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": [
      "network",
      "filesystem",
      "external_commands"
    ]
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "This is a documentation-only skill. All 88 static findings are false positives. The skill contains no executable code, only documentation teaching users how to use AgentDB vector search. Scanner artifacts from text pattern detection (flagging 'AgentDB' as crypto, backticks as shell execution, .db references as file access) do not represent actual security risks.",
    "risk_factor_evidence": [
      {
        "factor": "network",
        "evidence": [
          {
            "file": "skill-report.json",
            "line_start": 6,
            "line_end": 6
          },
          {
            "file": "SKILL.md",
            "line_start": 334,
            "line_end": 334
          },
          {
            "file": "SKILL.md",
            "line_start": 337,
            "line_end": 337
          }
        ]
      },
      {
        "factor": "filesystem",
        "evidence": [
          {
            "file": "skill-report.json",
            "line_start": 6,
            "line_end": 6
          }
        ]
      },
      {
        "factor": "external_commands",
        "evidence": [
          {
            "file": "SKILL.md",
            "line_start": 22,
            "line_end": 37
          },
          {
            "file": "SKILL.md",
            "line_start": 37,
            "line_end": 41
          },
          {
            "file": "SKILL.md",
            "line_start": 41,
            "line_end": 60
          },
          {
            "file": "SKILL.md",
            "line_start": 60,
            "line_end": 64
          },
          {
            "file": "SKILL.md",
            "line_start": 64,
            "line_end": 73
          },
          {
            "file": "SKILL.md",
            "line_start": 73,
            "line_end": 77
          },
          {
            "file": "SKILL.md",
            "line_start": 77,
            "line_end": 117
          },
          {
            "file": "SKILL.md",
            "line_start": 117,
            "line_end": 122
          },
          {
            "file": "SKILL.md",
            "line_start": 122,
            "line_end": 128
          },
          {
            "file": "SKILL.md",
            "line_start": 128,
            "line_end": 131
          },
          {
            "file": "SKILL.md",
            "line_start": 131,
            "line_end": 137
          },
          {
            "file": "SKILL.md",
            "line_start": 137,
            "line_end": 140
          },
          {
            "file": "SKILL.md",
            "line_start": 140,
            "line_end": 150
          },
          {
            "file": "SKILL.md",
            "line_start": 150,
            "line_end": 155
          },
          {
            "file": "SKILL.md",
            "line_start": 155,
            "line_end": 165
          },
          {
            "file": "SKILL.md",
            "line_start": 166,
            "line_end": 170
          },
          {
            "file": "SKILL.md",
            "line_start": 170,
            "line_end": 173
          },
          {
            "file": "SKILL.md",
            "line_start": 173,
            "line_end": 180
          },
          {
            "file": "SKILL.md",
            "line_start": 180,
            "line_end": 184
          },
          {
            "file": "SKILL.md",
            "line_start": 184,
            "line_end": 195
          },
          {
            "file": "SKILL.md",
            "line_start": 195,
            "line_end": 199
          },
          {
            "file": "SKILL.md",
            "line_start": 199,
            "line_end": 208
          },
          {
            "file": "SKILL.md",
            "line_start": 208,
            "line_end": 215
          },
          {
            "file": "SKILL.md",
            "line_start": 215,
            "line_end": 219
          },
          {
            "file": "SKILL.md",
            "line_start": 219,
            "line_end": 222
          },
          {
            "file": "SKILL.md",
            "line_start": 222,
            "line_end": 226
          },
          {
            "file": "SKILL.md",
            "line_start": 226,
            "line_end": 229
          },
          {
            "file": "SKILL.md",
            "line_start": 229,
            "line_end": 233
          },
          {
            "file": "SKILL.md",
            "line_start": 233,
            "line_end": 237
          },
          {
            "file": "SKILL.md",
            "line_start": 237,
            "line_end": 246
          },
          {
            "file": "SKILL.md",
            "line_start": 246,
            "line_end": 277
          },
          {
            "file": "SKILL.md",
            "line_start": 277,
            "line_end": 282
          },
          {
            "file": "SKILL.md",
            "line_start": 282,
            "line_end": 285
          },
          {
            "file": "SKILL.md",
            "line_start": 285,
            "line_end": 288
          },
          {
            "file": "SKILL.md",
            "line_start": 288,
            "line_end": 291
          },
          {
            "file": "SKILL.md",
            "line_start": 291,
            "line_end": 297
          },
          {
            "file": "SKILL.md",
            "line_start": 297,
            "line_end": 300
          },
          {
            "file": "SKILL.md",
            "line_start": 300,
            "line_end": 307
          },
          {
            "file": "SKILL.md",
            "line_start": 307,
            "line_end": 311
          },
          {
            "file": "SKILL.md",
            "line_start": 311,
            "line_end": 321
          },
          {
            "file": "SKILL.md",
            "line_start": 321,
            "line_end": 336
          },
          {
            "file": "SKILL.md",
            "line_start": 336,
            "line_end": 338
          },
          {
            "file": "SKILL.md",
            "line_start": 338,
            "line_end": 339
          }
        ]
      }
    ],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 2,
    "total_lines": 519,
    "audit_model": "claude",
    "audited_at": "2026-01-17T04:31:31.026Z"
  },
  "content": {
    "user_title": "Implement lightning-fast vector search with AgentDB",
    "value_statement": "Traditional vector databases are slow and memory-intensive. AgentDB delivers 150x faster semantic search with sub-millisecond query times and 4-32x memory reduction through advanced quantization. Build RAG systems, semantic search engines, and intelligent knowledge bases with ease.",
    "seo_keywords": [
      "vector search",
      "semantic search",
      "AgentDB",
      "RAG systems",
      "Claude Code",
      "AI search",
      "embeddings",
      "similarity matching",
      "knowledge base",
      "Claude"
    ],
    "actual_capabilities": [
      "Sub-millisecond vector search under 100 microseconds using HNSW indexing",
      "150x to 12,500x faster performance compared to traditional vector database solutions",
      "4-32x memory reduction through binary, scalar, and product quantization options",
      "Support for multiple distance metrics including cosine, euclidean, and dot product",
      "Efficient batch operations providing 500x faster bulk vector inserts",
      "MMR (Maximal Marginal Relevance) for diverse and non-redundant search results"
    ],
    "limitations": [
      "Requires Node.js 18 or higher and AgentDB v1.0.7 or later",
      "Needs OpenAI API key or compatible embedding model for text vectorization",
      "Database files must be locally accessible with no remote database server support",
      "Vector dimensions must match your embedding model output size exactly"
    ],
    "use_cases": [
      {
        "target_user": "AI developers building RAG systems",
        "title": "Retrieval Augmented Generation",
        "description": "Build RAG pipelines that retrieve relevant context from vector databases to enhance LLM responses with domain-specific knowledge."
      },
      {
        "target_user": "Enterprise teams managing document repositories",
        "title": "Intelligent Document Search",
        "description": "Replace keyword search with semantic understanding to find relevant documents based on meaning rather than exact word matches."
      },
      {
        "target_user": "Startup founders building AI products",
        "title": "Semantic Product Search",
        "description": "Power recommendation engines and similarity matching for products, content, or users in your AI-powered application."
      }
    ],
    "prompt_templates": [
      {
        "title": "Basic Vector Search",
        "scenario": "Store and search documents by similarity",
        "prompt": "Help me set up AgentDB vector search to store 1000 documents with OpenAI embeddings and find the most similar ones to a query about machine learning."
      },
      {
        "title": "RAG System Setup",
        "scenario": "Build a question-answering system",
        "prompt": "Create a RAG pipeline using AgentDB that retrieves relevant technical documentation and generates answers to user questions about our API."
      },
      {
        "title": "Performance Optimization",
        "scenario": "Optimize search speed and memory usage",
        "prompt": "Configure AgentDB with binary quantization and HNSW indexing for 100k vectors to achieve sub-100 microseconds search times with minimal memory usage."
      },
      {
        "title": "Hybrid Search Implementation",
        "scenario": "Combine vector and metadata filtering",
        "prompt": "Implement hybrid search that finds similar products by vector similarity but filters by category=electronics and price range in metadata."
      }
    ],
    "output_examples": [
      {
        "input": "Search for documents about quantum computing",
        "output": [
          "Found 5 relevant documents in 0.08ms:",
          "‚Ä¢ Quantum Computing Breakthrough (similarity: 0.92)",
          "‚Ä¢ Introduction to Quantum Algorithms (similarity: 0.89)",
          "‚Ä¢ Quantum Supremacy Explained (similarity: 0.85)",
          "‚Ä¢ Future of Quantum Technology (similarity: 0.82)",
          "‚Ä¢ Quantum vs Classical Computing (similarity: 0.79)"
        ]
      },
      {
        "input": "Set up AgentDB with 1000 vectors",
        "output": [
          "Database initialized at ./vectors.db",
          "Dimension: 1536 (OpenAI ada-002)",
          "Preset: medium (optimized for 10K-100K vectors)",
          "HNSW indexing enabled automatically",
          "Cache configured for 1000 patterns"
        ]
      },
      {
        "input": "Configure RAG pipeline with AgentDB",
        "output": [
          "RAG pipeline configured successfully:",
          "‚Ä¢ Similarity threshold set to 0.75",
          "‚Ä¢ MMR enabled with lambda=0.5",
          "‚Ä¢ Context synthesis activated",
          "‚Ä¢ Batch size: 100 vectors per insert",
          "‚Ä¢ Average retrieval time: 0.05ms"
        ]
      }
    ],
    "best_practices": [
      "Use binary quantization for 32x memory reduction when approximate results are acceptable for your use case",
      "Set similarity threshold between 0.7 and 0.8 for quality results, then adjust based on your specific domain",
      "Enable MMR (Maximal Marginal Relevance) to avoid redundant results and improve result diversity"
    ],
    "anti_patterns": [
      "Do not use example dimensions without verifying your embedding model actual output size",
      "Avoid storing raw vectors without quantization in production since this wastes 4-32x more memory",
      "Never skip similarity threshold tuning since default values may return too many or too few results"
    ],
    "faq": [
      {
        "question": "Is AgentDB compatible with my existing embedding models?",
        "answer": "Yes, AgentDB works with any embedding model. Match vector dimensions when initializing database (1536 for OpenAI, 768 for sentence-transformers, etc)."
      },
      {
        "question": "What are the limits on vector database size?",
        "answer": "AgentDB handles 1M+ vectors efficiently. Use quantization for larger datasets and consider sharding across multiple database files."
      },
      {
        "question": "Can I integrate this with my existing Node.js application?",
        "answer": "Yes, install the agentic-flow package and use the TypeScript or JavaScript API. Complete code examples are provided in the documentation."
      },
      {
        "question": "Is my data safe when using vector search?",
        "answer": "All vectors are stored locally in your database file. No data is sent to external services during search operations, ensuring complete privacy."
      },
      {
        "question": "Search is returning irrelevant results, how do I fix this?",
        "answer": "Adjust similarity threshold to 0.8 or higher, ensure embeddings come from the same model, and consider using MMR for more diverse relevant results."
      },
      {
        "question": "How does AgentDB compare to Pinecone or Weaviate?",
        "answer": "AgentDB offers 150x faster performance with sub-millisecond latency, runs locally without API costs, and provides advanced quantization for superior memory efficiency."
      }
    ]
  },
  "file_structure": [
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md",
      "lines": 340
    }
  ]
}
