{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-10T14:00:37.621Z",
    "slug": "dicklesworthstone-cm",
    "source_url": "https://github.com/Dicklesworthstone/agent_flywheel_clawdbot_skills_and_integrations/tree/main/skills/cm",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "2.0.0",
    "source_type": "community",
    "content_hash": "59d4e7006a2aff62b28c01871818069915fe459f414c6f5a58c30a766c9e608c",
    "tree_hash": "e66b5a6e17baddf5993b84f42d01c0fdcd7f09aeb6906d7a1e65d42e107571bd"
  },
  "skill": {
    "name": "cm",
    "description": "CASS Memory System - procedural memory for AI coding agents. Three-layer cognitive architecture with confidence decay, anti-pattern learning, cross-agent knowledge transfer, trauma guard safety system. Bun/TypeScript CLI.",
    "summary": "CASS Memory System - procedural memory for AI coding agents. Three-layer cognitive architecture with...",
    "icon": "ðŸ§ ",
    "version": "1.0.0",
    "author": "Dicklesworthstone",
    "license": "MIT",
    "category": "coding",
    "tags": [
      "memory",
      "learning",
      "productivity",
      "ai-agents",
      "knowledge-management"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": []
  },
  "security_audit": {
    "risk_level": "low",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "This is documentation-only content describing a memory system for AI agents. While the described system has legitimate security features (secret sanitization, local-first design, trauma guard), it would require filesystem access and network capabilities if implemented. The documentation itself poses no security risk.",
    "risk_factor_evidence": [],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [
      {
        "title": "System requires broad filesystem access",
        "description": "The described system would need to read/write to ~/.cass-memory/ directory, access session logs from various agents (Claude, Codex, Cursor), and potentially read remote hosts for cross-agent enrichment. While documentation claims local-first design, the actual implementation would have significant filesystem access.",
        "locations": [
          {
            "file": "SKILL.md",
            "line_start": 616,
            "line_end": 633
          }
        ]
      },
      {
        "title": "Network capabilities for cross-agent sync",
        "description": "Documentation describes remoteCass configuration for accessing session data from other machines (workstation, etc.) and MCP server functionality. This would require network access that could potentially expose data.",
        "locations": [
          {
            "file": "SKILL.md",
            "line_start": 590,
            "line_end": 593
          }
        ]
      },
      {
        "title": "External command execution",
        "description": "The system would execute external commands including cass binary, git operations, and shell commands for trauma guard hooks. Command execution always carries security implications.",
        "locations": [
          {
            "file": "SKILL.md",
            "line_start": 279,
            "line_end": 282
          }
        ]
      }
    ],
    "dangerous_patterns": [],
    "files_scanned": 1,
    "total_lines": 824,
    "audit_model": "claude",
    "audited_at": "2026-01-10T14:00:37.621Z"
  },
  "content": {
    "user_title": "Build persistent cross-agent memory with CM",
    "value_statement": "AI agents forget what they learn between sessions. CM captures and shares knowledge across all your agents, turning scattered experiences into persistent procedural memory that improves over time.",
    "seo_keywords": [
      "AI memory system",
      "Claude Code memory",
      "Codex integration",
      "cross-agent learning",
      "procedural memory",
      "AI coding assistant",
      "session persistence",
      "knowledge management",
      "CM CASS memory",
      "AI agent memory"
    ],
    "actual_capabilities": [
      "Extracts actionable rules from agent session logs",
      "Shares knowledge between Claude, Codex, Cursor and other agents",
      "Prevents repeated mistakes with trauma guard safety system",
      "Scores rule effectiveness with confidence decay over time",
      "Provides contextual guidance before starting tasks"
    ],
    "limitations": [
      "Requires installation of separate CASS tool for session indexing",
      "Needs API keys for LLM-powered reflection features",
      "Cross-agent enrichment is opt-in for privacy",
      "Performance depends on volume of session history"
    ],
    "use_cases": [
      {
        "target_user": "Developers using multiple AI coding agents",
        "title": "Share knowledge between Claude and Cursor",
        "description": "When Cursor learns a debugging pattern, CM makes it available to Claude Code automatically. No more solving the same auth bug three times."
      },
      {
        "target_user": "Teams managing complex codebases",
        "title": "Build team playbook from sessions",
        "description": "Convert individual agent experiences into shared team knowledge. CM extracts proven patterns and anti-patterns from real work sessions."
      },
      {
        "target_user": "Solo developers building expertise",
        "title": "Personal coding memory that improves",
        "description": "Never forget how you solved that tricky bug. CM remembers your successful patterns and warns about approaches that caused problems."
      }
    ],
    "prompt_templates": [
      {
        "title": "Get context before coding",
        "scenario": "Starting a new feature or bug fix",
        "prompt": "Run 'cm context \"implement user authentication with JWT\" --json' to get relevant patterns from your playbook and similar past sessions"
      },
      {
        "title": "Add team knowledge",
        "scenario": "After solving a difficult problem",
        "prompt": "Use 'cm playbook add \"Always validate JWT expiry before debugging auth errors\" --category security' to capture the solution"
      },
      {
        "title": "Review recent learnings",
        "scenario": "Weekly retrospective or planning",
        "prompt": "Run 'cm reflect --days 7 --json' to see what patterns CM extracted from your recent sessions and provide feedback"
      },
      {
        "title": "Prevent disasters",
        "scenario": "Before running dangerous commands",
        "prompt": "Install trauma guard with 'cm guard --install' to block commands matching patterns that caused problems in past sessions"
      }
    ],
    "output_examples": [
      {
        "input": "cm context \"fix authentication timeout bug\" --json",
        "output": [
          "Relevant rules found:",
          "â€¢ b-8f3a2c: Always check token expiry before auth debugging (Score: 8.5/10)",
          "â€¢ b-9k4p2m: JWT validation should happen before database queries (Score: 7.2/10)",
          "",
          "Anti-patterns to avoid:",
          "â€¢ Don't cache auth tokens without expiry validation",
          "",
          "Similar sessions:",
          "â€¢ 3 days ago: Fixed OAuth timeout in user service",
          "â€¢ 1 week ago: Resolved JWT refresh token issue",
          "",
          "Suggested searches:",
          "â€¢ cass search \"authentication timeout\" --robot",
          "â€¢ cass search \"JWT expiry validation\" --robot"
        ]
      }
    ],
    "best_practices": [
      "Run 'cm context' before starting non-trivial tasks to get relevant guidance",
      "Leave inline feedback comments like '// [cass: helpful b-8f3a2c]' when rules help or hurt",
      "Enable cross-agent enrichment only after reviewing privacy implications for your data"
    ],
    "anti_patterns": [
      "Don't manually add rules without evidence - let CM extract them from real sessions",
      "Avoid sharing playbook files containing sensitive project information",
      "Don't disable trauma guard without understanding why patterns were blocked"
    ],
    "faq": [
      {
        "question": "Is my session data sent to external services?",
        "answer": "No. CM uses local-first design. All processing happens on your machine. Cross-agent enrichment is opt-in only."
      },
      {
        "question": "What agents does CM support?",
        "answer": "Any agent that produces session logs. Built-in support for Claude Code, Codex, Cursor, Aider, PI, Gemini, and ChatGPT."
      },
      {
        "question": "How does the confidence decay system work?",
        "answer": "Rule confidence halves every 90 days without feedback. One harmful mark counts as 4 helpful marks. Rules progress from candidate to established to proven."
      },
      {
        "question": "Can I use CM without an LLM API key?",
        "answer": "Yes. Set CASS_MEMORY_LLM=none for LLM-free mode. You'll get deterministic reflection without semantic enhancement."
      },
      {
        "question": "What happens if CM makes a mistake?",
        "answer": "Use 'cm mark <rule-id> --harmful --reason <why>' or leave inline comments. CM learns from feedback and will deprecate bad rules."
      },
      {
        "question": "How is CM different from just searching my session history?",
        "answer": "CM extracts actionable rules from sessions, validates them against history, tracks effectiveness over time, and shares knowledge across agents."
      }
    ]
  },
  "file_structure": [
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md"
    }
  ]
}
