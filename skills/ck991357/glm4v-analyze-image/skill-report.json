{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-16T22:17:21.703Z",
    "slug": "ck991357-glm4v-analyze-image",
    "source_url": "https://github.com/CK991357/gemini-chat/tree/main/src/skills/glm4v_analyze_image",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "3.0.0",
    "source_type": "community",
    "content_hash": "28c793cfd9fe76aa1a116ef42270ee6678cb1e92ae89ab63aebb845101797510",
    "tree_hash": "9cc3fbfdfac5868fb012befb7a521aa143905f41803c5c95e3e64a3f3ace7672"
  },
  "skill": {
    "name": "glm4v-analyze-image",
    "description": "æ™ºè°±AIçš„è§†è§‰è¯­è¨€æ¨¡å‹ï¼Œç”¨äºå›¾åƒåˆ†æã€å†…å®¹è¯†åˆ«å’Œè§†è§‰é—®ç­”",
    "summary": "æ™ºè°±AIçš„è§†è§‰è¯­è¨€æ¨¡å‹ï¼Œç”¨äºå›¾åƒåˆ†æã€å†…å®¹è¯†åˆ«å’Œè§†è§‰é—®ç­”",
    "icon": "ğŸ‘ï¸",
    "version": "1.0",
    "author": "CK991357",
    "license": "MIT",
    "category": "vision",
    "tags": [
      "image-analysis",
      "vision",
      "recognition",
      "visual-qa",
      "multimodal"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": [
      "network",
      "external_commands"
    ]
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "Documentation-only skill defining an interface to ZhipuAI's GLM-4V vision model. Contains no executable code, scripts, or command execution. All 46 static findings are false positives: JSON code examples misidentified as shell commands, example URLs misclassified as network threats, and YAML frontmatter misinterpreted as high-entropy content. This is pure documentation.",
    "risk_factor_evidence": [
      {
        "factor": "network",
        "evidence": [
          {
            "file": "skill-report.json",
            "line_start": 6,
            "line_end": 6
          },
          {
            "file": "SKILL.md",
            "line_start": 35,
            "line_end": 35
          },
          {
            "file": "SKILL.md",
            "line_start": 42,
            "line_end": 42
          },
          {
            "file": "SKILL.md",
            "line_start": 48,
            "line_end": 48
          },
          {
            "file": "SKILL.md",
            "line_start": 54,
            "line_end": 54
          },
          {
            "file": "SKILL.md",
            "line_start": 72,
            "line_end": 72
          },
          {
            "file": "SKILL.md",
            "line_start": 84,
            "line_end": 84
          },
          {
            "file": "SKILL.md",
            "line_start": 96,
            "line_end": 96
          }
        ]
      },
      {
        "factor": "external_commands",
        "evidence": [
          {
            "file": "SKILL.md",
            "line_start": 20,
            "line_end": 29
          },
          {
            "file": "SKILL.md",
            "line_start": 29,
            "line_end": 31
          },
          {
            "file": "SKILL.md",
            "line_start": 31,
            "line_end": 34
          },
          {
            "file": "SKILL.md",
            "line_start": 34,
            "line_end": 36
          },
          {
            "file": "SKILL.md",
            "line_start": 36,
            "line_end": 41
          },
          {
            "file": "SKILL.md",
            "line_start": 41,
            "line_end": 43
          },
          {
            "file": "SKILL.md",
            "line_start": 43,
            "line_end": 44
          },
          {
            "file": "SKILL.md",
            "line_start": 44,
            "line_end": 47
          },
          {
            "file": "SKILL.md",
            "line_start": 47,
            "line_end": 49
          },
          {
            "file": "SKILL.md",
            "line_start": 49,
            "line_end": 53
          },
          {
            "file": "SKILL.md",
            "line_start": 53,
            "line_end": 55
          },
          {
            "file": "SKILL.md",
            "line_start": 55,
            "line_end": 59
          },
          {
            "file": "SKILL.md",
            "line_start": 59,
            "line_end": 67
          },
          {
            "file": "SKILL.md",
            "line_start": 67,
            "line_end": 76
          },
          {
            "file": "SKILL.md",
            "line_start": 76,
            "line_end": 79
          },
          {
            "file": "SKILL.md",
            "line_start": 79,
            "line_end": 88
          },
          {
            "file": "SKILL.md",
            "line_start": 88,
            "line_end": 91
          },
          {
            "file": "SKILL.md",
            "line_start": 91,
            "line_end": 100
          }
        ]
      }
    ],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 2,
    "total_lines": 309,
    "audit_model": "claude",
    "audited_at": "2026-01-16T22:17:21.703Z"
  },
  "content": {
    "user_title": "Analyze images with GLM-4V vision model",
    "value_statement": "Users need to extract insights from images automatically. This skill provides access to ZhipuAI's GLM-4V vision model for image recognition, visual question answering, and multimodal analysis through a simple tool interface.",
    "seo_keywords": [
      "GLM-4V",
      "image analysis",
      "visual question answering",
      "image recognition",
      "multimodal AI",
      "Claude",
      "Codex",
      "Claude Code",
      "æ™ºè°±AI",
      "vision model"
    ],
    "actual_capabilities": [
      "Analyze image content and generate detailed descriptions",
      "Answer questions about visual content (VQA)",
      "Extract text from images using OCR",
      "Identify objects, scenes, and emotions in images",
      "Analyze technical details and visual elements",
      "Understand spatial relationships and composition"
    ],
    "limitations": [
      "Cannot process sensitive or inappropriate content",
      "Image size and resolution have maximum limits",
      "Real-time video streams are not supported",
      "3D model analysis is not supported"
    ],
    "use_cases": [
      {
        "target_user": "Content creators",
        "title": "Generate image descriptions",
        "description": "Automatically create alt text and descriptions for images used in articles, social media, or accessibility purposes."
      },
      {
        "target_user": "Customer support teams",
        "title": "Visual inquiry responses",
        "description": "Answer customer questions about product images, screenshots, or documentation visuals automatically."
      },
      {
        "target_user": "Data analysts",
        "title": "Extract visual insights",
        "description": "Analyze charts, diagrams, and infographics to extract data points and key information."
      }
    ],
    "prompt_templates": [
      {
        "title": "Basic description",
        "scenario": "Get a general overview",
        "prompt": "Describe the main content of this image in detail."
      },
      {
        "title": "Object counting",
        "scenario": "Count items in images",
        "prompt": "How many people/objects are in this image? What are they doing?"
      },
      {
        "title": "Text extraction",
        "scenario": "Read text from images",
        "prompt": "Extract all text visible in this image and transcribe it accurately."
      },
      {
        "title": "Technical analysis",
        "scenario": "Analyze technical content",
        "prompt": "Analyze the technical details, data visualization, and key information shown in this image."
      }
    ],
    "output_examples": [
      {
        "input": "Analyze this chart image and tell me the main trends.",
        "output": [
          "The image shows a bar chart comparing quarterly revenue across four quarters",
          "Q4 has the highest revenue at $125,000, representing 35% growth from Q1",
          "There is a consistent upward trend throughout the year",
          "The chart uses blue bars on a white background with clear axis labels"
        ]
      },
      {
        "input": "Describe this product photo for an e-commerce listing.",
        "output": [
          "A white ceramic vase with a slender neck and rounded body",
          "The vase has a matte finish and is positioned on a wooden table",
          "Natural lighting from the left side creates soft shadows",
          "Dimensions appear to be approximately 25cm tall based on the table reference"
        ]
      },
      {
        "input": "What safety equipment do you see in this workplace photo?",
        "output": [
          "Three workers wearing yellow safety helmets with reflective strips",
          "High-visibility orange vests over blue work shirts",
          "Safety goggles are worn by two of the three workers",
          "Steel-toed boots are visible on all workers"
        ]
      }
    ],
    "best_practices": [
      "Use clear and specific prompts to guide the analysis focus",
      "Ensure image URLs are publicly accessible and return valid images",
      "Choose appropriate image sizes within limits for faster processing"
    ],
    "anti_patterns": [
      "Using overly vague prompts like \"analyze this image\" without specific guidance",
      "Providing URLs to private or authentication-protected images",
      "Expecting accurate analysis of highly compressed or low-resolution images"
    ],
    "faq": [
      {
        "question": "What image formats are supported?",
        "answer": "Common formats including JPEG, PNG, and WebP are supported. Ensure the URL returns a valid image."
      },
      {
        "question": "What is the maximum image size?",
        "answer": "There are limits on file size and resolution. Larger images may be rejected or require compression."
      },
      {
        "question": "How does this integrate with Claude?",
        "answer": "Use the tool_calls syntax with glm4v_analyze_image as the tool name and provide model, image_url, and prompt parameters."
      },
      {
        "question": "Is my image data stored or processed elsewhere?",
        "answer": "Images are sent to ZhipuAI's API for processing. Review their privacy policy for data handling details."
      },
      {
        "question": "Why did my request fail?",
        "answer": "Common causes include invalid image URLs, oversized images, unsupported formats, or network timeouts."
      },
      {
        "question": "How does this compare to other vision models?",
        "answer": "GLM-4V provides multilingual support and strong Chinese language capabilities with competitive pricing."
      }
    ]
  },
  "file_structure": [
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md",
      "lines": 132
    }
  ]
}
