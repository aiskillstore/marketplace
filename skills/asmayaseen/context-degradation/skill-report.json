{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-16T17:51:30.833Z",
    "slug": "asmayaseen-context-degradation",
    "source_url": "https://github.com/Asmayaseen/hackathon-2/tree/main/.claude/skills/context-degradation",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "3.0.0",
    "source_type": "community",
    "content_hash": "b0c1ee993391f40ccbfaa50bc178fcfd4c597fddaa65173dfb9cc29eb1874e08",
    "tree_hash": "1f1fdc3a8a9fb229f5ccc3cb8c3fe6c3d947cdd4cdac26d2657fd948e4100ae6"
  },
  "skill": {
    "name": "context-degradation",
    "description": "Recognize, diagnose, and mitigate patterns of context degradation in agent systems. Use when context grows large, agent performance degrades unexpectedly, or debugging agent failures.",
    "summary": "Recognize, diagnose, and mitigate patterns of context degradation in agent systems. Use when context...",
    "icon": "ðŸ§ ",
    "version": "1.0.0",
    "author": "Asmayaseen",
    "license": "MIT",
    "category": "data",
    "tags": [
      "context-engineering",
      "ai-agents",
      "performance",
      "debugging"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": [
      "external_commands",
      "network",
      "filesystem"
    ]
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "Pure documentation and analysis utility skill. Contains only educational content about context degradation patterns in AI systems. No network calls, no file writes, no command execution. All code examples are for demonstration purposes only with safe, simulated functions.",
    "risk_factor_evidence": [
      {
        "factor": "external_commands",
        "evidence": [
          {
            "file": "references/patterns.md",
            "line_start": 11,
            "line_end": 39
          },
          {
            "file": "references/patterns.md",
            "line_start": 39,
            "line_end": 45
          },
          {
            "file": "references/patterns.md",
            "line_start": 45,
            "line_end": 79
          },
          {
            "file": "references/patterns.md",
            "line_start": 79,
            "line_end": 87
          },
          {
            "file": "references/patterns.md",
            "line_start": 87,
            "line_end": 118
          },
          {
            "file": "references/patterns.md",
            "line_start": 118,
            "line_end": 124
          },
          {
            "file": "references/patterns.md",
            "line_start": 124,
            "line_end": 153
          },
          {
            "file": "references/patterns.md",
            "line_start": 153,
            "line_end": 161
          },
          {
            "file": "references/patterns.md",
            "line_start": 161,
            "line_end": 192
          },
          {
            "file": "references/patterns.md",
            "line_start": 192,
            "line_end": 200
          },
          {
            "file": "references/patterns.md",
            "line_start": 200,
            "line_end": 255
          },
          {
            "file": "references/patterns.md",
            "line_start": 255,
            "line_end": 261
          },
          {
            "file": "references/patterns.md",
            "line_start": 261,
            "line_end": 269
          },
          {
            "file": "references/patterns.md",
            "line_start": 269,
            "line_end": 277
          },
          {
            "file": "references/patterns.md",
            "line_start": 277,
            "line_end": 313
          },
          {
            "file": "SKILL.md",
            "line_start": 162,
            "line_end": 169
          },
          {
            "file": "SKILL.md",
            "line_start": 169,
            "line_end": 172
          },
          {
            "file": "SKILL.md",
            "line_start": 172,
            "line_end": 188
          }
        ]
      },
      {
        "factor": "network",
        "evidence": [
          {
            "file": "skill-report.json",
            "line_start": 6,
            "line_end": 6
          }
        ]
      },
      {
        "factor": "filesystem",
        "evidence": [
          {
            "file": "skill-report.json",
            "line_start": 6,
            "line_end": 6
          }
        ]
      }
    ],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 5,
    "total_lines": 1202,
    "audit_model": "claude",
    "audited_at": "2026-01-16T17:51:30.833Z"
  },
  "content": {
    "user_title": "Diagnose Context Degradation Issues",
    "value_statement": "AI agents degrade as context grows larger. This skill provides patterns to recognize, measure, and fix degradation before it affects your results. Use it to build resilient systems that handle long conversations reliably.",
    "seo_keywords": [
      "context degradation",
      "AI context engineering",
      "Claude context optimization",
      "long context handling",
      "agent performance",
      "lost in middle",
      "context poisoning",
      "context distraction",
      "AI debugging",
      "context window management"
    ],
    "actual_capabilities": [
      "Identify lost-in-middle phenomena where critical information gets lost in long contexts",
      "Detect context poisoning where errors compound through repeated references",
      "Recognize context distraction when irrelevant information overwhelms relevant content",
      "Apply four mitigation strategies: compaction, masking, partitioning, and isolation",
      "Calculate context health scores based on utilization and degradation metrics",
      "Determine model-specific degradation thresholds for different context lengths"
    ],
    "limitations": [
      "This skill provides guidance and patterns rather than automated fixes",
      "Actual attention weights require model internals access which is not available",
      "Mitigation effectiveness depends on specific model behavior and context content",
      "Does not modify external systems or automatically truncate context"
    ],
    "use_cases": [
      {
        "target_user": "AI System Architects",
        "title": "Design Resilient Systems",
        "description": "Build agent architectures that handle large contexts without performance degradation through proven patterns."
      },
      {
        "target_user": "AI Engineers",
        "title": "Debug Agent Failures",
        "description": "Diagnose why agents produce incorrect outputs during long conversations and apply targeted fixes."
      },
      {
        "target_user": "ML Researchers",
        "title": "Understand Attention Patterns",
        "description": "Learn how attention mechanics cause predictable degradation patterns and design better mitigations."
      }
    ],
    "prompt_templates": [
      {
        "title": "Quick Check",
        "scenario": "Agent behavior degrading",
        "prompt": "My agent is producing poor results after many conversation turns. Analyze what context degradation patterns might be causing this and how to fix them."
      },
      {
        "title": "Lost-in-Middle",
        "scenario": "Important information being missed",
        "prompt": "The critical requirements I provided in the middle of context are being ignored by the model. This is the lost-in-middle phenomenon. Help me reorganize my context structure to prevent this."
      },
      {
        "title": "Context Poisoning",
        "scenario": "Errors compounding over time",
        "prompt": "My agent seems stuck on incorrect assumptions from earlier in the conversation. This looks like context poisoning. How do I detect and recover from this?"
      },
      {
        "title": "Architectural Design",
        "scenario": "Building long-context system",
        "prompt": "I am designing a system that must handle 100K+ tokens of context reliably. What architectural patterns should I use to prevent context degradation?"
      }
    ],
    "output_examples": [
      {
        "input": "My agent produces poor results after about 50 conversation turns",
        "output": [
          "Context degradation likely caused by: lost-in-middle effect or context poisoning",
          "Immediate mitigation: reorganize context so critical info is at the start or end",
          "Medium-term: implement compaction triggers before reaching 60K tokens",
          "Long-term: consider partitioning context across sub-agents or sessions",
          "Monitor health score: token utilization, degradation score, poisoning indicators"
        ]
      },
      {
        "input": "I need to understand why my model ignores requirements I put in the middle of my prompt",
        "output": [
          "This is the classic lost-in-middle phenomenon - attention follows a U-curve",
          "Beginning and end tokens receive high attention, middle tokens get degraded attention",
          "Move critical requirements to start (after system prompt) or end of context",
          "Use explicit section markers like [CURRENT TASK] and [KEY FINDINGS]",
          "Consider splitting long contexts into multiple focused sessions"
        ]
      },
      {
        "input": "How do I prevent my agent from accumulating errors over time",
        "output": [
          "Implement hallucination tracking to detect when errors enter context",
          "Use explicit versioning for retrieved documents to prevent outdated info",
          "Set compaction triggers when error indicators exceed threshold (3-5 errors)",
          "Periodically truncate context to remove poisoned elements",
          "Design isolation patterns so errors in one section dont spread to others"
        ]
      }
    ],
    "best_practices": [
      "Place critical information (goals, constraints, requirements) at the beginning or end of context where attention is highest",
      "Monitor context health continuously and trigger compaction or partitioning before degradation becomes severe",
      "Use explicit versioning for retrieved documents to prevent context clash from outdated information"
    ],
    "anti_patterns": [
      "Assuming larger context windows solve all problems without architectural safeguards",
      "Putting all retrieved documents in context without filtering for relevance",
      "Continuing sessions indefinitely without truncating or partitioning accumulated context"
    ],
    "faq": [
      {
        "question": "What models handle large context best?",
        "answer": "Claude Opus 4.5 and GPT-5.2 with thinking mode show the best degradation resistance. Both have high context limits with managed attention."
      },
      {
        "question": "What context length causes degradation?",
        "answer": "Onset varies by model. Claude Sonnet 4.5 degrades around 80K tokens while severe effects appear at 150K tokens. Monitor your specific use case."
      },
      {
        "question": "Can I use this skill with other context skills?",
        "answer": "Yes. This skill complements context-fundamentals and context-optimization. Use fundamentals first, then apply degradation patterns."
      },
      {
        "question": "Does this skill send data externally?",
        "answer": "No. This is a local analysis skill with no network calls. All processing happens within your existing AI tool session."
      },
      {
        "question": "Why is my model ignoring middle content?",
        "answer": "This is the lost-in-middle phenomenon. Attention follows a U-curve where beginning and end tokens receive high attention. Reorganize critical information to attention-favored positions."
      },
      {
        "question": "How is this different from context optimization?",
        "answer": "Context-optimization focuses on techniques to extend capacity. This skill focuses on diagnosing WHY degradation happens and recognizing specific patterns before applying fixes."
      }
    ]
  },
  "file_structure": [
    {
      "name": "references",
      "type": "dir",
      "path": "references",
      "children": [
        {
          "name": "patterns.md",
          "type": "file",
          "path": "references/patterns.md",
          "lines": 314
        }
      ]
    },
    {
      "name": "scripts",
      "type": "dir",
      "path": "scripts",
      "children": [
        {
          "name": "degradation_detector.py",
          "type": "file",
          "path": "scripts/degradation_detector.py",
          "lines": 419
        },
        {
          "name": "verify.py",
          "type": "file",
          "path": "scripts/verify.py",
          "lines": 32
        }
      ]
    },
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md",
      "lines": 231
    }
  ]
}
