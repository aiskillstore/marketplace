{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-10T09:17:55.240Z",
    "slug": "2389-research-documentation-audit",
    "source_url": "https://github.com/2389-research/claude-plugins/tree/main/documentation-audit/skills",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "2.0.0",
    "source_type": "community",
    "content_hash": "672c8f4070bd99ce9c40e64dbb4070682c85b0d0620bd89a8d7dd0cb8ab8ad24",
    "tree_hash": "7eaf56fa0e5d139fa02cb4543a0dbb67fb22bad52b39887272e5f94df68a4e2b"
  },
  "skill": {
    "name": "documentation-audit",
    "description": "This skill should be used when verifying documentation claims against codebase reality. Triggers on \"audit docs\", \"verify documentation\", \"check docs\", \"docs accurate\", \"documentation drift\", \"before release\", \"after refactor\", \"docs don't match\". Uses two-pass extraction with pattern expansion for comprehensive detection.",
    "summary": "This skill should be used when verifying documentation claims against codebase reality. Triggers on ...",
    "icon": "üîç",
    "version": "1.0.0",
    "author": "2389-research",
    "license": "MIT",
    "category": "documentation",
    "tags": [
      "documentation",
      "verification",
      "audit",
      "quality-assurance"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": [
      "filesystem",
      "external_commands"
    ]
  },
  "security_audit": {
    "risk_level": "low",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "Prompt-based skill using Plan agent for documentation verification. Operates through read-only filesystem operations and claim extraction without executing code or making network calls. No malicious patterns detected.",
    "risk_factor_evidence": [
      {
        "factor": "filesystem",
        "evidence": [
          {
            "file": "SKILL.md",
            "line_start": 11,
            "line_end": 31
          },
          {
            "file": "checklist.md",
            "line_start": 7,
            "line_end": 10
          },
          {
            "file": "extraction-patterns.md",
            "line_start": 20,
            "line_end": 24
          }
        ]
      },
      {
        "factor": "external_commands",
        "evidence": [
          {
            "file": "checklist.md",
            "line_start": 57,
            "line_end": 69
          },
          {
            "file": "extraction-patterns.md",
            "line_start": 84,
            "line_end": 88
          }
        ]
      }
    ],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 3,
    "total_lines": 167,
    "audit_model": "claude",
    "audited_at": "2026-01-10T09:17:55.240Z"
  },
  "content": {
    "user_title": "Verify documentation accuracy against codebase",
    "value_statement": "Documentation drift causes confusion and bugs. This skill systematically verifies claims in markdown documentation against the actual codebase using a two-pass approach with pattern expansion to catch similar issues.",
    "seo_keywords": [
      "documentation audit",
      "verify documentation",
      "documentation accuracy",
      "Claude Code skill",
      "codebase verification",
      "docs drift",
      "CLAUDE.md",
      "CLAUDE",
      "Codex",
      "Claude Code"
    ],
    "actual_capabilities": [
      "Extracts verifiable claims from markdown documentation (file paths, config defaults, env vars, CLI flags)",
      "Verifies each claim against the actual codebase using glob, grep, and file existence checks",
      "Uses parallel Task agents for efficient multi-document extraction",
      "Performs pattern expansion to find similar issues across all documentation",
      "Detects gaps between documented items and actual codebase artifacts",
      "Generates audit reports with false claims, patterns, and suggested fixes"
    ],
    "limitations": [
      "Only verifies factual claims, not prose quality or writing style",
      "Behavioral claims (timing, intervals) require human review",
      "Does not auto-fix documentation, only reports issues",
      "Skips design docs, plans, and historical artifacts"
    ],
    "use_cases": [
      {
        "target_user": "Development teams",
        "title": "Pre-release verification",
        "description": "Verify all documentation is accurate before deploying or shipping releases"
      },
      {
        "target_user": "Codebase maintainers",
        "title": "Post-refactor checks",
        "description": "Detect documentation drift after refactoring or renaming files and services"
      },
      {
        "target_user": "Technical writers",
        "title": "Documentation audits",
        "description": "Systematically scan documentation for outdated references and stale claims"
      }
    ],
    "prompt_templates": [
      {
        "title": "Quick audit",
        "scenario": "Verify specific docs",
        "prompt": "Audit these documentation files for accuracy: [list files]"
      },
      {
        "title": "Full project scan",
        "scenario": "Complete documentation review",
        "prompt": "Run a complete documentation audit of this project. Focus on user-facing docs only."
      },
      {
        "title": "Refactor check",
        "scenario": "After major changes",
        "prompt": "Check if documentation matches reality after our recent refactor. Look for dead script references, renamed services, and outdated config defaults."
      },
      {
        "title": "Pattern search",
        "scenario": "Find similar issues",
        "description": "Expand patterns",
        "prompt": "I found a dead script reference. Search all docs for similar patterns and verify each one."
      }
    ],
    "output_examples": [
      {
        "input": "Audit the documentation files in docs/ for accuracy",
        "output": [
          "Documentation Audit Report - Generated: 2026-01-10",
          "Executive Summary: 12 documents scanned, ~180 claims verified",
          "Verified TRUE: 145 claims (81%)",
          "Verified FALSE: 31 claims (17%) requiring fixes",
          "False Claim - CONFIGURATION.md:135 - 'claude-sonnet-4-5' should be 'claude-3-5-sonnet-latest'",
          "Pattern Found: 9 dead script references across 4 files",
          "Human Review Queue: 4 behavioral claims need verification"
        ]
      }
    ],
    "best_practices": [
      "Use parallel agents for extraction to maximize efficiency across multiple documents",
      "Always run Pass 2 pattern expansion - it catches 10-20% more issues",
      "Record evidence (file:line) for every verdict to support suggested fixes"
    ],
    "anti_patterns": [
      "Skipping Pass 2 pattern expansion reduces issue detection significantly",
      "Trusting documentation 'looks correct' without verification leads to hidden drift",
      "Auditing design docs or plans instead of user-facing documentation wastes effort"
    ],
    "faq": [
      {
        "question": "What claim types can this skill verify automatically?",
        "answer": "File paths, config defaults, environment variables, and CLI flags are auto-verified. Behavioral claims require human review."
      },
      {
        "question": "Does this skill modify my documentation files?",
        "answer": "No. The skill only reads documentation and generates audit reports. It never modifies source files."
      },
      {
        "question": "What is Pass 2 pattern expansion?",
        "answer": "After finding false claims, the skill searches all docs for similar patterns to catch issues the initial scan missed."
      },
      {
        "question": "How long does a full audit take?",
        "answer": "Depends on codebase size. A typical project with 10-20 docs completes in 5-10 minutes using parallel extraction."
      },
      {
        "question": "Can I integrate this into CI/CD pipelines?",
        "answer": "Not directly. Run manually before releases or use scripts that invoke the skill and parse the generated audit report."
      },
      {
        "question": "How is this different from linters or static analysis?",
        "answer": "Linters check code quality. This skill verifies that documentation accurately describes the codebase behavior."
      }
    ]
  },
  "file_structure": [
    {
      "name": "checklist.md",
      "type": "file",
      "path": "checklist.md"
    },
    {
      "name": "extraction-patterns.md",
      "type": "file",
      "path": "extraction-patterns.md"
    },
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md"
    }
  ]
}
