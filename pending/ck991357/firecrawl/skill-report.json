{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-10T11:56:28.351Z",
    "slug": "ck991357-firecrawl",
    "source_url": "https://github.com/CK991357/gemini-chat/tree/main/src/skills/firecrawl",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "2.0.0",
    "source_type": "community",
    "content_hash": "df25c9160677cc9f58d78c7e941a8a0539480367d455889e65e353e46258f332",
    "tree_hash": "68e021ec2dbe725575c612591bb7dcfb68948f469291a14917044e84214f0636"
  },
  "skill": {
    "name": "firecrawl",
    "description": "å¤šåŠŸèƒ½ç½‘é¡µæŠ“å–å’Œæ•°æ®æå–å·¥å…·ï¼Œæ”¯æŒåŒæ­¥æŠ“å–ã€æœç´¢ã€ç½‘ç«™åœ°å›¾è·å–å’Œå¼‚æ­¥çˆ¬å–",
    "summary": "å¤šåŠŸèƒ½ç½‘é¡µæŠ“å–å’Œæ•°æ®æå–å·¥å…·ï¼Œæ”¯æŒåŒæ­¥æŠ“å–ã€æœç´¢ã€ç½‘ç«™åœ°å›¾è·å–å’Œå¼‚æ­¥çˆ¬å–",
    "icon": "ğŸ•¸ï¸",
    "version": "1.0",
    "author": "CK991357",
    "license": "MIT",
    "category": "web-crawling",
    "tags": [
      "web-scraping",
      "data-extraction",
      "crawling",
      "automation",
      "firecrawl"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": []
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "This skill contains only documentation for the Firecrawl MCP tool interface. No executable code, scripts, or network operations are present in the SKILL.md file. The tool documentation describes how to call various web scraping modes (scrape, search, map, crawl, extract, check_status) through a structured MCP interface.",
    "risk_factor_evidence": [],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 1,
    "total_lines": 119,
    "audit_model": "claude",
    "audited_at": "2026-01-10T11:56:28.351Z"
  },
  "content": {
    "user_title": "Extract web data with Firecrawl",
    "value_statement": "Manual web scraping requires writing code and handling anti-bot measures. Firecrawl provides a unified interface to scrape websites, search the web, extract structured data, and crawl entire sites with async job support.",
    "seo_keywords": [
      "Firecrawl",
      "web scraping",
      "data extraction",
      "web crawling",
      "Claude",
      "Codex",
      "Claude Code",
      "MCP",
      "automation",
      "markdown extraction"
    ],
    "actual_capabilities": [
      "Scrape single web pages and extract content as markdown or HTML",
      "Search the web for information with result limits",
      "Map website structures by extracting sitemap URLs",
      "Crawl entire websites asynchronously with pagination limits",
      "Extract structured data from URLs using custom prompts and schemas",
      "Check async job status for crawl and extract operations"
    ],
    "limitations": [
      "Cannot scrape websites with strong anti-bot protection",
      "No JavaScript rendering for dynamic single-page applications",
      "Rate limits depend on the underlying Firecrawl API plan",
      "Crawl and extract operations are asynchronous and require status polling"
    ],
    "use_cases": [
      {
        "target_user": "Researchers",
        "title": "Gather research sources",
        "description": "Extract content from multiple web pages for literature reviews and data collection"
      },
      {
        "target_user": "Content creators",
        "title": "Build content datasets",
        "description": "Aggregate information from competitor websites or news sources for analysis"
      },
      {
        "target_user": "Developers",
        "title": "Automate data pipelines",
        "description": "Extract structured data from web sources to feed into applications and workflows"
      }
    ],
    "prompt_templates": [
      {
        "title": "Scrape a webpage",
        "scenario": "Get page content",
        "prompt": "Use Firecrawl to scrape {url} and return the content in markdown format."
      },
      {
        "title": "Search the web",
        "scenario": "Find current information",
        "prompt": "Search for {topic} using Firecrawl and show me the top {number} results."
      },
      {
        "title": "Map a website",
        "scenario": "Discover site structure",
        "prompt": "Get the sitemap for {url} using Firecrawl map mode to see what pages are available."
      },
      {
        "title": "Extract structured data",
        "scenario": "Parse specific fields",
        "prompt": "Extract structured data from {urls} using this schema: {schema}. Prompt: {instructions}."
      }
    ],
    "output_examples": [
      {
        "input": "Scrape the Firecrawl documentation page",
        "output": [
          "Title: Firecrawl Documentation",
          "Key sections: Getting Started, API Reference, Examples",
          "URL: https://docs.firecrawl.dev/",
          "Content preview: Firecrawl makes it easy to scrape websites..."
        ]
      }
    ],
    "best_practices": [
      "Use scrape mode for single pages and crawl mode for multiple pages with limits",
      "Check async job status before attempting to retrieve results",
      "Always include URL protocols (http:// or https://) in parameters"
    ],
    "anti_patterns": [
      "Calling extract with a single URL instead of an array of URLs",
      "Omitting the mode parameter or placing parameters at the top level",
      "Using crawl without a limit on large websites"
    ],
    "faq": [
      {
        "question": "Which modes return immediate results?",
        "answer": "Scrape, search, and map are synchronous and return results immediately. Crawl and extract return a job_id for status polling."
      },
      {
        "question": "What formats can I extract content in?",
        "answer": "Scrape supports markdown and HTML formats. Markdown is the default and recommended for most use cases."
      },
      {
        "question": "How do I check if my crawl job completed?",
        "answer": "Use check_status mode with the job_id returned from crawl or extract operations to retrieve results."
      },
      {
        "question": "Is my scraping data stored anywhere?",
        "answer": "Data handling depends on your Firecrawl API provider. Consult their privacy policy for storage details."
      },
      {
        "question": "Why is my crawl returning no results?",
        "answer": "Check that the URL is accessible, the domain allows crawling, and you have sufficient API credits or rate limits."
      },
      {
        "question": "How is this different from Tavily search?",
        "answer": "Firecrawl focuses on direct website scraping and crawling, while Tavily specializes in search engine queries with optimized results."
      }
    ]
  },
  "file_structure": [
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md"
    }
  ]
}
