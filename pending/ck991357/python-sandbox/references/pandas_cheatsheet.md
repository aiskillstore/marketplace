# ä»£ç è§£é‡Šå™¨ä½¿ç”¨æŒ‡å— v2.5 (æœ€ç»ˆèåˆç‰ˆ)

## ğŸ¯ æ ¸å¿ƒåŸåˆ™ï¼šåç«¯è‡ªåŠ¨åŒ–ï¼Œä»£ç è¦ç®€æ´

### âœ… **åç«¯å·²è‡ªåŠ¨å¤„ç†çš„åŠŸèƒ½ï¼š**
1. **å›¾è¡¨æ•è·**ï¼š`plt.show()` è‡ªåŠ¨ç”Ÿæˆå›¾ç‰‡ï¼Œæ— éœ€æ‰‹åŠ¨ç¼–ç 
2. **æ–‡ä»¶ç®¡ç†**ï¼š`/data` ç›®å½•å·²é…ç½®å¥½ï¼Œæ”¯æŒä¼šè¯æŒä¹…åŒ–
3. **è¾“å‡ºå¤„ç†**ï¼šç³»ç»Ÿè‡ªåŠ¨å¤„ç†æ‰€æœ‰ `print()` è¾“å‡º
4. **é”™è¯¯æ•è·**ï¼šåç«¯æœ‰å®Œæ•´çš„é”™è¯¯å¤„ç†ç³»ç»Ÿ

### âš ï¸ **èµ„æºé™åˆ¶ï¼š**
1. **å†…å­˜é™åˆ¶**ï¼šå¯ç”¨å†…å­˜ä¸Šé™ä¸º6GB
2. **æ—¶é—´é™åˆ¶**ï¼šä»£ç æ‰§è¡Œæœ‰90ç§’è¶…æ—¶é™åˆ¶

### âŒ **æ¨¡å‹ä¸éœ€è¦åšçš„ï¼š**
1. ä¸è¦æ‰‹åŠ¨ç¼–ç å›¾è¡¨ä¸º base64
2. ä¸è¦ç¼–å†™å¤æ‚çš„é”™è¯¯å¤„ç†åŒ…è£…å™¨
3. ä¸è¦ç®¡ç†æ–‡ä»¶æ ¼å¼è½¬æ¢ï¼ˆåç«¯è‡ªåŠ¨å¤„ç†ï¼‰
4. ä¸è¦å¤„ç†å›¾è¡¨æ ‡é¢˜å’Œæ ¼å¼ï¼ˆç³»ç»Ÿè‡ªåŠ¨ä¼˜åŒ–ï¼‰

---

## ğŸ“‚ æ–‡ä»¶æ“ä½œï¼ˆä¼šè¯å·¥ä½œåŒºï¼š`/data`ï¼‰

### ä»å·¥ä½œåŒºè¯»å–æ–‡ä»¶
```python
import pandas as pd

# æœ€ç®€å•çš„æ–‡ä»¶è¯»å–ï¼ˆæ”¯æŒ CSVã€Excelã€Parquet ç­‰ï¼‰
df = pd.read_csv('/data/your_file.csv')

# å¿«é€ŸæŸ¥çœ‹æ•°æ®
print(f"æ•°æ®å½¢çŠ¶: {df.shape}")
print(df.head())
```

### ä¿å­˜æ–‡ä»¶åˆ°å·¥ä½œåŒº
```python
# ä¿å­˜å¤„ç†ç»“æœ
df_processed.to_csv('/data/processed_data.csv', index=False)

# ä¿å­˜ä¸ºé«˜æ•ˆæ ¼å¼ï¼ˆä¾›åç»­ä½¿ç”¨ï¼‰
import pyarrow.feather as feather
feather.write_feather(df_processed, '/data/processed_data.feather')
```

### ğŸ“ é‡è¦è¯´æ˜
- **æ–‡ä»¶ä½ç½®**ï¼šæ‰€æœ‰æ–‡ä»¶éƒ½åœ¨ `/data` ç›®å½•ä¸‹
- **ä¼šè¯æŒä¹…**ï¼šæ–‡ä»¶åœ¨åŒä¸€ä¼šè¯çš„å¤šæ¬¡æ‰§è¡Œä¸­ä¿æŒå¯ç”¨
- **è‡ªåŠ¨æ¸…ç†**ï¼š24å°æ—¶åä¼šè¯æ–‡ä»¶è‡ªåŠ¨æ¸…ç†

---

## ğŸ“Š æ•°æ®å¯è§†åŒ–ï¼ˆè‡ªåŠ¨æ•è·ï¼‰

### åŸºç¡€å›¾è¡¨
```python
import matplotlib.pyplot as plt

# è®¾ç½®ä¸­æ–‡å­—ä½“ï¼ˆåç«¯å·²é…ç½®ï¼Œè¿™é‡Œåªæ˜¯ç¡®ä¿ï¼‰
plt.rcParams['font.sans-serif'] = ['WenQuanYi Micro Hei']

# 1. æŠ˜çº¿å›¾
plt.figure(figsize=(10, 6))
plt.plot(df['date'], df['value'], marker='o', linewidth=2)
plt.title('é”€å”®è¶‹åŠ¿å›¾')  # æ ‡é¢˜ä¼šè¢«è‡ªåŠ¨æ•è·
plt.xlabel('æ—¥æœŸ')
plt.ylabel('é”€å”®é¢')
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()  # ğŸ¯ å…³é”®ï¼šç›´æ¥ show()ï¼Œç³»ç»Ÿè‡ªåŠ¨æ•è·ï¼

# 2. æŸ±çŠ¶å›¾
plt.figure(figsize=(10, 6))
df.groupby('category')['sales'].sum().plot(kind='bar')
plt.title('å„å“ç±»é”€å”®é¢')
plt.tight_layout()
plt.show()  # ğŸ¯ å…³é”®ï¼šç³»ç»Ÿè‡ªåŠ¨å¤„ç†ï¼

# 3. æ•£ç‚¹å›¾
plt.figure(figsize=(10, 6))
plt.scatter(df['x'], df['y'], alpha=0.6, c=df['value'], cmap='viridis')
plt.title('æ•£ç‚¹åˆ†å¸ƒå›¾')
plt.colorbar(label='å€¼å¤§å°')
plt.tight_layout()
plt.show()  # ğŸ¯ å…³é”®ï¼šç³»ç»Ÿè‡ªåŠ¨æ•è·ï¼
```

### é«˜çº§å›¾è¡¨
```python
# 4. å­å›¾ï¼ˆå¤šå›¾è¡¨ï¼‰
fig, axes = plt.subplots(2, 2, figsize=(12, 10))

axes[0, 0].plot(df['date'], df['value1'])
axes[0, 0].set_title('å›¾è¡¨1')

axes[0, 1].hist(df['value2'], bins=30)
axes[0, 1].set_title('å›¾è¡¨2')

axes[1, 0].scatter(df['x'], df['y'])
axes[1, 0].set_title('å›¾è¡¨3')

axes[1, 1].boxplot([df['group1'], df['group2']])
axes[1, 1].set_title('å›¾è¡¨4')

plt.tight_layout()
plt.show()  # ğŸ¯ ç³»ç»Ÿè‡ªåŠ¨æ•è·æ•´ä¸ªå›¾å½¢ï¼

# 5. çƒ­åŠ›å›¾ï¼ˆç›¸å…³æ€§çŸ©é˜µï¼‰
import seaborn as sns

corr_matrix = df.corr()
plt.figure(figsize=(10, 8))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0)
plt.title('ç‰¹å¾ç›¸å…³æ€§çƒ­åŠ›å›¾')
plt.tight_layout()
plt.show()  # ğŸ¯ ç³»ç»Ÿè‡ªåŠ¨æ•è·ï¼
```

### ğŸ“ å›¾è¡¨è¯´æ˜
- **åç«¯è‡ªåŠ¨å¤„ç†**ï¼šæ‰€æœ‰å›¾è¡¨ç±»å‹ï¼ˆMatplotlibã€Seabornã€Graphvizã€NetworkXï¼‰
- **æ ‡é¢˜æ•è·**ï¼šç³»ç»Ÿä¼šè‡ªåŠ¨æå–å›¾è¡¨æ ‡é¢˜æ˜¾ç¤ºç»™ç”¨æˆ·
- **ä¸­æ–‡å­—ä½“**ï¼šåç«¯å·²é…ç½®ä¸­æ–‡æ”¯æŒï¼Œæ— éœ€æ‹…å¿ƒä¹±ç 

---

## ğŸ§¹ æ•°æ®å¤„ç†ï¼ˆç®€æ´å®ç”¨ç‰ˆï¼‰

### åŸºç¡€æ¸…æ´—
```python
import pandas as pd
import numpy as np

# è¯»å–æ•°æ®
df = pd.read_csv('/data/raw_data.csv')

# æ‰“å°åŸºæœ¬ä¿¡æ¯
print(f"åŸå§‹æ•°æ®: {df.shape[0]}è¡Œ Ã— {df.shape[1]}åˆ—")
print(f"ç¼ºå¤±å€¼æ€»æ•°: {df.isnull().sum().sum()}")

# å¤„ç†ç¼ºå¤±å€¼ï¼ˆæ•°å€¼åˆ—ç”¨ä¸­ä½æ•°ï¼‰
numeric_cols = df.select_dtypes(include=[np.number]).columns
for col in numeric_cols:
    if df[col].isnull().any():
        df[col].fillna(df[col].median(), inplace=True)

# å¤„ç†ç¼ºå¤±å€¼ï¼ˆæ–‡æœ¬åˆ—ç”¨ä¼—æ•°ï¼‰
text_cols = df.select_dtypes(include=['object']).columns
for col in text_cols:
    if df[col].isnull().any():
        if not df[col].mode().empty:
            df[col].fillna(df[col].mode()[0], inplace=True)

# åˆ é™¤é‡å¤è¡Œ
df = df.drop_duplicates()
print(f"æ¸…æ´—åæ•°æ®: {df.shape[0]}è¡Œ Ã— {df.shape[1]}åˆ—")
```

### ç»Ÿè®¡åˆ†æ
```python
# åŸºç¡€ç»Ÿè®¡
print("æ•°å€¼åˆ—ç»Ÿè®¡:")
print(df.describe())

# åˆ†ç»„ç»Ÿè®¡
print("\nåˆ†ç»„ç»Ÿè®¡:")
group_stats = df.groupby('category').agg({
    'value': ['mean', 'sum', 'count', 'std']
}).round(2)
print(group_stats)

# é€è§†è¡¨
print("\né€è§†è¡¨:")
pivot = pd.pivot_table(df, 
                      values='sales', 
                      index='region', 
                      columns='month',
                      aggfunc='sum')
print(pivot)
```

---

## ğŸš€ æ€§èƒ½ä¼˜åŒ–ï¼ˆé’ˆå¯¹å¤§æ–‡ä»¶ï¼‰

### æ–¹æ³•1ï¼šDuckDBï¼ˆSQLæŸ¥è¯¢ï¼Œæ¯”Pandaså¿«3-10å€ï¼‰
```python
import duckdb

# ç›´æ¥æŸ¥è¯¢CSV/Parquetæ–‡ä»¶ï¼ˆä¸åŠ è½½åˆ°å†…å­˜ï¼‰
result = duckdb.sql("""
    SELECT department, 
           AVG(salary) as avg_salary,
           COUNT(*) as employee_count
    FROM read_csv_auto('/data/employees.csv')
    WHERE department IS NOT NULL
    GROUP BY department
    ORDER BY avg_salary DESC
""").df()

print("éƒ¨é—¨è–ªèµ„ç»Ÿè®¡:")
print(result)
```

### æ–¹æ³•2ï¼šåˆ†å—å¤„ç†ï¼ˆå¤§CSVæ–‡ä»¶ï¼‰
```python
# åˆ†å—è¯»å–å¤§æ–‡ä»¶
chunks = []
for chunk in pd.read_csv('/data/large_file.csv', chunksize=50000):
    # å¤„ç†æ¯ä¸ªæ•°æ®å—
    processed = chunk[chunk['value'] > 0]  # ç¤ºä¾‹ç­›é€‰
    chunks.append(processed)

# åˆå¹¶ç»“æœ
final_df = pd.concat(chunks, ignore_index=True)
print(f"å¤„ç†å®Œæˆ: {len(final_df)}è¡Œ")
```

### æ–¹æ³•3ï¼šé«˜æ•ˆæ ¼å¼è½¬æ¢
```python
# å°†CSVè½¬æ¢ä¸ºFeatheræ ¼å¼ï¼ˆæé€Ÿ10-100å€ï¼‰
import pyarrow.feather as feather

df = pd.read_csv('/data/large.csv')
feather.write_feather(df, '/data/large.feather')

# ä¸‹æ¬¡è¯»å–æ—¶ï¼ˆæé€Ÿï¼‰
df_fast = feather.read_feather('/data/large.feather')
```

---

## ğŸ’¡ å®ç”¨ä»£ç ç‰‡æ®µ

### æ¨¡æ¿1ï¼šåŸºç¡€åˆ†æ
```python
import pandas as pd
import matplotlib.pyplot as plt

# 1. è¯»å–æ•°æ®
df = pd.read_csv('/data/data.csv')

# 2. å¿«é€Ÿåˆ†æ
print(f"æ•°æ®å½¢çŠ¶: {df.shape}")
print(df.describe())

# 3. ç®€å•å¯è§†åŒ–
df.groupby('category')['value'].mean().plot(kind='bar')
plt.title('å„åˆ†ç±»å¹³å‡å€¼')
plt.tight_layout()
plt.show()
```

### æ¨¡æ¿2ï¼šæ•°æ®æ¸…æ´—æµæ°´çº¿
```python
# 1. è¯»å–
df = pd.read_csv('/data/raw.csv')

# 2. æ¸…æ´—
df = df.dropna().drop_duplicates()

# 3. åˆ†æ
print(f"æ¸…æ´—å: {df.shape}")
print(df.groupby('group')['value'].mean())

# 4. ä¿å­˜
df.to_csv('/data/cleaned.csv', index=False)
```

### æ¨¡æ¿3ï¼šå®Œæ•´æŠ¥å‘Šç”Ÿæˆ
```python
import pandas as pd
import matplotlib.pyplot as plt
from datetime import datetime

# æ·»åŠ èµ„æºä½¿ç”¨æç¤º
print(f"å¯ç”¨å†…å­˜é™åˆ¶: 6GB")
print(f"å»ºè®®å¤§æ–‡ä»¶å¤„ç†: ä½¿ç”¨åˆ†å—æˆ–DuckDB")
print("æ³¨æ„ï¼šä»£ç æ‰§è¡Œæœ‰90ç§’è¶…æ—¶é™åˆ¶ï¼Œå¤æ‚è®¡ç®—è¯·ä¼˜åŒ–")

print("=" * 50)
print(f"æ•°æ®åˆ†ææŠ¥å‘Š - {datetime.now().strftime('%Y-%m-%d')}")
print("=" * 50)

# 1. æ•°æ®æ¦‚è§ˆ
df = pd.read_csv('/data/sales.csv')
print(f"æ•°æ®é›†: {df.shape[0]}è¡Œ Ã— {df.shape[1]}åˆ—")
print(f"æ—¶é—´èŒƒå›´: {df['date'].min()} è‡³ {df['date'].max()}")

# 2. å…³é”®æŒ‡æ ‡
total_sales = df['amount'].sum()
avg_sale = df['amount'].mean()
print(f"\nå…³é”®æŒ‡æ ‡:")
print(f"  æ€»é”€å”®é¢: Â¥{total_sales:,.2f}")
print(f"  å¹³å‡äº¤æ˜“é¢: Â¥{avg_sale:,.2f}")

# 3. å¯è§†åŒ–
plt.figure(figsize=(12, 5))

# é”€å”®é¢è¶‹åŠ¿
plt.subplot(1, 2, 1)
df.groupby('date')['amount'].sum().plot()
plt.title('æ¯æ—¥é”€å”®é¢')
plt.grid(True, alpha=0.3)

# å“ç±»åˆ†å¸ƒ
plt.subplot(1, 2, 2)
df['category'].value_counts().head(10).plot(kind='bar')
plt.title('Top 10 å“ç±»')
plt.xticks(rotation=45)

plt.tight_layout()
plt.show()

print("\nâœ… åˆ†æå®Œæˆï¼")
```

---

## âš ï¸ é‡è¦æé†’ï¼ˆåŸºäºåç«¯ç‰¹æ€§ï¼‰

### åç«¯å·²é…ç½®ï¼Œæ— éœ€æ‹…å¿ƒï¼š
1. **ä¸­æ–‡å­—ä½“**ï¼šå·²å®‰è£… WenQuanYi å­—ä½“ï¼Œå›¾è¡¨æ— ä¹±ç 
2. **å›¾è¡¨æ•è·**ï¼šæ‰€æœ‰ `plt.show()` è‡ªåŠ¨è½¬æ¢ä¸ºå›¾ç‰‡
3. **å†…å­˜ç®¡ç†**ï¼šå®¹å™¨é™åˆ¶ 6GBï¼Œè‡ªåŠ¨å¤„ç†å†…å­˜æº¢å‡º
4. **æ–‡ä»¶æƒé™**ï¼š`/data` ç›®å½•æœ‰è¯»å†™æƒé™

### ä»£ç æ‰§è¡Œé™åˆ¶ï¼š
1. **å†…å­˜é™åˆ¶**ï¼šå¯ç”¨å†…å­˜ä¸Šé™ä¸º6GBï¼Œå¤„ç†å¤§æ–‡ä»¶æ—¶å»ºè®®ä½¿ç”¨åˆ†å—å¤„ç†æˆ–DuckDB
2. **è¶…æ—¶é™åˆ¶**ï¼šä»£ç æ‰§è¡Œæœ‰90ç§’è¶…æ—¶é™åˆ¶ï¼Œå¤æ‚è®¡ç®—è¯·ä¼˜åŒ–ç®—æ³•æˆ–åˆ†æ­¥æ‰§è¡Œ

### ä»£ç ç¼–å†™åŸåˆ™ï¼š
1. **ä¿æŒç®€æ´**ï¼šå†™ç›´ç™½çš„ Python ä»£ç ï¼Œæ— éœ€å¤æ‚åŒ…è£…
2. **ç›¸ä¿¡åç«¯**ï¼šç³»ç»Ÿä¼šè‡ªåŠ¨å¤„ç†å›¾è¡¨ã€é”™è¯¯ã€è¾“å‡ºæ ¼å¼
3. **ä½¿ç”¨æ ‡å‡†åº“**ï¼šPandasã€Matplotlibã€NumPy ç­‰å·²é¢„è£…
4. **å…³æ³¨ä¸šåŠ¡é€»è¾‘**ï¼šè®©åç«¯å¤„ç†æŠ€æœ¯ç»†èŠ‚

---

## ğŸ”§ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜ï¼š
1. **æ–‡ä»¶ä¸å­˜åœ¨**ï¼šæ£€æŸ¥æ–‡ä»¶åæ˜¯å¦æ­£ç¡®ï¼Œæ³¨æ„å¤§å°å†™
2. **å†…å­˜ä¸è¶³**ï¼šä½¿ç”¨åˆ†å—å¤„ç†æˆ– DuckDB æŸ¥è¯¢
3. **å›¾è¡¨ä¸æ˜¾ç¤º**ï¼šç¡®ä¿è°ƒç”¨äº† `plt.show()`
4. **ä¸­æ–‡ä¹±ç **ï¼šåç«¯å·²é…ç½®å­—ä½“ï¼Œæ— éœ€é¢å¤–å¤„ç†
5. **æ‰§è¡Œè¶…æ—¶**ï¼šä»£ç æ‰§è¡Œè¶…è¿‡90ç§’é™åˆ¶ï¼Œè¯·ä¼˜åŒ–ç®—æ³•æˆ–åˆ†æ­¥æ‰§è¡Œ

### æ€§èƒ½å»ºè®®ï¼š
- **å°æ–‡ä»¶**ï¼šç›´æ¥ä½¿ç”¨ Pandas
- **å¤§æ–‡ä»¶**ï¼šä½¿ç”¨ DuckDB æˆ–åˆ†å—å¤„ç†
- **é‡å¤è®¡ç®—**ï¼šä¿å­˜ä¸­é—´ç»“æœåˆ° `/data` ç›®å½•
- **å¤æ‚å›¾è¡¨**ï¼šåç«¯ä¼šè‡ªåŠ¨ä¼˜åŒ–æ¸²æŸ“
- **å†…å­˜ä½¿ç”¨**ï¼šå¯ç”¨å†…å­˜é™åˆ¶ä¸º6GBï¼Œå¤„ç†å¤§å‹æ•°æ®é›†æ—¶è¯·æ³¨æ„ä½¿ç”¨åˆ†å—æˆ–DuckDBä»¥é™ä½å†…å­˜å ç”¨
- **æ‰§è¡Œæ—¶é—´**ï¼šä»£ç æ‰§è¡Œæœ‰90ç§’è¶…æ—¶é™åˆ¶ï¼Œå¯¹äºå¤æ‚è®¡ç®—å»ºè®®ä¼˜åŒ–ç®—æ³•æˆ–åˆ†è§£ä¸ºå¤šä¸ªæ­¥éª¤æ‰§è¡Œ

---

## ğŸ“‹ å¿«é€Ÿå‚è€ƒå¡

```python
# è¯»å–æ–‡ä»¶
df = pd.read_csv('/data/file.csv')

# ä¿å­˜æ–‡ä»¶
df.to_csv('/data/output.csv', index=False)

# æ˜¾ç¤ºå›¾è¡¨
plt.plot(x, y)
plt.show()  # ğŸ¯ å…³é”®ï¼

# æ‰“å°ç»“æœ
print(df.describe())

# é«˜æ•ˆæŸ¥è¯¢ï¼ˆå¤§æ–‡ä»¶ï¼‰
import duckdb
result = duckdb.sql("SELECT * FROM read_csv_auto('/data/big.csv')").df()

# æ·»åŠ èµ„æºä½¿ç”¨æç¤º
print(f"å¯ç”¨å†…å­˜é™åˆ¶: 6GB")
print(f"å»ºè®®å¤§æ–‡ä»¶å¤„ç†: ä½¿ç”¨åˆ†å—æˆ–DuckDB")
print("æ³¨æ„ï¼šä»£ç æ‰§è¡Œæœ‰90ç§’è¶…æ—¶é™åˆ¶ï¼Œå¤æ‚è®¡ç®—è¯·ä¼˜åŒ–")
```

---

**æœ€ç»ˆåŸåˆ™**ï¼šå†™ä½ **æƒ³å†™**çš„ä»£ç ï¼Œåç«¯ä¼šå¤„ç†**è¯¥å¤„ç†**çš„ç»†èŠ‚ï¼å›¾è¡¨ã€æ–‡ä»¶ã€è¾“å‡ºéƒ½äº¤ç»™ç³»ç»Ÿï¼Œä½ åªéœ€è¦å…³æ³¨æ•°æ®åˆ†æå’Œä¸šåŠ¡é€»è¾‘ã€‚