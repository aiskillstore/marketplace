{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-10T12:51:45.456Z",
    "slug": "crearize-guard-regression",
    "source_url": "https://github.com/Crearize/ProjectTemplate/tree/main/.claude/skills/guard-regression",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "2.0.0",
    "source_type": "community",
    "content_hash": "96460d3a1cc73c05cd6ba989546acd5e356c48a596d7f044a863047171f6f44b",
    "tree_hash": "54f6921bcf63a1ea1611828db141ffd203dae4654aa758a8c95d5266f020332c"
  },
  "skill": {
    "name": "guard-regression",
    "description": "ãƒ‡ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç›£è¦–ã‚¹ã‚­ãƒ«ï¼ˆãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°å‰å¾Œã®å“è³ªæ¯”è¼ƒã€ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯åˆ¤æ–­ï¼‰",
    "summary": "ãƒ‡ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç›£è¦–ã‚¹ã‚­ãƒ«ï¼ˆãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°å‰å¾Œã®å“è³ªæ¯”è¼ƒã€ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯åˆ¤æ–­ï¼‰",
    "icon": "ğŸ›¡ï¸",
    "version": "1.0.0",
    "author": "Crearize",
    "license": "MIT",
    "category": "security",
    "tags": [
      "regression",
      "quality-assurance",
      "refactoring",
      "testing",
      "devops"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": []
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "Pure prompt-based skill containing only AI agent instructions in markdown format. No executable code, no network calls, no file system access beyond its own documentation. The skill defines regression monitoring workflows without any security-sensitive capabilities.",
    "risk_factor_evidence": [],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 1,
    "total_lines": 329,
    "audit_model": "claude",
    "audited_at": "2026-01-10T12:51:45.456Z"
  },
  "content": {
    "user_title": "Monitor refactoring quality with automated regression detection",
    "value_statement": "Code refactoring can introduce silent regressions that break tests, builds, or performance. This skill automatically captures baseline metrics before refactoring and compares post-refactoring results to detect issues and recommend rollbacks when needed.",
    "seo_keywords": [
      "regression testing",
      "code refactoring",
      "quality assurance",
      "automated monitoring",
      "Claude Code",
      "test coverage",
      "build validation",
      "lint checking",
      "rollback automation",
      "CI/CD quality"
    ],
    "actual_capabilities": [
      "Records baseline metrics before refactoring including test success rates, build status, lint errors, and code coverage",
      "Compares post-refactoring results against baseline to detect regressions",
      "Categorizes issues as critical (rollback required) or minor (warning only)",
      "Generates detailed comparison reports with specific failure details",
      "Recommends rollback when critical regressions are detected",
      "Validates restoration after rollback to confirm baseline is restored"
    ],
    "limitations": [
      "Does not execute tests or builds itself - relies on available CI/CD or local commands",
      "Designed for projects using Gradle (backend) and pnpm (frontend) build systems",
      "Requires pre-existing test infrastructure and coverage tools",
      "Cannot prevent regressions - only detects and reports them"
    ],
    "use_cases": [
      {
        "target_user": "Software developers",
        "title": "Safe refactoring execution",
        "description": "Refactor code with confidence knowing regressions will be caught immediately and rollbacks recommended when needed"
      },
      {
        "target_user": "QA engineers",
        "title": "Automated quality gates",
        "description": "Automate regression detection in CI/CD pipelines to catch issues before they reach production"
      },
      {
        "target_user": "Tech leads",
        "title": "Refactoring governance",
        "description": "Enforce quality standards by requiring regression validation before merging refactoring changes"
      }
    ],
    "prompt_templates": [
      {
        "title": "Start baseline recording",
        "scenario": "Before beginning refactoring",
        "prompt": "Run the guard-regression skill to record the current baseline metrics including test success rates, lint errors, build status, and code coverage for both backend and frontend"
      },
      {
        "title": "Verify post-refactoring",
        "scenario": "After completing refactoring",
        "prompt": "Run guard-regression to compare current metrics against the baseline and check for any regressions in tests, build, lint, or coverage"
      },
      {
        "title": "When regressions detected",
        "prompt": "Guard-regression detected regressions. Provide detailed analysis including specific failed tests, error messages, and recommend whether rollback is required"
      },
      {
        "title": "After rollback execution",
        "prompt": "Verify the rollback was successful by running guard-regression to confirm all metrics match the original baseline"
      }
    ],
    "output_examples": [
      {
        "input": "Run guard-regression to check for regressions after refactoring",
        "output": [
          "âœ… No regressions detected",
          "Backend: Tests 95%â†’97% (improved), Lint 12â†’8 (reduced), Build success, Coverage 78%â†’80%",
          "Frontend: Tests 92%â†’92% (maintained), Lint 3â†’2 (reduced), Build success, Coverage 85%â†’85%",
          "Refactoring is safe. Proceed with completion."
        ]
      }
    ],
    "best_practices": [
      "Always record baseline before starting any refactoring work to ensure accurate comparison",
      "Use strict regression criteria - even minor issues should be reviewed and addressed",
      "Combine with pre-commit checks to prevent regressions before they enter the codebase"
    ],
    "anti_patterns": [
      "Skipping baseline recording and proceeding directly to refactoring",
      "Ignoring minor regressions that could accumulate into major issues",
      "Running regressions in different environments than the baseline (different OS, tools versions)"
    ],
    "faq": [
      {
        "question": "Which build systems are supported?",
        "answer": "Designed for Gradle backend projects and pnpm frontend projects. Other systems require skill customization."
      },
      {
        "question": "What metrics are tracked?",
        "answer": "Test success rate, test count, lint errors and warnings, build status, and code coverage percentage."
      },
      {
        "question": "How does it integrate with CI/CD?",
        "answer:": "The skill provides commands and formats that can be incorporated into existing CI/CD pipelines for automated quality gates."
      },
      {
        "question": "Is my code data safe?",
        "answer": "The skill only reads build outputs and reports. It does not access or transmit any source code or credentials."
      },
      {
        "question": "What causes a critical regression?",
        "answer": "Test failures, build failures, or coverage drops of 5% or more require immediate rollback according to the skill."
      },
      {
        "question": "How is this different from traditional testing?",
        "answer": "Traditional testing validates correctness. This skill focuses on detecting unintended changes caused specifically by refactoring."
      }
    ]
  },
  "file_structure": [
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md"
    }
  ]
}
