{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2025-12-30T12:27:36.005Z",
    "slug": "mcp-builder",
    "source_url": "https://github.com/anthropics/skills/tree/main/skills/mcp-builder",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "2.0.0",
    "trust_level": "official"
  },
  "skill": {
    "name": "mcp-builder",
    "description": "Guide for creating high-quality MCP (Model Context Protocol) servers that enable LLMs to interact with external services through well-designed tools. Use when building MCP servers to integrate external APIs or services, whether in Python (FastMCP) or Node/TypeScript (MCP SDK).",
    "summary": "Guide for creating high-quality MCP (Model Context Protocol) servers that enable LLMs to interact wi...",
    "icon": "ðŸ”§",
    "version": "1.0.0",
    "author": "Anthropic",
    "license": "Complete terms in LICENSE.txt",
    "category": "development",
    "tags": [
      "mcp",
      "model-context-protocol",
      "server-development",
      "api-integration",
      "llm-tools",
      "typescript",
      "python",
      "fastmcp",
      "code-generation"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": [
      "scripts",
      "network",
      "env_access"
    ]
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "Official Anthropic skill providing documentation and templates for MCP server development. Contains reference materials, evaluation scripts, and best practices with no malicious code detected.",
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 10,
    "total_lines": 3532,
    "audit_model": "claude",
    "audited_at": "2025-12-30T12:27:36.004Z"
  },
  "content": {
    "user_title": "MCP Server Builder - Complete Development Guide",
    "value_statement": "Build professional Model Context Protocol servers that enable LLMs to interact with external APIs using comprehensive guides, code templates, and automated evaluation tools for both Python and TypeScript.",
    "seo_keywords": [
      "mcp server development",
      "model context protocol",
      "llm tool integration",
      "api integration for ai",
      "fastmcp python",
      "mcp typescript sdk",
      "ai agent tools",
      "llm server development",
      "mcp best practices",
      "ai tool evaluation"
    ],
    "actual_capabilities": [
      "Provides step-by-step guides for building MCP servers in Python (FastMCP) and TypeScript",
      "Includes comprehensive best practices for tool design, naming, pagination, and error handling",
      "Offers complete code templates and working examples for both language stacks",
      "Contains evaluation framework with scripts to test MCP server quality with real LLM interactions",
      "Covers transport mechanisms (streamable HTTP, stdio) with configuration examples",
      "Includes input validation patterns using Pydantic (Python) and Zod (TypeScript)",
      "Provides quality checklists and code review guidelines for production-ready servers",
      "Offers guidance on tool annotations, response formats, and context management"
    ],
    "limitations": [
      "Focused specifically on MCP server development, not general API development",
      "Requires familiarity with either Python or TypeScript/Node.js",
      "Evaluation scripts require Anthropic API key to run automated tests",
      "Does not cover MCP client development or integration",
      "Assumes basic understanding of async programming and HTTP protocols"
    ],
    "use_cases": [
      {
        "title": "Build a GitHub MCP Server",
        "description": "Create a complete MCP server that exposes GitHub API operations (issues, PRs, repos) as tools for LLMs to use, with proper pagination, error handling, and both JSON/Markdown response formats",
        "target_user": "Backend developers integrating version control into AI workflows"
      },
      {
        "title": "Integrate Project Management APIs",
        "description": "Develop MCP servers for tools like Jira, Asana, or Linear with comprehensive workflow support including task creation, updates, searching, and filtering with proper validation",
        "target_user": "DevOps engineers and productivity tool developers"
      },
      {
        "title": "Create Custom Business Logic MCP Servers",
        "description": "Build internal MCP servers that expose company-specific APIs, databases, or services to LLMs with proper authentication, authorization, and audit logging",
        "target_user": "Enterprise software architects and internal tools teams"
      },
      {
        "title": "Evaluate MCP Server Quality",
        "description": "Use the evaluation framework to create comprehensive test suites that verify LLMs can successfully complete complex, multi-step tasks using your MCP server's tools",
        "target_user": "QA engineers and MCP server maintainers"
      }
    ],
    "prompt_templates": [
      {
        "title": "Create a New MCP Server from Scratch",
        "prompt": "Build a TypeScript MCP server for the [SERVICE_NAME] API. Implement tools for [list key operations like 'creating issues', 'searching users', 'listing projects']. Use streamable HTTP transport and include comprehensive error handling, pagination support, and both JSON/Markdown response formats.",
        "scenario": "Starting a new MCP server project for a specific API service"
      },
      {
        "title": "Add Evaluation Suite to Existing Server",
        "prompt": "Create a comprehensive evaluation suite for my [SERVICE_NAME] MCP server. Generate 10 realistic, complex questions that test multi-step workflows. Questions should require read-only operations, be independent, and have stable, verifiable answers. Output in the XML qa_pair format.",
        "scenario": "Testing the quality and effectiveness of an existing MCP server"
      },
      {
        "title": "Review MCP Server Code Quality",
        "prompt": "Review my MCP server implementation against the quality checklist in the [language] guide. Check for: proper tool naming, comprehensive descriptions, input validation with [Zod/Pydantic], error handling, pagination, response formats, and code reusability. Identify areas for improvement.",
        "scenario": "Getting feedback on MCP server code before production deployment"
      },
      {
        "title": "Convert API Endpoints to MCP Tools",
        "prompt": "I have a REST API with these endpoints: [list endpoints]. Design MCP tools that cover these operations following best practices. For each tool, specify: name (with service prefix), description, input schema with validation, annotations (readOnlyHint, etc.), and example usage.",
        "scenario": "Planning the tool design for a new MCP server integration"
      }
    ],
    "output_examples": [
      {
        "input": "Build a Python MCP server for Slack with tools to send messages and search channels",
        "output": "Creates complete Python MCP server with:\n- FastMCP initialization: `mcp = FastMCP('slack_mcp')`\n- Pydantic models for input validation with constraints\n- `@mcp.tool()` decorated functions for `slack_send_message` and `slack_search_channels`\n- Async httpx client for API calls\n- Error handling with actionable messages\n- Support for both JSON and Markdown response formats\n- Pagination support with limit/offset parameters\n- Complete docstrings with Args/Returns documentation"
      },
      {
        "input": "Create an evaluation suite with 10 questions for a GitHub MCP server",
        "output": "Generates evaluation.xml with 10 complex questions like:\n- 'Find the repository archived in Q3 2023 that had the most forks. What was the primary language?'\n- 'Among critical bugs reported in January 2024, which assignee resolved the highest percentage within 48 hours?'\nEach with verifiable answers, requiring multiple tool calls, read-only operations, and stable historical data."
      }
    ],
    "best_practices": [
      "Use consistent tool naming with service prefixes (e.g., `github_create_issue` not `create_issue`)",
      "Implement both JSON and Markdown response formats for flexibility",
      "Always include pagination support with limit/offset parameters for list operations",
      "Provide actionable error messages that guide agents toward solutions",
      "Extract common functionality into reusable helper functions to avoid code duplication",
      "Use Zod (TypeScript) or Pydantic (Python) for comprehensive input validation",
      "Set proper tool annotations (readOnlyHint, destructiveHint, idempotentHint, openWorldHint)",
      "Include complete tool descriptions with parameter details, return schemas, and usage examples",
      "Implement character limits (e.g., 25000) to prevent overwhelming responses",
      "Use streamable HTTP for remote/multi-client servers, stdio for local tools",
      "Build evaluations with complex, multi-step questions using historical, stable data",
      "Test servers with `npx @modelcontextprotocol/inspector` before deployment"
    ],
    "anti_patterns": [
      "Avoid generic tool names without service prefixes that could conflict with other servers",
      "Don't skip input validation - always use schema validation libraries",
      "Never return only one response format - support both JSON and Markdown",
      "Don't ignore pagination - agents need to handle large result sets efficiently",
      "Avoid vague error messages - always provide specific guidance and next steps",
      "Don't duplicate code across tools - extract shared logic into utilities",
      "Never omit tool annotations - they help agents understand tool behavior",
      "Avoid incomplete docstrings - specify all parameters, return types, and examples",
      "Don't create evaluation questions with changing answers (e.g., 'current open issues count')",
      "Never use synchronous I/O operations - always use async/await for network calls"
    ],
    "faq": [
      {
        "question": "Should I use Python (FastMCP) or TypeScript for my MCP server?",
        "answer": "TypeScript is recommended for most cases due to high-quality SDK support, broad compatibility, and excellent static typing. Use Python if you're integrating with Python-specific libraries or have existing Python infrastructure. Both have full-featured SDKs and comprehensive guides."
      },
      {
        "question": "What's the difference between tools, resources, and prompts in MCP?",
        "answer": "Tools are functions that perform operations (API calls, computations). Resources expose data via URI templates for efficient access. Prompts are reusable templates for common tasks. Most MCP servers primarily implement tools for maximum flexibility."
      },
      {
        "question": "How do I choose between streamable HTTP and stdio transport?",
        "answer": "Use streamable HTTP for remote servers, web services, and multi-client scenarios. Use stdio for local integrations, command-line tools, and single-user workflows. Streamable HTTP with stateless JSON is recommended for scalability."
      },
      {
        "question": "What makes a good evaluation question?",
        "answer": "Good questions are: (1) complex, requiring multiple tool calls, (2) realistic use cases, (3) read-only and non-destructive, (4) independent of other questions, (5) have stable answers that won't change, and (6) answers are verifiable with direct string comparison."
      },
      {
        "question": "How do I run the evaluation scripts?",
        "answer": "Install dependencies: `pip install -r scripts/requirements.txt`. Set API key: `export ANTHROPIC_API_KEY=key`. Run: `python scripts/evaluation.py -t stdio -c python -a your_server.py evaluation.xml`. For streamable HTTP servers, start the server first, then use `-t http -u http://localhost:3000/mcp`."
      },
      {
        "question": "Should I implement comprehensive API coverage or specialized workflow tools?",
        "answer": "Prioritize comprehensive API coverage for flexibility. Agents can compose basic tools into workflows. Some clients support code execution which helps combine operations. Add specialized workflow tools for very common patterns, but comprehensive coverage gives agents more power."
      }
    ],
    "technical_requirements": {
      "dependencies": [
        "Python: mcp>=1.1.0, pydantic>=2.0, httpx (for Python servers)",
        "TypeScript: @modelcontextprotocol/sdk>=1.6.1, zod>=3.23.8, axios (for TypeScript servers)",
        "Evaluation: anthropic>=0.39.0, mcp>=1.1.0",
        "Node.js >=18 (for TypeScript) or Python >=3.10 (for Python)"
      ],
      "permissions": [
        "API keys or OAuth tokens for target service being integrated",
        "Anthropic API key (for running evaluation scripts)",
        "Network access to external APIs",
        "File system access (for stdio transport and local development)"
      ],
      "complexity": "intermediate"
    }
  },
  "file_structure": [
    {
      "name": "reference",
      "type": "dir",
      "path": "reference",
      "children": [
        {
          "name": "evaluation.md",
          "type": "file",
          "path": "reference/evaluation.md"
        },
        {
          "name": "mcp_best_practices.md",
          "type": "file",
          "path": "reference/mcp_best_practices.md"
        },
        {
          "name": "node_mcp_server.md",
          "type": "file",
          "path": "reference/node_mcp_server.md"
        },
        {
          "name": "python_mcp_server.md",
          "type": "file",
          "path": "reference/python_mcp_server.md"
        }
      ]
    },
    {
      "name": "scripts",
      "type": "dir",
      "path": "scripts",
      "children": [
        {
          "name": "connections.py",
          "type": "file",
          "path": "scripts/connections.py"
        },
        {
          "name": "evaluation.py",
          "type": "file",
          "path": "scripts/evaluation.py"
        },
        {
          "name": "example_evaluation.xml",
          "type": "file",
          "path": "scripts/example_evaluation.xml"
        },
        {
          "name": "requirements.txt",
          "type": "file",
          "path": "scripts/requirements.txt"
        }
      ]
    },
    {
      "name": "LICENSE.txt",
      "type": "file",
      "path": "LICENSE.txt"
    },
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md"
    }
  ]
}