{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-10T14:36:26.397Z",
    "slug": "dowwie-harness-model-protocol",
    "source_url": "https://github.com/Dowwie/agent_framework_study/tree/main/.claude/skills/harness-model-protocol",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "2.0.0",
    "source_type": "community",
    "content_hash": "3eecb2efaad3cbfd9698365c0eff7a9ebe2cabe78c7ea68c921fb510023ad842",
    "tree_hash": "c918f13dee8570b1bebe81612825fadc46d2f4239fc212ad85de28a064617ccf"
  },
  "skill": {
    "name": "harness-model-protocol",
    "description": "Analyze the protocol layer between agent harness and LLM model. Use when (1) understanding message wire formats and API contracts, (2) examining tool call encoding/decoding mechanisms, (3) evaluating streaming protocols and partial response handling, (4) identifying agentic chat primitives (system prompts, scratchpads, interrupts), (5) comparing multi-provider abstraction strategies, or (6) understanding how frameworks translate between native LLM APIs and internal representations.",
    "summary": "Analyze the protocol layer between agent harness and LLM model. Use when (1) understanding message w...",
    "icon": "ðŸ”Œ",
    "version": "1.0.0",
    "author": "Dowwie",
    "license": "MIT",
    "category": "research",
    "tags": [
      "protocol-analysis",
      "agent-frameworks",
      "LLM-integration",
      "message-formats",
      "multi-provider"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": []
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "Pure documentation skill containing only analysis guidance and protocol documentation. No executable code, network access, file system operations, or command execution capabilities. Contains only markdown documentation and code examples for analysis purposes.",
    "risk_factor_evidence": [],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 1,
    "total_lines": 716,
    "audit_model": "claude",
    "audited_at": "2026-01-10T14:36:26.397Z"
  },
  "content": {
    "user_title": "Analyze harness-model wire protocols",
    "value_statement": "Understanding how agent frameworks communicate with LLMs is essential for debugging, integration, and building new systems. This skill provides structured analysis methods to examine message formats, tool encoding, streaming mechanics, and multi-provider abstraction patterns.",
    "seo_keywords": [
      "harness model protocol",
      "agent framework analysis",
      "LLM wire format",
      "tool call encoding",
      "streaming protocol",
      "multi-provider abstraction",
      "Claude Code",
      "OpenAI API",
      "message format analysis"
    ],
    "actual_capabilities": [
      "Map message protocol wire formats across OpenAI, Anthropic, and Gemini providers",
      "Trace tool call encoding and decoding mechanisms in framework code",
      "Analyze streaming protocols including SSE event handling and partial responses",
      "Catalog agentic primitives like system prompts, scratchpads, and interrupt mechanisms",
      "Evaluate multi-provider abstraction strategies and adapter patterns",
      "Document provider feature matrices comparing function calling, streaming, and tool choice support"
    ],
    "limitations": [
      "This is an analysis skill that produces documentation, not executable code",
      "Does not modify or interact with live LLM APIs directly",
      "Requires the target framework codebase to be present for analysis",
      "Output quality depends on the clarity of the framework code being analyzed"
    ],
    "use_cases": [
      {
        "target_user": "Framework Developers",
        "title": "Debug protocol issues",
        "description": "Trace message flow and identify where translation errors occur between internal types and provider formats"
      },
      {
        "target_user": "Integration Engineers",
        "title": "Compare LLM providers",
        "description": "Evaluate how different frameworks abstract multiple LLM providers and assess abstraction quality"
      },
      {
        "target_user": "Security Auditors",
        "title": "Review message handling",
        "description": "Analyze how frameworks parse streaming responses and validate tool call extraction for security issues"
      }
    ],
    "prompt_templates": [
      {
        "title": "Basic protocol analysis",
        "scenario": "Analyze a new framework",
        "prompt": "Use the harness-model-protocol skill to analyze how [framework_name] handles message translation between its internal types and provider-specific formats. Focus on the adapter pattern used and which providers are supported."
      },
      {
        "title": "Streaming behavior review",
        "scenario": "Examine streaming implementation",
        "prompt": "Analyze the streaming protocol implementation in [framework_name]. How does it handle partial tool calls? What event types does it emit and where are they defined?"
      },
      {
        "title": "Tool call extraction audit",
        "scenario": "Audit tool encoding",
        "prompt": "Trace how [framework_name] encodes tool requests and parses tool responses. Identify the parsing strategy used (native API, regex, XML) and evaluate the robustness of the extraction logic."
      },
      {
        "title": "Multi-provider comparison",
        "scenario": "Compare abstraction strategies",
        "prompt": "Compare how [framework_name] supports multiple LLM providers. Create a feature matrix showing which providers are supported and which capabilities (streaming, tool choice, parallel tools) each has."
      }
    ],
    "output_examples": [
      {
        "input": "Analyze how AutoGen handles message protocol translation between its internal types and OpenAI's format.",
        "output": [
          "Message Protocol Analysis for AutoGen",
          "Wire Format Family: OpenAI-compatible with thin adapters",
          "Providers Supported: OpenAI (via adapters/openai.py), Azure (via adapters/azure.py)",
          "Abstraction Strategy: Thin adapter pattern with Provider protocol",
          "Key Finding 1: Internal UniversalMessage type maps cleanly to OpenAI's message format",
          "Key Finding 2: System prompts handled separately via dedicated field (not in messages array)",
          "Key Finding 3: Tool calls use native OpenAI tool_calls array for encoding"
        ]
      }
    ],
    "best_practices": [
      "Use thin adapter patterns that translate between internal universal types and provider-native formats",
      "Handle streaming edge cases like partial JSON arguments by implementing accumulator patterns",
      "Maintain proper tool_call_id attribution when reconstructing multi-turn conversations"
    ],
    "anti_patterns": [
      "Using regex-based parsing for structured responses instead of proper JSON/XML parsing",
      "Embedding tool schemas directly in system prompts without validation or escaping",
      "Failing to handle streaming interruptions or incomplete tool call responses gracefully"
    ],
    "faq": [
      {
        "question": "Which LLM providers does this skill support analysis for?",
        "answer": "The skill covers OpenAI Chat Completions, Anthropic Messages API, and Google Gemini formats with examples for each."
      },
      {
        "question": "What streaming protocols are covered in the analysis?",
        "answer": "Server-Sent Events (SSE) for OpenAI and Anthropic, plus WebSocket and polling patterns with event type documentation."
      },
      {
        "question": "How does this skill integrate with other analysis skills?",
        "answer": "Use codebase-mapping first to find LLM client code, then harness-model-protocol for protocol analysis, and tool-interface-analysis for schema generation."
      },
      {
        "question": "What data does this skill access during analysis?",
        "answer": "The skill reads framework source code to trace message flow. No user data, credentials, or external systems are accessed."
      },
      {
        "question": "Why is my framework showing incomplete protocol coverage?",
        "answer": "Some frameworks use provider-native types internally without abstraction. The analysis will document this pattern and note limitations."
      },
      {
        "question": "How does this differ from tool-interface-analysis?",
        "answer": "Tool-interface-analysis covers tool registration and schema generation. This skill covers wire encoding of tool calls and message translation."
      }
    ]
  },
  "file_structure": [
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md"
    }
  ]
}
