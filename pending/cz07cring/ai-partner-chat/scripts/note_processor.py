"""
Note Processor - è‡ªåŠ¨æ£€æµ‹å’Œå¤„ç†é¡¹ç›®ç¬”è®°

ç”¨äº Claude Code Skillï¼Œè‡ªåŠ¨åŒ–å¤„ç†é¡¹ç›® notes/ ç›®å½•ä¸­çš„ç¬”è®°ã€‚
"""

import sys
from pathlib import Path
from datetime import datetime
import json

# ç¡®ä¿å¯ä»¥å¯¼å…¥ orchestrator
sys.path.insert(0, str(Path(__file__).parent))

from orchestrator import AIPartnerOrchestrator


class NoteProcessor:
    """ç¬”è®°å¤„ç†å™¨ - è‡ªåŠ¨æ£€æµ‹å’Œå¤„ç†é¡¹ç›®ç¬”è®°"""

    def __init__(self, project_root: str = "."):
        """
        åˆå§‹åŒ–ç¬”è®°å¤„ç†å™¨

        Args:
            project_root: é¡¹ç›®æ ¹ç›®å½•
        """
        self.project_root = Path(project_root).resolve()
        self.notes_dir = self.project_root / 'notes'
        self.orchestrator = AIPartnerOrchestrator(project_root=str(self.project_root))

        # çŠ¶æ€æ–‡ä»¶ï¼šè®°å½•å·²å¤„ç†çš„ç¬”è®°
        self.state_file = (
            Path.home() / '.claude/skills/ai-partner-chat/data' /
            'indexes' / 'processed_notes.json'
        )
        self.state = self._load_state()

    def _load_state(self) -> dict:
        """åŠ è½½å¤„ç†çŠ¶æ€"""
        if self.state_file.exists():
            with open(self.state_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        return {'processed': {}}

    def _save_state(self):
        """ä¿å­˜å¤„ç†çŠ¶æ€"""
        self.state_file.parent.mkdir(parents=True, exist_ok=True)
        with open(self.state_file, 'w', encoding='utf-8') as f:
            json.dump(self.state, f, ensure_ascii=False, indent=2)

    def scan_notes(self) -> list:
        """
        æ‰«æ notes/ ç›®å½•ï¼ŒæŸ¥æ‰¾æ–°çš„æˆ–ä¿®æ”¹çš„ç¬”è®°

        Returns:
            éœ€è¦å¤„ç†çš„ç¬”è®°åˆ—è¡¨ [(path, mtime), ...]
        """
        if not self.notes_dir.exists():
            print(f"âš ï¸  notes/ ç›®å½•ä¸å­˜åœ¨: {self.notes_dir}")
            return []

        new_or_modified = []

        for note_file in self.notes_dir.glob('**/*.md'):
            note_path = str(note_file.relative_to(self.project_root))
            mtime = note_file.stat().st_mtime

            # æ£€æŸ¥æ˜¯å¦éœ€è¦å¤„ç†
            if note_path not in self.state['processed']:
                # æ–°ç¬”è®°
                new_or_modified.append((note_file, mtime))
            elif self.state['processed'][note_path] < mtime:
                # ä¿®æ”¹è¿‡çš„ç¬”è®°
                new_or_modified.append((note_file, mtime))

        return new_or_modified

    def process_note(self, note_path: Path) -> dict:
        """
        å¤„ç†å•ä¸ªç¬”è®°

        Args:
            note_path: ç¬”è®°æ–‡ä»¶è·¯å¾„

        Returns:
            å¤„ç†ç»“æœ
        """
        content = note_path.read_text(encoding='utf-8')

        result = self.orchestrator.process_new_note(
            note_path=str(note_path),
            content=content
        )

        # æ›´æ–°çŠ¶æ€
        relative_path = str(note_path.relative_to(self.project_root))
        self.state['processed'][relative_path] = note_path.stat().st_mtime
        self._save_state()

        return result

    def process_all_new_notes(self) -> dict:
        """
        å¤„ç†æ‰€æœ‰æ–°çš„å’Œä¿®æ”¹è¿‡çš„ç¬”è®°

        Returns:
            å¤„ç†ç»“æœæ‘˜è¦
        """
        notes_to_process = self.scan_notes()

        if not notes_to_process:
            print("âœ… æ²¡æœ‰æ–°ç¬”è®°éœ€è¦å¤„ç†")
            return {
                'processed_count': 0,
                'notes': []
            }

        print(f"ğŸ“ å‘ç° {len(notes_to_process)} ä¸ªæ–°/ä¿®æ”¹çš„ç¬”è®°")

        results = []
        for note_path, _ in notes_to_process:
            print(f"\nå¤„ç†: {note_path.name}")
            result = self.process_note(note_path)
            results.append({
                'file': note_path.name,
                'tags': result['tags'],
                'code_blocks': result['code_blocks'],
                'chunks': result['chunks_created']
            })

        print(f"\nâœ… æˆåŠŸå¤„ç† {len(results)} ä¸ªç¬”è®°")

        return {
            'processed_count': len(results),
            'notes': results
        }


# ä¾¿æ·å‡½æ•°

def check_and_process_notes(project_root: str = ".") -> dict:
    """
    æ£€æŸ¥å¹¶å¤„ç†é¡¹ç›®ç¬”è®°ï¼ˆä¾¿æ·å‡½æ•°ï¼‰

    Args:
        project_root: é¡¹ç›®æ ¹ç›®å½•

    Returns:
        å¤„ç†ç»“æœ
    """
    processor = NoteProcessor(project_root)
    return processor.process_all_new_notes()


def list_processed_notes() -> list:
    """
    åˆ—å‡ºå·²å¤„ç†çš„ç¬”è®°

    Returns:
        å·²å¤„ç†ç¬”è®°åˆ—è¡¨
    """
    state_file = (
        Path.home() / '.claude/skills/ai-partner-chat/data' /
        'indexes' / 'processed_notes.json'
    )

    if not state_file.exists():
        return []

    with open(state_file, 'r', encoding='utf-8') as f:
        state = json.load(f)

    return list(state['processed'].keys())


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # å¤„ç†å½“å‰é¡¹ç›®çš„ç¬”è®°
    result = check_and_process_notes()

    print("\n" + "="*50)
    print("å¤„ç†æ‘˜è¦:")
    print(f"  å¤„ç†ç¬”è®°æ•°: {result['processed_count']}")
    for note in result['notes']:
        print(f"\n  ğŸ“ {note['file']}")
        print(f"     æ ‡ç­¾: {', '.join(note['tags'][:5])}")
        print(f"     ä»£ç å—: {note['code_blocks']} ä¸ª")
        print(f"     Chunks: {note['chunks']} ä¸ª")
