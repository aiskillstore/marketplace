{
  "skill": {
    "name": "pytdc",
    "description": "Therapeutics Data Commons. AI-ready drug discovery datasets (ADME, toxicity, DTI), benchmarks, scaffold splits, molecular oracles, for therapeutic ML and pharmacological prediction.",
    "summary": "Access AI-ready drug discovery datasets and benchmarks for molecular property prediction, drug-target interactions, and molecule generation.",
    "icon": "ðŸ”¬",
    "version": "0.4.2",
    "author": "K-Dense Inc.",
    "license": "MIT license",
    "category": "data",
    "tags": ["drug-discovery", "machine-learning", "molecular-biology", "bioinformatics", "datasets"],
    "supported_tools": ["claude", "codex", "claude-code"]
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "PyTDC is a legitimate scientific library for drug discovery ML. All 401 static findings are FALSE POSITIVES. The scanner misinterpreted markdown backticks as shell execution, biological target names (GSK3B, DRD2) as C2 keywords, and scientific acronyms (SA, QED) as weak crypto. No actual security risks found.",
    "static_findings_evaluation": [
      {
        "finding": "[MEDIUM] external_commands: Ruby/shell backtick execution (338 locations in markdown files)",
        "verdict": "false_positive",
        "confidence": "high",
        "reasoning": "The scanner detected backtick characters (`) in markdown files (datasets.md, oracles.md, utilities.md, SKILL.md) and flagged them as shell execution. In markdown, backticks create inline code formatting (e.g., `Caco2_Wang`). This is standard documentation syntax, not Ruby/shell backtick execution. All 338 occurrences are benign markdown code formatting for dataset names, function names, and technical terms."
      },
      {
        "finding": "[HIGH] blocker: C2 keywords (GSK3B, DRD2)",
        "verdict": "false_positive",
        "confidence": "high",
        "reasoning": "The scanner flagged 'GSK3B' and 'DRD2' as C2 (command-and-control) keywords. These are legitimate biological target names: GSK3B = Glycogen Synthase Kinase 3 Beta, DRD2 = Dopamine Receptor D2. This is a name collision, not malware indicators. These are used as oracle names for evaluating molecular binding affinity to these targets."
      },
      {
        "finding": "[HIGH] blocker: Weak cryptographic algorithm (SA, QED, LogP)",
        "verdict": "false_positive",
        "confidence": "high",
        "reasoning": "The scanner flagged acronyms like 'SA', 'QED', and 'LogP' as weak cryptographic algorithms. These are scientific metrics: SA = Synthetic Accessibility score, QED = Quantitative Estimation of Drug-likeness, LogP = Lipophilicity coefficient. No cryptographic functions or implementations exist in this codebase."
      },
      {
        "finding": "[LOW] network: Hardcoded URL (tdcommons.ai, readthedocs.io, github.com)",
        "verdict": "false_positive",
        "confidence": "high",
        "reasoning": "The scanner detected hardcoded URLs in documentation. These are legitimate project resources: https://tdcommons.ai (official website), https://tdc.readthedocs.io (documentation), https://github.com/mims-harvard/TDC (repository). No suspicious network endpoints or exfiltration patterns found."
      },
      {
        "finding": "[LOW] blocker: System reconnaissance (benchmark.keys(), list())",
        "verdict": "false_positive",
        "confidence": "high",
        "reasoning": "The scanner flagged Python dictionary operations like benchmark.keys() and list() as system reconnaissance. These are standard Python operations for iterating over dataset splits in the benchmark evaluation workflow. No file system scanning, process enumeration, or privilege detection code exists."
      },
      {
        "finding": "[HIGH] sensitive: Certificate/key files",
        "verdict": "false_positive",
        "confidence": "medium",
        "reasoning": "The scanner flagged lines containing 'key' as certificate files. These are variable names like 'oracle = Oracle(name=name)' and 'predictions[seed] = y_pred'. No actual certificate or private key files exist in the codebase. No credential storage or handling code found."
      },
      {
        "finding": "[CRITICAL] obfuscation: [HEURISTIC] DANGEROUS COMBINATION: Code execution + Network + Credential access",
        "verdict": "false_positive",
        "confidence": "high",
        "reasoning": "This critical heuristic finding is a false alarm triggered by the combination of benign patterns. 'Code execution' = backtick characters in markdown. 'Network' = documentation URLs. 'Credential access' = variable names containing 'key'. This skill makes no network calls, stores no credentials, and poses no security risk. It is a data access library for scientific computing."
      }
    ],
    "risk_factor_evidence": [],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 7,
    "total_lines": 2741
  },
  "content": {
    "user_title": "Access drug discovery datasets for ML",
    "value_statement": "Access curated drug discovery datasets for training machine learning models. Load ADME, toxicity, and drug-target interaction data with standardized splits and evaluation metrics.",
    "seo_keywords": ["Therapeutics Data Commons", "drug discovery datasets", "PyTDC", "molecular property prediction", "machine learning datasets", "ADME prediction", "drug-target interaction", "molecule generation", "Claude", "Codex"],
    "actual_capabilities": [
      "Load ADME, toxicity, and pharmacokinetics datasets for drug discovery ML",
      "Access drug-target interaction (DTI) and drug-drug interaction (DDI) data",
      "Generate novel molecules using oracle-guided optimization",
      "Evaluate models with standardized metrics (ROC-AUC, RMSE, MAE, F1)",
      "Apply scaffold, random, and cold-split strategies for robust model validation"
    ],
    "limitations": [
      "Does not include pre-trained models for inference",
      "Dataset downloads require internet access to external repositories",
      "Does not perform molecular docking or experimental validation",
      "Oracles provide property predictions, not guarantees of drug efficacy"
    ],
    "use_cases": [
      {
        "target_user": "Computational chemists",
        "title": "Build ADME prediction models",
        "description": "Train ML models on Caco2 permeability, bioavailability, and toxicity datasets for drug candidate screening."
      },
      {
        "target_user": "ML researchers",
        "title": "Benchmark therapeutic ML models",
        "description": "Evaluate drug-target binding affinity and molecular generation models against standardized benchmarks."
      },
      {
        "target_user": "Drug discovery teams",
        "title": "Generate novel molecules",
        "description": "Use oracle functions to guide molecule generation toward desired properties like drug-likeness and synthetic accessibility."
      }
    ],
    "prompt_templates": [
      {
        "title": "Load a dataset",
        "scenario": "Getting started with TDC",
        "prompt": "Load the Caco2_Wang dataset from TDC using scaffold split with seed 42, then show me the first 5 training examples."
      },
      {
        "title": "Evaluate predictions",
        "scenario": "Model evaluation",
        "prompt": "Use TDC to evaluate my regression predictions using MAE metric on the Lipophilicity_AstraZeneca test set."
      },
      {
        "title": "Molecular generation",
        "scenario": "Guided molecule design",
        "prompt": "Generate 10 novel molecules optimized for GSK3B binding using TDC oracles, then evaluate their drug-likeness (QED) and synthetic accessibility (SA) scores."
      },
      {
        "title": "Benchmark comparison",
        "scenario": "Multi-seed evaluation",
        "prompt": "Run a full 5-seed benchmark evaluation on the ADMET group for my custom model and report mean and standard deviation across all 22 datasets."
      }
    ],
    "output_examples": [
      {
        "input": "Load the hERG toxicity dataset with scaffold split and show me the class distribution",
        "output": [
          "Dataset loaded: hERG (648 compounds)",
          "Split method: scaffold (default for molecular data)",
          "Train/Valid/Test: 453 / 65 / 130 compounds",
          "Class distribution: Blockers (42.1%) / Non-blockers (57.9%)",
          "Available splits: scaffold, random, stratified"
        ]
      }
    ],
    "best_practices": [
      "Use scaffold splits for molecular data to ensure test set contains novel chemical scaffolds",
      "Run 5-seed evaluations and report mean with standard deviation for robust benchmarking",
      "Combine multiple oracles (QED, SA, LogP) for balanced molecular optimization"
    ],
    "anti_patterns": [
      "Using random splits for molecular data leads to data leakage and inflated performance",
      "Training on all data without proper train/validation/test separation",
      "Relying on single oracle scores without considering multiple drug properties"
    ],
    "faq": [
      {
        "question": "What datasets are available in PyTDC?",
        "answer": "PyTDC includes 50+ datasets across ADME, toxicity, DTI, DDI, QM, and molecule generation tasks from sources like ChEMBL and BindingDB."
      },
      {
        "question": "How do I choose the right split method?",
        "answer": "Use scaffold split for molecular data to test generalization. Use cold_drug or cold_target for DTI tasks to evaluate on unseen entities."
      },
      {
        "question": "Can I use PyTDC offline?",
        "answer": "Datasets are downloaded on first use. You can cache them locally for offline work by setting the appropriate data path."
      },
      {
        "question": "What evaluation metrics are supported?",
        "answer": "Classification: ROC-AUC, PR-AUC, F1, Accuracy. Regression: RMSE, MAE, R2, Pearson, Spearman."
      },
      {
        "question": "How do I generate novel molecules?",
        "answer": "Use MolGen with Oracle functions to score generated molecules. Oracles like GSK3B, DRD2, QED, and SA guide optimization."
      },
      {
        "question": "What is the difference between oracles and evaluators?",
        "answer": "Oracles measure molecular properties for generation guidance. Evaluators compare predictions against ground truth for model assessment."
      }
    ]
  }
}
