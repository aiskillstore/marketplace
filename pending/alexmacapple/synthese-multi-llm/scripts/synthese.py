#!/usr/bin/env python3
"""
SynthÃ¨se Co-fabriquÃ©e par Conseil de LLMs
Orchestre Claude, Gemini et Codex pour produire une synthÃ¨se robuste.

Version 2.2 - Retry avec backoff (PRD-004)

InspirÃ© de Council (bacoco/Council-board-skill)
"""

import argparse
import asyncio
import json
import os
import subprocess
import sys
import time
import re
from datetime import datetime
from pathlib import Path
from typing import Optional, Dict, List, Any, Tuple, Callable, Awaitable, Protocol, runtime_checkable
from dataclasses import dataclass, field, asdict
from enum import Enum
import hashlib


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PROTOCOLES POUR INJECTION DE DÃ‰PENDANCES (PRD-015 Story 15.1)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@runtime_checkable
class CLIExecutor(Protocol):
    """
    Protocole pour l'exÃ©cution de commandes CLI.

    PRD-015: Permet l'injection de dÃ©pendances pour les tests.
    """

    async def run(
        self,
        cmd: List[str],
        timeout: int = 300
    ) -> Tuple[str, str, int]:
        """
        ExÃ©cute une commande CLI.

        Args:
            cmd: Commande et arguments
            timeout: Timeout en secondes

        Returns:
            Tuple (stdout, stderr, returncode)
        """
        ...


class DefaultCLIExecutor:
    """
    ExÃ©cuteur CLI par dÃ©faut utilisant asyncio.create_subprocess_exec.

    PRD-015: ImplÃ©mentation standard, peut Ãªtre remplacÃ©e dans les tests.
    """

    async def run(
        self,
        cmd: List[str],
        timeout: int = 300
    ) -> Tuple[str, str, int]:
        """ExÃ©cute une commande via asyncio subprocess."""
        proc = await asyncio.create_subprocess_exec(
            *cmd,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE
        )

        try:
            stdout, stderr = await asyncio.wait_for(
                proc.communicate(),
                timeout=timeout
            )
            return (
                stdout.decode('utf-8', errors='replace'),
                stderr.decode('utf-8', errors='replace'),
                proc.returncode
            )
        except asyncio.TimeoutError:
            proc.kill()
            await proc.wait()
            raise

# Import du module de configuration (PRD-003)
try:
    from config import (
        ConfigLoader, ConfigError, DEFAULT_CONFIG,
        get_expert_roles, get_default_cadrage
    )
    CONFIG_MODULE_AVAILABLE = True
except ImportError:
    CONFIG_MODULE_AVAILABLE = False
    # Fallback si le module n'est pas disponible
    DEFAULT_CONFIG = {
        "max_rounds": 2,
        "timeout": 300,
        "enable_trail": True,
        "trail_dir": "synthese_trails",
        "models": ["claude", "gemini", "codex"],
        "convergence_threshold": 0.8,
        "fallback_to_available": True,
    }

# Import du module retry (PRD-004)
try:
    from retry import (
        retry, is_retryable, classify_error,
        RetryMetricsCollector, PrintRetryCallback,
        get_retry_metrics, reset_retry_metrics,
        DEFAULT_RETRY_CONFIG, RetryableError
    )
    RETRY_MODULE_AVAILABLE = True
except ImportError:
    RETRY_MODULE_AVAILABLE = False
    DEFAULT_RETRY_CONFIG = {
        "enabled": False,
        "max_attempts": 1,
    }

# Import du module pÃ©dagogique (PRD-005)
try:
    from pedagogy import (
        PedagogicPresenter, PedagogicStep,
        create_pedagogy, get_expert_explanation
    )
    PEDAGOGY_MODULE_AVAILABLE = True
except ImportError:
    PEDAGOGY_MODULE_AVAILABLE = False

# Import du module convergence (PRD-007)
try:
    from convergence import (
        calculate_convergence as calc_convergence_hybrid,
        interpret_convergence, get_keywords
    )
    CONVERGENCE_MODULE_AVAILABLE = True
except ImportError:
    CONVERGENCE_MODULE_AVAILABLE = False

# Import du module backends (PRD-008)
try:
    from backends import (
        BackendRegistry, LLMBackend, LLMResponse as BackendResponse,
        check_anthropic_availability, AnthropicBackend
    )
    BACKENDS_MODULE_AVAILABLE = True
except ImportError:
    BACKENDS_MODULE_AVAILABLE = False

# Import du module sanitize (PRD-008 Story 8.4)
try:
    from sanitize import (
        validate_and_sanitize, sanitize_prompt, sanitize_cadrage,
        validate_source_text, validate_cadrage as validate_cadrage_fn,
        ValidationError
    )
    SANITIZE_MODULE_AVAILABLE = True
except ImportError:
    SANITIZE_MODULE_AVAILABLE = False

# PRD-018: Import des extracteurs optionnels
try:
    import pdfplumber
    PDF_AVAILABLE = True
except ImportError:
    PDF_AVAILABLE = False

try:
    from docx import Document as DocxDocument
    DOCX_AVAILABLE = True
except ImportError:
    DOCX_AVAILABLE = False

try:
    import requests
    from bs4 import BeautifulSoup
    URL_AVAILABLE = True
except ImportError:
    URL_AVAILABLE = False


# PRD-018: Dataclass Source pour multi-sources
@dataclass
class Source:
    """ReprÃ©sente une source de texte (PRD-018)."""
    name: str           # Nom de la source (fichier, URL)
    content: str        # Contenu textuel
    source_type: str    # "file", "pdf", "docx", "url", "text"
    metadata: Dict[str, Any] = field(default_factory=dict)


# PRD-019: Dataclass IndexedSource pour rÃ©fÃ©rences
@dataclass
class IndexedSource:
    """
    Source avec index de paragraphes pour rÃ©fÃ©rences [Â§N].

    PRD-019: Permet de crÃ©er des rÃ©fÃ©rences vÃ©rifiables vers le texte source.
    """
    content: str
    paragraphs: List[str]
    index: Dict[int, Tuple[int, int]]  # para_num -> (start, end)
    source_name: str = "source"


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# INDEXATION ET RÃ‰FÃ‰RENCES (PRD-019)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def index_source(text: str, source_name: str = "source") -> IndexedSource:
    """
    Indexe un texte source par paragraphes.

    PRD-019: CrÃ©e un mapping paragraphe -> position pour les rÃ©fÃ©rences [Â§N].

    Args:
        text: Texte source Ã  indexer
        source_name: Nom de la source (pour multi-sources)

    Returns:
        IndexedSource avec paragraphes numÃ©rotÃ©s
    """
    paragraphs = []
    index = {}
    current_pos = 0

    # SÃ©parer par doubles sauts de ligne ou lignes vides
    raw_paras = re.split(r'\n\s*\n', text)

    for i, para in enumerate(raw_paras, 1):
        para = para.strip()
        if para:
            start = text.find(para, current_pos)
            end = start + len(para)
            paragraphs.append(para)
            index[i] = (start, end)
            current_pos = end

    return IndexedSource(
        content=text,
        paragraphs=paragraphs,
        index=index,
        source_name=source_name
    )


def format_indexed_for_prompt(indexed: IndexedSource) -> str:
    """
    Formate le texte source avec numÃ©ros de paragraphes.

    PRD-019: PrÃ©pare le texte pour le prompt de synthÃ¨se avec rÃ©fÃ©rences.

    Args:
        indexed: Source indexÃ©e

    Returns:
        Texte formatÃ© avec [Â§N] devant chaque paragraphe
    """
    lines = []
    for i, para in enumerate(indexed.paragraphs, 1):
        lines.append(f"[Â§{i}] {para}")
    return "\n\n".join(lines)


def format_multi_indexed_for_prompt(
    indexed_sources: List[Tuple[str, IndexedSource]]
) -> str:
    """
    Formate plusieurs sources indexÃ©es pour le prompt.

    PRD-019: Support multi-sources avec rÃ©fÃ©rences [S:nomÂ§N].

    Args:
        indexed_sources: Liste de (nom, IndexedSource)

    Returns:
        Texte formatÃ© avec rÃ©fÃ©rences multi-sources
    """
    parts = []
    for name, indexed in indexed_sources:
        header = f"â•â•â• SOURCE: {name} â•â•â•"
        formatted = []
        for i, para in enumerate(indexed.paragraphs, 1):
            formatted.append(f"[S:{name}Â§{i}] {para}")
        parts.append(f"{header}\n\n" + "\n\n".join(formatted))

    return "\n\n".join(parts)


def validate_references(
    synthesis: str,
    indexed: IndexedSource
) -> Tuple[bool, List[str], List[str]]:
    """
    VÃ©rifie que les rÃ©fÃ©rences existent dans la source.

    PRD-019: DÃ©tecte les rÃ©fÃ©rences invalides ou inventÃ©es.

    Args:
        synthesis: Texte de synthÃ¨se avec rÃ©fÃ©rences [Â§N]
        indexed: Source indexÃ©e

    Returns:
        Tuple (valid, errors, valid_refs)
    """
    errors = []
    valid_refs = []

    # Pattern pour rÃ©fÃ©rences simples [Â§N] ou [Â§N.M]
    refs = re.findall(r'\[Â§(\d+(?:\.\d+)?)\]', synthesis)

    max_para = len(indexed.paragraphs)

    for ref in refs:
        para_num = int(ref.split('.')[0])
        if para_num < 1 or para_num > max_para:
            errors.append(f"[Â§{ref}] invalide (max: Â§{max_para})")
        else:
            valid_refs.append(f"Â§{ref}")

    return (len(errors) == 0, errors, valid_refs)


def validate_multi_references(
    synthesis: str,
    indexed_sources: Dict[str, IndexedSource]
) -> Tuple[bool, List[str], List[str]]:
    """
    VÃ©rifie les rÃ©fÃ©rences multi-sources [S:nomÂ§N].

    PRD-019: Validation pour synthÃ¨ses multi-sources.

    Args:
        synthesis: Texte de synthÃ¨se
        indexed_sources: Dict nom -> IndexedSource

    Returns:
        Tuple (valid, errors, valid_refs)
    """
    errors = []
    valid_refs = []

    # Pattern pour rÃ©fÃ©rences multi-sources [S:nomÂ§N]
    multi_refs = re.findall(r'\[S:([^\]Â§]+)Â§(\d+)\]', synthesis)

    for source_name, para_num_str in multi_refs:
        para_num = int(para_num_str)
        if source_name not in indexed_sources:
            errors.append(f"[S:{source_name}Â§{para_num}] source inconnue")
        else:
            max_para = len(indexed_sources[source_name].paragraphs)
            if para_num < 1 or para_num > max_para:
                errors.append(f"[S:{source_name}Â§{para_num}] invalide (max: Â§{max_para})")
            else:
                valid_refs.append(f"S:{source_name}Â§{para_num}")

    # Aussi valider les rÃ©fÃ©rences simples [Â§N] si une seule source
    simple_refs = re.findall(r'\[Â§(\d+)\]', synthesis)
    if len(indexed_sources) == 1:
        indexed = list(indexed_sources.values())[0]
        max_para = len(indexed.paragraphs)
        for ref in simple_refs:
            para_num = int(ref)
            if para_num < 1 or para_num > max_para:
                errors.append(f"[Â§{ref}] invalide (max: Â§{max_para})")
            else:
                valid_refs.append(f"Â§{ref}")

    return (len(errors) == 0, errors, valid_refs)


def extract_reference_excerpts(
    valid_refs: List[str],
    indexed_sources: Dict[str, IndexedSource],
    max_excerpt_len: int = 50
) -> List[Dict[str, str]]:
    """
    Extrait les passages correspondant aux rÃ©fÃ©rences.

    PRD-019: GÃ©nÃ¨re la section RÃ©fÃ©rences avec extraits.

    Args:
        valid_refs: Liste des rÃ©fÃ©rences valides
        indexed_sources: Dict nom -> IndexedSource
        max_excerpt_len: Longueur max des extraits

    Returns:
        Liste de {ref, excerpt}
    """
    excerpts = []

    for ref in valid_refs:
        if ref.startswith("S:"):
            # Multi-source: S:nomÂ§N
            match = re.match(r'S:([^Â§]+)Â§(\d+)', ref)
            if match:
                source_name, para_num = match.groups()
                para_num = int(para_num)
                if source_name in indexed_sources:
                    indexed = indexed_sources[source_name]
                    if 0 < para_num <= len(indexed.paragraphs):
                        text = indexed.paragraphs[para_num - 1]
                        excerpt = text[:max_excerpt_len] + "..." if len(text) > max_excerpt_len else text
                        excerpts.append({"ref": f"[S:{source_name}Â§{para_num}]", "excerpt": excerpt})
        else:
            # Simple: Â§N
            para_num = int(ref.replace("Â§", ""))
            # Prendre la premiÃ¨re source
            if indexed_sources:
                indexed = list(indexed_sources.values())[0]
                if 0 < para_num <= len(indexed.paragraphs):
                    text = indexed.paragraphs[para_num - 1]
                    excerpt = text[:max_excerpt_len] + "..." if len(text) > max_excerpt_len else text
                    excerpts.append({"ref": f"[Â§{para_num}]", "excerpt": excerpt})

    return excerpts


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TEMPLATES ET CADRAGE (PRD-020)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def resolve_cadrage(
    args: "argparse.Namespace",
    default_cadrage: Dict[str, str]
) -> Dict[str, str]:
    """
    RÃ©sout le cadrage selon la prioritÃ© : CLI > template > dÃ©faut.

    PRD-020: Support des templates de cadrage.

    Args:
        args: Arguments CLI parsÃ©s
        default_cadrage: Cadrage par dÃ©faut

    Returns:
        Cadrage rÃ©solu
    """
    # Si template spÃ©cifiÃ©, l'utiliser comme base
    template_name = getattr(args, 'template', None)
    if template_name:
        if template_name not in CADRAGE_TEMPLATES:
            raise ValueError(f"Template inconnu: {template_name}")
        cadrage = CADRAGE_TEMPLATES[template_name].copy()
        cadrage["_template"] = template_name  # MÃ©tadonnÃ©e
    else:
        cadrage = default_cadrage.copy()

    # Les options CLI explicites ont prioritÃ© sur le template
    if getattr(args, 'destinataire', None):
        cadrage["destinataire"] = args.destinataire
    if getattr(args, 'finalite', None):
        cadrage["finalite"] = args.finalite
    if getattr(args, 'longueur', None):
        cadrage["longueur"] = args.longueur
    if getattr(args, 'ton', None):
        cadrage["ton"] = args.ton
    if getattr(args, 'niveau', None):
        cadrage["niveau"] = args.niveau

    return cadrage


def list_templates() -> None:
    """
    Affiche les templates de cadrage disponibles.

    PRD-020: Commande --list-templates.
    """
    print("\nðŸ“‹ Templates de cadrage disponibles:\n")
    for name, template in CADRAGE_TEMPLATES.items():
        print(f"  {name}:")
        for key, value in template.items():
            print(f"    {key}: {value}")
        print()


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PREVIEW ET CONFIRMATION (PRD-021)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def display_draft(session: "SyntheseSession") -> None:
    """
    Affiche le brouillon de la synthÃ¨se pour validation.

    PRD-021: Preview avant confirmation.
    """
    print("\n" + "â•" * 64)
    print("                    ðŸ“ BROUILLON")
    print("â•" * 64)
    print(f"\nSession: {session.session_id}")
    print(f"Mode: {session.mode} | ModÃ¨les: {', '.join(session.models_used)}")
    print(f"Convergence: {session.convergence:.0%} | DurÃ©e: {session.duration_total:.1f}s")

    # Cadrage
    print("\nâ”Œâ”€ Cadrage â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
    for key, value in session.cadrage.items():
        if not key.startswith("_"):
            print(f"â”‚  {key}: {value}")
    print("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")

    # SynthÃ¨se
    print("\nâ”Œâ”€ SynthÃ¨se â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
    for line in session.synthese_finale.split("\n"):
        # Tronquer les lignes trop longues
        if len(line) > 58:
            line = line[:55] + "..."
        print(f"â”‚  {line}")
    print("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")

    print("\n" + "â•" * 64)


def prompt_confirmation() -> str:
    """
    Affiche le menu de confirmation et retourne le choix.

    PRD-021: Boucle de validation interactive.

    Returns:
        'export', 'regenerate', 'modify', ou 'cancel'
    """
    print("\nðŸ“‹ Que souhaitez-vous faire ?")
    print()
    print("  [E] Exporter      - Sauvegarder la synthÃ¨se")
    print("  [R] RÃ©gÃ©nÃ©rer     - Relancer la synthÃ¨se")
    print("  [M] Modifier      - Ajuster le cadrage")
    print("  [A] Annuler       - Quitter sans sauvegarder")
    print()

    while True:
        try:
            choice = input("Votre choix [E/R/M/A] : ").strip().upper()
        except EOFError:
            return 'export'  # Non-interactif, exporter par dÃ©faut

        if choice in ['E', 'EXPORT', 'EXPORTER']:
            return 'export'
        elif choice in ['R', 'REGENERATE', 'REGENERER', 'RÃ‰GÃ‰NÃ‰RER']:
            return 'regenerate'
        elif choice in ['M', 'MODIFY', 'MODIFIER']:
            return 'modify'
        elif choice in ['A', 'ANNULER', 'CANCEL', 'Q', 'QUIT']:
            return 'cancel'
        else:
            print("âŒ Choix invalide. Entrez E, R, M ou A.")


def prompt_modify_cadrage(current_cadrage: Dict[str, str]) -> Dict[str, str]:
    """
    Permet de modifier le cadrage existant.

    PRD-021: Ajustement interactif du cadrage.

    Args:
        current_cadrage: Cadrage actuel

    Returns:
        Cadrage modifiÃ©
    """
    print("\nðŸ“ Modification du cadrage (EntrÃ©e = garder la valeur actuelle)")
    print()

    new_cadrage = {}
    fields = ["destinataire", "finalite", "longueur", "ton", "niveau"]

    for field in fields:
        current = current_cadrage.get(field, "")
        try:
            new_value = input(f"  {field.capitalize()} [{current}] : ").strip()
        except EOFError:
            new_value = ""
        new_cadrage[field] = new_value if new_value else current

    # Conserver les mÃ©tadonnÃ©es
    if "_template" in current_cadrage:
        new_cadrage["_template"] = current_cadrage["_template"]

    return new_cadrage


def generate_frontmatter(session: "SyntheseSession") -> str:
    """
    Genere le frontmatter YAML depuis la session.

    PRD-022: Metadonnees YAML pour ecosystemes statiques.

    Args:
        session: Session de synthese complete

    Returns:
        Frontmatter YAML avec delimiteurs ---
    """
    import yaml

    source_name = "unknown"
    if hasattr(session, 'sources_info') and session.sources_info:
        sources = session.sources_info.get("sources", [])
        if len(sources) == 1:
            source_name = sources[0].get("name", "unknown")
        elif len(sources) > 1:
            source_name = [s.get("name", "unknown") for s in sources]

    metadata = {
        "session_id": session.session_id,
        "source": source_name,
        "date": session.timestamp_start[:10] if session.timestamp_start else None,
        "modeles": session.models_used if hasattr(session, 'models_used') else [],
        "mode": session.mode if hasattr(session, 'mode') else "unknown",
        "convergence": round(session.convergence, 2) if hasattr(session, 'convergence') and session.convergence else 0,
        "duree": round(session.duration_total, 1) if hasattr(session, 'duration_total') and session.duration_total else 0,
    }

    if hasattr(session, 'cadrage') and session.cadrage:
        metadata["cadrage"] = {k: v for k, v in session.cadrage.items() if not k.startswith("_")}
        if session.cadrage.get("_template"):
            metadata["template"] = session.cadrage["_template"]

    yaml_content = yaml.dump(metadata, default_flow_style=False, allow_unicode=True, sort_keys=False)
    return f"---\n{yaml_content}---\n\n"


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CACHE DES RÃ‰PONSES (PRD-024)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class ResponseCache:
    """
    Cache persistant pour les rÃ©ponses LLM.

    PRD-024: Ã‰viter les appels redondants en cas d'interruption.
    """

    def __init__(
        self,
        cache_dir: Optional[Path] = None,
        default_ttl: int = 86400,
        enabled: bool = True
    ):
        self.cache_dir = cache_dir or Path.home() / ".synthese_cache"
        self.default_ttl = default_ttl
        self.enabled = enabled
        # PRD-029 Story 29.1: MÃ©triques de cache
        self.hits = 0
        self.misses = 0
        self.total_latency_saved_ms = 0.0
        self._avg_call_duration_ms = 30000.0  # Estimation: 30s par appel
        if self.enabled:
            self.cache_dir.mkdir(parents=True, exist_ok=True)

    def _compute_key(self, model: str, prompt: str, role: str, cadrage: Dict) -> str:
        """Calcule la clÃ© de cache unique."""
        import hashlib
        normalized = {k: v for k, v in sorted(cadrage.items()) if not k.startswith("_")}
        key_data = json.dumps({
            "model": model,
            "prompt": prompt[:500],
            "role": role,
            "cadrage": normalized
        }, sort_keys=True)
        return hashlib.sha256(key_data.encode()).hexdigest()[:16]

    def get(self, model: str, prompt: str, role: str, cadrage: Dict) -> Optional[str]:
        """RÃ©cupÃ¨re une rÃ©ponse du cache."""
        if not self.enabled:
            return None
        key = self._compute_key(model, prompt, role, cadrage)
        cache_path = self.cache_dir / f"{key}.json"
        if not cache_path.exists():
            self.misses += 1  # PRD-029: Track miss
            return None
        try:
            with open(cache_path, encoding="utf-8") as f:
                data = json.load(f)
            if data.get("ttl", 0) > 0 and time.time() - data.get("timestamp", 0) > data["ttl"]:
                cache_path.unlink()
                self.misses += 1  # PRD-029: Track miss (expired)
                return None
            # PRD-029: Track hit and estimate latency saved
            self.hits += 1
            self.total_latency_saved_ms += self._avg_call_duration_ms
            return data.get("content")
        except Exception:
            self.misses += 1  # PRD-029: Track miss (error)
            return None

    def set(
        self,
        model: str,
        prompt: str,
        role: str,
        cadrage: Dict,
        content: str,
        ttl: Optional[int] = None
    ) -> None:
        """Stocke une rÃ©ponse dans le cache."""
        if not self.enabled:
            return
        key = self._compute_key(model, prompt, role, cadrage)
        cache_path = self.cache_dir / f"{key}.json"
        with open(cache_path, "w", encoding="utf-8") as f:
            json.dump({
                "content": content,
                "model": model,
                "timestamp": time.time(),
                "ttl": ttl or self.default_ttl
            }, f, ensure_ascii=False)

    def clear(self) -> int:
        """Vide le cache. Retourne le nombre d'entrÃ©es supprimÃ©es."""
        count = 0
        if self.cache_dir.exists():
            for f in self.cache_dir.glob("*.json"):
                f.unlink()
                count += 1
        return count

    def stats(self) -> Dict[str, Any]:
        """Retourne les statistiques du cache (PRD-029 Story 29.1)."""
        if not self.cache_dir.exists():
            entries_count = 0
            total_size = 0
        else:
            entries = list(self.cache_dir.glob("*.json"))
            entries_count = len(entries)
            total_size = sum(f.stat().st_size for f in entries)

        total_requests = self.hits + self.misses
        hit_rate = self.hits / total_requests if total_requests > 0 else 0.0

        return {
            "entries": entries_count,
            "size_mb": round(total_size / 1024 / 1024, 2),
            "cache_dir": str(self.cache_dir),
            # PRD-029: Nouvelles mÃ©triques
            "hits": self.hits,
            "misses": self.misses,
            "hit_rate": round(hit_rate, 3),
            "latency_saved_ms": round(self.total_latency_saved_ms, 0),
            "latency_saved_s": round(self.total_latency_saved_ms / 1000, 1)
        }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# EXTRACTEURS DE CONTENU (PRD-018)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def extract_pdf(file_path: str) -> str:
    """
    Extrait le texte d'un fichier PDF.

    PRD-018: Support des fichiers PDF via pdfplumber.

    Args:
        file_path: Chemin vers le fichier PDF

    Returns:
        Texte extrait du PDF

    Raises:
        RuntimeError: Si pdfplumber n'est pas installÃ©
        FileNotFoundError: Si le fichier n'existe pas
    """
    if not PDF_AVAILABLE:
        raise RuntimeError(
            "pdfplumber non installÃ©. Installez avec: pip install pdfplumber"
        )

    path = Path(file_path)
    if not path.exists():
        raise FileNotFoundError(f"Fichier PDF non trouvÃ©: {file_path}")

    text_parts = []
    with pdfplumber.open(path) as pdf:
        for page in pdf.pages:
            page_text = page.extract_text()
            if page_text:
                text_parts.append(page_text)

    return "\n\n".join(text_parts)


def extract_docx(file_path: str) -> str:
    """
    Extrait le texte d'un fichier DOCX.

    PRD-018: Support des fichiers Word via python-docx.

    Args:
        file_path: Chemin vers le fichier DOCX

    Returns:
        Texte extrait du document

    Raises:
        RuntimeError: Si python-docx n'est pas installÃ©
        FileNotFoundError: Si le fichier n'existe pas
    """
    if not DOCX_AVAILABLE:
        raise RuntimeError(
            "python-docx non installÃ©. Installez avec: pip install python-docx"
        )

    path = Path(file_path)
    if not path.exists():
        raise FileNotFoundError(f"Fichier DOCX non trouvÃ©: {file_path}")

    doc = DocxDocument(path)
    paragraphs = [p.text for p in doc.paragraphs if p.text.strip()]

    return "\n\n".join(paragraphs)


def extract_url(url: str, timeout: int = 30) -> Tuple[str, str]:
    """
    Extrait le texte d'une page web.

    PRD-018: Support des URLs via requests + BeautifulSoup.

    Args:
        url: URL de la page web
        timeout: Timeout en secondes

    Returns:
        Tuple (texte extrait, titre de la page)

    Raises:
        RuntimeError: Si requests/beautifulsoup4 non installÃ©s
        requests.RequestException: Si erreur rÃ©seau
    """
    if not URL_AVAILABLE:
        raise RuntimeError(
            "requests/beautifulsoup4 non installÃ©s. "
            "Installez avec: pip install requests beautifulsoup4"
        )

    headers = {
        'User-Agent': 'Mozilla/5.0 (compatible; SyntheseBot/1.0)'
    }

    response = requests.get(url, headers=headers, timeout=timeout)
    response.raise_for_status()

    soup = BeautifulSoup(response.content, 'html.parser')

    # Extraire le titre
    title = soup.title.string if soup.title else url

    # Supprimer scripts, styles, etc.
    for element in soup(['script', 'style', 'nav', 'footer', 'header', 'aside']):
        element.decompose()

    # Extraire le texte principal
    # Chercher d'abord dans article, main, ou body
    main_content = soup.find('article') or soup.find('main') or soup.body

    if main_content:
        text = main_content.get_text(separator='\n', strip=True)
    else:
        text = soup.get_text(separator='\n', strip=True)

    # Nettoyer les lignes vides multiples
    lines = [line.strip() for line in text.split('\n') if line.strip()]
    text = '\n'.join(lines)

    return text, title


def load_sources(
    files: Optional[List[str]] = None,
    urls: Optional[List[str]] = None,
    text: Optional[str] = None
) -> List[Source]:
    """
    Charge toutes les sources de contenu.

    PRD-018: Fonction unifiÃ©e pour charger fichiers, URLs et texte.

    Args:
        files: Liste de chemins de fichiers (txt, pdf, docx)
        urls: Liste d'URLs
        text: Texte brut optionnel

    Returns:
        Liste de Sources avec leur contenu
    """
    sources = []

    # Charger les fichiers
    if files:
        for file_path in files:
            path = Path(file_path)
            ext = path.suffix.lower()

            try:
                if ext == '.pdf':
                    content = extract_pdf(file_path)
                    source_type = "pdf"
                elif ext in ['.docx', '.doc']:
                    content = extract_docx(file_path)
                    source_type = "docx"
                else:
                    # Fichier texte par dÃ©faut
                    content = path.read_text(encoding='utf-8')
                    source_type = "file"

                sources.append(Source(
                    name=path.name,
                    content=content,
                    source_type=source_type,
                    metadata={"path": str(path.absolute())}
                ))
            except Exception as e:
                print(f"âš ï¸  Erreur lecture {file_path}: {e}", file=sys.stderr)

    # Charger les URLs
    if urls:
        for url in urls:
            try:
                content, title = extract_url(url)
                sources.append(Source(
                    name=title,
                    content=content,
                    source_type="url",
                    metadata={"url": url}
                ))
            except Exception as e:
                print(f"âš ï¸  Erreur URL {url}: {e}", file=sys.stderr)

    # Ajouter le texte brut
    if text:
        sources.append(Source(
            name="Texte direct",
            content=text,
            source_type="text",
            metadata={}
        ))

    return sources


def format_sources_for_prompt(
    sources: List[Source],
    mode: str = "merge"
) -> str:
    """
    Formate les sources pour inclusion dans le prompt.

    PRD-018: PrÃ©pare le texte combinÃ© ou comparÃ© selon le mode.

    Args:
        sources: Liste des sources chargÃ©es
        mode: "merge" (fusion) ou "compare" (comparaison)

    Returns:
        Texte formatÃ© pour le prompt
    """
    if not sources:
        return ""

    if len(sources) == 1:
        return sources[0].content

    if mode == "compare":
        # Mode comparaison: identifier clairement chaque source
        parts = []
        for i, source in enumerate(sources, 1):
            header = f"â•â•â• SOURCE {i}: {source.name} ({source.source_type}) â•â•â•"
            parts.append(f"{header}\n\n{source.content}")

        intro = f"[{len(sources)} sources Ã  comparer]\n\n"
        return intro + "\n\n".join(parts)

    else:  # mode == "merge"
        # Mode fusion: combiner avec sÃ©parateurs lÃ©gers
        parts = []
        for source in sources:
            header = f"--- {source.name} ---"
            parts.append(f"{header}\n{source.content}")

        return "\n\n".join(parts)


# RÃ´les experts pour la synthÃ¨se (utilisÃ©s si config module non disponible)
EXPERT_ROLES = {
    "extracteur": {
        "name": "L'Extracteur de Substance",
        "focus": "faits, donnÃ©es, thÃ¨se centrale",
        "prompt_suffix": "Concentre-toi sur les FAITS et la THÃˆSE centrale. Identifie les donnÃ©es concrÃ¨tes, les affirmations vÃ©rifiables, et le message principal. Ignore les ornements rhÃ©toriques."
    },
    "critique": {
        "name": "Le Gardien de la FidÃ©litÃ©",
        "focus": "glissements, biais, omissions",
        "prompt_suffix": "Traque les GLISSEMENTS de sens. VÃ©rifie que rien n'est ajoutÃ© ni omis. Distingue ce que le texte DIT de ce qu'il SUGGÃˆRE. Signale tout risque de surinterprÃ©tation."
    },
    "architecte": {
        "name": "L'Architecte du Sens",
        "focus": "structure, logique, cohÃ©rence",
        "prompt_suffix": "Analyse la STRUCTURE argumentative. Identifie les prÃ©supposÃ©s, les enchaÃ®nements logiques, les tensions. Propose une architecture claire pour la synthÃ¨se finale."
    }
}

# PRD-017: Presets de personas par domaine
PERSONA_PRESETS = {
    "tech": [
        {"name": "L'Architecte Logiciel", "focus": "structure, patterns, maintenabilitÃ©"},
        {"name": "L'Expert SÃ©curitÃ©", "focus": "vulnÃ©rabilitÃ©s, bonnes pratiques, risques"},
        {"name": "L'Optimisateur", "focus": "performance, scalabilitÃ©, efficacitÃ©"},
    ],
    "science": [
        {"name": "Le MÃ©thodologue", "focus": "rigueur scientifique, protocole, biais"},
        {"name": "Le SpÃ©cialiste Domaine", "focus": "Ã©tat de l'art, concepts clÃ©s, implications"},
        {"name": "Le Statisticien", "focus": "donnÃ©es, significativitÃ©, reproductibilitÃ©"},
    ],
    "legal": [
        {"name": "Le Juriste", "focus": "conformitÃ© lÃ©gale, clauses, risques juridiques"},
        {"name": "Le Fiscaliste", "focus": "implications fiscales, optimisation, conformitÃ©"},
        {"name": "L'Expert Compliance", "focus": "rÃ©gulations, obligations, sanctions"},
    ],
    "business": [
        {"name": "Le StratÃ¨ge", "focus": "vision, positionnement, avantage concurrentiel"},
        {"name": "L'Analyste Financier", "focus": "chiffres, ratios, rentabilitÃ©"},
        {"name": "L'Expert OpÃ©rations", "focus": "faisabilitÃ©, ressources, mise en Å“uvre"},
    ],
    "medical": [
        {"name": "Le Clinicien", "focus": "pratique mÃ©dicale, diagnostic, traitement"},
        {"name": "L'Ã‰pidÃ©miologiste", "focus": "donnÃ©es populationnelles, tendances, facteurs de risque"},
        {"name": "Le Biostatisticien", "focus": "analyses statistiques, significativitÃ©, biais"},
    ],
    "default": [
        {"name": "L'Extracteur de Substance", "focus": "faits, donnÃ©es, thÃ¨se centrale"},
        {"name": "Le Gardien de la FidÃ©litÃ©", "focus": "glissements, biais, omissions"},
        {"name": "L'Architecte du Sens", "focus": "structure, logique, cohÃ©rence"},
    ],
}

# PRD-020: Templates de cadrage prÃ©dÃ©finis
CADRAGE_TEMPLATES = {
    "comite-direction": {
        "destinataire": "comitÃ© de direction",
        "finalite": "dÃ©cision",
        "longueur": "1 page",
        "ton": "formel",
        "niveau": "expert"
    },
    "executive": {
        "destinataire": "direction gÃ©nÃ©rale",
        "finalite": "briefing rapide",
        "longueur": "5 lignes",
        "ton": "concis et direct",
        "niveau": "stratÃ©gique"
    },
    "technique": {
        "destinataire": "dÃ©veloppeurs et ingÃ©nieurs",
        "finalite": "documentation technique",
        "longueur": "10-15 lignes",
        "ton": "technique et prÃ©cis",
        "niveau": "expert"
    },
    "vulgarisation": {
        "destinataire": "grand public",
        "finalite": "information accessible",
        "longueur": "10 lignes",
        "ton": "accessible et clair",
        "niveau": "dÃ©butant"
    },
    "academique": {
        "destinataire": "chercheurs et universitaires",
        "finalite": "analyse approfondie",
        "longueur": "2 pages",
        "ton": "acadÃ©mique et rigoureux",
        "niveau": "expert"
    },
    "juridique": {
        "destinataire": "juristes et avocats",
        "finalite": "conformitÃ© et risques",
        "longueur": "1 page",
        "ton": "formel et prÃ©cis",
        "niveau": "expert"
    },
    "formation": {
        "destinataire": "apprenants et Ã©tudiants",
        "finalite": "apprentissage",
        "longueur": "15 lignes",
        "ton": "didactique et progressif",
        "niveau": "intermÃ©diaire"
    },
    "presse": {
        "destinataire": "journalistes et mÃ©dias",
        "finalite": "communication",
        "longueur": "5 lignes",
        "ton": "accrocheur et factuel",
        "niveau": "grand public"
    },
}


class Mode(Enum):
    """Modes de dÃ©libÃ©ration"""
    STANDARD = "standard"      # Processus complet en 5 Ã©tapes
    RAPIDE = "rapide"          # Cadrage minimal, synthÃ¨se directe
    CRITIQUE = "critique"      # Focus sur les glissements
    PEDAGOGIQUE = "pedagogique"  # Explique chaque Ã©tape
    DIRECT = "direct"          # Un seul modÃ¨le, sans dÃ©libÃ©ration


@dataclass
class ModelResult:
    """RÃ©sultat d'un appel Ã  un modÃ¨le"""
    model: str
    role: str
    content: str
    duration: float
    success: bool
    error: Optional[str] = None
    timestamp: str = field(default_factory=lambda: datetime.now().isoformat())
    from_cache: bool = False  # PRD-027 Story 27.3


@dataclass
class SyntheseSession:
    """Session de synthÃ¨se complÃ¨te"""
    session_id: str
    query: str
    source_text: str
    mode: str
    cadrage: Dict[str, str]
    rounds: List[Dict[str, Any]] = field(default_factory=list)
    synthese_finale: str = ""
    convergence: float = 0.0
    duration_total: float = 0.0
    timestamp_start: str = field(default_factory=lambda: datetime.now().isoformat())
    timestamp_end: str = ""
    models_used: List[str] = field(default_factory=list)
    retry_metrics: Dict[str, Any] = field(default_factory=dict)  # PRD-004
    cache_metrics: Dict[str, Any] = field(default_factory=dict)  # PRD-029 Story 29.1
    personas_info: Dict[str, Any] = field(default_factory=dict)  # PRD-017
    sources_info: Dict[str, Any] = field(default_factory=dict)  # PRD-018
    references_info: Dict[str, Any] = field(default_factory=dict)  # PRD-019


class NoModelsAvailableError(RuntimeError):
    """
    Exception levÃ©e quand aucun modÃ¨le LLM n'est disponible.
    
    PRD-008 Story 8.1: Gestion gracieuse des erreurs de configuration.
    """
    def __init__(self, message: str = None):
        default_message = (
            "Aucun modÃ¨le LLM disponible.\n\n"
            "Solutions possibles:\n"
            "  1. DÃ©finir ANTHROPIC_API_KEY pour utiliser l'API Anthropic\n"
            "  2. Installer un CLI wrapper (claude, gemini, codex)\n"
            "  3. Configurer un backend dans synthese.config.yaml\n\n"
            "Documentation: https://github.com/your-repo/synthese-council#installation"
        )
        super().__init__(message or default_message)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# AFFICHAGE THREAD-SAFE (Story 2.5)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AsyncPrinter:
    """GÃ¨re l'affichage concurrent sans mÃ©lange de lignes."""

    def __init__(self, file=None):
        self._lock = None  # CrÃ©Ã© Ã  la demande pour Ã©viter l'erreur "no event loop"
        self._file = file  # None = stdout, sys.stderr pour logs

    def _get_lock(self):
        """Retourne le lock, le crÃ©ant si nÃ©cessaire."""
        if self._lock is None:
            try:
                self._lock = asyncio.Lock()
            except RuntimeError:
                # Pas d'event loop, crÃ©er un dummy lock
                self._lock = asyncio.Lock()
        return self._lock

    async def print(self, message: str, end: str = "\n", flush: bool = True):
        """Affiche un message de maniÃ¨re thread-safe."""
        lock = self._get_lock()
        async with lock:
            print(message, end=end, flush=flush, file=self._file)

    def print_sync(self, message: str, end: str = "\n", flush: bool = True):
        """Version synchrone pour le code non-async."""
        print(message, end=end, flush=flush, file=self._file)

    def set_file(self, file):
        """Change la destination de sortie."""
        self._file = file


# Instance globale pour l'affichage
_printer = AsyncPrinter()

# Destination des logs (stdout par dÃ©faut, stderr si sortie structurÃ©e)
_log_file = None


def log(message: str, end: str = "\n", flush: bool = True):
    """Affiche un message de log (redirigÃ© vers stderr si sortie structurÃ©e)."""
    print(message, end=end, flush=flush, file=_log_file)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# UTILITAIRES CLI (synchrones - pour vÃ©rification)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def check_cli(model: str) -> Tuple[bool, str]:
    """VÃ©rifie si un CLI est disponible (synchrone)"""
    cli_map = {
        "claude": "claude",
        "gemini": "gemini",
        "codex": "codex"
    }
    cli = cli_map.get(model, model)
    
    try:
        result = subprocess.run(
            [cli, "--version"],
            capture_output=True,
            text=True,
            timeout=10
        )
        version = result.stdout.strip() or result.stderr.strip()
        return True, version
    except FileNotFoundError:
        return False, f"{cli} non trouvÃ©"
    except subprocess.TimeoutExpired:
        return False, "timeout"
    except Exception as e:
        return False, str(e)


def check_all_clis() -> Dict[str, Tuple[bool, str]]:
    """
    VÃ©rifie les 3 CLIs disponibles.
    
    PRD-013: Retourne uniquement les CLIs (claude, gemini, codex).
    Les backends API sont gÃ©rÃ©s sÃ©parÃ©ment par get_available_backends().
    
    Returns:
        Dict[model_name, (available, info_message)]
    """
    results = {}
    
    # VÃ©rifier uniquement les CLIs
    for model in ["claude", "gemini", "codex"]:
        results[model] = check_cli(model)
    
    return results


def get_available_backends() -> List[LLMBackend]:
    """
    RÃ©cupÃ¨re les backends API disponibles.
    
    PRD-008: Support des backends natifs (Anthropic, etc.)
    PRD-013: UtilisÃ© comme fallback si aucun CLI disponible.
    
    Returns:
        Liste des backends disponibles
    """
    if not BACKENDS_MODULE_AVAILABLE:
        return []
    
    return BackendRegistry.get_available()


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# APPELS MODÃˆLES - VERSION SYNCHRONE (compatibilitÃ©)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def call_model(
    model: str,
    prompt: str,
    timeout: int = 300,
    role: str = "default"
) -> ModelResult:
    """Appelle un modÃ¨le via son CLI (version synchrone)"""
    
    start_time = time.time()
    
    # PRD-013: Commandes CLI correctes
    # - claude: claude -p "prompt"
    # - gemini: gemini -p "prompt"  
    # - codex: codex exec "prompt" (mode non-interactif)
    #   Note: --skip-git-repo-check requis hors d'un repo git
    cli_map = {
        "claude": ["claude", "-p"],
        "gemini": ["gemini", "-p"],
        "codex": ["codex", "exec", "--skip-git-repo-check"]
    }
    
    cmd = cli_map.get(model)
    if not cmd:
        return ModelResult(
            model=model,
            role=role,
            content="",
            duration=0,
            success=False,
            error=f"ModÃ¨le inconnu: {model}"
        )
    
    try:
        result = subprocess.run(
            cmd + [prompt],
            capture_output=True,
            text=True,
            timeout=timeout
        )
        
        duration = time.time() - start_time
        content = result.stdout.strip()
        
        if result.returncode != 0 and not content:
            return ModelResult(
                model=model,
                role=role,
                content="",
                duration=duration,
                success=False,
                error=result.stderr.strip() or f"Code retour: {result.returncode}"
            )
        
        return ModelResult(
            model=model,
            role=role,
            content=content,
            duration=duration,
            success=True
        )
        
    except subprocess.TimeoutExpired:
        return ModelResult(
            model=model,
            role=role,
            content="",
            duration=timeout,
            success=False,
            error=f"Timeout aprÃ¨s {timeout}s"
        )
    except FileNotFoundError:
        return ModelResult(
            model=model,
            role=role,
            content="",
            duration=time.time() - start_time,
            success=False,
            error=f"CLI non trouvÃ©: {model}"
        )
    except Exception as e:
        return ModelResult(
            model=model,
            role=role,
            content="",
            duration=time.time() - start_time,
            success=False,
            error=str(e)
        )


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# APPELS MODÃˆLES - VERSION ASYNCHRONE (Story 2.1)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Instance globale de l'executor par dÃ©faut (PRD-015)
_default_cli_executor = None


def get_default_cli_executor() -> DefaultCLIExecutor:
    """Retourne l'executor CLI par dÃ©faut (singleton)."""
    global _default_cli_executor
    if _default_cli_executor is None:
        _default_cli_executor = DefaultCLIExecutor()
    return _default_cli_executor


async def call_model_async(
    model: str,
    prompt: str,
    timeout: int = 300,
    role: str = "default",
    printer: AsyncPrinter = None,
    cli_executor: CLIExecutor = None
) -> ModelResult:
    """
    Appelle un modÃ¨le via son CLI de maniÃ¨re asynchrone.

    Story 2.1 du PRD-002: Version async de call_model avec asyncio.create_subprocess_exec
    PRD-015: Support de l'injection de dÃ©pendances via cli_executor

    Args:
        model: Nom du modÃ¨le (claude, gemini, codex)
        prompt: Prompt Ã  envoyer
        timeout: Timeout en secondes
        role: RÃ´le assignÃ©
        printer: Printer async pour l'affichage
        cli_executor: Executor CLI injectable (pour les tests)
    """

    start_time = time.time()
    executor = cli_executor or get_default_cli_executor()

    # PRD-013: Commandes CLI correctes
    # - claude: claude -p "prompt"
    # - gemini: gemini -p "prompt"
    # - codex: codex exec "prompt" (mode non-interactif)
    #   Note: --skip-git-repo-check requis hors d'un repo git
    cli_map = {
        "claude": ["claude", "-p"],
        "gemini": ["gemini", "-p"],
        "codex": ["codex", "exec", "--skip-git-repo-check"]
    }

    cmd = cli_map.get(model)
    if not cmd:
        return ModelResult(
            model=model,
            role=role,
            content="",
            duration=0,
            success=False,
            error=f"ModÃ¨le inconnu: {model}"
        )

    try:
        # Utiliser l'executor injectable (PRD-015)
        stdout, stderr, returncode = await executor.run(cmd + [prompt], timeout)

        duration = time.time() - start_time
        content = stdout.strip()
        stderr_text = stderr.strip()

        if returncode != 0 and not content:
            return ModelResult(
                model=model,
                role=role,
                content="",
                duration=duration,
                success=False,
                error=stderr_text or f"Code retour: {returncode}"
            )

        return ModelResult(
            model=model,
            role=role,
            content=content,
            duration=duration,
            success=True
        )

    except asyncio.TimeoutError:
        return ModelResult(
            model=model,
            role=role,
            content="",
            duration=timeout,
            success=False,
            error=f"Timeout aprÃ¨s {timeout}s"
        )
    except FileNotFoundError:
        return ModelResult(
            model=model,
            role=role,
            content="",
            duration=time.time() - start_time,
            success=False,
            error=f"CLI non trouvÃ©: {model}"
        )
    except asyncio.CancelledError:
        # Propagate cancellation
        raise
    except Exception as e:
        return ModelResult(
            model=model,
            role=role,
            content="",
            duration=time.time() - start_time,
            success=False,
            error=str(e)
        )


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# APPELS MODÃˆLES AVEC RETRY (PRD-004)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async def call_model_async_with_retry(
    model: str,
    prompt: str,
    timeout: int = 300,
    role: str = "default",
    printer: AsyncPrinter = None,
    retry_config: Dict[str, Any] = None,
    metrics_collector = None,
    cli_executor: CLIExecutor = None,
    cache: "ResponseCache" = None,
    cadrage: Dict[str, Any] = None
) -> ModelResult:
    """
    Appelle un modÃ¨le avec retry automatique sur erreurs transitoires.

    PRD-004: Wrapper de call_model_async avec backoff exponentiel.
    PRD-027 Story 27.3: IntÃ©gration cache.

    Args:
        model: Nom du modÃ¨le (claude, gemini, codex)
        prompt: Prompt Ã  envoyer
        timeout: Timeout par tentative
        role: RÃ´le assignÃ© au modÃ¨le
        printer: Printer async pour l'affichage
        retry_config: Configuration du retry (depuis config YAML)
        metrics_collector: Collecteur de mÃ©triques de retry
        cache: Cache de rÃ©ponses (PRD-027)
        cadrage: ParamÃ¨tres de cadrage pour clÃ© de cache

    Returns:
        ModelResult avec succÃ¨s ou erreur finale
    """
    # PRD-027 Story 27.3: Cache lookup
    if cache and cache.enabled:
        cached_content = cache.get(model, prompt, role, cadrage or {})
        if cached_content:
            if printer:
                await printer.print(f"  âš¡ Cache hit pour {model}")
            return ModelResult(
                model=model,
                content=cached_content,
                success=True,
                duration=0.0,
                role=role,
                from_cache=True
            )

    if not RETRY_MODULE_AVAILABLE:
        # Pas de module retry, appel direct
        result = await call_model_async(model, prompt, timeout, role, printer, cli_executor)
        # Cache store aprÃ¨s succÃ¨s
        if cache and cache.enabled and result.success:
            cache.set(model, prompt, role, cadrage or {}, result.content)
        return result

    # Configuration par dÃ©faut
    cfg = {**DEFAULT_RETRY_CONFIG, **(retry_config or {})}

    if not cfg.get("enabled", True):
        # Retry dÃ©sactivÃ©
        result = await call_model_async(model, prompt, timeout, role, printer, cli_executor)
        if cache and cache.enabled and result.success:
            cache.set(model, prompt, role, cadrage or {}, result.content)
        return result
    
    # RÃ©cupÃ©rer les paramÃ¨tres
    max_attempts = cfg.get("max_attempts", 3)
    base_delay = cfg.get("base_delay", 2.0)
    max_delay = cfg.get("max_delay", 30.0)
    exponential_base = cfg.get("exponential_base", 2.0)
    jitter = cfg.get("jitter", 0.1)
    
    # Callback pour l'affichage
    callback = PrintRetryCallback(printer) if printer else None
    
    # MÃ©triques
    collector = metrics_collector or get_retry_metrics()
    
    last_result = None
    
    for attempt in range(1, max_attempts + 1):
        collector.record_attempt(model)

        # Appel au modÃ¨le (PRD-015: avec executor injectable)
        result = await call_model_async(model, prompt, timeout, role, printer, cli_executor)
        
        if result.success:
            # SuccÃ¨s
            if callback and attempt > 1:
                await callback.on_success(model, attempt)

            if attempt > 1:
                collector.record_success_after_retry(model)

            # PRD-027 Story 27.3: Cache store aprÃ¨s succÃ¨s
            if cache and cache.enabled:
                cache.set(model, prompt, role, cadrage or {}, result.content)

            return result
        
        # Ã‰chec - vÃ©rifier si retryable
        last_result = result
        
        if not is_retryable(result.error or ""):
            # Erreur non-retryable (CLI absent, etc.)
            collector.record_failure(model)
            return result
        
        if attempt == max_attempts:
            # DerniÃ¨re tentative, Ã©chec final
            collector.record_failure(model)
            
            if callback:
                await callback.on_failure(model, attempt, classify_error(result.error or ""))
            
            return result
        
        # Calculer le dÃ©lai
        import random as _random
        delay = base_delay * (exponential_base ** (attempt - 1))
        delay = min(delay, max_delay)
        jitter_range = delay * jitter
        delay += _random.uniform(-jitter_range, jitter_range)
        delay = max(0, delay)
        
        # Logger et notifier
        reason = classify_error(result.error or "")
        # PRD-027 Story 27.2: Ã‰vÃ©nements dÃ©taillÃ©s
        collector.record_retry(
            model, reason, delay,
            attempt=attempt,
            error_snippet=result.error or ""
        )
        
        if callback:
            await callback.on_retry(model, attempt, max_attempts, delay, reason)
        
        # Attendre avant le retry
        await asyncio.sleep(delay)
    
    return last_result


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MOTEUR DE SYNTHÃˆSE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class SyntheseCouncil:
    """Orchestre la synthÃ¨se multi-LLM avec appels asynchrones et config dynamique"""

    def __init__(
        self,
        config: Dict = None,
        config_path: str = None,
        cli_executor: CLIExecutor = None,
        backend_factory = None
    ):
        """
        Initialise le council avec configuration.

        PRD-015: Support de l'injection de dÃ©pendances pour les tests.

        Args:
            config: Override de configuration (dict)
            config_path: Chemin vers un fichier de config YAML
            cli_executor: Executor CLI injectable (pour les tests)
            backend_factory: Factory de backends injectable (pour les tests)
        """
        # PRD-015: Injection de dÃ©pendances
        self.cli_executor = cli_executor
        self.backend_factory = backend_factory
        # Charger la configuration (PRD-003)
        if CONFIG_MODULE_AVAILABLE:
            try:
                self.config = ConfigLoader.load(
                    path=config_path,
                    cli_overrides=config
                )
            except ConfigError as e:
                print(f"âš  Erreur de configuration: {e}")
                print("  Utilisation de la configuration par dÃ©faut.")
                self.config = {**DEFAULT_CONFIG, **(config or {})}
        else:
            self.config = {**DEFAULT_CONFIG, **(config or {})}
        
        # Charger les rÃ´les experts (avec personnalisation)
        if CONFIG_MODULE_AVAILABLE:
            self.expert_roles = get_expert_roles(self.config)
        else:
            self.expert_roles = EXPERT_ROLES
        
        # Configuration retry (PRD-004)
        self.retry_config = self.config.get("retry", DEFAULT_RETRY_CONFIG)
        
        # MÃ©triques de retry (PRD-004)
        if RETRY_MODULE_AVAILABLE:
            self.retry_metrics = RetryMetricsCollector()
        else:
            self.retry_metrics = None
        
        # Mode pÃ©dagogique (PRD-005)
        self.pedagogy = None  # Sera initialisÃ© dans run_async selon le mode
        
        self.available_models: List[str] = []
        self.session: Optional[SyntheseSession] = None
        self.printer = _printer  # Utiliser le printer global (PRD-014)
        
        # PRD-008: Backends API natifs
        self.backends: Dict[str, Any] = {}  # model_name -> backend instance

        # PRD-029: Cache de rÃ©ponses cÃ¢blÃ© dans flux principal
        cache_config = self.config.get("cache", {})
        self.cache = ResponseCache(
            enabled=cache_config.get("enabled", True),
            default_ttl=cache_config.get("ttl", 3600),
            cache_dir=Path(cache_config.get("directory", ".cache/synthese")) if cache_config.get("directory") else None
        )
        self.cadrage: Dict[str, str] = {}  # StockÃ© pour clÃ© de cache
        
    def setup(self) -> bool:
        """
        VÃ©rifie et configure les modÃ¨les disponibles.
        
        PRD-013: PrioritÃ© aux CLIs, API en fallback.
        
        Ordre de prioritÃ©:
        1. CLIs (claude, gemini, codex) - mÃ©thode principale
        2. Backend API (Anthropic) - fallback si aucun CLI
        """
        log("\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
        log("â•‘           VÃ‰RIFICATION DES MODÃˆLES                           â•‘")
        log("â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")

        # 1. VÃ©rifier les CLIs en premier (mÃ©thode principale)
        cli_status = check_all_clis()

        for model, (available, info) in cli_status.items():
            status = "âœ“" if available else "âœ—"
            log(f"â•‘  {status} {model:10} â”‚ {info[:45]:<45} â•‘")
            if available:
                self.available_models.append(model)

        # 2. Fallback: Backend API si aucun CLI disponible
        if not self.available_models and BACKENDS_MODULE_AVAILABLE:
            log("â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
            log("â•‘  Aucun CLI trouvÃ©, recherche de backends API...              â•‘")
            log("â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")

            api_backends = get_available_backends()
            for backend in api_backends:
                model_name = backend.name.split(":")[0]
                self.backends[model_name] = backend
                self.available_models.append(model_name)
                log(f"â•‘  âœ“ {model_name:10} â”‚ {backend.display_name[:45]:<45} â•‘")

        log("â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")

        if len(self.available_models) == 0:
            log("â•‘  ERREUR: Aucun modÃ¨le disponible                            â•‘")
            log("â•‘                                                              â•‘")
            log("â•‘  Solutions:                                                  â•‘")
            log("â•‘  1. Installer les CLIs:                                      â•‘")
            log("â•‘     npm install -g @anthropic-ai/claude-code                 â•‘")
            log("â•‘     npm install -g @google/gemini-cli                        â•‘")
            log("â•‘     npm install -g @openai/codex                             â•‘")
            log("â•‘  2. Ou dÃ©finir ANTHROPIC_API_KEY (fallback)                  â•‘")
            log("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
            return False
        elif len(self.available_models) < 3 and not self.backends:
            log(f"â•‘  ATTENTION: {len(self.available_models)}/3 CLIs disponibles                          â•‘")
            if not self.config["fallback_to_available"]:
                log("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
                return False

        # Afficher le type de backend utilisÃ©
        if self.backends:
            log(f"â•‘  STATUS: PrÃªt avec {len(self.available_models)} modÃ¨le(s) (API fallback) âœ“         â•‘")
        else:
            log(f"â•‘  STATUS: PrÃªt avec {len(self.available_models)} modÃ¨le(s) (CLI) âœ“                  â•‘")
        log("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
        return True
    
    def _generate_session_id(self) -> str:
        """GÃ©nÃ¨re un ID de session unique"""
        timestamp = datetime.now().strftime("%Y%m%d-%H%M%S")
        hash_suffix = hashlib.md5(str(time.time()).encode()).hexdigest()[:6]
        return f"synthese-{timestamp}-{hash_suffix}"
    
    def _assign_roles(self) -> Dict[str, str]:
        """Assigne les rÃ´les aux modÃ¨les disponibles"""
        roles = list(self.expert_roles.keys())
        assignments = {}

        for i, model in enumerate(self.available_models):
            role = roles[i % len(roles)]
            assignments[model] = role

        return assignments

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # PERSONAS DYNAMIQUES (PRD-017)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def _preset_to_roles(self, preset: List[Dict]) -> Dict[str, Dict]:
        """Convertit un preset de personas en structure expert_roles (PRD-017)."""
        roles = {}
        for i, persona in enumerate(preset):
            role_key = f"persona_{i}"
            roles[role_key] = {
                "name": persona["name"],
                "focus": persona["focus"],
                "prompt_suffix": f"En tant que {persona['name']}, concentre-toi sur: {persona['focus']}. Apporte ta perspective d'expert sur ces aspects spÃ©cifiques."
            }
        return roles

    def _custom_to_roles(self, names: List[str]) -> Dict[str, Dict]:
        """Convertit une liste de noms personnalisÃ©s en structure expert_roles (PRD-017)."""
        roles = {}
        for i, name in enumerate(names[:3]):  # Max 3 personas
            role_key = f"persona_{i}"
            clean_name = name.strip().capitalize()
            roles[role_key] = {
                "name": f"L'Expert {clean_name}",
                "focus": f"perspective {clean_name}",
                "prompt_suffix": f"En tant qu'expert {clean_name}, analyse ce document avec ta perspective spÃ©cialisÃ©e. Apporte ton regard critique et tes connaissances du domaine."
            }
        return roles

    async def generate_personas(self, source_text: str, model: str = None) -> List[Dict[str, str]]:
        """
        GÃ©nÃ¨re des personas experts adaptÃ©s au document (PRD-017).

        Args:
            source_text: Texte Ã  analyser
            model: ModÃ¨le Ã  utiliser (dÃ©faut: premier disponible)

        Returns:
            Liste de 3 personas avec name et focus
        """
        model = model or self.available_models[0]

        prompt = f"""Analyse ce document et gÃ©nÃ¨re 3 experts complÃ©mentaires pour le synthÃ©tiser.

DOCUMENT (extrait):
---
{source_text[:2000]}
---

CONSIGNES:
1. Identifie le domaine principal du document
2. GÃ©nÃ¨re 3 personas d'experts avec des angles complÃ©mentaires
3. Chaque persona doit avoir un nom Ã©vocateur et un focus prÃ©cis

FORMAT DE RÃ‰PONSE (JSON strict):
{{
  "domaine": "nom du domaine identifiÃ©",
  "personas": [
    {{"name": "Le/La [Titre Expert 1]", "focus": "aspect 1, aspect 2, aspect 3"}},
    {{"name": "Le/La [Titre Expert 2]", "focus": "aspect 1, aspect 2, aspect 3"}},
    {{"name": "Le/La [Titre Expert 3]", "focus": "aspect 1, aspect 2, aspect 3"}}
  ]
}}

RÃ©ponds UNIQUEMENT avec le JSON, sans texte avant ou aprÃ¨s."""

        result = await self._call_model_smart(model, prompt, timeout=60, role="persona_generator")

        if not result.success:
            log(f"âš  GÃ©nÃ©ration personas Ã©chouÃ©e, utilisation des dÃ©fauts")
            return PERSONA_PRESETS["default"]

        try:
            # Parser le JSON
            import re
            json_match = re.search(r'\{[\s\S]*\}', result.content)
            if json_match:
                data = json.loads(json_match.group())
                personas = data.get("personas", [])
                domaine = data.get("domaine", "inconnu")
                if len(personas) >= 3:
                    log(f"âœ“ Domaine dÃ©tectÃ©: {domaine}")
                    # Stocker le domaine dÃ©tectÃ© pour le trail
                    self._detected_domain = domaine
                    return personas[:3]
        except (json.JSONDecodeError, KeyError) as e:
            log(f"âš  Erreur parsing personas: {e}")

        return PERSONA_PRESETS["default"]

    async def resolve_personas(self, personas_arg: str, source_text: str) -> Tuple[Dict[str, Dict], str, List[Dict]]:
        """
        RÃ©sout les personas selon l'argument fourni (PRD-017).

        Args:
            personas_arg: 'auto', nom de preset, ou liste personnalisÃ©e
            source_text: Texte source pour l'auto-dÃ©tection

        Returns:
            Tuple (expert_roles, mode_label, personas_list)
        """
        self._detected_domain = None

        if personas_arg == "auto":
            log("\nâ”€â”€â”€ GÃ‰NÃ‰RATION DES PERSONAS â”€â”€â”€")
            log("â”œâ”€ Analyse du document...")
            personas_list = await self.generate_personas(source_text)
            roles = self._preset_to_roles(personas_list)
            return roles, "auto", personas_list

        elif personas_arg in PERSONA_PRESETS:
            personas_list = PERSONA_PRESETS[personas_arg]
            roles = self._preset_to_roles(personas_list)
            log(f"âœ“ Personas preset: {personas_arg}")
            return roles, personas_arg, personas_list

        else:
            # Liste personnalisÃ©e "expert1,expert2,expert3"
            custom_names = [p.strip() for p in personas_arg.split(",")]
            roles = self._custom_to_roles(custom_names)
            personas_list = [{"name": f"L'Expert {n.strip().capitalize()}", "focus": f"perspective {n.strip()}"} for n in custom_names[:3]]
            log(f"âœ“ Personas personnalisÃ©s: {', '.join(custom_names[:3])}")
            return roles, "custom", personas_list

    async def _call_model_smart(
        self,
        model: str,
        prompt: str,
        timeout: int = 300,
        role: str = "default"
    ) -> ModelResult:
        """
        Appelle un modÃ¨le via le backend appropriÃ© (API ou CLI).
        
        PRD-008 Story 8.2: Utilise le backend API si disponible,
        sinon fallback sur CLI avec retry.
        
        Args:
            model: Nom du modÃ¨le
            prompt: Prompt Ã  envoyer
            timeout: Timeout en secondes
            role: RÃ´le assignÃ©
            
        Returns:
            ModelResult avec le rÃ©sultat
        """
        start_time = time.time()
        
        # VÃ©rifier si un backend API est disponible pour ce modÃ¨le
        if model in self.backends:
            backend = self.backends[model]
            
            try:
                # Appel via backend API
                response = await backend.call(prompt, timeout=timeout)
                
                return ModelResult(
                    model=model,
                    role=role,
                    content=response.content,
                    duration=response.duration,
                    success=response.success,
                    error=response.error
                )
                
            except Exception as e:
                duration = time.time() - start_time
                return ModelResult(
                    model=model,
                    role=role,
                    content="",
                    duration=duration,
                    success=False,
                    error=f"Erreur backend {model}: {e}"
                )
        
        # Fallback sur CLI avec retry (PRD-015: avec executor injectable)
        # PRD-029: Cache cÃ¢blÃ© dans flux principal
        return await call_model_async_with_retry(
            model,
            prompt,
            timeout,
            role,
            printer=self.printer,
            retry_config=self.retry_config,
            metrics_collector=self.retry_metrics,
            cli_executor=self.cli_executor,
            cache=self.cache,
            cadrage=self.cadrage
        )
    
    def _build_prompt(
        self,
        stage: str,
        source_text: str,
        cadrage: Dict[str, str],
        role: str,
        previous_outputs: List[Dict] = None,
        with_refs: bool = False  # PRD-019
    ) -> str:
        """Construit le prompt pour une Ã©tape donnÃ©e"""

        role_info = self.expert_roles.get(role, {})
        role_name = role_info.get("name", role)
        role_suffix = role_info.get("prompt_suffix", "")
        
        base_prompt = f"""Tu es {role_name}, expert en analyse de texte.

CONTEXTE DE LA SYNTHÃˆSE:
- Destinataire: {cadrage.get('destinataire', 'non prÃ©cisÃ©')}
- FinalitÃ©: {cadrage.get('finalite', 'non prÃ©cisÃ©')}
- Longueur: {cadrage.get('longueur', 'non prÃ©cisÃ©')}
- Ton: {cadrage.get('ton', 'non prÃ©cisÃ©')}
- Niveau: {cadrage.get('niveau', 'non prÃ©cisÃ©')}

TEXTE SOURCE:
---
{source_text}
---

"""
        
        if stage == "extraction":
            base_prompt += f"""TÃ‚CHE: Extraction initiale

{role_suffix}

Produis une analyse structurÃ©e selon ton expertise. Format attendu:
1. THÃˆSE CENTRALE (1-2 phrases)
2. FAITS CLÃ‰S (liste)
3. MOTS-CADRES (termes importants)
4. LOGIQUE ARGUMENTATIVE (structure)
5. POINTS DE VIGILANCE (risques de glissement)
"""
        
        elif stage == "critique":
            prev_content = "\n\n".join([
                f"=== {p['model']} ({p['role']}) ===\n{p['content']}"
                for p in (previous_outputs or [])
            ])
            
            base_prompt += f"""TÃ‚CHE: Critique croisÃ©e

Les autres experts ont produit les analyses suivantes:

{prev_content}

{role_suffix}

Ã‰value les analyses prÃ©cÃ©dentes:
1. CONVERGENCES (points d'accord)
2. DIVERGENCES (dÃ©saccords Ã  rÃ©soudre)
3. GLISSEMENTS DÃ‰TECTÃ‰S (erreurs potentielles)
4. ENRICHISSEMENTS (ce qui manque)
5. VERDICT (fiabilitÃ© globale 0-10)
"""
        
        elif stage == "synthese":
            prev_content = "\n\n".join([
                f"=== {p['model']} ({p['role']}) ===\n{p['content']}"
                for p in (previous_outputs or [])
            ])

            # PRD-019: Instructions de rÃ©fÃ©rencement
            refs_instructions = ""
            if with_refs:
                refs_instructions = """
RÃˆGLES DE RÃ‰FÃ‰RENCEMENT (OBLIGATOIRE):
- Chaque fait ou chiffre DOIT avoir une rÃ©fÃ©rence [Â§N]
- N = numÃ©ro du paragraphe source (voir [Â§1], [Â§2], etc. dans le texte)
- Format: "Le CA a augmentÃ© de 15% [Â§3]"
- Ne rÃ©fÃ©rence que ce qui est DANS le texte source
- Pas de rÃ©fÃ©rence pour conclusions/interprÃ©tations personnelles
- Multi-sources: utilise [S:nomÂ§N] si plusieurs sources
"""

            base_prompt += f"""TÃ‚CHE: SynthÃ¨se finale

Voici les analyses et critiques des experts:

{prev_content}

CONSIGNES:
- Longueur: {cadrage.get('longueur', '10-15 lignes')}
- Ton: {cadrage.get('ton', 'sobre')}
- Ne retenir QUE ce que le texte affirme
- Signaler les interprÃ©tations si nÃ©cessaire
- Mentionner les points de dissensus importants
{refs_instructions}
Produis la SYNTHÃˆSE FINALE.
"""
        
        return base_prompt
    
    def _calculate_convergence(self, results: List[ModelResult]) -> int:
        """
        Calcule le score de convergence entre les modÃ¨les.

        PRD-007: Utilise l'algorithme hybride si disponible.
        PRD-027 Story 27.1: Support sÃ©mantique optionnel.
        Combine Jaccard n-grams + cosine similarity pour une mesure robuste.

        Returns:
            Score de convergence en pourcentage (0-100)
        """
        if len(results) < 2:
            return 100

        # Extraire les contenus
        contents = [r.content for r in results if r.content]

        if len(contents) < 2:
            return 100

        # Utiliser le module hybride si disponible (PRD-007, PRD-027)
        if CONVERGENCE_MODULE_AVAILABLE:
            weights = self.config.get("convergence_weights", None)
            result = calc_convergence_hybrid(contents, weights, self.config)
            # PRD-027: result est maintenant un dict
            if isinstance(result, dict):
                # Stocker les dÃ©tails pour les mÃ©triques
                self._convergence_details = result
                return result.get("score", 0)
            # CompatibilitÃ© avec ancien format (float)
            return int(result * 100)
        
        # Fallback: algorithme Jaccard simple
        all_words = []
        for content in contents:
            words = set(re.findall(r'\b\w{4,}\b', content.lower()))
            all_words.append(words)
        
        if not all_words:
            return 0.5
        
        # Intersection / Union (Jaccard simplifiÃ©)
        common = all_words[0]
        total = all_words[0]
        for words in all_words[1:]:
            common = common & words
            total = total | words
        
        if not total:
            return 0.5
        
        return len(common) / len(total)
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # EXECUTION PARALLÃˆLE DES ROUNDS (Story 2.2)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    async def _run_round_async(
        self,
        stage: str,
        source_text: str,
        cadrage: Dict[str, str],
        role_assignments: Dict[str, str],
        previous_outputs: List[Dict] = None
    ) -> List[Dict[str, Any]]:
        """
        ExÃ©cute un round avec tous les modÃ¨les EN PARALLÃˆLE.
        
        Story 2.2 du PRD-002: Utilise asyncio.gather pour parallÃ©liser les appels.
        PRD-004: Utilise call_model_async_with_retry pour la rÃ©silience.
        """
        
        async def call_single_model(model: str) -> Dict[str, Any]:
            """Appelle un modÃ¨le et retourne le rÃ©sultat formatÃ©."""
            role = role_assignments[model]
            role_name = self.expert_roles[role]["name"]
            
            # Affichage du dÃ©marrage (thread-safe)
            await self.printer.print(f"â”œâ”€ {model} ({role_name})...", end=" ", flush=True)
            
            # Construire le prompt
            if stage == "critique":
                # Pour la critique, exclure sa propre sortie
                others = [r for r in (previous_outputs or []) if r["model"] != model and r.get("success", True)]
                prompt = self._build_prompt(stage, source_text, cadrage, role, others)
            else:
                prompt = self._build_prompt(stage, source_text, cadrage, role, previous_outputs)
            
            # Appel asynchrone avec backend smart (PRD-008) + retry (PRD-004)
            result = await self._call_model_smart(
                model, 
                prompt, 
                self.config["timeout"], 
                role
            )
            
            # Affichage du rÃ©sultat (thread-safe)
            if result.success:
                await self.printer.print(f"âœ“ ({result.duration:.1f}s)")
            else:
                await self.printer.print(f"âœ— ({result.error})")
            
            return {
                "model": model,
                "role": role,
                "content": result.content,
                "duration": result.duration,
                "success": result.success,
                "error": result.error
            }
        
        # ExÃ©cuter tous les modÃ¨les en parallÃ¨le
        tasks = [call_single_model(model) for model in self.available_models]
        
        # asyncio.gather avec return_exceptions=True pour ne pas interrompre si un Ã©choue
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Traiter les rÃ©sultats
        processed_results = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                # Un modÃ¨le a levÃ© une exception
                model = self.available_models[i]
                processed_results.append({
                    "model": model,
                    "role": role_assignments[model],
                    "content": "",
                    "duration": 0,
                    "success": False,
                    "error": str(result)
                })
            else:
                processed_results.append(result)
        
        return processed_results
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # MÃ‰THODE RUN ASYNCHRONE (Story 2.3)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    async def run_async(
        self,
        source_text: str,
        cadrage: Dict[str, str],
        mode: Mode = Mode.STANDARD,
        interactive_pedagogy: bool = False,
        personas: str = None,
        with_refs: bool = False  # PRD-019
    ) -> SyntheseSession:
        """
        ExÃ©cute le processus complet de synthÃ¨se de maniÃ¨re ASYNCHRONE.

        Story 2.3 du PRD-002: Version async de run() avec appels parallÃ¨les.
        PRD-005: Mode pÃ©dagogique intÃ©grÃ©.
        PRD-017: Personas dynamiques.
        PRD-019: RÃ©fÃ©rences aux sources.

        Args:
            source_text: Texte Ã  synthÃ©tiser
            cadrage: ParamÃ¨tres de cadrage
            mode: Mode de synthÃ¨se (STANDARD, RAPIDE, CRITIQUE, PEDAGOGIQUE)
            interactive_pedagogy: Pause aprÃ¨s chaque explication pÃ©dagogique
            personas: 'auto', preset (tech/science/legal/business/medical), ou liste personnalisÃ©e
            with_refs: Inclure des rÃ©fÃ©rences [Â§N] aux passages sources
        """

        start_time = time.time()
        personas_info = None  # Pour le trail
        references_info = None  # PRD-019
        
        # PRD-008 Story 8.1: VÃ©rifier qu'au moins un modÃ¨le est disponible
        if not self.available_models:
            raise NoModelsAvailableError()
        
        # PRD-008 Story 8.4: Sanitiser les entrÃ©es
        if SANITIZE_MODULE_AVAILABLE:
            clean_text, clean_cadrage, _, warnings = validate_and_sanitize(
                source_text, cadrage, strict=False
            )
            if warnings:
                for w in warnings:
                    print(f"âš  {w}")
            source_text = clean_text
            cadrage = clean_cadrage

        # PRD-029: Stocker cadrage pour clÃ© de cache
        self.cadrage = cadrage

        # PRD-017: RÃ©soudre les personas dynamiques
        if personas:
            new_roles, personas_mode, personas_list = await self.resolve_personas(personas, source_text)
            self.expert_roles = new_roles
            personas_info = {
                "mode": personas_mode,
                "domain": getattr(self, '_detected_domain', None),
                "personas": personas_list
            }
            # Afficher les personas gÃ©nÃ©rÃ©s
            log("â””â”€ Personas gÃ©nÃ©rÃ©s:")
            for p in personas_list:
                log(f"   â€¢ {p['name']} ({p['focus']})")

        # Initialiser le mode pÃ©dagogique (PRD-005)
        if PEDAGOGY_MODULE_AVAILABLE:
            self.pedagogy = create_pedagogy(mode.value, interactive_pedagogy)
        else:
            self.pedagogy = None
        
        # Afficher l'introduction pÃ©dagogique
        if self.pedagogy:
            self.pedagogy.explain(PedagogicStep.INTRO)
        
        # Initialisation de la session
        self.session = SyntheseSession(
            session_id=self._generate_session_id(),
            query="synthÃ¨se",
            source_text=source_text[:500] + "..." if len(source_text) > 500 else source_text,
            mode=mode.value,
            cadrage=cadrage,
            models_used=self.available_models.copy()
        )
        
        log(f"\nSession: {self.session.session_id}")
        log(f"Mode: {mode.value} | ModÃ¨les: {', '.join(self.available_models)}")
        log(f"âš¡ ExÃ©cution parallÃ¨le activÃ©e")
        
        role_assignments = self._assign_roles()
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ROUND 1: EXTRACTION (parallÃ¨le)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        
        # Explication pÃ©dagogique de l'extraction (PRD-005)
        if self.pedagogy:
            self.pedagogy.explain(PedagogicStep.EXTRACTION)
            # Expliquer chaque expert
            for model in self.available_models:
                role = role_assignments[model]
                self.pedagogy.explain_expert(role, model)
        
        log("\nâ”€â”€â”€ ROUND 1: EXTRACTION (parallÃ¨le) â”€â”€â”€")
        round1_start = time.time()
        
        round1_results = await self._run_round_async(
            "extraction",
            source_text,
            cadrage,
            role_assignments
        )
        
        round1_duration = time.time() - round1_start
        log(f"â””â”€ Round 1 terminÃ© en {round1_duration:.1f}s")
        
        self.session.rounds.append({
            "stage": "extraction",
            "results": round1_results,
            "duration": round1_duration
        })
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ROUND 2: CRITIQUE CROISÃ‰E (parallÃ¨le, si applicable)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        
        successful_round1 = [r for r in round1_results if r["success"]]
        
        if mode != Mode.RAPIDE and len(successful_round1) >= 2:
            # Explication pÃ©dagogique de la critique (PRD-005)
            if self.pedagogy:
                self.pedagogy.explain(PedagogicStep.CRITIQUE)
                self.pedagogy.explain(PedagogicStep.GLISSEMENTS)
            
            log("\nâ”€â”€â”€ ROUND 2: CRITIQUE CROISÃ‰E (parallÃ¨le) â”€â”€â”€")
            round2_start = time.time()
            
            round2_results = await self._run_round_async(
                "critique",
                source_text,
                cadrage,
                role_assignments,
                round1_results
            )
            
            round2_duration = time.time() - round2_start
            log(f"â””â”€ Round 2 terminÃ© en {round2_duration:.1f}s")
            
            self.session.rounds.append({
                "stage": "critique",
                "results": round2_results,
                "duration": round2_duration
            })
            
            # Calcul de convergence
            successful_results = [
                ModelResult(
                    model=r["model"],
                    role=r["role"],
                    content=r["content"],
                    duration=r["duration"],
                    success=r["success"]
                )
                for r in round2_results if r["success"]
            ]
            self.session.convergence = self._calculate_convergence(successful_results)
            log(f"    Convergence: {self.session.convergence:.2f}")
            
            # Explication pÃ©dagogique de la convergence (PRD-005)
            if self.pedagogy:
                self.pedagogy.explain(PedagogicStep.CONVERGENCE)
                self.pedagogy.show_convergence(self.session.convergence)
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ROUND FINAL: SYNTHÃˆSE
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        
        # Explication pÃ©dagogique de la synthÃ¨se (PRD-005)
        if self.pedagogy:
            self.pedagogy.explain(PedagogicStep.SYNTHESE)
        
        log("\nâ”€â”€â”€ SYNTHÃˆSE FINALE â”€â”€â”€")

        # Rassembler tous les outputs rÃ©ussis
        all_outputs = []
        for round_data in self.session.rounds:
            for r in round_data["results"]:
                if r["success"]:
                    all_outputs.append(r)

        # Utiliser le premier modÃ¨le disponible pour la synthÃ¨se
        synthesizer = self.available_models[0]
        log(f"â”œâ”€ {synthesizer} (synthÃ©tiseur)...", end=" ")

        # PRD-019: Indexer le texte source si rÃ©fÃ©rences demandÃ©es
        indexed_source = None
        source_for_prompt = source_text
        if with_refs:
            indexed_source = index_source(source_text)
            source_for_prompt = format_indexed_for_prompt(indexed_source)

        prompt = self._build_prompt(
            "synthese", source_for_prompt, cadrage, "architecte", all_outputs, with_refs=with_refs
        )

        # Appel avec backend smart (PRD-008) + retry (PRD-004)
        result = await self._call_model_smart(
            synthesizer,
            prompt,
            self.config["timeout"],
            "synthese"
        )

        if result.success:
            log(f"âœ“ ({result.duration:.1f}s)")
            self.session.synthese_finale = result.content

            # PRD-019: Valider les rÃ©fÃ©rences
            if with_refs and indexed_source:
                valid, errors, valid_refs = validate_references(
                    result.content, indexed_source
                )
                if errors:
                    log(f"âš ï¸  RÃ©fÃ©rences invalides: {', '.join(errors)}")

                # GÃ©nÃ©rer les extraits
                indexed_dict = {"source": indexed_source}
                excerpts = extract_reference_excerpts(valid_refs, indexed_dict)

                references_info = {
                    "enabled": True,
                    "count": len(valid_refs),
                    "valid": valid,
                    "errors": errors,
                    "refs": excerpts
                }
        else:
            log(f"âœ— ({result.error})")
            # Fallback: combiner les extractions
            self.session.synthese_finale = "SYNTHÃˆSE (mode dÃ©gradÃ©):\n" + "\n".join([
                r["content"][:200] for r in round1_results if r["success"]
            ])
        
        # Finalisation
        self.session.duration_total = time.time() - start_time
        self.session.timestamp_end = datetime.now().isoformat()
        
        # Sauvegarder les mÃ©triques de retry (PRD-004)
        if self.retry_metrics:
            self.session.retry_metrics = self.retry_metrics.to_dict()

            # Afficher rÃ©sumÃ© des retries si pertinent
            summary = self.retry_metrics.summary()
            if "retry" in summary.lower() and "aucun" not in summary.lower():
                log(f"\n{summary}")

        # PRD-029 Story 29.1: Sauvegarder les mÃ©triques de cache
        if self.cache and self.cache.enabled:
            self.session.cache_metrics = self.cache.stats()
            if self.session.cache_metrics.get("hits", 0) > 0:
                log(f"\nâš¡ Cache: {self.session.cache_metrics['hits']} hits, "
                    f"{self.session.cache_metrics['latency_saved_s']}s Ã©conomisÃ©s")

        log(f"\nâ•â•â• TOTAL: {self.session.duration_total:.1f}s â•â•â•")

        # PRD-017: Ajouter les infos personas Ã  la session
        if personas_info:
            self.session.personas_info = personas_info

        # PRD-019: Ajouter les infos rÃ©fÃ©rences Ã  la session
        if references_info:
            self.session.references_info = references_info

        # Afficher le rÃ©sumÃ© pÃ©dagogique (PRD-005)
        if self.pedagogy and self.pedagogy.enabled:
            self.pedagogy.explain(PedagogicStep.SUMMARY)
            stats = self.pedagogy.summary_stats(self.session)
            if stats:
                log(stats)

        return self.session
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # MÃ‰THODE RUN SYNCHRONE (compatibilitÃ© avec les tests)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def run(
        self,
        source_text: str,
        cadrage: Dict[str, str],
        mode: Mode = Mode.STANDARD,
        personas: str = None
    ) -> SyntheseSession:
        """
        ExÃ©cute le processus de synthÃ¨se.

        Version wrapper qui appelle run_async via asyncio.run() si possible,
        sinon utilise une version synchrone pour compatibilitÃ©.
        """
        try:
            # Essayer d'obtenir un event loop existant
            loop = asyncio.get_running_loop()
            # Si on est dÃ©jÃ  dans un event loop, crÃ©er une tÃ¢che
            import concurrent.futures
            with concurrent.futures.ThreadPoolExecutor() as pool:
                future = pool.submit(asyncio.run, self.run_async(source_text, cadrage, mode, personas=personas))
                return future.result()
        except RuntimeError:
            # Pas d'event loop en cours, utiliser asyncio.run directement
            return asyncio.run(self.run_async(source_text, cadrage, mode, personas=personas))

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # MODE DIRECT (PRD-016)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def _build_direct_prompt(self, source_text: str, cadrage: Dict[str, str]) -> str:
        """Construit le prompt pour le mode direct (PRD-016)."""
        return f"""Tu es un expert en synthÃ¨se de documents.

CADRAGE:
- Destinataire: {cadrage.get('destinataire', 'non spÃ©cifiÃ©')}
- FinalitÃ©: {cadrage.get('finalite', 'non spÃ©cifiÃ©e')}
- Longueur: {cadrage.get('longueur', 'non spÃ©cifiÃ©e')}
- Ton: {cadrage.get('ton', 'non spÃ©cifiÃ©')}
- Niveau: {cadrage.get('niveau', 'non spÃ©cifiÃ©')}

TEXTE Ã€ SYNTHÃ‰TISER:
---
{source_text}
---

CONSIGNES:
Produis une synthÃ¨se fidÃ¨le au texte source, adaptÃ©e au cadrage ci-dessus.
Ã‰vite les glissements de sens et les ajouts non prÃ©sents dans le texte original.
Structure ta rÃ©ponse de maniÃ¨re claire et exploitable par le destinataire.
"""

    async def run_direct_async(
        self,
        source_text: str,
        model: str,
        cadrage: Dict[str, str]
    ) -> SyntheseSession:
        """
        ExÃ©cute une synthÃ¨se directe avec un seul modÃ¨le (PRD-016).

        Args:
            source_text: Texte Ã  synthÃ©tiser
            model: ModÃ¨le Ã  utiliser (claude, gemini, codex)
            cadrage: ParamÃ¨tres de cadrage

        Returns:
            SyntheseSession avec la synthÃ¨se directe
        """
        start_time = time.time()
        timestamp_start = datetime.now().isoformat()

        # VÃ©rifier disponibilitÃ© du modÃ¨le
        if model not in self.available_models:
            raise ValueError(
                f"ModÃ¨le '{model}' non disponible. "
                f"Disponibles: {', '.join(self.available_models)}"
            )

        # PRD-008 Story 8.4: Sanitiser les entrÃ©es
        if SANITIZE_MODULE_AVAILABLE:
            clean_text, clean_cadrage, _, warnings = validate_and_sanitize(
                source_text, cadrage, strict=False
            )
            if warnings:
                for w in warnings:
                    log(f"âš  {w}")
            source_text = clean_text
            cadrage = clean_cadrage

        # PRD-029: Stocker cadrage pour clÃ© de cache
        self.cadrage = cadrage

        # Construire le prompt
        prompt = self._build_direct_prompt(source_text, cadrage)

        # ExÃ©cuter
        log(f"\nâ”€â”€â”€ MODE DIRECT : {model} â”€â”€â”€")
        result = await self._call_model_smart(
            model=model,
            prompt=prompt,
            timeout=self.config.get("timeout", 300),
            role="direct"
        )

        if not result.success:
            raise RuntimeError(f"Ã‰chec du modÃ¨le {model}: {result.error}")

        log(f"â””â”€ {model}... âœ“ ({result.duration:.1f}s)")

        duration = time.time() - start_time
        log(f"\nâ•â•â• TOTAL: {duration:.1f}s â•â•â•\n")

        return SyntheseSession(
            session_id=self._generate_session_id(),
            query="synthÃ¨se directe",
            source_text=source_text[:500] + "..." if len(source_text) > 500 else source_text,
            mode="direct",
            cadrage=cadrage,
            rounds=[],  # Pas de rounds en mode direct
            synthese_finale=result.content,
            convergence=1.0,  # Pas de convergence en mono-modÃ¨le
            duration_total=duration,
            timestamp_start=timestamp_start,
            timestamp_end=datetime.now().isoformat(),
            models_used=[model]
        )

    def run_direct(
        self,
        source_text: str,
        model: str,
        cadrage: Dict[str, str]
    ) -> SyntheseSession:
        """
        Version synchrone de run_direct_async (PRD-016).
        """
        try:
            loop = asyncio.get_running_loop()
            import concurrent.futures
            with concurrent.futures.ThreadPoolExecutor() as pool:
                future = pool.submit(
                    asyncio.run,
                    self.run_direct_async(source_text, model, cadrage)
                )
                return future.result()
        except RuntimeError:
            return asyncio.run(self.run_direct_async(source_text, model, cadrage))

    def save_trail(self, session: SyntheseSession) -> Optional[str]:
        """Sauvegarde le trail de la session"""
        if not self.config["enable_trail"]:
            return None
        
        trail_dir = Path(self.config["trail_dir"])
        
        try:
            trail_dir.mkdir(parents=True, exist_ok=True)
        except Exception as e:
            print(f"Erreur crÃ©ation rÃ©pertoire trail: {e}")
            return None
        
        trail_file = trail_dir / f"{session.session_id}.json"
        
        try:
            with open(trail_file, "w", encoding="utf-8") as f:
                json.dump(asdict(session), f, ensure_ascii=False, indent=2)
            return str(trail_file)
        except Exception as e:
            log(f"Erreur sauvegarde trail: {e}")
            return None

    def save_markdown(self, session: SyntheseSession, with_frontmatter: bool = False) -> Optional[str]:
        """
        Sauvegarde automatique de la synthÃ¨se en Markdown (PRD-014).

        PRD-022: Support optionnel du frontmatter YAML.

        Args:
            session: Session de synthese
            with_frontmatter: Ajouter le frontmatter YAML

        Returns:
            Chemin du fichier crÃ©Ã© ou None si erreur
        """
        output_dir = Path("output")

        try:
            output_dir.mkdir(parents=True, exist_ok=True)
        except Exception as e:
            log(f"Erreur crÃ©ation rÃ©pertoire output: {e}")
            return None

        md_file = output_dir / f"{session.session_id}.md"

        try:
            content = ""
            # PRD-022: Frontmatter optionnel
            if with_frontmatter:
                content += generate_frontmatter(session)
            content += format_output_markdown(session)
            with open(md_file, "w", encoding="utf-8") as f:
                f.write(content)
            return str(md_file)
        except Exception as e:
            log(f"Erreur sauvegarde markdown: {e}")
            return None

    def load_session(self, trail_path: Path) -> SyntheseSession:
        """
        Charge une session depuis un trail JSON.

        PRD-025: Reprise de session interrompue.

        Args:
            trail_path: Chemin vers le fichier trail

        Returns:
            Session reconstruite
        """
        with open(trail_path, encoding="utf-8") as f:
            data = json.load(f)

        return SyntheseSession(
            session_id=data["session_id"],
            query=data.get("query", "resume"),
            source_text=data["source_text"],
            mode=data["mode"],
            cadrage=data["cadrage"],
            rounds=data.get("rounds", []),
            synthese_finale=data.get("synthese_finale", ""),
            convergence=data.get("convergence", 0),
            duration_total=data.get("duration_total", 0),
            timestamp_start=data.get("timestamp_start", ""),
            timestamp_end=data.get("timestamp_end", ""),
            models_used=data.get("models_used", []),
            retry_metrics=data.get("retry_metrics", {}),
            personas_info=data.get("personas_info", {}),
            sources_info=data.get("sources_info", {}),
            references_info=data.get("references_info", {})
        )

    def get_next_stage(self, session: SyntheseSession) -> Optional[str]:
        """
        DÃ©termine le prochain stage Ã  exÃ©cuter.

        PRD-025: Identification du point de reprise.

        Args:
            session: Session chargÃ©e

        Returns:
            'extraction', 'critique', 'synthese', ou None si complet
        """
        completed_stages = {r["stage"] for r in session.rounds}

        if "extraction" not in completed_stages:
            return "extraction"

        mode = Mode[session.mode.upper()] if isinstance(session.mode, str) else session.mode

        if mode in [Mode.STANDARD, Mode.CRITIQUE]:
            if "critique" not in completed_stages:
                return "critique"

        if not session.synthese_finale:
            return "synthese"

        return None


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# INTERFACE UTILISATEUR
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def prompt_cadrage() -> Dict[str, str]:
    """Dialogue de cadrage interactif"""
    print("\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    print("â•‘              CADRAGE DE LA SYNTHÃˆSE                          â•‘")
    print("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n")
    
    cadrage = {}
    
    cadrage["destinataire"] = input("Ã€ qui s'adresse cette synthÃ¨se ? [gÃ©nÃ©ral] ").strip() or "public gÃ©nÃ©ral"
    cadrage["finalite"] = input("Pour quoi faire ? (dÃ©cision/information/argumentation) [information] ").strip() or "information"
    cadrage["longueur"] = input("Quelle longueur ? (ex: 10 lignes, 200 mots) [10-15 lignes] ").strip() or "10-15 lignes"
    cadrage["ton"] = input("Quel ton ? (formel/accessible/technique) [accessible] ").strip() or "accessible"
    cadrage["niveau"] = input("Quel niveau d'expertise ? (dÃ©butant/intermÃ©diaire/expert) [intermÃ©diaire] ").strip() or "intermÃ©diaire"
    
    return cadrage


def format_output(session: SyntheseSession) -> str:
    """Formate la sortie pour l'utilisateur"""
    output = []
    output.append("\n" + "â•" * 64)
    output.append("                    SYNTHÃˆSE CO-FABRIQUÃ‰E")
    output.append("â•" * 64)
    output.append(f"\nSession: {session.session_id}")
    output.append(f"ModÃ¨les: {', '.join(session.models_used)}")

    # PRD-018: Afficher les sources si multiples
    if session.sources_info and session.sources_info.get("count", 0) > 1:
        count = session.sources_info["count"]
        mode = session.sources_info.get("mode", "merge")
        output.append(f"Sources: {count} (mode {mode})")

    # PRD-017: Afficher les personas si disponibles
    if session.personas_info and session.personas_info.get("personas"):
        personas = session.personas_info["personas"]
        domain = session.personas_info.get("domain")
        if domain:
            output.append(f"Domaine: {domain}")
        output.append("Personas: " + ", ".join([p["name"] for p in personas]))

    output.append(f"Convergence: {session.convergence:.0%}")
    output.append(f"DurÃ©e: {session.duration_total:.1f}s")
    output.append("\n" + "â”€" * 64)
    output.append("\n" + session.synthese_finale)
    output.append("\n" + "â•" * 64)

    return "\n".join(output)


def format_output_markdown(session: SyntheseSession) -> str:
    """Formate la sortie en Markdown (PRD-014)."""

    output = []

    # Titre
    output.append("# SynthÃ¨se Co-fabriquÃ©e\n")

    # MÃ©tadonnÃ©es en tableau
    output.append("## MÃ©tadonnÃ©es\n")
    output.append("| Champ | Valeur |")
    output.append("|-------|--------|")
    output.append(f"| Session | `{session.session_id}` |")
    output.append(f"| Mode | {session.mode} |")
    output.append(f"| ModÃ¨les | {', '.join(session.models_used)} |")
    output.append(f"| Convergence | {session.convergence}% |")
    output.append(f"| DurÃ©e | {session.duration_total:.1f}s |")
    output.append("")

    # PRD-018: Sources si multiples
    if session.sources_info and session.sources_info.get("count", 0) > 1:
        output.append("## Sources\n")
        mode = session.sources_info.get("mode", "merge")
        output.append(f"**Mode** : {mode}\n")
        for src in session.sources_info.get("sources", []):
            output.append(f"- **{src['name']}** ({src['type']})")
        output.append("")

    # PRD-017: Personas si disponibles
    if session.personas_info and session.personas_info.get("personas"):
        output.append("## Personas\n")
        domain = session.personas_info.get("domain")
        if domain:
            output.append(f"**Domaine dÃ©tectÃ©** : {domain}\n")
        for p in session.personas_info["personas"]:
            output.append(f"- **{p['name']}** : {p['focus']}")
        output.append("")

    # Cadrage
    output.append("## Cadrage\n")
    for key, value in session.cadrage.items():
        output.append(f"- **{key.capitalize()}** : {value}")
    output.append("")

    # SynthÃ¨se
    output.append("## SynthÃ¨se\n")
    output.append(session.synthese_finale)
    output.append("")

    # Footer
    output.append("---")
    output.append(f"*Trail : `synthese_trails/{session.session_id}.json`*")

    return "\n".join(output)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# POINT D'ENTRÃ‰E ASYNC (Story 2.4)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async def async_main(args: argparse.Namespace) -> int:
    """
    Point d'entrÃ©e asynchrone principal.

    Story 2.4 du PRD-002: Permet l'exÃ©cution async depuis le CLI.
    PRD-003: IntÃ©gration de la configuration dynamique.
    """

    # PRD-025: Reprise de session
    if args.resume:
        council = SyntheseCouncil()
        trail_path = Path("synthese_trails") / f"{args.resume}.json"

        if not trail_path.exists():
            # Essayer avec ID partiel
            matches = list(Path("synthese_trails").glob(f"*{args.resume}*.json"))
            if len(matches) == 1:
                trail_path = matches[0]
            elif len(matches) > 1:
                print(f"âŒ Plusieurs sessions correspondent Ã  '{args.resume}':")
                for m in matches[:5]:
                    print(f"   {m.stem}")
                return 1
            else:
                print(f"âŒ Session introuvable: {args.resume}")
                return 1

        log(f"ðŸ”„ Reprise de session: {trail_path.stem}")
        session = council.load_session(trail_path)

        next_stage = council.get_next_stage(session)
        if next_stage is None:
            log("âœ“ Session dÃ©jÃ  complÃ¨te")
        else:
            log(f"   Prochain stage: {next_stage}")
            # TODO: ImplÃ©menter resume_session() pour continuer l'exÃ©cution

        # Afficher le rÃ©sultat existant
        if args.json:
            print(json.dumps(asdict(session), ensure_ascii=False, indent=2))
        elif args.markdown:
            print(format_output_markdown(session))
        else:
            print(format_output(session))

        return 0

    # PRD-018: RÃ©cupÃ©ration des sources (fichiers, URLs, texte)
    sources = []
    source_mode = "single"  # Par dÃ©faut
    urls_arg = getattr(args, 'url', None)

    if args.file or urls_arg or args.text:
        # Charger toutes les sources
        sources = load_sources(
            files=args.file,
            urls=urls_arg,
            text=args.text
        )

        if not sources:
            print("Erreur: aucune source n'a pu Ãªtre chargÃ©e")
            return 1

        # DÃ©terminer le mode multi-sources (compare par dÃ©faut si plusieurs sources)
        compare_mode = getattr(args, 'compare', False)
        merge_mode = getattr(args, 'merge', False)

        if compare_mode:
            source_mode = "compare"
        elif merge_mode:
            source_mode = "merge"
        else:
            # Par dÃ©faut: compare si plusieurs sources, sinon merge
            source_mode = "compare" if len(sources) > 1 else "merge"

        # Formater les sources pour le prompt
        source_text = format_sources_for_prompt(sources, mode=source_mode)

        # Log multi-sources
        if len(sources) > 1:
            log(f"ðŸ“š {len(sources)} sources chargÃ©es (mode {source_mode})")
            for src in sources:
                log(f"   â€¢ {src.name} ({src.source_type})")
    else:
        # Mode interactif
        print("Entrez le texte Ã  synthÃ©tiser (terminez par une ligne vide):")
        lines = []
        while True:
            line = input()
            if line == "":
                break
            lines.append(line)
        source_text = "\n".join(lines)
        sources = [Source(name="Texte interactif", content=source_text, source_type="text")]

    if not source_text or not source_text.strip():
        print("Erreur: aucun texte fourni")
        return 1
    
    # Construction des overrides CLI (PRD-003)
    cli_overrides = {}
    if hasattr(args, 'timeout') and args.timeout is not None:
        cli_overrides["timeout"] = args.timeout
    if hasattr(args, 'max_rounds') and args.max_rounds is not None:
        cli_overrides["max_rounds"] = args.max_rounds
    if args.no_trail:
        cli_overrides["enable_trail"] = False
    
    # Chemin de config personnalisÃ©
    config_path = getattr(args, 'config', None)
    
    # CrÃ©er le council avec configuration (PRD-003)
    council = SyntheseCouncil(config=cli_overrides, config_path=config_path)
    
    # PRD-020: Cadrage via template ou CLI
    template_name = getattr(args, 'template', None)
    has_cadrage_args = any([args.destinataire, args.finalite, args.longueur, args.ton, args.niveau])

    if template_name or has_cadrage_args:
        # Utiliser resolve_cadrage (template + overrides CLI)
        if CONFIG_MODULE_AVAILABLE:
            default_cadrage = get_default_cadrage(council.config)
        else:
            default_cadrage = {
                "destinataire": "public gÃ©nÃ©ral",
                "finalite": "information",
                "longueur": "10-15 lignes",
                "ton": "accessible",
                "niveau": "intermÃ©diaire"
            }

        cadrage = resolve_cadrage(args, default_cadrage)

        if template_name:
            log(f"ðŸ“‹ Template: {template_name}")
    else:
        cadrage = prompt_cadrage()
    
    # Setup et exÃ©cution
    if not council.setup():
        return 1
    
    mode = Mode(args.mode)

    # Option pÃ©dagogique interactive (PRD-005)
    interactive_pedagogy = getattr(args, 'interactive_pedagogy', False)

    # PRD-017: RÃ©cupÃ©rer l'argument personas
    personas = getattr(args, 'personas', None)

    # PRD-019: RÃ©cupÃ©rer l'argument refs
    with_refs = getattr(args, 'refs', False)

    # Appel asynchrone (PRD-016: mode direct ou dÃ©libÃ©ration)
    if mode == Mode.DIRECT:
        # Mode direct : un seul modÃ¨le, sans dÃ©libÃ©ration
        session = await council.run_direct_async(source_text, args.model, cadrage)
    else:
        # Modes dÃ©libÃ©ration : standard, rapide, critique, pÃ©dagogique
        session = await council.run_async(
            source_text, cadrage, mode, interactive_pedagogy,
            personas=personas, with_refs=with_refs
        )

    # PRD-018: Ajouter les informations de sources
    if sources and len(sources) > 0:
        session.sources_info = {
            "count": len(sources),
            "mode": source_mode,
            "sources": [
                {
                    "name": src.name,
                    "type": src.source_type,
                    "metadata": src.metadata
                }
                for src in sources
            ]
        }

    # PRD-021: Mode confirmation (boucle de validation)
    confirm_mode = getattr(args, 'confirm', False)

    # Ignorer --confirm si non-interactif (pipe, redirection)
    if confirm_mode and not sys.stdin.isatty():
        log("âš ï¸  Mode --confirm ignorÃ© (entrÃ©e non-interactive)")
        confirm_mode = False

    if confirm_mode:
        regeneration_count = 0
        while True:
            # Afficher le brouillon
            display_draft(session)

            # Demander confirmation
            choice = prompt_confirmation()

            if choice == 'export':
                # Continuer vers l'export normal
                break

            elif choice == 'regenerate':
                regeneration_count += 1
                log(f"\nðŸ”„ RÃ©gÃ©nÃ©ration #{regeneration_count}...")
                if mode == Mode.DIRECT:
                    session = await council.run_direct_async(source_text, args.model, cadrage)
                else:
                    session = await council.run_async(
                        source_text, cadrage, mode, interactive_pedagogy,
                        personas=personas, with_refs=with_refs
                    )

            elif choice == 'modify':
                cadrage = prompt_modify_cadrage(cadrage)
                regeneration_count += 1
                log(f"\nðŸ”„ RÃ©gÃ©nÃ©ration #{regeneration_count} avec nouveau cadrage...")
                if mode == Mode.DIRECT:
                    session = await council.run_direct_async(source_text, args.model, cadrage)
                else:
                    session = await council.run_async(
                        source_text, cadrage, mode, interactive_pedagogy,
                        personas=personas, with_refs=with_refs
                    )

            elif choice == 'cancel':
                print("\nâŒ AnnulÃ©. Aucun fichier sauvegardÃ©.")
                return 0

    # Sauvegarde du trail JSON
    if council.config.get("enable_trail", True):
        trail_path = council.save_trail(session)
        if trail_path:
            log(f"\nTrail sauvegardÃ©: {trail_path}")

    # Sauvegarde automatique du Markdown (PRD-014)
    # PRD-022: Support frontmatter
    with_frontmatter = getattr(args, 'frontmatter', False)
    md_path = council.save_markdown(session, with_frontmatter=with_frontmatter)
    if md_path:
        log(f"SynthÃ¨se Markdown: {md_path}")

    # Sortie
    if args.json:
        print(json.dumps(asdict(session), ensure_ascii=False, indent=2))
    elif args.markdown:
        # PRD-022: Support frontmatter sur stdout
        if with_frontmatter:
            print(generate_frontmatter(session) + format_output_markdown(session))
        else:
            print(format_output_markdown(session))
    else:
        print(format_output(session))

    # PRD-026: Affichage des mÃ©triques dÃ©taillÃ©es
    if getattr(args, 'metrics', False):
        print("\nâ•â•â• MÃ‰TRIQUES â•â•â•")
        print(f"DurÃ©e totale: {session.duration_total:.1f}s")
        print(f"ModÃ¨les: {', '.join(session.models_used)}")
        print(f"Rounds: {len(session.rounds)}")
        if session.retry_metrics:
            total_retries = sum(
                m.get('total_attempts', 1) - 1
                for m in session.retry_metrics.values()
            )
            if total_retries > 0:
                print(f"Retries: {total_retries}")
        print(f"Convergence: {session.convergence:.0%}")

    return 0


def main():
    """Point d'entrÃ©e synchrone (wrapper pour async_main)"""
    
    parser = argparse.ArgumentParser(
        description="SynthÃ¨se co-fabriquÃ©e par conseil de LLMs (v2.2 - mode pÃ©dagogique)"
    )
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # COMMANDES DE BASE
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    parser.add_argument(
        "--check",
        action="store_true",
        help="VÃ©rifier les CLI disponibles"
    )
    parser.add_argument(
        "--file", "-f",
        type=str,
        nargs="+",
        help="Fichier(s) source Ã  synthÃ©tiser (txt, pdf, docx)"
    )
    parser.add_argument(
        "--text", "-t",
        type=str,
        help="Texte source direct"
    )
    parser.add_argument(
        "--url",
        type=str,
        nargs="+",
        help="URL(s) de pages web Ã  synthÃ©tiser"
    )
    parser.add_argument(
        "--compare",
        action="store_true",
        help="Mode comparaison : analyse les diffÃ©rences entre sources"
    )
    parser.add_argument(
        "--merge",
        action="store_true",
        help="Mode fusion : combine les sources en une synthÃ¨se unifiÃ©e (dÃ©faut)"
    )
    parser.add_argument(
        "--mode", "-m",
        choices=["standard", "rapide", "critique", "pedagogique", "direct"],
        default="standard",
        help="Mode de synthÃ¨se"
    )
    parser.add_argument(
        "--direct",
        action="store_true",
        help="Mode direct : un seul modÃ¨le, sans dÃ©libÃ©ration (alias pour --mode direct)"
    )
    parser.add_argument(
        "--model",
        type=str,
        choices=["claude", "gemini", "codex"],
        help="ModÃ¨le Ã  utiliser (requis avec --direct ou --mode direct)"
    )
    parser.add_argument(
        "--personas",
        type=str,
        help="Personas experts: 'auto', preset (tech/science/legal/business/medical), ou liste personnalisÃ©e"
    )
    parser.add_argument(
        "--refs", "--references",
        action="store_true",
        help="Inclure des rÃ©fÃ©rences [Â§N] aux passages sources (PRD-019)"
    )
    parser.add_argument(
        "--template", "-T",
        type=str,
        choices=list(CADRAGE_TEMPLATES.keys()),
        help="Template de cadrage prÃ©dÃ©fini (PRD-020)"
    )
    parser.add_argument(
        "--list-templates",
        action="store_true",
        help="Afficher les templates de cadrage disponibles"
    )
    parser.add_argument(
        "--confirm", "-C",
        action="store_true",
        help="Demander confirmation avant l'export final (PRD-021)"
    )
    parser.add_argument(
        "--frontmatter", "-F",
        action="store_true",
        help="Ajouter un frontmatter YAML aux fichiers Markdown (PRD-022)"
    )

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # CACHE (PRD-024)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    parser.add_argument(
        "--no-cache",
        action="store_true",
        help="DÃ©sactiver le cache des rÃ©ponses (PRD-024)"
    )
    parser.add_argument(
        "--clear-cache",
        action="store_true",
        help="Vider le cache des rÃ©ponses"
    )
    parser.add_argument(
        "--cache-stats",
        action="store_true",
        help="Afficher les statistiques du cache"
    )

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # REPRISE DE SESSION (PRD-025)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    parser.add_argument(
        "--resume", "-R",
        type=str,
        metavar="SESSION_ID",
        help="Reprendre une session interrompue (PRD-025)"
    )
    parser.add_argument(
        "--list-sessions",
        action="store_true",
        help="Lister les sessions disponibles pour reprise"
    )

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # MÃ‰TRIQUES (PRD-026)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    parser.add_argument(
        "--metrics",
        action="store_true",
        help="Afficher les mÃ©triques dÃ©taillÃ©es (PRD-026)"
    )

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ARGUMENTS DE CADRAGE
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    parser.add_argument(
        "--destinataire",
        type=str,
        help="Destinataire de la synthÃ¨se"
    )
    parser.add_argument(
        "--finalite",
        type=str,
        help="FinalitÃ© de la synthÃ¨se"
    )
    parser.add_argument(
        "--longueur",
        type=str,
        help="Longueur souhaitÃ©e"
    )
    parser.add_argument(
        "--ton",
        type=str,
        help="Ton de la synthÃ¨se"
    )
    parser.add_argument(
        "--niveau",
        type=str,
        help="Niveau d'expertise"
    )
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ARGUMENTS DE CONFIGURATION (PRD-003)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    parser.add_argument(
        "--config", "-c",
        type=str,
        help="Chemin vers un fichier de configuration YAML"
    )
    parser.add_argument(
        "--validate-config",
        action="store_true",
        help="Valider le fichier de configuration"
    )
    parser.add_argument(
        "--show-config",
        action="store_true",
        help="Afficher la configuration effective"
    )
    parser.add_argument(
        "--init-config",
        action="store_true",
        help="CrÃ©er un fichier de configuration template"
    )
    parser.add_argument(
        "--force",
        action="store_true",
        help="Forcer l'Ã©crasement (avec --init-config)"
    )
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # AUTRES ARGUMENTS
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    parser.add_argument(
        "--no-trail",
        action="store_true",
        help="DÃ©sactiver la sauvegarde du trail"
    )
    parser.add_argument(
        "--json",
        action="store_true",
        help="Sortie JSON"
    )
    parser.add_argument(
        "--markdown", "--md",
        action="store_true",
        help="Sortie Markdown formatÃ©e"
    )
    parser.add_argument(
        "--timeout",
        type=int,
        help="Timeout par modÃ¨le en secondes (override)"
    )
    parser.add_argument(
        "--max-rounds",
        type=int,
        help="Nombre de rounds (override)"
    )
    parser.add_argument(
        "--interactive-pedagogy",
        action="store_true",
        help="Mode pÃ©dagogique interactif (pause aprÃ¨s chaque explication)"
    )
    
    args = parser.parse_args()

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # VALIDATION MODE DIRECT (PRD-016)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    # --direct est un alias pour --mode direct
    if args.direct:
        args.mode = "direct"

    # VÃ©rifier que --model est fourni pour le mode direct
    if args.mode == "direct" and not args.model:
        parser.error("--direct (ou --mode direct) nÃ©cessite --model (claude, gemini, codex)")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # COMMANDES DE CONFIGURATION (PRD-003 Story 3.5)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    if args.init_config:
        # CrÃ©er un fichier de configuration template
        if not CONFIG_MODULE_AVAILABLE:
            print("Erreur: Module de configuration non disponible.")
            print("Installez PyYAML: pip install pyyaml")
            sys.exit(1)
        
        try:
            path = ConfigLoader.init_config(force=args.force)
            print(f"âœ“ Fichier de configuration crÃ©Ã©: {path}")
            sys.exit(0)
        except ConfigError as e:
            print(f"âœ— {e}")
            sys.exit(1)
    
    if args.validate_config:
        # Valider le fichier de configuration
        if not CONFIG_MODULE_AVAILABLE:
            print("Erreur: Module de configuration non disponible.")
            sys.exit(1)
        
        try:
            config = ConfigLoader.load(path=args.config)
            print("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
            print("â•‘           VALIDATION DE LA CONFIGURATION                     â•‘")
            print("â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
            
            # Afficher les sources
            sources = config.get("_sources", ["default"])
            for source in sources:
                print(f"â•‘  âœ“ Source chargÃ©e: {source:<46} â•‘")
            
            print("â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
            print("â•‘  Configuration valide âœ“                                      â•‘")
            print("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
            sys.exit(0)
        except ConfigError as e:
            print("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
            print("â•‘           VALIDATION DE LA CONFIGURATION                     â•‘")
            print("â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
            print("â•‘  Configuration INVALIDE âœ—                                    â•‘")
            print("â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
            for err in e.errors:
                print(f"â•‘  â€¢ {err:<58} â•‘")
            print("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
            sys.exit(1)
    
    if args.show_config:
        # Afficher la configuration effective
        if not CONFIG_MODULE_AVAILABLE:
            print("Erreur: Module de configuration non disponible.")
            sys.exit(1)
        
        try:
            # Construire les overrides CLI
            cli_overrides = {}
            if args.timeout:
                cli_overrides["timeout"] = args.timeout
            if args.max_rounds:
                cli_overrides["max_rounds"] = args.max_rounds
            if args.no_trail:
                cli_overrides["enable_trail"] = False
            
            config = ConfigLoader.load(path=args.config, cli_overrides=cli_overrides)
            
            print("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
            print("â•‘           CONFIGURATION EFFECTIVE                            â•‘")
            print("â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
            
            # Afficher les sources
            sources = config.get("_sources", ["default"])
            print(f"â•‘  Sources: {' â†’ '.join(sources):<51} â•‘")
            print("â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
            
            # Afficher les chemins
            paths = ConfigLoader.get_config_paths()
            for name, (path, exists) in paths.items():
                status = "âœ“" if exists else "âœ—"
                print(f"â•‘  {status} {name}: {str(path)[:50]:<50} â•‘")
            
            print("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
            print("\n" + ConfigLoader.show_config(config))
            sys.exit(0)
        except ConfigError as e:
            print(f"Erreur: {e}")
            sys.exit(1)
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # COMMANDE DE VÃ‰RIFICATION CLI
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    if args.check:
        results = check_all_clis()
        print("\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
        print("â•‘           VÃ‰RIFICATION DES CLI                               â•‘")
        print("â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
        for model, (available, info) in results.items():
            status = "âœ“" if available else "âœ—"
            print(f"â•‘  {status} {model:10} â”‚ {info[:45]:<45} â•‘")
        print("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
        
        available_count = sum(1 for _, (a, _) in results.items() if a)
        sys.exit(0 if available_count > 0 else 1)

    # PRD-020: Afficher les templates disponibles
    if args.list_templates:
        list_templates()
        sys.exit(0)

    # PRD-024: Gestion du cache
    if args.cache_stats:
        cache = ResponseCache()
        stats = cache.stats()
        print(f"ðŸ“¦ Cache: {stats['entries']} entrÃ©es ({stats['size_mb']} MB)")
        if stats.get('cache_dir'):
            print(f"   RÃ©pertoire: {stats['cache_dir']}")
        sys.exit(0)

    if args.clear_cache:
        cache = ResponseCache()
        count = cache.clear()
        print(f"ðŸ—‘ï¸  Cache vidÃ©: {count} entrÃ©es supprimÃ©es")
        sys.exit(0)

    # PRD-025: Lister les sessions disponibles
    if args.list_sessions:
        trail_dir = Path("synthese_trails")
        if not trail_dir.exists():
            print("Aucune session disponible")
            sys.exit(0)
        print("ðŸ“‹ Sessions disponibles:\n")
        for trail in sorted(trail_dir.glob("*.json"), reverse=True)[:10]:
            try:
                with open(trail, encoding="utf-8") as f:
                    data = json.load(f)
                completed = "âœ“" if data.get("synthese_finale") else "â¸ï¸"
                rounds = len(data.get("rounds", []))
                print(f"  {completed} {data['session_id']}")
                print(f"     Mode: {data.get('mode', '?')} | Rounds: {rounds}")
            except Exception:
                continue
        sys.exit(0)

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # EXÃ‰CUTION PRINCIPALE
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    # PRD-014: Rediriger logs vers stderr si sortie structurÃ©e (json/markdown)
    global _log_file
    if args.json or args.markdown:
        _log_file = sys.stderr
        _printer.set_file(sys.stderr)

    # Compatible Windows/Linux/macOS
    if sys.platform == "win32":
        asyncio.set_event_loop_policy(asyncio.WindowsProactorEventLoopPolicy())

    exit_code = asyncio.run(async_main(args))
    sys.exit(exit_code)


if __name__ == "__main__":
    main()
