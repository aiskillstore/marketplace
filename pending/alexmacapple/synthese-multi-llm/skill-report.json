{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-10T10:15:14.019Z",
    "slug": "alexmacapple-synthese-multi-llm",
    "source_url": "https://github.com/Alexmacapple/Synthese-Council/tree/main/skills/synthese-multi-llm",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "2.0.0",
    "source_type": "community",
    "content_hash": "8a2eb0564b2e9eb8d8a05d588c44e4e6d451a1d9e21a95a9c9c9f935d2ef9113",
    "tree_hash": "5b5eecb029cb2a752d57f4987878cf10c417247b5d064b5f6e2309f776ab1adc"
  },
  "skill": {
    "name": "synthese-multi-llm",
    "description": "Synthèse co-fabriquée par un conseil de 3 LLMs (Claude, Gemini, Codex). Ce skill devrait être utilisé quand l'utilisateur demande une synthèse robuste, traçable et vérifiée. Il orchestre trois modèles avec des rôles experts distincts (Extracteur, Critique, Architecte) pour produire une synthèse fidèle au texte source, avec contrôle des glissements sémantiques et trail d'audit complet.",
    "summary": "Synthèse co-fabriquée par un conseil de 3 LLMs (Claude, Gemini, Codex). Ce skill devrait être utilis...",
    "icon": "⚖️",
    "version": "1.0.0",
    "author": "Alexmacapple",
    "license": "MIT",
    "category": "documentation",
    "tags": [
      "synthesis",
      "multi-llm",
      "claude",
      "gemini",
      "codex"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": [
      "scripts",
      "network",
      "filesystem",
      "env_access",
      "external_commands"
    ]
  },
  "security_audit": {
    "risk_level": "low",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "Legitimate multi-LLM synthesis tool. Capabilities align with stated purpose. Subprocess and network calls are documented and expected for calling external LLM services. Input sanitization and validation present. No malicious patterns detected.",
    "risk_factor_evidence": [
      {
        "factor": "scripts",
        "evidence": [
          {
            "file": "scripts/synthese.py",
            "line_start": 1,
            "line_end": 1500
          },
          {
            "file": "scripts/config.py",
            "line_start": 1,
            "line_end": 534
          },
          {
            "file": "scripts/retry.py",
            "line_start": 1,
            "line_end": 611
          }
        ]
      },
      {
        "factor": "network",
        "evidence": [
          {
            "file": "scripts/backends/anthropic_backend.py",
            "line_start": 1,
            "line_end": 321
          },
          {
            "file": "wrappers/claude_wrapper.sh",
            "line_start": 20,
            "line_end": 50
          },
          {
            "file": "wrappers/ollama_wrapper.sh",
            "line_start": 40,
            "line_end": 46
          }
        ]
      },
      {
        "factor": "filesystem",
        "evidence": [
          {
            "file": "scripts/config.py",
            "line_start": 175,
            "line_end": 177
          },
          {
            "file": "scripts/synthese.py",
            "line_start": 634,
            "line_end": 724
          }
        ]
      },
      {
        "factor": "env_access",
        "evidence": [
          {
            "file": "scripts/backends/anthropic_backend.py",
            "line_start": 106,
            "line_end": 108
          },
          {
            "file": "scripts/backends/cli_backend.py",
            "line_start": 151,
            "line_end": 152
          }
        ]
      },
      {
        "factor": "external_commands",
        "evidence": [
          {
            "file": "scripts/synthese.py",
            "line_start": 64,
            "line_end": 89
          },
          {
            "file": "scripts/backends/cli_backend.py",
            "line_start": 127,
            "line_end": 224
          }
        ]
      }
    ],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [
      {
        "title": "Subprocess execution for LLM calls",
        "description": "The code executes subprocess calls to invoke external CLI commands (claude, gemini, codex). This is a legitimate capability for an LLM orchestration tool. Callers are hardcoded CLI tools, not user-controlled input. Code: `asyncio.create_subprocess_exec(*cmd)` at scripts/synthese.py:70",
        "locations": [
          {
            "file": "scripts/synthese.py",
            "line_start": 70,
            "line_end": 70
          }
        ]
      },
      {
        "title": "Network calls to external APIs",
        "description": "The code makes HTTP requests to external LLM APIs (Anthropic, Ollama). Endpoints are documented and expected: https://api.anthropic.com/v1/messages and http://localhost:11434/api/generate. Required for core functionality.",
        "locations": [
          {
            "file": "wrappers/claude_wrapper.sh",
            "line_start": 40,
            "line_end": 50
          }
        ]
      }
    ],
    "dangerous_patterns": [],
    "files_scanned": 14,
    "total_lines": 4642,
    "audit_model": "claude",
    "audited_at": "2026-01-10T10:15:14.019Z"
  },
  "content": {
    "user_title": "Create multi-LLM summaries with expert critique",
    "value_statement": "Generate robust document summaries by orchestrating Claude, Gemini, and Codex in a council format. Three expert perspectives (Extractor, Guardian, Architect) cross-validate findings for accurate, traceable outputs.",
    "seo_keywords": [
      "claude ai",
      "gemini",
      "codex",
      "multi-llm synthesis",
      "document summarization",
      "ai council",
      "claude code",
      "text analysis",
      "semantic validation",
      "automated summary"
    ],
    "actual_capabilities": [
      "Orchestrates 3 LLMs with distinct expert roles for analysis",
      "Cross-critique round detects semantic shifts and biases",
      "Convergence score measures agreement between experts",
      "Generates audit trails for traceability",
      "Supports PDF, DOCX, and multi-source synthesis",
      "Template-based framing for audience and purpose"
    ],
    "limitations": [
      "Requires at least one LLM CLI installed (claude, gemini, or codex)",
      "Processing time longer than single-model synthesis (60-180 seconds)",
      "Does not perform web searches or access external data sources",
      "Accuracy depends on source document quality"
    ],
    "use_cases": [
      {
        "target_user": "Business professionals",
        "title": "Executive briefing synthesis",
        "description": "Transform lengthy reports into concise executive summaries with validated key points"
      },
      {
        "target_user": "Researchers",
        "title": "Academic paper analysis",
        "description": "Extract and cross-validate findings from scientific documents with citation tracking"
      },
      {
        "target_user": "Legal professionals",
        "title": "Contract review summary",
        "description": "Identify key clauses and potential risks across multiple legal documents"
      }
    ],
    "prompt_templates": [
      {
        "title": "Basic synthesis",
        "scenario": "Quick document summary",
        "prompt": "Synthétise ce texte avec le conseil: [votre texte ici]"
      },
      {
        "title": "With framing",
        "scenario": "Targeted audience summary",
        "prompt": "Synthétise ce texte pour le comité de direction avec une finalité de décision stratégique en 1 page"
      },
      {
        "title": "Critical analysis",
        "scenario": "Validation-focused review",
        "prompt": "Fais une analyse critique de cette synthèse existante en vérifiant les glissements sémantiques"
      },
      {
        "title": "Multi-source",
        "scenario": "Cross-document comparison",
        "prompt": "Compare ces deux documents et identifie les points de convergence et divergence"
      }
    ],
    "output_examples": [
      {
        "input": "Synthétise ce rapport trimestriel avec le conseil pour le comité de direction",
        "output": [
          "Points clés identifiés: Croissance de 15% du CA, réduction des coûts opérationnels de 8%",
          "Convergence: 92% - Les 3 experts s'accordent sur les tendances principales",
          "Points de vigilance: Dépendance croissante au marché européen (signalé par le Gardien)",
          "Recommandation: Poursuivre l'expansion en Amérique du Nord tout en diversifiant les fournisseurs"
        ]
      }
    ],
    "best_practices": [
      "Provide clear framing (audience, purpose, length) for more relevant outputs",
      "Use the critical mode to validate existing summaries before sharing",
      "Review convergence scores below 70% for potential disagreements to investigate",
      "Enable --refs flag for verifiable paragraph references in long documents"
    ],
    "anti_patterns": [
      "Using extremely short prompts without context or framing expectations",
      "Skipping the critique round for complex documents requiring accuracy",
      "Ignoring low convergence scores without investigating root causes",
      "Processing confidential documents without reviewing trail retention settings"
    ],
    "faq": [
      {
        "question": "Which LLMs are supported?",
        "answer": "Claude CLI, Gemini CLI, Codex CLI, Ollama, and Anthropic API. At least one is required."
      },
      {
        "question": "What is the convergence score?",
        "answer": "A 0-100% metric indicating expert agreement. Above 80% means strong consensus on findings."
      },
      {
        "question": "Can I use this with local LLMs?",
        "answer": "Yes, configure Ollama or other local CLI wrappers in synthese.config.yaml."
      },
      {
        "question": "Is my data sent to external servers?",
        "answer": "Only if using cloud APIs (Anthropic, Gemini). Local CLI calls stay on your machine."
      },
      {
        "question": "What if one model fails?",
        "answer": "The system continues with available models. Convergence may be limited but process completes."
      },
      {
        "question": "How does this compare to single-model summary?",
        "answer": "More robust through cross-validation, but takes 3-5x longer due to multi-round deliberation."
      }
    ]
  },
  "file_structure": [
    {
      "name": "references",
      "type": "dir",
      "path": "references",
      "children": [
        {
          "name": "cadrage.md",
          "type": "file",
          "path": "references/cadrage.md"
        },
        {
          "name": "configuration.md",
          "type": "file",
          "path": "references/configuration.md"
        },
        {
          "name": "couches-semiotiques.md",
          "type": "file",
          "path": "references/couches-semiotiques.md"
        },
        {
          "name": "glissements.md",
          "type": "file",
          "path": "references/glissements.md"
        },
        {
          "name": "metrics.md",
          "type": "file",
          "path": "references/metrics.md"
        },
        {
          "name": "troubleshooting.md",
          "type": "file",
          "path": "references/troubleshooting.md"
        }
      ]
    },
    {
      "name": "scripts",
      "type": "dir",
      "path": "scripts",
      "children": [
        {
          "name": "backends",
          "type": "dir",
          "path": "scripts/backends",
          "children": [
            {
              "name": "__init__.py",
              "type": "file",
              "path": "scripts/backends/__init__.py"
            },
            {
              "name": "anthropic_backend.py",
              "type": "file",
              "path": "scripts/backends/anthropic_backend.py"
            },
            {
              "name": "base.py",
              "type": "file",
              "path": "scripts/backends/base.py"
            },
            {
              "name": "cli_backend.py",
              "type": "file",
              "path": "scripts/backends/cli_backend.py"
            }
          ]
        },
        {
          "name": "config.py",
          "type": "file",
          "path": "scripts/config.py"
        },
        {
          "name": "convergence.py",
          "type": "file",
          "path": "scripts/convergence.py"
        },
        {
          "name": "pedagogy.py",
          "type": "file",
          "path": "scripts/pedagogy.py"
        },
        {
          "name": "retry.py",
          "type": "file",
          "path": "scripts/retry.py"
        },
        {
          "name": "sanitize.py",
          "type": "file",
          "path": "scripts/sanitize.py"
        },
        {
          "name": "synthese.py",
          "type": "file",
          "path": "scripts/synthese.py"
        }
      ]
    },
    {
      "name": "wrappers",
      "type": "dir",
      "path": "wrappers",
      "children": [
        {
          "name": "claude_wrapper.sh",
          "type": "file",
          "path": "wrappers/claude_wrapper.sh"
        },
        {
          "name": "ollama_wrapper.sh",
          "type": "file",
          "path": "wrappers/ollama_wrapper.sh"
        },
        {
          "name": "README.md",
          "type": "file",
          "path": "wrappers/README.md"
        }
      ]
    },
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md"
    },
    {
      "name": "synthese.config.yaml",
      "type": "file",
      "path": "synthese.config.yaml"
    }
  ]
}
