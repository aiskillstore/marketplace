{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-02T02:31:42.604Z",
    "slug": "K-Dense-AI-get-available-resources",
    "source_url": "https://github.com/K-Dense-AI/claude-scientific-skills/tree/main/scientific-skills/get-available-resources",
    "source_ref": "main",
    "model": "codex",
    "analysis_version": "2.0.0",
    "source_type": "community"
  },
  "skill": {
    "name": "get-available-resources",
    "description": "This skill should be used at the start of any computationally intensive scientific task to detect and report available system resources (CPU cores, GPUs, memory, disk space). It creates a JSON file with resource information and strategic recommendations that inform computational approach decisions such as whether to use parallel processing (joblib, multiprocessing), out-of-core computing (Dask, Zarr), GPU acceleration (PyTorch, JAX), or memory-efficient strategies. Use this skill before running analyses, training models, processing large datasets, or any task where resource constraints matter.",
    "summary": "This skill should be used at the start of any computationally intensive scientific task to detect an...",
    "icon": "üñ•Ô∏è",
    "version": "1.0.0",
    "author": "K-Dense Inc.",
    "license": "MIT license",
    "category": "research",
    "tags": [
      "resources",
      "hardware",
      "performance",
      "scientific",
      "planning"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": [
      "scripts",
      "external_commands"
    ]
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "Reviewed SKILL.md and scripts/detect_resources.py. The code only queries local system tools and writes a local JSON file. No network access or sensitive file harvesting was found.",
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 2,
    "total_lines": 675,
    "audit_model": "codex",
    "audited_at": "2026-01-02T02:31:42.603Z"
  },
  "content": {
    "user_title": "Detect available compute resources",
    "value_statement": "Large workloads fail when resources are unknown. This skill reports CPU, GPU, memory, and disk details with practical recommendations.",
    "seo_keywords": [
      "Claude",
      "Codex",
      "Claude Code",
      "resource detection",
      "GPU availability",
      "CPU cores",
      "memory check",
      "disk space",
      "scientific computing",
      "performance planning"
    ],
    "actual_capabilities": [
      "Detects CPU core counts, architecture, and frequency",
      "Reports total and available RAM plus swap usage",
      "Checks disk usage for the working directory",
      "Detects NVIDIA, AMD, and Apple Silicon GPU backends",
      "Generates recommendations for parallel, memory, GPU, and disk strategies",
      "Writes a .claude_resources.json report with timestamp and OS info"
    ],
    "limitations": [
      "Requires Python and the psutil package installed",
      "GPU detection depends on system tools like nvidia-smi or rocm-smi",
      "Disk metrics only cover the specified path",
      "Resource readings are a point-in-time snapshot"
    ],
    "use_cases": [
      {
        "target_user": "Data scientist",
        "title": "Plan large dataset loading",
        "description": "Check memory and disk before deciding between pandas and Dask."
      },
      {
        "target_user": "ML engineer",
        "title": "Choose GPU backend",
        "description": "Detect CUDA, ROCm, or Metal and pick a training stack."
      },
      {
        "target_user": "Research analyst",
        "title": "Set parallel workers",
        "description": "Use core counts to size joblib or multiprocessing jobs."
      }
    ],
    "prompt_templates": [
      {
        "title": "Quick resource check",
        "scenario": "New project setup",
        "prompt": "Run the resource detection skill and summarize CPU, memory, disk, and GPU availability."
      },
      {
        "title": "Parallel plan",
        "scenario": "Batch processing",
        "prompt": "Detect resources and recommend an optimal worker count for joblib based on my machine."
      },
      {
        "title": "Large data decision",
        "scenario": "50 GB dataset",
        "prompt": "Detect resources and advise whether to use out of core tools like Dask or Zarr."
      },
      {
        "title": "GPU backend selection",
        "scenario": "Model training",
        "prompt": "Detect GPU backends and suggest suitable libraries for acceleration on this system."
      }
    ],
    "output_examples": [
      {
        "input": "Check my machine resources and give me a quick plan for processing a large dataset.",
        "output": [
          "CPU: 12 logical cores, recommended 10 workers for parallel tasks",
          "Memory: 32 GB total, 18 GB available, moderate memory strategy",
          "Disk: 1.2 TB total, 640 GB free, disk abundant",
          "GPU: NVIDIA CUDA available, consider PyTorch or CuPy"
        ]
      }
    ],
    "best_practices": [
      "Run the detection before heavy compute tasks",
      "Re run when system load changes",
      "Keep the JSON report with project notes"
    ],
    "anti_patterns": [
      "Assuming GPU availability without detection",
      "Setting worker counts higher than cores",
      "Ignoring disk space before large intermediate files"
    ],
    "faq": [
      {
        "question": "Is this compatible with macOS, Linux, and Windows",
        "answer": "Yes. It supports all three platforms with OS specific GPU detection."
      },
      {
        "question": "What are the limits of the detection",
        "answer": "It is a snapshot and depends on psutil and GPU tools installed."
      },
      {
        "question": "How do I integrate it into my workflow",
        "answer": "Run the script at project start and read the JSON in your code."
      },
      {
        "question": "Does it collect or send my data",
        "answer": "No. It only reads local system stats and writes a local JSON file."
      },
      {
        "question": "What if GPU is not detected",
        "answer": "Check driver tools like nvidia-smi or rocm-smi and your PATH."
      },
      {
        "question": "How does it compare to manual checks",
        "answer": "It automates CPU, memory, disk, and GPU checks in one report."
      }
    ]
  },
  "file_structure": [
    {
      "name": "scripts",
      "type": "dir",
      "path": "scripts",
      "children": [
        {
          "name": "detect_resources.py",
          "type": "file",
          "path": "scripts/detect_resources.py"
        }
      ]
    },
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md"
    }
  ]
}