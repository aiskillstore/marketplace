{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-02-04T08:53:52.388Z",
    "slug": "inference-sh-ai-video-generation",
    "source_url": "https://github.com/inference-sh/skills/tree/main/skills/ai-video-generation/",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "3.0.0",
    "source_type": "community",
    "content_hash": "642d499d6c040b3bc514e258deebc91a0616be623476ace79ed127370cf532fe",
    "tree_hash": "36a4a19910a50eceecfbf3f9df98ddfe03e8329213250fb720a537113f2d69db"
  },
  "skill": {
    "name": "ai-video-generation",
    "description": "Generate AI videos using 40+ models via inference.sh CLI. Create videos from text, images, or audio. Supports Veo 3.1, Grok Video, Wan 2.5, OmniHuman, and other AI video tools for social media, marketing, and content creation.",
    "summary": "Generate AI videos with Google Veo, Seedance, Wan, Grok and 40+ models via inference.sh CLI.",
    "icon": "ðŸ“¦",
    "version": "1.0.0",
    "author": "inference-sh",
    "license": "MIT",
    "category": "design",
    "tags": [
      "video",
      "ai-video",
      "inference.sh",
      "generative-ai",
      "content-creation"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": [
      "external_commands",
      "network"
    ]
  },
  "security_audit": {
    "risk_level": "low",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "All static findings are false positives. The 42 external_command alerts are curl commands for CLI installation, and 16 network alerts are documentation links. No code execution or credential exposure risk detected.",
    "files_scanned": 1,
    "total_lines": 181,
    "audit_model": "claude",
    "audited_at": "2026-02-04T08:53:52.388Z",
    "risk_factor_evidence": [
      {
        "factor": "external_commands",
        "evidence": [
          {
            "file": "SKILL.md",
            "line_start": 20,
            "line_end": 26
          },
          {
            "file": "SKILL.md",
            "line_start": 26,
            "line_end": 34
          },
          {
            "file": "SKILL.md",
            "line_start": 34,
            "line_end": 35
          },
          {
            "file": "SKILL.md",
            "line_start": 35,
            "line_end": 36
          },
          {
            "file": "SKILL.md",
            "line_start": 36,
            "line_end": 37
          },
          {
            "file": "SKILL.md",
            "line_start": 37,
            "line_end": 38
          },
          {
            "file": "SKILL.md",
            "line_start": 38,
            "line_end": 39
          },
          {
            "file": "SKILL.md",
            "line_start": 39,
            "line_end": 40
          },
          {
            "file": "SKILL.md",
            "line_start": 40,
            "line_end": 41
          },
          {
            "file": "SKILL.md",
            "line_start": 41,
            "line_end": 47
          },
          {
            "file": "SKILL.md",
            "line_start": 47,
            "line_end": 48
          },
          {
            "file": "SKILL.md",
            "line_start": 48,
            "line_end": 49
          },
          {
            "file": "SKILL.md",
            "line_start": 49,
            "line_end": 55
          },
          {
            "file": "SKILL.md",
            "line_start": 55,
            "line_end": 56
          },
          {
            "file": "SKILL.md",
            "line_start": 56,
            "line_end": 57
          },
          {
            "file": "SKILL.md",
            "line_start": 57,
            "line_end": 58
          },
          {
            "file": "SKILL.md",
            "line_start": 58,
            "line_end": 64
          },
          {
            "file": "SKILL.md",
            "line_start": 64,
            "line_end": 65
          },
          {
            "file": "SKILL.md",
            "line_start": 65,
            "line_end": 66
          },
          {
            "file": "SKILL.md",
            "line_start": 66,
            "line_end": 70
          },
          {
            "file": "SKILL.md",
            "line_start": 70,
            "line_end": 72
          },
          {
            "file": "SKILL.md",
            "line_start": 72,
            "line_end": 78
          },
          {
            "file": "SKILL.md",
            "line_start": 78,
            "line_end": 82
          },
          {
            "file": "SKILL.md",
            "line_start": 82,
            "line_end": 86
          },
          {
            "file": "SKILL.md",
            "line_start": 86,
            "line_end": 91
          },
          {
            "file": "SKILL.md",
            "line_start": 91,
            "line_end": 95
          },
          {
            "file": "SKILL.md",
            "line_start": 95,
            "line_end": 99
          },
          {
            "file": "SKILL.md",
            "line_start": 99,
            "line_end": 103
          },
          {
            "file": "SKILL.md",
            "line_start": 103,
            "line_end": 108
          },
          {
            "file": "SKILL.md",
            "line_start": 108,
            "line_end": 112
          },
          {
            "file": "SKILL.md",
            "line_start": 112,
            "line_end": 117
          },
          {
            "file": "SKILL.md",
            "line_start": 117,
            "line_end": 121
          },
          {
            "file": "SKILL.md",
            "line_start": 121,
            "line_end": 126
          },
          {
            "file": "SKILL.md",
            "line_start": 126,
            "line_end": 130
          },
          {
            "file": "SKILL.md",
            "line_start": 130,
            "line_end": 132
          },
          {
            "file": "SKILL.md",
            "line_start": 132,
            "line_end": 136
          },
          {
            "file": "SKILL.md",
            "line_start": 136,
            "line_end": 141
          },
          {
            "file": "SKILL.md",
            "line_start": 141,
            "line_end": 145
          },
          {
            "file": "SKILL.md",
            "line_start": 145,
            "line_end": 150
          },
          {
            "file": "SKILL.md",
            "line_start": 150,
            "line_end": 154
          },
          {
            "file": "SKILL.md",
            "line_start": 154,
            "line_end": 172
          },
          {
            "file": "SKILL.md",
            "line_start": 172,
            "line_end": 174
          }
        ]
      },
      {
        "factor": "network",
        "evidence": [
          {
            "file": "SKILL.md",
            "line_start": 16,
            "line_end": 16
          },
          {
            "file": "SKILL.md",
            "line_start": 22,
            "line_end": 22
          },
          {
            "file": "SKILL.md",
            "line_start": 97,
            "line_end": 97
          },
          {
            "file": "SKILL.md",
            "line_start": 105,
            "line_end": 105
          },
          {
            "file": "SKILL.md",
            "line_start": 106,
            "line_end": 106
          },
          {
            "file": "SKILL.md",
            "line_start": 114,
            "line_end": 114
          },
          {
            "file": "SKILL.md",
            "line_start": 115,
            "line_end": 115
          },
          {
            "file": "SKILL.md",
            "line_start": 123,
            "line_end": 123
          },
          {
            "file": "SKILL.md",
            "line_start": 124,
            "line_end": 124
          },
          {
            "file": "SKILL.md",
            "line_start": 131,
            "line_end": 131
          },
          {
            "file": "SKILL.md",
            "line_start": 138,
            "line_end": 138
          },
          {
            "file": "SKILL.md",
            "line_start": 147,
            "line_end": 147
          },
          {
            "file": "SKILL.md",
            "line_start": 147,
            "line_end": 147
          },
          {
            "file": "SKILL.md",
            "line_start": 178,
            "line_end": 178
          },
          {
            "file": "SKILL.md",
            "line_start": 179,
            "line_end": 179
          },
          {
            "file": "SKILL.md",
            "line_start": 180,
            "line_end": 180
          }
        ]
      }
    ],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [
      {
        "title": "Shell Pipe in Documentation",
        "description": "curl command with pipe to shell in installation example (line 22). While potentially risky in production, this is a documented self-install method for the official inference.sh CLI. Requires user confirmation.",
        "locations": [
          {
            "file": "SKILL.md",
            "line_start": 22,
            "line_end": 22
          }
        ]
      }
    ],
    "dangerous_patterns": []
  },
  "content": {
    "user_title": "Generate AI Videos",
    "value_statement": "Create videos from text, images, or audio using 40+ AI models. Generate social media clips, marketing content, and explainer videos with tools like Veo 3.1, Grok Video, and Wan 2.5.",
    "seo_keywords": [
      "AI video generator",
      "text to video",
      "image to video",
      "AI animation",
      "Veo 3.1",
      "Grok video",
      "Wan 2.5",
      "Claude Code",
      "Claudex",
      "AI content creation"
    ],
    "actual_capabilities": [
      "Generate videos from text prompts using Veo 3.1, Grok, and Seedance models",
      "Create videos from static images using Wan 2.5 and Seedance image-to-video",
      "Animate avatars with lipsync using OmniHuman and Fabric",
      "Upscale video quality with Topaz Video Upscaler",
      "Add sound effects and foley to videos",
      "Merge multiple videos with transitions"
    ],
    "limitations": [
      "Requires inference.sh CLI installation and login",
      "Network connection required for API calls",
      "Video generation may have processing time delays",
      "No local video editing capabilities",
      "Example URLs in documentation are placeholders"
    ],
    "use_cases": [
      {
        "title": "Social Media Content Creator",
        "description": "Generate viral TikTok and Instagram Reels from text descriptions. Create trending content quickly using text-to-video models.",
        "target_user": "Content creators, social media managers"
      },
      {
        "title": "Marketing Professional",
        "description": "Create product demos, explainer videos, and ad content. Use image-to-video to transform product images into engaging videos.",
        "target_user": "Marketing teams, brand managers"
      },
      {
        "title": "Video Editor",
        "description": "Animate static footage and add realistic motion. Use upscaling and foley tools to enhance existing video content.",
        "target_user": "Video editors, production houses"
      }
    ],
    "prompt_templates": [
      {
        "title": "Beginner: Generate a simple video",
        "prompt": "Generate a video from the following text prompt using the Veo 3.1 model:\n\nText: [PROMPT]\n\nRequirements:\n- Use infsh app run google/veo-3-1-fast\n- Format the input as JSON\n- Generate high-quality output"
      },
      {
        "title": "Intermediate: Image-to-video animation",
        "prompt": "Create an image-to-video animation using Wan 2.5:\n\nImage URL: [IMAGE_URL]\nPrompt: [DESIRED_ANIMATION]\n\nRequirements:\n- Use infsh app run falai/wan-2-5-i2v\n- Specify smooth animation parameters\n- Ensure consistent character appearance"
      },
      {
        "title": "Advanced: Avatar with lipsync",
        "prompt": "Create an AI avatar with realistic lipsync:\n\nPortrait Image: [IMAGE_URL]\nAudio: [AUDIO_URL]\n\nRequirements:\n- Use bytedance/omnihuman-1-5 for best quality\n- Configure appropriate mouth movement parameters\n- Output direct video URL for preview"
      },
      {
        "title": "Expert: Complete video pipeline",
        "prompt": "Build a complete video creation pipeline:\n\n1. Generate text-to-video with Grok Video\n2. Upscale with Topaz Video Upscaler\n3. Add foley sound effects\n4. Merge with transition\n\nUse appropriate inference.sh apps for each step. Provide complete JSON inputs for all operations."
      }
    ],
    "output_examples": [
      {
        "input": "Generate a drone shot flying over a forest",
        "output": "Run the following command:\n\n```bash\ninfsh app run google/veo-3-1-fast --input '{\"prompt\": \"drone shot flying over a forest\"}'\n```\n\nThis generates a video clip with camera movement effects."
      },
      {
        "input": "Animate this image: https://example.com/portrait.jpg with speech",
        "output": "Use OmniHuman to create an avatar:\n\n```bash\ninfsh app run bytedance/omnihuman-1-5 --input '{\n  \"image_url\": \"https://example.com/portrait.jpg\",\n  \"audio_url\": \"https://example.com/speech.mp3\"\n}'\n```\n\nThis creates a video with the avatar speaking the audio."
      }
    ],
    "best_practices": [
      "Install inference.sh CLI before using video generation commands",
      "Review output video quality before distribution",
      "Use image URLs from reliable sources for best results",
      "Test parameters in small batches before full production",
      "Check API rate limits when generating multiple videos"
    ],
    "anti_patterns": [
      "Pasting untrusted URLs directly into video generation commands",
      "Generating videos with inappropriate or copyrighted content",
      "Using test API keys in production environments",
      "Bypassing inference.sh authentication",
      "Mixing example URLs from documentation with real work"
    ],
    "faq": [
      {
        "question": "Which AI video models are available?",
        "answer": "The skill supports 40+ models including Google Veo 3.1, Grok Video, Wan 2.5, Seedance 1.5 Pro, OmniHuman, Fabric, and HunyuanVideo for different use cases like text-to-video, image-to-video, and lipsync."
      },
      {
        "question": "Do I need to install anything to use this skill?",
        "answer": "Yes, you need to install the inference.sh CLI using curl and run `infsh login` to authenticate. The skill uses the CLI to generate videos through the inference.sh API."
      },
      {
        "question": "What video formats are supported?",
        "answer": "The skill generates standard video formats compatible with common players. Output formats depend on the specific model and are provided by the inference.sh API."
      },
      {
        "question": "Can I upscale existing videos?",
        "answer": "Yes, use the Topaz Video Upscaler model to enhance video quality and resolution before using the video in your projects."
      },
      {
        "question": "Is this free to use?",
        "answer": "Usage depends on the inference.sh API pricing. Check the inference.sh documentation for current rates and subscription options."
      },
      {
        "question": "What is the maximum video duration?",
        "answer": "Video duration varies by model. Check the available models table in the documentation for specific time limits per model type."
      }
    ]
  },
  "file_structure": [
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md",
      "lines": 181
    }
  ]
}
