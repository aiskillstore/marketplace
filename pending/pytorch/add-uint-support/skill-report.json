{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-06T01:18:27.451Z",
    "slug": "pytorch-add-uint-support",
    "source_url": "https://github.com/pytorch/pytorch/tree/main/.claude/skills/add-uint-support",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "2.0.0",
    "source_type": "community",
    "content_hash": "aa1619a8cd839fdaea05597965e71c60466b453e0fc78f0f5f3196b6bad4d0c7",
    "tree_hash": "0c238c2d4485833b9929050e00609419bbf8b66e76f1f679bfb3f9cfe25d4be6"
  },
  "skill": {
    "name": "add-uint-support",
    "description": "Add unsigned integer (uint) type support to PyTorch operators by updating AT_DISPATCH macros. Use when adding support for uint16, uint32, uint64 types to operators, kernels, or when user mentions enabling unsigned types, barebones unsigned types, or uint support.",
    "summary": "Add unsigned integer (uint) type support to PyTorch operators by updating AT_DISPATCH macros. Use wh...",
    "icon": "ðŸ”¢",
    "version": "1.0.0",
    "author": "pytorch",
    "license": "MIT",
    "category": "coding",
    "tags": [
      "pytorch",
      "cpp",
      "dispatch",
      "uint",
      "kernels"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": []
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "This is a documentation-only skill that provides instructions for adding unsigned integer support to PyTorch operators. It contains no executable code, network calls, file system access, or other potentially dangerous capabilities. The skill is purely educational and provides C++ code examples for PyTorch kernel development.",
    "risk_factor_evidence": [],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 1,
    "total_lines": 320,
    "audit_model": "claude",
    "audited_at": "2026-01-06T01:18:27.450Z"
  },
  "content": {
    "user_title": "Add Unsigned Integer Support to PyTorch Operators",
    "value_statement": "PyTorch operators often lack support for unsigned integer types like uint16, uint32, and uint64. This skill automatically updates AT_DISPATCH macros to include these types, expanding your operator's compatibility with unsigned integer tensors.",
    "seo_keywords": [
      "pytorch",
      "unsigned integer",
      "uint support",
      "AT_DISPATCH",
      "kernel development",
      "cpp",
      "claude",
      "codex",
      "claude code",
      "pytorch operators"
    ],
    "actual_capabilities": [
      "Updates AT_DISPATCH_V2 macros to include unsigned integer types",
      "Supports both explicit AT_BAREBONES_UNSIGNED_TYPES addition and INTEGRAL_TYPES_V2 substitution",
      "Handles multiple dispatch sites within the same file",
      "Works with existing AT_ALL_TYPES, AT_INTEGRAL_TYPES, and AT_FLOATING_TYPES combinations",
      "Provides clear examples and decision trees for different code patterns"
    ],
    "limitations": [
      "Requires files to already use AT_DISPATCH_V2 format",
      "Only supports uint16, uint32, and uint64 types (not uint8)",
      "Cannot add uint support to operators that only handle floating-point types",
      "Does not validate semantic correctness of uint support for specific operators"
    ],
    "use_cases": [
      {
        "target_user": "PyTorch kernel developer",
        "title": "Enable uint support for reduction operations",
        "description": "Add unsigned integer support to min/max/sum reduction kernels to handle uint16, uint32, and uint64 tensors"
      },
      {
        "target_user": "ML framework maintainer",
        "title": "Expand operator type coverage",
        "description": "Systematically add uint support across multiple operators in your custom PyTorch extension"
      },
      {
        "target_user": "Performance optimizer",
        "title": "Fix uint compatibility issues",
        "description": "Resolve runtime errors when users pass unsigned integer tensors to operators lacking uint support"
      }
    ],
    "prompt_templates": [
      {
        "title": "Basic uint addition",
        "scenario": "Single operator needs uint support",
        "prompt": "Add unsigned integer support to this PyTorch operator file. It currently uses AT_DISPATCH_V2 with AT_ALL_TYPES."
      },
      {
        "title": "Multiple dispatch sites",
        "scenario": "File has CPU and CUDA kernels",
        "prompt": "This file has multiple AT_DISPATCH_V2 calls for CPU and CUDA implementations. Add uint support to all of them."
      },
      {
        "title": "Convert then add uint",
        "scenario": "File uses old AT_DISPATCH format",
        "prompt": "First convert this file from AT_DISPATCH_ALL_TYPES to AT_DISPATCH_V2, then add unsigned integer support."
      },
      {
        "title": "Selective uint addition",
        "scenario": "Only integral operations need uint",
        "prompt": "Add uint support only to the operations that use AT_INTEGRAL_TYPES, leave floating-point operations unchanged."
      }
    ],
    "output_examples": [
      {
        "input": "Add unsigned integer support to my reduction kernel that currently uses AT_ALL_TYPES",
        "output": [
          "âœ“ Identified 2 AT_DISPATCH_V2 calls in your file",
          "âœ“ Added AT_EXPAND(AT_BAREBONES_UNSIGNED_TYPES) to both dispatch sites",
          "âœ“ Your kernel now supports uint16, uint32, and uint64 tensors",
          "âš  Remember to test functional correctness with unsigned integer inputs"
        ]
      }
    ],
    "best_practices": [
      "Always verify that your operator semantically supports unsigned integer operations before adding uint types",
      "Apply uint support consistently across all dispatch sites in a file to avoid type coverage inconsistencies",
      "Test with edge cases like UINT_MAX values to ensure proper overflow handling"
    ],
    "anti_patterns": [
      "Adding uint support to floating-point only operations like softmax or layer normalization",
      "Forgetting to update all dispatch sites in files with multiple CPU/CUDA kernel implementations",
      "Assuming uint8 is included in BAREBONES_UNSIGNED_TYPES (it's not - uint8 is kByte)"
    ],
    "faq": [
      {
        "question": "Which unsigned integer types are supported?",
        "answer": "This skill adds support for uint16, uint32, and uint64 (kUInt16, kUInt32, kUInt64). It does not include uint8 which is already available as kByte."
      },
      {
        "question": "Can I use this on files with old AT_DISPATCH format?",
        "answer": "No, you must first convert to AT_DISPATCH_V2 using the at-dispatch-v2 skill. This skill only works with the V2 format."
      },
      {
        "question": "Will this break existing functionality?",
        "answer": "The skill only adds type support without changing existing behavior. However, ensure your operator's logic correctly handles unsigned integer semantics."
      },
      {
        "question": "How do I verify the changes worked?",
        "answer": "After applying changes, test with uint16, uint32, and uint64 tensors. The operator should accept these types without runtime errors."
      },
      {
        "question": "Should I add uint support to all operators?",
        "answer": "Only add uint support to operators that make semantic sense. Avoid adding it to floating-point specific operations like normalization or activation functions."
      },
      {
        "question": "What's the difference between the two methods?",
        "answer": "Method 1 explicitly adds AT_BAREBONES_UNSIGNED_TYPES. Method 2 replaces AT_INTEGRAL_TYPES with AT_INTEGRAL_TYPES_V2 which includes both signed and unsigned integers."
      }
    ]
  },
  "file_structure": [
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md"
    }
  ]
}
