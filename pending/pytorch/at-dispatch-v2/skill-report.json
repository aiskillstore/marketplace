{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-06T01:50:49.629Z",
    "slug": "pytorch-at-dispatch-v2",
    "source_url": "https://github.com/pytorch/pytorch/tree/main/.claude/skills/at-dispatch-v2",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "2.0.0",
    "source_type": "community",
    "content_hash": "441e54058d3446fdc95d8b015f03b028e09ecd619f5431a38079177b50f14528",
    "tree_hash": "60ee9f7f18f13c3cebf03c2866952f641e59414917981b13012daaa53c5880ce"
  },
  "skill": {
    "name": "at-dispatch-v2",
    "description": "Convert PyTorch AT_DISPATCH macros to AT_DISPATCH_V2 format in ATen C++ code. Use when porting AT_DISPATCH_ALL_TYPES_AND*, AT_DISPATCH_FLOATING_TYPES*, or other dispatch macros to the new v2 API. For ATen kernel files, CUDA kernels, and native operator implementations.",
    "summary": "Convert PyTorch AT_DISPATCH macros to AT_DISPATCH_V2 format in ATen C++ code. Use when porting AT_DI...",
    "icon": "ðŸ”„",
    "version": "1.0.0",
    "author": "pytorch",
    "license": "BSD-3-Clause",
    "category": "coding",
    "tags": [
      "PyTorch",
      "C++",
      "ATen",
      "dispatch macros",
      "kernel development"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": []
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "This skill is a pure documentation and guidance file (SKILL.md). It contains no executable code, no scripts, no network calls, and no filesystem access capabilities. The skill provides instructions to AI agents on how to convert PyTorch dispatch macros - it does not perform any actions itself.",
    "risk_factor_evidence": [],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 1,
    "total_lines": 306,
    "audit_model": "claude",
    "audited_at": "2026-01-06T01:50:49.629Z"
  },
  "content": {
    "user_title": "Convert PyTorch AT_DISPATCH macros to V2",
    "value_statement": "PyTorch kernel code uses legacy AT_DISPATCH macros that need migration to the new AT_DISPATCH_V2 API. This skill automates the conversion process with clear patterns, examples, and verification steps for correct macro transformation.",
    "seo_keywords": [
      "PyTorch AT_DISPATCH",
      "AT_DISPATCH_V2",
      "PyTorch dispatch macros",
      "ATen kernel conversion",
      "PyTorch C++ kernels",
      "Dispatch_v2.h",
      "Claude Code",
      "Codex",
      "PyTorch migration"
    ],
    "actual_capabilities": [
      "Identify legacy AT_DISPATCH macros in C++ code",
      "Add the Dispatch_v2.h include header",
      "Transform macro arguments to V2 format",
      "Wrap lambdas with AT_WRAP for comma handling",
      "Expand type groups using AT_EXPAND macro",
      "Verify conversion correctness"
    ],
    "limitations": [
      "Does not compile or test the converted code",
      "Does not modify files without user confirmation",
      "Does not handle complex macro edge cases manually",
      "Focused only on AT_DISPATCH to AT_DISPATCH_V2 conversion"
    ],
    "use_cases": [
      {
        "target_user": "PyTorch kernel developers",
        "title": "Migrate legacy kernels",
        "description": "Convert ATen kernel files from old dispatch macros to the new v2 API with proper type expansion"
      },
      {
        "target_user": "CUDA kernel contributors",
        "title": "Port CUDA dispatch code",
        "description": "Update CUDA kernel implementations to use the modern AT_DISPATCH_V2 format"
      },
      {
        "target_user": "PyTorch maintainers",
        "title": "Modernize operator code",
        "description": "Refactor native operator implementations to use the extensible v2 dispatch pattern"
      }
    ],
    "prompt_templates": [
      {
        "title": "Basic conversion",
        "scenario": "Convert a simple dispatch macro",
        "prompt": "Convert this AT_DISPATCH_ALL_TYPES_AND2 macro to AT_DISPATCH_V2 format: [paste code snippet]"
      },
      {
        "title": "CUDA kernel",
        "scenario": "Convert GPU kernel dispatch",
        "prompt": "Convert the CUDA kernel dispatch in [file path] from AT_DISPATCH_FLOATING_TYPES_AND3 to AT_DISPATCH_V2"
      },
      {
        "title": "Complex types",
        "scenario": "Handle complex type combinations",
        "prompt": "Convert this AT_DISPATCH_ALL_TYPES_AND_COMPLEX_AND2 macro showing how to handle both type groups"
      },
      {
        "title": "Batch migration",
        "scenario": "Convert entire file",
        "prompt": "Convert all AT_DISPATCH macros in [file path] to AT_DISPATCH_V2 format and show the complete converted file"
      }
    ],
    "output_examples": [
      {
        "input": "Convert this macro: AT_DISPATCH_ALL_TYPES_AND3(kBFloat16, kHalf, kBool, dtype, \"min_values_cuda\", [&]() { min_values_kernel_cuda_impl<scalar_t>(iter); });",
        "output": [
          "AT_DISPATCH_V2(dtype, \"min_values_cuda\", AT_WRAP([&]() { min_values_kernel_cuda_impl<scalar_t>(iter); }), AT_EXPAND(AT_ALL_TYPES), kBFloat16, kHalf, kBool)",
          "Added #include <ATen/Dispatch_v2.h>",
          "Key changes: moved dtype and name first, wrapped lambda with AT_WRAP, expanded ALL_TYPES with AT_EXPAND, listed individual types last"
        ]
      }
    ],
    "best_practices": [
      "Always wrap lambdas in AT_WRAP to handle internal commas",
      "Use AT_EXPAND() for type groups but not for individual types",
      "Verify the conversion by checking argument order and wrapping",
      "Keep the old Dispatch.h include until all code is migrated"
    ],
    "anti_patterns": [
      "Forgetting to wrap lambdas with AT_WRAP causes parsing errors",
      "Adding AT_EXPAND() to individual types breaks the macro",
      "Not including Dispatch_v2.h header before using AT_DISPATCH_V2",
      "Using the wrong type group mapping (e.g., FLOATING_TYPES for integral code)"
    ],
    "faq": [
      {
        "question": "What is the difference between AT_DISPATCH and AT_DISPATCH_V2?",
        "answer": "V2 removes arity from macro names, uses AT_EXPAND for type groups, and wraps lambdas with AT_WRAP for comma handling."
      },
      {
        "question": "Can I mix AT_DISPATCH and AT_DISPATCH_V2 in the same file?",
        "answer": "Yes, both macros can coexist. Keep the old Dispatch.h include until full migration is complete."
      },
      {
        "question": "What happens if I forget AT_WRAP?",
        "answer": "Lambdas with internal commas (like function calls or template arguments) will cause parsing errors without AT_WRAP."
      },
      {
        "question": "Is this skill safe to use with production code?",
        "answer": "Yes, the skill only provides conversion patterns. It does not modify files or execute code without your confirmation."
      },
      {
        "question": "Does this work for CUDA kernels?",
        "answer": "Yes, the conversion patterns apply to all ATen kernel files including CUDA implementations."
      },
      {
        "question": "What type groups are available in V2?",
        "answer": "AT_ALL_TYPES, AT_FLOATING_TYPES, AT_INTEGRAL_TYPES, AT_COMPLEX_TYPES, and their combinations with AT_EXPAND."
      }
    ]
  },
  "file_structure": [
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md"
    }
  ]
}
