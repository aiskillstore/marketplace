{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-06T04:24:06.792Z",
    "slug": "pytorch-at-dispatch-v2",
    "source_url": "https://github.com/pytorch/pytorch/tree/main/.claude/skills/at-dispatch-v2",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "2.0.0",
    "source_type": "community",
    "content_hash": "441e54058d3446fdc95d8b015f03b028e09ecd619f5431a38079177b50f14528",
    "tree_hash": "60ee9f7f18f13c3cebf03c2866952f641e59414917981b13012daaa53c5880ce"
  },
  "skill": {
    "name": "at-dispatch-v2",
    "description": "Convert PyTorch AT_DISPATCH macros to AT_DISPATCH_V2 format in ATen C++ code. Use when porting AT_DISPATCH_ALL_TYPES_AND*, AT_DISPATCH_FLOATING_TYPES*, or other dispatch macros to the new v2 API. For ATen kernel files, CUDA kernels, and native operator implementations.",
    "summary": "Convert PyTorch AT_DISPATCH macros to AT_DISPATCH_V2 format in ATen C++ code. Use when porting AT_DI...",
    "icon": "ðŸ”§",
    "version": "1.0.0",
    "author": "pytorch",
    "license": "MIT",
    "category": "coding",
    "tags": [
      "pytorch",
      "c++",
      "dispatch",
      "aten",
      "macro"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": []
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "This is a documentation-only skill that provides instructions for converting PyTorch AT_DISPATCH macros. It contains no executable code, no network access, no file system operations, and no environment variable access. The skill is purely informational and safe for users.",
    "risk_factor_evidence": [],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 1,
    "total_lines": 306,
    "audit_model": "claude",
    "audited_at": "2026-01-06T04:24:06.792Z"
  },
  "content": {
    "user_title": "Convert PyTorch AT_DISPATCH Macros to V2 Format",
    "value_statement": "PyTorch developers need to update legacy AT_DISPATCH macros to the new V2 format for better type composition and extensibility. This skill provides step-by-step instructions and examples for converting AT_DISPATCH_ALL_TYPES_AND*, AT_DISPATCH_FLOATING_TYPES*, and other dispatch macros to AT_DISPATCH_V2.",
    "seo_keywords": [
      "PyTorch",
      "AT_DISPATCH",
      "AT_DISPATCH_V2",
      "C++",
      "macro conversion",
      "ATen",
      "CUDA kernels",
      "Claude Code",
      "dispatch macros"
    ],
    "actual_capabilities": [
      "Converts AT_DISPATCH_ALL_TYPES_AND* macros to AT_DISPATCH_V2 format",
      "Transforms AT_DISPATCH_FLOATING_TYPES_AND* macros with proper syntax",
      "Handles complex multi-type dispatch patterns",
      "Provides step-by-step conversion instructions",
      "Includes examples for edge cases and common patterns"
    ],
    "limitations": [
      "Only works with PyTorch AT_DISPATCH macro conversions",
      "Requires manual application of transformations",
      "Does not compile or test converted code",
      "Limited to C++ ATen kernel implementations"
    ],
    "use_cases": [
      {
        "target_user": "PyTorch Core Developer",
        "title": "Update Legacy Dispatch Macros",
        "description": "Convert existing AT_DISPATCH macros in ATen kernels to use the new V2 API for better maintainability and extensibility."
      },
      {
        "target_user": "CUDA Kernel Developer",
        "title": "Port CUDA Kernels to V2",
        "description": "Update CUDA kernel implementations to use AT_DISPATCH_V2 for improved type handling and reduced macro complexity."
      },
      {
        "target_user": "PyTorch Contributor",
        "title": "Modernize Codebase",
        "description": "Help migrate PyTorch codebase from legacy dispatch macros to the modern V2 format during refactoring efforts."
      }
    ],
    "prompt_templates": [
      {
        "title": "Basic Conversion",
        "scenario": "Convert simple AT_DISPATCH macro",
        "prompt": "Convert this AT_DISPATCH_ALL_TYPES_AND2(kHalf, kBFloat16, dtype, \"kernel\", [&]() { /* code */ }); to AT_DISPATCH_V2 format"
      },
      {
        "title": "Complex Pattern",
        "scenario": "Handle multi-type dispatch",
        "prompt": "Transform AT_DISPATCH_ALL_TYPES_AND_COMPLEX_AND3(kHalf, kBFloat16, kBool, scalar_type, \"op\", lambda) to V2 syntax"
      },
      {
        "title": "Add Include",
        "scenario": "Add necessary header",
        "prompt": "Add #include <ATen/Dispatch_v2.h> to this file and convert all AT_DISPATCH macros to V2 format"
      },
      {
        "title": "Bulk Conversion",
        "scenario": "Convert multiple macros",
        "prompt": "Find all AT_DISPATCH macros in this file and convert them to AT_DISPATCH_V2 format with proper includes"
      }
    ],
    "output_examples": [
      {
        "input": "Convert AT_DISPATCH_FLOATING_TYPES_AND2(kHalf, kBFloat16, tensor.scalar_type(), \"float_op\", [&] { process<scalar_t>(tensor); });",
        "output": [
          "AT_DISPATCH_V2(tensor.scalar_type(), \"float_op\", AT_WRAP([&] {",
          "  process<scalar_t>(tensor);",
          "}), AT_EXPAND(AT_FLOATING_TYPES), kHalf, kBFloat16);"
        ]
      }
    ],
    "best_practices": [
      "Always wrap lambdas with AT_WRAP() to prevent comma parsing issues",
      "Use AT_EXPAND() for type groups but not for individual types",
      "Keep the original Dispatch.h include for compatibility with other code",
      "Verify argument order: scalar_type, name, lambda, type groups, individual types"
    ],
    "anti_patterns": [
      "Forgetting AT_WRAP() around lambdas with internal commas",
      "Using AT_EXPAND() on individual types like kHalf or kBFloat16",
      "Removing the original #include <ATen/Dispatch.h> include",
      "Incorrect argument ordering in AT_DISPATCH_V2 calls"
    ],
    "faq": [
      {
        "question": "Which PyTorch versions support AT_DISPATCH_V2?",
        "answer": "AT_DISPATCH_V2 is available in recent PyTorch versions. Check aten/src/ATen/Dispatch_v2.h for availability in your version."
      },
      {
        "question": "Do I need to remove the old Dispatch.h include?",
        "answer": "No, keep both includes. Other code in the file may still depend on the original Dispatch.h."
      },
      {
        "question": "Why is AT_WRAP() necessary?",
        "answer": "AT_WRAP() prevents comma parsing issues in complex lambdas that contain function calls with multiple parameters."
      },
      {
        "question": "Can I convert multiple macros at once?",
        "answer": "Yes, the skill can handle files with multiple AT_DISPATCH macros and convert them all systematically."
      },
      {
        "question": "What if my lambda has no captures?",
        "answer": "Use AT_WRAP([]() { ... }) instead of AT_WRAP([&]() { ... }) for lambdas without captures."
      },
      {
        "question": "Are there performance differences between V1 and V2?",
        "answer": "No, AT_DISPATCH_V2 provides the same performance with better syntax and extensibility."
      }
    ]
  },
  "file_structure": [
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md"
    }
  ]
}
