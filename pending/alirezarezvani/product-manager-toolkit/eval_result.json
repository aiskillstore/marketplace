{
  "skill": {
    "name": "product-manager-toolkit",
    "description": "Comprehensive toolkit for product managers including RICE prioritization, customer interview analysis, PRD templates, discovery frameworks, and go-to-market strategies. Use for feature prioritization, user research synthesis, requirement documentation, and product strategy development.",
    "summary": "Product management toolkit with RICE prioritization, interview analysis, and PRD templates",
    "icon": "ðŸ“¦",
    "version": "1.0.0",
    "author": "Community",
    "license": "MIT",
    "category": "productivity",
    "tags": ["prioritization", "rice", "prd", "interview-analysis"],
    "supported_tools": ["claude", "codex", "claude-code"]
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "All 70 static findings are FALSE POSITIVES. The scanner misidentified markdown documentation syntax, business terminology (TAM/SAM), and security best-practice references as security threats. This is a legitimate product management skill with no malicious code, network calls, credential access, or data exfiltration patterns.",
    "static_findings_evaluation": [
      {
        "finding": "[MEDIUM] external_commands: Ruby/shell backtick execution at references/prd_templates.md:65",
        "verdict": "false_positive",
        "confidence": "high",
        "reasoning": "Line 65 is a markdown code block showing user story template format (```). Backticks are markdown syntax for code blocks, not shell execution. No subprocess or os.system calls exist."
      },
      {
        "finding": "[MEDIUM] external_commands: Ruby/shell backtick execution at references/prd_templates.md:74",
        "verdict": "false_positive",
        "confidence": "high",
        "reasoning": "Same code block as line 65. Checklist syntax (- [ ]) is markdown, not shell commands. No actual code execution occurs."
      },
      {
        "finding": "[MEDIUM] external_commands: Ruby/shell backtick execution at references/prd_templates.md:268",
        "verdict": "false_positive",
        "confidence": "high",
        "reasoning": "Markdown code block (```) showing user flow diagram with arrows. Documentation syntax only, no shell commands or execution."
      },
      {
        "finding": "[CRITICAL] sensitive: Windows SAM database at references/prd_templates.md:27",
        "verdict": "false_positive",
        "confidence": "high",
        "reasoning": "Line 27 in prd_templates.md contains 'TAM, SAM, SOM' - Total/Serviceable/Obtainable Available Market business metrics. Scanner confused business terminology with Windows security database. No sensitive system files referenced."
      },
      {
        "finding": "[HIGH] blocker: Weak cryptographic algorithm at references/prd_templates.md:41",
        "verdict": "false_positive",
        "confidence": "high",
        "reasoning": "Line 41 discusses 'Key Capabilities' in a PRD template. Scanner detected word 'Key' as cryptographic reference. No encryption code or weak algorithms exist. Documentation only."
      },
      {
        "finding": "[HIGH] blocker: Weak cryptographic algorithm at references/prd_templates.md:47-49, 91, 93-96, 116, 122, 166, 176, 205, 277, 284, 315",
        "verdict": "false_positive",
        "confidence": "high",
        "reasoning": "All references are PRD template sections discussing security best practices (authentication, encryption, data protection). No actual cryptographic algorithms or weak encryption code exists in the repository."
      },
      {
        "finding": "[HIGH] blocker: Weak cryptographic algorithm at SKILL.md:3, 102, 159, 331",
        "verdict": "false_positive",
        "confidence": "high",
        "reasoning": "SKILL.md contains feature names and documentation. No cryptographic code. Scanner triggered on words like 'Key', 'Secure', 'Token' in documentation context."
      },
      {
        "finding": "[MEDIUM] external_commands: Ruby/shell backtick execution at SKILL.md:13, 16, 19, 21, 24, 40, 43, 67, 69, 119, 128, 143, 149, 179, 194, 197, 205, 216, 236, 239, 244, 247, 255, 266, 274, 338",
        "verdict": "false_positive",
        "confidence": "high",
        "reasoning": "All occurrences are bash command examples in markdown code blocks (```bash). These are documentation showing CLI usage, not actual subprocess calls. No subprocess or os.system in the actual Python scripts."
      },
      {
        "finding": "[LOW] network: HTTP client library at scripts/customer_interview_analyzer.py:118, 281",
        "verdict": "false_positive",
        "confidence": "high",
        "reasoning": "Lines 116-118 and 281 show regex patterns (re module) for NLP analysis. No urllib, requests, or HTTP calls exist. Script processes local text files only."
      },
      {
        "finding": "[LOW] network: Python HTTP libraries at scripts/customer_interview_analyzer.py:116",
        "verdict": "false_positive",
        "confidence": "high",
        "reasoning": "Line 116 is import re (regex). No HTTP libraries imported. Script has no network capability."
      },
      {
        "finding": "[HIGH] filesystem: Path traversal sequence at scripts/customer_interview_analyzer.py:382",
        "verdict": "false_positive",
        "confidence": "high",
        "reasoning": "Line 382 is within output formatting, not file operations. The '../' pattern appears in NLP regex (line 40) for Jobs-to-be-Done pattern matching: 'when i + want to + so that'. This is text analysis, not file system access."
      },
      {
        "finding": "[HIGH] sensitive: Certificate/key files at scripts/rice_prioritizer.py:288",
        "verdict": "false_positive",
        "confidence": "high",
        "reasoning": "Line 288 is CSV output formatting: print(','.join(keys)). Scanner triggered on 'keys' as cryptographic term. No certificate or key files accessed."
      },
      {
        "finding": "[MEDIUM] filesystem: Python file write/append at scripts/rice_prioritizer.py:240",
        "verdict": "false_positive",
        "confidence": "high",
        "reasoning": "Line 240 is create_sample_csv() writing a local sample CSV file. This is expected behavior for the rice_prioritizer tool to generate sample data. Safe, documented file operation."
      },
      {
        "finding": "[CRITICAL] obfuscation: [HEURISTIC] DANGEROUS COMBINATION: Code execution + Network + Credential access at multiple:1",
        "verdict": "false_positive",
        "confidence": "high",
        "reasoning": "Heuristic triggered on CLI tool pattern. Script reads interview transcripts, performs NLP analysis, outputs text/JSON. No network calls, no credentials, no obfuscation. False positive based on static analysis noise."
      },
      {
        "finding": "[HIGH] obfuscation: [HEURISTIC] SUSPICIOUS COMBINATION: Filesystem + Credentials + Network at multiple:1",
        "verdict": "false_positive",
        "confidence": "high",
        "reasoning": "False positive heuristic. Script processes local files (CSV, text), outputs results. No credentials accessed, no network calls, no data exfiltration. Standard file I/O for data processing tool."
      },
      {
        "finding": "[LOW] blocker: System reconnaissance at SKILL.md:304, 317",
        "verdict": "false_positive",
        "confidence": "high",
        "reasoning": "Line 304 in SKILL.md: 'Interview in their environment' is customer discovery advice. Line 317 is section title 'Common Pitfalls to Avoid'. No system reconnaissance code exists."
      }
    ],
    "risk_factor_evidence": [
      {
        "factor": "scripts",
        "evidence": [
          {"file": "scripts/rice_prioritizer.py", "line_start": 1, "line_end": 296},
          {"file": "scripts/customer_interview_analyzer.py", "line_start": 1, "line_end": 441}
        ]
      }
    ],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 4,
    "total_lines": 1409
  },
  "content": {
    "user_title": "Prioritize features with RICE framework",
    "value_statement": "Product managers struggle to prioritize competing feature requests objectively. This toolkit provides RICE prioritization, customer interview analysis, and PRD templates to make data-driven decisions.",
    "seo_keywords": [
      "product manager toolkit",
      "RICE prioritization",
      "feature prioritization",
      "customer interview analysis",
      "Claude Code",
      "Claude",
      "product requirements document",
      "PRD template",
      "product management",
      "user research"
    ],
    "actual_capabilities": [
      "Calculate RICE scores for features using the proven Reach x Impact x Confidence / Effort formula",
      "Analyze customer interview transcripts to extract pain points, feature requests, and sentiment",
      "Generate quarterly roadmaps with capacity planning across multiple quarters",
      "Create professional PRDs using templates for standard, one-page, agile epic, and feature brief formats",
      "Identify quick wins and big bets in feature portfolio for balanced prioritization"
    ],
    "limitations": [
      "Does not integrate with external tools like Jira, Linear, or Figma - outputs are local files",
      "Interview analysis is keyword-based NLP, not AI-powered semantic understanding",
      "RICE scores require manual input for reach, impact, confidence, and effort values"
    ],
    "use_cases": [
      {
        "target_user": "Product Managers",
        "title": "Prioritize feature backlog",
        "description": "Score and rank feature requests using RICE to build quarterly roadmaps"
      },
      {
        "target_user": "UX Researchers",
        "title": "Analyze interview transcripts",
        "description": "Extract pain points, themes, and feature requests from customer interviews"
      },
      {
        "target_user": "Startup Founders",
        "title": "Document product requirements",
        "description": "Create professional PRDs to align engineering and design teams"
      }
    ],
    "prompt_templates": [
      {
        "title": "Prioritize feature list",
        "scenario": "Create sample data and run prioritization",
        "prompt": "Use the rice_prioritizer to create sample_features.csv then prioritize with capacity of 20 person-months"
      },
      {
        "title": "Analyze customer interview",
        "scenario": "Extract insights from transcript",
        "prompt": "Analyze the interview_transcript.txt using customer_interview_analyzer and output as JSON"
      },
      {
        "title": "Compare feature trade-offs",
        "scenario": "Portfolio balance analysis",
        "prompt": "Run rice_prioritizer on features.csv and identify the quick wins versus big bets"
      },
      {
        "title": "Generate quarterly roadmap",
        "scenario": "Multi-quarter capacity planning",
        "prompt": "Use rice_prioritizer with --capacity 15 to generate a quarterly roadmap for the prioritized features"
      }
    ],
    "output_examples": [
      {
        "input": "Create sample CSV and run RICE prioritization",
        "output": [
          "Top Prioritized Feature: Onboarding Flow (RICE: 7628.57)",
          "Quick Wins Identified: Dark Mode, API Rate Limiting",
          "Big Bets Identified: Team Collaboration, User Dashboard Redesign",
          "Quarter 1 Roadmap: 5 features using 11/15 person-months capacity"
        ]
      },
      {
        "input": "Analyze customer interview transcript",
        "output": [
          "Overall Sentiment: NEGATIVE (score: -0.33)",
          "Top Pain Point: 'frustrated' - 'waste of time doing manually'",
          "Key Theme: onboarding, workflow, integration",
          "Feature Request: 'would be nice to have' - 'automated workflow' (priority: medium)"
        ]
      }
    ],
    "best_practices": [
      "Update RICE scores quarterly as confidence and reach data improves",
      "Combine RICE with strategic alignment - high score does not always mean right priority",
      "Validate interview analysis with multiple transcripts before making major decisions"
    ],
    "anti_patterns": [
      "Using RICE without considering dependencies between features",
      "Analyzing single interviews for major product decisions",
      "Ignoring quick wins in favor of only big bets"
    ],
    "faq": [
      {
        "question": "What input format does rice_prioritizer expect?",
        "answer": "CSV with columns: name, reach, impact, confidence, effort, description. Impact uses massive/high/medium/low/minimal."
      },
      {
        "question": "Can I customize the RICE scoring formula?",
        "answer": "The formula is fixed (Reach x Impact x Confidence / Effort) but impact multipliers are configurable in the code."
      },
      {
        "question": "What NLP patterns does the interview analyzer detect?",
        "answer": "Pain indicators, delight indicators, feature request phrases, Jobs-to-be-Done patterns, and competitor mentions."
      },
      {
        "question": "How many interviews should I analyze?",
        "answer": "For reliable patterns, analyze at least 5-10 interviews. The tool aggregates across multiple files."
      },
      {
        "question": "Can I export results to Jira or Linear?",
        "answer": "Export as JSON or CSV, then import. No direct integration exists. Manual mapping required."
      },
      {
        "question": "What RICE confidence levels map to percentages?",
        "answer": "High = 100%, Medium = 80%, Low = 50%. These are configurable in the script."
      }
    ]
  }
}
