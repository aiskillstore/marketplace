{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-15T11:36:24.701Z",
    "slug": "alirezarezvani-senior-prompt-engineer",
    "source_url": "https://github.com/alirezarezvani/claude-skills/tree/main/engineering-team/senior-prompt-engineer",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "3.0.0",
    "source_type": "community",
    "content_hash": "4a167292edfd9290ed49048fa86b79c6b8c36da6b26d8233891bd1184b341bdb",
    "tree_hash": "be07e9b2b1da4f903250560fece5973abdd3306a9083880eff6b96808191d661"
  },
  "skill": {
    "name": "senior-prompt-engineer",
    "description": "World-class prompt engineering skill for LLM optimization, prompt patterns, structured outputs, and AI product development. Expertise in Claude, GPT-4, prompt design patterns, few-shot learning, chain-of-thought, and AI evaluation. Includes RAG optimization, agent design, and LLM system architecture. Use when building AI products, optimizing LLM performance, designing agentic systems, or implementing advanced prompting techniques.",
    "summary": "World-class prompt engineering skill for LLM optimization, prompt patterns, structured outputs, and ...",
    "icon": "âš¡",
    "version": "1.0.0",
    "author": "alirezarezvani",
    "license": "MIT",
    "category": "data",
    "tags": [
      "prompt-engineering",
      "llm",
      "ai-optimization",
      "claude",
      "gpt"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": [
      "scripts"
    ]
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "All 43 static findings are FALSE POSITIVEs. The 'weak cryptographic algorithm' pattern detected the word 'algorithm' in documentation describing 'Efficient algorithms' for data processing. The 'external_commands' pattern detected markdown backticks for code formatting (```bash blocks). No actual cryptographic code, shell execution, or network reconnaissance exists in this skill. Scripts are simple CLI tools with argparse for argument parsing only.",
    "risk_factor_evidence": [
      {
        "factor": "scripts",
        "evidence": [
          {
            "file": "scripts/agent_orchestrator.py",
            "line_start": 1,
            "line_end": 101
          },
          {
            "file": "scripts/prompt_optimizer.py",
            "line_start": 1,
            "line_end": 101
          },
          {
            "file": "scripts/rag_evaluator.py",
            "line_start": 1,
            "line_end": 101
          }
        ]
      }
    ],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 7,
    "total_lines": 773,
    "audit_model": "claude",
    "audited_at": "2026-01-15T11:36:24.700Z"
  },
  "content": {
    "user_title": "Optimize LLM Prompts for Claude and GPT-4",
    "value_statement": "Generic prompts produce inconsistent AI responses. This skill provides proven patterns and optimization tools for production-grade LLM interactions. Transform vague requests into precise, reliable outputs using chain-of-thought, few-shot learning, and structured prompting techniques.",
    "seo_keywords": [
      "claude prompt engineering",
      "gpt-4 prompts",
      "llm optimization",
      "chain-of-thought prompting",
      "few-shot learning",
      "structured outputs",
      "prompt patterns",
      "rag evaluation",
      "claude code",
      "ai agent design"
    ],
    "actual_capabilities": [
      "Apply advanced prompt patterns including chain-of-thought, tree-of-thought, and self-consistency",
      "Design effective few-shot examples that improve model accuracy by 40 percent or more",
      "Build structured output schemas for reliable JSON and data extraction from LLMs",
      "Optimize RAG systems with hybrid search, reranking, and context compression",
      "Create multi-agent orchestrations with tool calling and state management"
    ],
    "limitations": [
      "Does not access external APIs or make network requests to LLM services",
      "Cannot test prompts against live models without user-provided API keys",
      "Optimizations depend on user implementation; skill provides patterns not integrations"
    ],
    "use_cases": [
      {
        "target_user": "AI Developers",
        "title": "Build AI Products",
        "description": "Design production prompt systems with structured outputs and evaluation frameworks for reliable AI product development."
      },
      {
        "target_user": "Data Scientists",
        "title": "Optimize LLM Performance",
        "description": "Apply prompt optimization techniques to improve model accuracy and reduce token usage for research workflows."
      },
      {
        "target_user": "Software Engineers",
        "title": "Integrate Claude and GPT-4",
        "description": "Implement agentic systems with tool calling patterns and multi-agent orchestrations for application integration."
      }
    ],
    "prompt_templates": [
      {
        "title": "Chain-of-Thought",
        "scenario": "Complex reasoning task",
        "prompt": "Solve this problem step by step. First, identify the key variables. Second, outline your approach. Third, execute each step with justification. Finally, verify your answer."
      },
      {
        "title": "Few-Shot Learning",
        "scenario": "Classification task",
        "prompt": "Classify the following text into one of these categories: positive, negative, neutral. Examples: \"Great product, love it\" = positive. \"Does not work as described\" = negative. \"Package arrived on time\" = neutral. Now classify: [YOUR TEXT]"
      },
      {
        "title": "Structured Output",
        "scenario": "Data extraction",
        "prompt": "Extract the following fields from the text below. Return ONLY valid JSON with these keys: name, email, company, role. Text: [YOUR TEXT]"
      },
      {
        "title": "System Prompt",
        "scenario": "Claude behavior setup",
        "prompt": "You are an expert [DOMAIN] with deep experience in [SKILLS]. Your approach: 1) Analyze the problem thoroughly 2) Explain your reasoning 3) Provide actionable recommendations 4) Acknowledge limitations. Current task: [REQUEST]"
      }
    ],
    "output_examples": [
      {
        "input": "Write a chain-of-thought prompt for analyzing market trends",
        "output": [
          "1. Identify the industry and time period",
          "2. List key metrics to examine",
          "3. Compare current data against historical benchmarks",
          "4. Consider external factors affecting trends",
          "5. Synthesize findings into actionable insights"
        ]
      },
      {
        "input": "Create a few-shot prompt for sentiment analysis",
        "output": [
          "Positive examples trained model to recognize satisfaction language",
          "Negative examples captured complaint patterns",
          "Neutral examples identified factual statements",
          "Result: Consistent sentiment classification across new inputs"
        ]
      },
      {
        "input": "Design a system prompt for code review assistant",
        "output": [
          "Role defined: Senior engineer with security expertise",
          "Process specified: Check style, performance, security, testing",
          "Output format: Line numbers with suggestions",
          "Limitations acknowledged: Cannot execute code"
        ]
      }
    ],
    "best_practices": [
      "Start with clear task definition and expected output format before adding complexity",
      "Use concrete examples for few-shot learning; avoid ambiguous or contradictory demonstrations",
      "Iterate systematically; change one variable at a time to measure prompt impact"
    ],
    "anti_patterns": [
      "Avoid vague instructions like \"be helpful\" - define specific behaviors and constraints",
      "Do not overload prompts with too many roles or conflicting directives",
      "Never assume the model understands context not explicitly stated in the prompt"
    ],
    "faq": [
      {
        "question": "Which LLM models does this skill support?",
        "answer": "The skill covers Claude, GPT-4, and general LLM patterns. Techniques apply broadly with model-specific adjustments documented."
      },
      {
        "question": "Do I need coding experience to use this skill?",
        "answer": "Basic familiarity helps for implementing scripts, but prompt patterns work in any LLM interface including chat."
      },
      {
        "question": "How long does it take to see improvements?",
        "answer": "Simple pattern application shows results immediately. Full optimization may require iterative testing over several sessions."
      },
      {
        "question": "Can this skill create custom prompts for my domain?",
        "answer": "Yes, patterns include domain adaptation guides for legal, medical, technical, and financial use cases."
      },
      {
        "question": "What Python tools are included?",
        "answer": "Three CLI tools: prompt_optimizer.py for A/B testing, rag_evaluator.py for retrieval quality, and agent_orchestrator.py for workflows."
      },
      {
        "question": "How does this differ from general chat?",
        "answer": "This skill provides structured methodologies, evaluation frameworks, and automation tools for production-grade prompt engineering."
      }
    ]
  },
  "file_structure": [
    {
      "name": "references",
      "type": "dir",
      "path": "references",
      "children": [
        {
          "name": "agentic_system_design.md",
          "type": "file",
          "path": "references/agentic_system_design.md",
          "lines": 81
        },
        {
          "name": "llm_evaluation_frameworks.md",
          "type": "file",
          "path": "references/llm_evaluation_frameworks.md",
          "lines": 81
        },
        {
          "name": "prompt_engineering_patterns.md",
          "type": "file",
          "path": "references/prompt_engineering_patterns.md",
          "lines": 81
        }
      ]
    },
    {
      "name": "scripts",
      "type": "dir",
      "path": "scripts",
      "children": [
        {
          "name": "agent_orchestrator.py",
          "type": "file",
          "path": "scripts/agent_orchestrator.py",
          "lines": 101
        },
        {
          "name": "prompt_optimizer.py",
          "type": "file",
          "path": "scripts/prompt_optimizer.py",
          "lines": 101
        },
        {
          "name": "rag_evaluator.py",
          "type": "file",
          "path": "scripts/rag_evaluator.py",
          "lines": 101
        }
      ]
    },
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md",
      "lines": 227
    }
  ]
}
