{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-15T11:58:36.907Z",
    "slug": "alirezarezvani-senior-ml-engineer",
    "source_url": "https://github.com/alirezarezvani/claude-skills/tree/main/engineering-team/senior-ml-engineer",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "3.0.0",
    "source_type": "community",
    "content_hash": "05955e286d61b9d7729d3feb5e628661c72fd7e4b67f5e0a04d65878757eb2e0",
    "tree_hash": "288fe4679e434a07a535c7bf89ec9f253b067d7011f1d2dc61670c0920d9db15"
  },
  "skill": {
    "name": "senior-ml-engineer",
    "description": "World-class ML engineering skill for productionizing ML models, MLOps, and building scalable ML systems. Expertise in PyTorch, TensorFlow, model deployment, feature stores, model monitoring, and ML infrastructure. Includes LLM integration, fine-tuning, RAG systems, and agentic AI. Use when deploying ML models, building ML platforms, implementing MLOps, or integrating LLMs into production systems.",
    "summary": "World-class ML engineering skill for productionizing ML models, MLOps, and building scalable ML syst...",
    "icon": "ðŸ“¦",
    "version": "1.0.0",
    "author": "alirezarezvani",
    "license": "MIT",
    "tags": [
      "senior-ml-engineer",
      "ai",
      "skill",
      "claude"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": [
      "external_commands"
    ]
  },
  "security_audit": {
    "risk_level": "medium",
    "is_blocked": false,
    "safe_to_publish": false,
    "summary": "AI analysis failed after multiple attempts - MANUAL REVIEW REQUIRED before publishing. This skill cannot be auto-published until reviewed by a human.",
    "risk_factor_evidence": [
      {
        "factor": "external_commands",
        "evidence": [
          {
            "file": "SKILL.md",
            "line_start": 14,
            "line_end": 23
          },
          {
            "file": "SKILL.md",
            "line_start": 23,
            "line_end": 54
          },
          {
            "file": "SKILL.md",
            "line_start": 54,
            "line_end": 65
          },
          {
            "file": "SKILL.md",
            "line_start": 65,
            "line_end": 75
          },
          {
            "file": "SKILL.md",
            "line_start": 75,
            "line_end": 167
          },
          {
            "file": "SKILL.md",
            "line_start": 167,
            "line_end": 185
          },
          {
            "file": "SKILL.md",
            "line_start": 185,
            "line_end": 189
          },
          {
            "file": "SKILL.md",
            "line_start": 189,
            "line_end": 190
          },
          {
            "file": "SKILL.md",
            "line_start": 190,
            "line_end": 191
          },
          {
            "file": "SKILL.md",
            "line_start": 191,
            "line_end": 192
          }
        ]
      }
    ],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [
      {
        "title": "Weak cryptographic algorithm",
        "description": "Weak cryptographic algorithm detected in code",
        "locations": [
          {
            "file": "references/llm_integration_guide.md",
            "line_start": 9,
            "line_end": 9
          },
          {
            "file": "references/llm_integration_guide.md",
            "line_start": 11,
            "line_end": 11
          },
          {
            "file": "references/llm_integration_guide.md",
            "line_start": 17,
            "line_end": 17
          },
          {
            "file": "references/llm_integration_guide.md",
            "line_start": 62,
            "line_end": 62
          },
          {
            "file": "references/mlops_production_patterns.md",
            "line_start": 9,
            "line_end": 9
          },
          {
            "file": "references/mlops_production_patterns.md",
            "line_start": 11,
            "line_end": 11
          },
          {
            "file": "references/mlops_production_patterns.md",
            "line_start": 17,
            "line_end": 17
          },
          {
            "file": "references/mlops_production_patterns.md",
            "line_start": 62,
            "line_end": 62
          },
          {
            "file": "references/rag_system_architecture.md",
            "line_start": 9,
            "line_end": 9
          },
          {
            "file": "references/rag_system_architecture.md",
            "line_start": 11,
            "line_end": 11
          },
          {
            "file": "references/rag_system_architecture.md",
            "line_start": 17,
            "line_end": 17
          },
          {
            "file": "references/rag_system_architecture.md",
            "line_start": 62,
            "line_end": 62
          },
          {
            "file": "scripts/ml_monitoring_suite.py",
            "line_start": 71,
            "line_end": 71
          },
          {
            "file": "scripts/model_deployment_pipeline.py",
            "line_start": 71,
            "line_end": 71
          },
          {
            "file": "scripts/rag_system_builder.py",
            "line_start": 71,
            "line_end": 71
          },
          {
            "file": "SKILL.md",
            "line_start": 3,
            "line_end": 3
          },
          {
            "file": "SKILL.md",
            "line_start": 3,
            "line_end": 3
          },
          {
            "file": "SKILL.md",
            "line_start": 30,
            "line_end": 30
          },
          {
            "file": "SKILL.md",
            "line_start": 68,
            "line_end": 68
          },
          {
            "file": "SKILL.md",
            "line_start": 69,
            "line_end": 69
          },
          {
            "file": "SKILL.md",
            "line_start": 77,
            "line_end": 77
          },
          {
            "file": "SKILL.md",
            "line_start": 90,
            "line_end": 90
          }
        ]
      },
      {
        "title": "Network reconnaissance",
        "description": "Network reconnaissance detected in code",
        "locations": [
          {
            "file": "references/llm_integration_guide.md",
            "line_start": 21,
            "line_end": 22
          },
          {
            "file": "references/mlops_production_patterns.md",
            "line_start": 21,
            "line_end": 22
          },
          {
            "file": "references/rag_system_architecture.md",
            "line_start": 21,
            "line_end": 22
          }
        ]
      },
      {
        "title": "Ruby/shell backtick execution",
        "description": "Ruby/shell backtick execution detected in code",
        "locations": [
          {
            "file": "SKILL.md",
            "line_start": 14,
            "line_end": 23
          },
          {
            "file": "SKILL.md",
            "line_start": 23,
            "line_end": 54
          },
          {
            "file": "SKILL.md",
            "line_start": 54,
            "line_end": 65
          },
          {
            "file": "SKILL.md",
            "line_start": 65,
            "line_end": 75
          },
          {
            "file": "SKILL.md",
            "line_start": 75,
            "line_end": 167
          },
          {
            "file": "SKILL.md",
            "line_start": 167,
            "line_end": 185
          },
          {
            "file": "SKILL.md",
            "line_start": 185,
            "line_end": 189
          },
          {
            "file": "SKILL.md",
            "line_start": 189,
            "line_end": 190
          },
          {
            "file": "SKILL.md",
            "line_start": 190,
            "line_end": 191
          },
          {
            "file": "SKILL.md",
            "line_start": 191,
            "line_end": 192
          }
        ]
      }
    ],
    "files_scanned": 7,
    "total_lines": 773,
    "audit_model": "claude",
    "audited_at": "2026-01-15T11:58:36.907Z"
  },
  "content": {
    "user_title": "Senior Ml Engineer",
    "value_statement": "An AI skill for Claude, Codex, and Claude Code",
    "seo_keywords": [
      "senior-ml-engineer",
      "ai",
      "skill",
      "claude"
    ],
    "actual_capabilities": [
      "Production ML model deployment with PyTorch, TensorFlow, and Scikit-learn",
      "MLOps pipeline automation using Airflow, MLflow, and Kubernetes",
      "Scalable data processing with Spark, Kafka, and Databricks",
      "LLM integration using LangChain, LlamaIndex, and DSPy frameworks",
      "RAG system architecture and implementation",
      "Feature store design and model monitoring",
      "Real-time inference systems with batching and caching",
      "Distributed computing and horizontal scaling architecture",
      "Model A/B testing and drift detection",
      "Cloud deployment on AWS, GCP, and Azure"
    ],
    "limitations": [
      "Requires existing ML models or training data to deploy",
      "Cloud infrastructure costs can be significant at scale",
      "Performance targets may require substantial compute resources",
      "Complex distributed systems require DevOps expertise",
      "Security and compliance implementation varies by regulatory requirements"
    ],
    "use_cases": [
      {
        "title": "Deploy ML Model to Production",
        "description": "Deploy trained machine learning models with low-latency serving, A/B testing infrastructure, and automated monitoring for drift detection",
        "target_user": "ML Engineers deploying models to production environments"
      },
      {
        "title": "Build RAG System",
        "description": "Implement retrieval-augmented generation systems with vector databases, embedding pipelines, and LLM integration for context-aware AI applications",
        "target_user": "AI Engineers building LLM-powered applications"
      },
      {
        "title": "Set Up MLOps Pipeline",
        "description": "Create end-to-end MLOps infrastructure with automated training, testing, deployment, and monitoring using industry-standard tools",
        "target_user": "Data Scientists and ML Teams scaling their workflows"
      }
    ],
    "prompt_templates": [
      {
        "title": "Deploy PyTorch Model",
        "prompt": "Help me deploy my PyTorch model to production with Docker and Kubernetes. The model needs to handle 1000 requests/second with P95 latency under 100ms. Include monitoring and auto-scaling.",
        "scenario": "Production model deployment with performance requirements"
      },
      {
        "title": "Build RAG System",
        "prompt": "Build a RAG system for our documentation using Pinecone vector database and OpenAI embeddings. Include document chunking, semantic search, and LLM response generation.",
        "scenario": "Implementing retrieval-augmented generation for knowledge base"
      },
      {
        "title": "Set Up Model Monitoring",
        "prompt": "Set up comprehensive model monitoring with drift detection, performance metrics, and alerting using MLflow and Prometheus. Alert on accuracy drops or prediction drift.",
        "scenario": "Monitoring ML models in production"
      }
    ],
    "output_examples": [
      {
        "input": "Deploy my trained sentiment analysis model to production",
        "output": "I'll help you deploy your sentiment analysis model to production. Here's the deployment pipeline:\n\n1. Model Serving: FastAPI service with batching\n2. Containerization: Docker with optimized Python runtime\n3. Orchestration: Kubernetes deployment with HPA\n4. Monitoring: Prometheus metrics + Grafana dashboards\n5. CI/CD: Automated testing and canary deployments\n\nI'll create the deployment scripts and configuration files."
      },
      {
        "input": "Build a RAG system for customer support documentation",
        "output": "I'll build a RAG system for your customer support docs:\n\n1. Document Processing: Chunk docs into semantic segments\n2. Embeddings: Generate vectors using sentence-transformers\n3. Vector Store: Pinecone for similarity search\n4. Retrieval: Top-k relevant chunks for context\n5. Generation: LLM response with retrieved context\n6. Monitoring: Track retrieval quality and response accuracy\n\nLet me create the implementation using the rag_system_builder.py script."
      }
    ],
    "best_practices": [
      "Implement comprehensive monitoring for model performance, latency, and drift detection",
      "Use feature stores to ensure consistency between training and inference",
      "Deploy models with A/B testing and canary releases to minimize risk",
      "Automate model retraining pipelines with data quality validation",
      "Implement proper authentication, authorization, and data encryption for production systems",
      "Use horizontal scaling and load balancing for high-throughput requirements",
      "Monitor and optimize costs across compute, storage, and API usage",
      "Document architecture decisions and maintain runbooks for incident response",
      "Test models thoroughly with unit tests, integration tests, and performance benchmarks",
      "Version control everything including code, models, data schemas, and configurations"
    ],
    "anti_patterns": [
      "Deploying models without proper monitoring or drift detection",
      "Skipping A/B testing and deploying directly to all production traffic",
      "Using different feature engineering logic in training vs inference",
      "Ignoring model versioning and reproducibility requirements",
      "Hardcoding credentials or sensitive data in code or containers",
      "Running production models without autoscaling or load balancing",
      "Neglecting security reviews and compliance requirements",
      "Deploying without proper error handling and fallback mechanisms",
      "Ignoring latency requirements and SLA commitments",
      "Building custom infrastructure instead of leveraging managed services when appropriate"
    ],
    "faq": [
      {
        "question": "What ML frameworks are supported?",
        "answer": "This skill supports PyTorch, TensorFlow, Scikit-learn, and XGBoost for model training and deployment. It also includes support for LLM frameworks like LangChain, LlamaIndex, and DSPy."
      },
      {
        "question": "How do I deploy models to production?",
        "answer": "Use the model_deployment_pipeline.py script to containerize your model with Docker, deploy to Kubernetes with autoscaling, and set up monitoring. The skill includes best practices for A/B testing, canary deployments, and drift detection."
      },
      {
        "question": "What cloud platforms are supported?",
        "answer": "The skill supports AWS, GCP, and Azure with infrastructure-as-code templates. It includes deployment patterns for managed services like SageMaker, Vertex AI, and Azure ML."
      },
      {
        "question": "How do I build a RAG system?",
        "answer": "Use the rag_system_builder.py script which implements document chunking, embedding generation, vector database integration (Pinecone, Weaviate), and LLM response generation. Reference the rag_system_architecture.md guide for architecture patterns."
      },
      {
        "question": "What performance can I expect?",
        "answer": "Target performance: P50 latency < 50ms, P95 < 100ms, P99 < 200ms with >1000 requests/second throughput. Actual performance depends on model complexity, infrastructure, and optimization."
      }
    ]
  },
  "file_structure": [
    {
      "name": "references",
      "type": "dir",
      "path": "references",
      "children": [
        {
          "name": "llm_integration_guide.md",
          "type": "file",
          "path": "references/llm_integration_guide.md",
          "lines": 81
        },
        {
          "name": "mlops_production_patterns.md",
          "type": "file",
          "path": "references/mlops_production_patterns.md",
          "lines": 81
        },
        {
          "name": "rag_system_architecture.md",
          "type": "file",
          "path": "references/rag_system_architecture.md",
          "lines": 81
        }
      ]
    },
    {
      "name": "scripts",
      "type": "dir",
      "path": "scripts",
      "children": [
        {
          "name": "ml_monitoring_suite.py",
          "type": "file",
          "path": "scripts/ml_monitoring_suite.py",
          "lines": 101
        },
        {
          "name": "model_deployment_pipeline.py",
          "type": "file",
          "path": "scripts/model_deployment_pipeline.py",
          "lines": 101
        },
        {
          "name": "rag_system_builder.py",
          "type": "file",
          "path": "scripts/rag_system_builder.py",
          "lines": 101
        }
      ]
    },
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md",
      "lines": 227
    }
  ]
}
