{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-10T13:30:07.235Z",
    "slug": "dnyoussef-agentdb-vector-search-optimization",
    "source_url": "https://github.com/DNYoussef/ai-chrome-extension/tree/main/.claude/skills/agentdb/when-optimizing-vector-search-use-agentdb-optimization",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "2.0.0",
    "source_type": "community",
    "content_hash": "6e5184c270992167de4a7a54515e89f0ee648e5d6c11bac35f9c3fc6e6cddd62",
    "tree_hash": "40e19ea13053884c100a214d85866ff2ebbc1b8f43bf4c5c33e0c4e9a96695af"
  },
  "skill": {
    "name": "AgentDB Vector Search Optimization",
    "description": "Optimize AgentDB performance with quantization (4-32x memory reduction), HNSW indexing (150x faster search), caching, and batch operations for scaling to millions of vectors.",
    "summary": "Optimize AgentDB performance with quantization (4-32x memory reduction), HNSW indexing (150x faster ...",
    "icon": "ðŸš€",
    "version": "1.0.0",
    "author": "DNYoussef",
    "license": "MIT",
    "category": "agentdb",
    "tags": [
      "agentdb",
      "optimization",
      "vector-search",
      "quantization",
      "performance"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": []
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "Documentation-only skill containing process guides and code examples. No executable code, network calls, file system access, or external commands detected. Purely educational content about vector database optimization techniques.",
    "risk_factor_evidence": [],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 4,
    "total_lines": 250,
    "audit_model": "claude",
    "audited_at": "2026-01-10T13:30:07.235Z"
  },
  "content": {
    "user_title": "Optimize AgentDB vector search performance",
    "value_statement": "Vector search becomes slow and memory-intensive at scale. This skill provides a systematic 5-phase approach to achieve 4-32x memory reduction and 150x faster search using quantization, HNSW indexing, and intelligent caching.",
    "seo_keywords": [
      "AgentDB optimization",
      "vector search",
      "quantization",
      "HNSW indexing",
      "Claude Code",
      "Claude",
      "Codex",
      "performance tuning",
      "vector database",
      "embedding search"
    ],
    "actual_capabilities": [
      "Measure baseline performance metrics (latency, throughput, memory)",
      "Apply product/scalar/binary quantization for 4-32x memory reduction",
      "Implement HNSW indexing for 150x faster search speed",
      "Configure query caching with LRU and TTL eviction policies",
      "Validate accuracy above 95% after optimization",
      "Generate performance benchmarks comparing before and after results"
    ],
    "limitations": [
      "Requires AgentDB installation and basic familiarity with vector databases",
      "Accuracy trade-off: binary quantization at 32x compression may reduce precision",
      "HNSW index building requires memory overhead during construction phase",
      "Optimal parameters depend on specific dataset characteristics and require tuning"
    ],
    "use_cases": [
      {
        "target_user": "ML Engineers",
        "title": "Scale vector databases",
        "description": "Optimize production vector databases to handle millions of embeddings efficiently with reduced infrastructure costs."
      },
      {
        "target_user": "AI Application Developers",
        "title": "Speed up RAG systems",
        "description": "Accelerate retrieval-augmented generation systems with faster vector similarity search and caching layers."
      },
      {
        "target_user": "Data Infrastructure Teams",
        "title": "Reduce memory costs",
        "description": "Achieve significant memory reduction while maintaining search quality for large-scale vector workloads."
      }
    ],
    "prompt_templates": [
      {
        "title": "Quick Optimization",
        "scenario": "Start basic optimization",
        "prompt": "When optimizing vector search, apply quantization and HNSW indexing to reduce memory by 4x and speed up search by 10x."
      },
      {
        "title": "Measure Baseline",
        "scenario": "Establish performance baseline",
        "prompt": "When optimizing vector search, first measure baseline metrics including p95 latency, memory usage, and throughput for 1000 queries."
      },
      {
        "title": "Configure Quantization",
        "scenario": "Apply compression",
        "prompt": "When optimizing vector search, configure product quantization with codebook size 256 and 8 subvectors to achieve 4x compression while maintaining accuracy above 95%."
      },
      {
        "title": "Full Optimization",
        "scenario": "Complete optimization workflow",
        "prompt": "When optimizing vector search for production, execute the full 5-phase workflow: baseline measurement, quantization, HNSW indexing, caching setup, and comprehensive benchmarking with before-after comparison."
      }
    ],
    "output_examples": [
      {
        "input": "Optimize my AgentDB vector database with 1M embeddings of 1536 dimensions",
        "output": [
          "Phase 1: Baseline - Measured 45ms p95 latency, 64GB memory usage",
          "Phase 2: Quantization - Applied 4x compression, accuracy 96.2%",
          "Phase 3: HNSW Index - Built index with M=16, efConstruction=200",
          "Phase 4: Caching - Configured LRU cache with 10K entries, 1hr TTL",
          "Phase 5: Results - 16GB memory (4x reduction), 0.3ms latency (150x faster), 72% cache hit rate"
        ]
      }
    ],
    "best_practices": [
      "Always measure baseline performance before applying optimizations to establish improvement benchmarks",
      "Start with product quantization (4x compression) before trying aggressive binary quantization to balance memory savings and accuracy",
      "Monitor cache hit rates and adjust TTL/eviction policies based on query patterns for optimal performance"
    ],
    "anti_patterns": [
      "Skipping baseline measurement makes it impossible to validate improvement claims or detect regressions",
      "Applying aggressive 32x binary quantization without accuracy validation destroys search quality",
      "Ignoring cache warm-up period after deployment causes cold-start latency spikes for initial queries"
    ],
    "faq": [
      {
        "question": "Which quantization method should I start with?",
        "answer": "Start with product quantization for 4x compression and minimal accuracy loss. Move to binary quantization only if you need extreme compression."
      },
      {
        "question": "What HNSW parameters optimize speed?",
        "answer": "Increase M (16-64) for higher recall and efSearch (100-500) for faster queries. Higher values increase memory but improve accuracy."
      },
      {
        "question": "How do I integrate with existing AgentDB code?",
        "answer": "Import Quantization and QueryCache from agentdb-optimization package and apply before creating your index or querying."
      },
      {
        "question": "Is my data safe during optimization?",
        "answer": "Yes. Quantization creates compressed copies. Original vectors remain intact until you explicitly replace them."
      },
      {
        "question": "Why is accuracy dropping after optimization?",
        "answer": "Check compression ratio (lower is more accurate), validate codebook training on representative data, and adjust subvector count."
      },
      {
        "question": "How does this compare to other vector databases?",
        "answer": "AgentDB optimization achieves comparable results to specialized solutions. HNSW indexing provides similar speedups as pgvector and Milvus."
      }
    ]
  },
  "file_structure": [
    {
      "name": "process-diagram.gv",
      "type": "file",
      "path": "process-diagram.gv"
    },
    {
      "name": "PROCESS.md",
      "type": "file",
      "path": "PROCESS.md"
    },
    {
      "name": "README.md",
      "type": "file",
      "path": "README.md"
    },
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md"
    }
  ]
}
