{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-10T13:38:15.312Z",
    "slug": "dnyoussef-when-developing-ml-models-use-ml-expert",
    "source_url": "https://github.com/DNYoussef/ai-chrome-extension/tree/main/.claude/skills/machine-learning/when-developing-ml-models-use-ml-expert",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "2.0.0",
    "source_type": "community",
    "content_hash": "907f44ae71366bd788b3daaecf76bb11923bf5603e48a7543101f43e9da2c29c",
    "tree_hash": "e90d30844d2e6230e45874af670c1eeba976840a3804cd8c0bf09f1e1f514ccb"
  },
  "skill": {
    "name": "when-developing-ml-models-use-ml-expert",
    "description": "Specialized ML model development, training, and deployment workflow",
    "summary": "Specialized ML model development, training, and deployment workflow",
    "icon": "ðŸ§ ",
    "version": "1.0.0",
    "author": "DNYoussef",
    "license": "MIT",
    "category": "machine-learning",
    "tags": [
      "ml",
      "training",
      "deployment",
      "model-development",
      "neural-networks"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": [
      "filesystem",
      "network",
      "external_commands"
    ]
  },
  "security_audit": {
    "risk_level": "medium",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "The ML Expert skill is a legitimate machine learning development workflow with standard ML practices. It involves file I/O operations for data loading and model saving, external dependencies for ML frameworks, and optional distributed training via Flow-Nexus. While these capabilities could potentially be misused, the code follows standard ML development patterns with no evidence of malicious intent.",
    "risk_factor_evidence": [
      {
        "factor": "filesystem",
        "evidence": [
          {
            "file": "SKILL.md",
            "line_start": 60,
            "line_end": 60
          },
          {
            "file": "SKILL.md",
            "line_start": 112,
            "line_end": 114
          },
          {
            "file": "SKILL.md",
            "line_start": 365,
            "line_end": 375
          },
          {
            "file": "SKILL.md",
            "line_start": 380,
            "line_end": 389
          }
        ]
      },
      {
        "factor": "network",
        "evidence": [
          {
            "file": "SKILL.md",
            "line_start": 267,
            "line_end": 281
          }
        ]
      },
      {
        "factor": "external_commands",
        "evidence": [
          {
            "file": "README.md",
            "line_start": 14,
            "line_end": 18
          }
        ]
      }
    ],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [
      {
        "title": "Arbitrary CSV File Loading Without Validation",
        "description": "The skill loads CSV files directly with `pd.read_csv('dataset.csv')` without any validation of the file path or content. This could allow loading of malicious files if an attacker controls the filename or path.",
        "locations": [
          {
            "file": "SKILL.md",
            "line_start": 60,
            "line_end": 60
          }
        ]
      },
      {
        "title": "Command Execution via claude-flow",
        "description": "The skill executes external commands through `npx claude-flow@alpha skill-run` which could be exploited if input parameters are not properly sanitized.",
        "locations": [
          {
            "file": "README.md",
            "line_start": 14,
            "line_end": 18
          }
        ]
      }
    ],
    "low_findings": [
      {
        "title": "Model File Serialization Without Integrity Checks",
        "description": "The skill saves and loads model files (`model.save()`, `tf.keras.models.load_model()`) without verifying file integrity, which could lead to loading of tampered models.",
        "locations": [
          {
            "file": "SKILL.md",
            "line_start": 300,
            "line_end": 300
          }
        ]
      },
      {
        "title": "Preprocessing Pipeline Persistence",
        "description": "Scaler objects are saved with `joblib.dump(scaler, 'scaler.pkl')` which could be tampered with to manipulate data preprocessing.",
        "locations": [
          {
            "file": "SKILL.md",
            "line_start": 375,
            "line_end": 375
          }
        ]
      }
    ],
    "dangerous_patterns": [],
    "files_scanned": 4,
    "total_lines": 647,
    "audit_model": "claude",
    "audited_at": "2026-01-10T13:38:15.312Z"
  },
  "content": {
    "user_title": "Build production-ready ML models with automated workflows",
    "value_statement": "Developing machine learning models requires expertise across data preparation, architecture selection, training, and deployment. This skill automates the entire ML pipeline with best practices built-in, delivering production-ready models in under 90 minutes.",
    "seo_keywords": [
      "machine learning",
      "neural networks",
      "model training",
      "ML deployment",
      "TensorFlow",
      "PyTorch",
      "Claude",
      "Codex",
      "Claude Code",
      "AI model development"
    ],
    "actual_capabilities": [
      "Automated 5-phase ML pipeline from data to deployment",
      "Supports DNN, CNN, RNN, and Transformer architectures",
      "Distributed training with Flow-Nexus integration",
      "Exports models in Keras, TensorFlow, and TFLite formats",
      "Generates evaluation reports and training visualizations",
      "Creates production-ready deployment packages"
    ],
    "limitations": [
      "Requires TensorFlow or PyTorch installation",
      "Input data must be in CSV format",
      "Training time varies based on dataset size and complexity",
      "Distributed training requires Flow-Nexus setup"
    ],
    "use_cases": [
      {
        "target_user": "Data Scientists",
        "title": "Rapid Model Prototyping",
        "description": "Quickly train and validate multiple model architectures to find the best performer for your dataset."
      },
      {
        "target_user": "ML Engineers",
        "title": "Production Model Deployment",
        "description": "Package trained models with preprocessing pipelines and inference scripts for seamless deployment."
      },
      {
        "target_user": "Researchers",
        "title": "Distributed Training at Scale",
        "description": "Leverage Flow-Nexus to train large models across multiple nodes with data parallelism."
      }
    ],
    "prompt_templates": [
      {
        "title": "Basic Classification Model",
        "scenario": "Train a neural network for tabular data classification",
        "prompt": "I have a CSV file called 'customer_data.csv' with features like age, income, purchase_history. The target column is 'will_purchase'. Train a deep neural network to predict purchase behavior."
      },
      {
        "title": "Image Classification with CNN",
        "scenario": "Build a CNN for image recognition tasks",
        "prompt": "I need to classify images of products into 10 categories. My data is in 'product_images.csv' with image paths and labels. Create a CNN model with data augmentation."
      },
      {
        "title": "Time Series Forecasting",
        "scenario": "Train an RNN for sequential data prediction",
        "prompt": "I have time series data in 'sales_data.csv' with daily sales figures. Build an LSTM model to forecast next 30 days of sales."
      },
      {
        "title": "Transfer Learning Setup",
        "scenario": "Fine-tune a pre-trained model",
        "prompt": "I want to use a pre-trained ResNet model and fine-tune it on my custom dataset 'medical_images.csv' for disease classification. Use transfer learning with frozen early layers."
      }
    ],
    "output_examples": [
      {
        "input": "Train a neural network on my dataset 'housing_data.csv' to predict house prices",
        "output": [
          "âœ“ Loaded 10,000 rows with 15 features from housing_data.csv",
          "âœ“ Applied data cleaning: removed 50 outliers, filled 120 missing values",
          "âœ“ Selected regression architecture: 3-layer DNN with dropout",
          "âœ“ Training completed: 85 epochs, final MSE: 0.023",
          "âœ“ Model exported: model.h5 (2.3MB), scaler.pkl (1.2KB)",
          "âœ“ Deployment package created with inference script"
        ]
      }
    ],
    "best_practices": [
      "Always validate your data quality before training - clean data produces better models",
      "Monitor training curves for overfitting and adjust dropout/regularization accordingly",
      "Test the deployment package locally before pushing to production environment"
    ],
    "anti_patterns": [
      "Don't skip data exploration - understanding your data prevents model failures",
      "Avoid training for too many epochs without early stopping to prevent overfitting",
      "Never deploy models without testing on held-out validation data first"
    ],
    "faq": [
      {
        "question": "Which ML frameworks are compatible?",
        "answer": "The skill supports both TensorFlow and PyTorch. It automatically detects your environment and uses the appropriate framework."
      },
      {
        "question": "What's the maximum dataset size?",
        "answer": "Limited by your system's memory. For datasets >1GB, use the distributed training option with Flow-Nexus to split processing across multiple nodes."
      },
      {
        "question": "Can I integrate with existing MLOps pipelines?",
        "answer": "Yes, the skill outputs standard model formats (.h5, SavedModel, TFLite) that integrate with MLflow, Kubeflow, and other MLOps platforms."
      },
      {
        "question": "Is my data safe during processing?",
        "answer": "All processing happens locally on your machine. No data is sent to external services unless you explicitly enable distributed training."
      },
      {
        "question": "What if training fails or performs poorly?",
        "answer": "The skill includes automatic retry logic and hyperparameter adjustment. Check the evaluation report for specific improvement recommendations."
      },
      {
        "question": "How does this compare to AutoML platforms?",
        "answer": "Unlike black-box AutoML, this skill provides full transparency with editable code, detailed metrics, and complete control over the training process."
      }
    ]
  },
  "file_structure": [
    {
      "name": "process-diagram.gv",
      "type": "file",
      "path": "process-diagram.gv"
    },
    {
      "name": "PROCESS.md",
      "type": "file",
      "path": "PROCESS.md"
    },
    {
      "name": "README.md",
      "type": "file",
      "path": "README.md"
    },
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md"
    }
  ]
}
