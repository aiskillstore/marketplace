{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-10T10:32:34.921Z",
    "slug": "asmayaseen-context-optimization",
    "source_url": "https://github.com/Asmayaseen/hackathon-2/tree/main/.claude/skills/context-optimization",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "2.0.0",
    "source_type": "community",
    "content_hash": "b2135857a248b8b6957aa4d0dfae942476e05d15f1deb53bc6c07620c7494f16",
    "tree_hash": "33935ae975563b1d2d6b2f2146c43b3076b50a8b94f23d0e76cdf3f7cfbdd5cc"
  },
  "skill": {
    "name": "context-optimization",
    "description": "Apply optimization techniques to extend effective context capacity. Use when context limits constrain agent performance, when optimizing for cost or latency, or when implementing long-running agent systems.",
    "summary": "Apply optimization techniques to extend effective context capacity. Use when context limits constrai...",
    "icon": "ðŸ“¦",
    "version": "1.0.0",
    "author": "Asmayaseen",
    "license": "MIT",
    "category": "coding",
    "tags": [
      "context-engineering",
      "optimization",
      "performance",
      "ai-agents",
      "token-reduction"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": [
      "scripts",
      "filesystem"
    ]
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "This is a pure utility skill containing only documentation and in-memory Python utilities for context optimization. No network calls, no file writes beyond its own directory, no external commands, no credential access. All code operates locally with standard library operations only.",
    "risk_factor_evidence": [
      {
        "factor": "scripts",
        "evidence": [
          {
            "file": "scripts/compaction.py",
            "line_start": 1,
            "line_end": 379
          },
          {
            "file": "scripts/verify.py",
            "line_start": 1,
            "line_end": 32
          }
        ]
      },
      {
        "factor": "filesystem",
        "evidence": [
          {
            "file": "scripts/verify.py",
            "line_start": 14,
            "line_end": 14
          }
        ]
      }
    ],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 4,
    "total_lines": 856,
    "audit_model": "claude",
    "audited_at": "2026-01-10T10:32:34.921Z"
  },
  "content": {
    "user_title": "Optimize AI Context Capacity",
    "value_statement": "Context limits constrain AI agent performance and increase costs. This skill provides proven techniques to extend effective context capacity through strategic compression, masking, caching, and partitioning without requiring larger models.",
    "seo_keywords": [
      "Claude context optimization",
      "Claude Code context window",
      "AI context engineering",
      "token reduction",
      "KV cache optimization",
      "context compaction",
      "observation masking",
      "long-running AI agents",
      "multi-agent partitioning",
      "cost optimization"
    ],
    "actual_capabilities": [
      "Apply compaction strategies to summarize and compress context when approaching limits",
      "Implement observation masking to replace verbose tool outputs with compact references",
      "Design prompts for optimal KV-cache reuse across requests",
      "Partition work across sub-agents with isolated contexts",
      "Monitor context utilization and trigger optimization based on thresholds",
      "Calculate token budgets and allocation across system prompts, tools, and history"
    ],
    "limitations": [
      "Does not increase actual model context window limits",
      "Requires integration with agent framework for full functionality",
      "Quality degradation may occur with aggressive optimization",
      "Production use requires model-specific tokenizers for accurate counts"
    ],
    "use_cases": [
      {
        "target_user": "AI Engineers",
        "title": "Build Long-Running Agents",
        "description": "Implement agent systems that maintain performance across extended conversations without hitting context limits"
      },
      {
        "target_user": "Cost-Conscious Developers",
        "title": "Reduce Token Costs",
        "description": "Optimize context usage to lower API costs while preserving output quality and task completion"
      },
      {
        "target_user": "Production Engineers",
        "title": "Scale AI Systems",
        "description": "Design context management strategies that enable high-throughput AI applications at scale"
      }
    ],
    "prompt_templates": [
      {
        "title": "Check Context Usage",
        "scenario": "When conversation grows long",
        "prompt": "Analyze the current context utilization. What percentage of the context window is used? Which components (system prompt, tool definitions, message history, tool outputs, retrieved documents) dominate? Recommend specific optimization techniques."
      },
      {
        "title": "Compact Context",
        "scenario": "When approaching context limits",
        "prompt": "Compact the current context using summarize-and-continue strategy. Preserve task goals, user preferences, and recent conversation. Summarize old turns and verbose tool outputs. Report token reduction achieved."
      },
      {
        "title": "Design Cache-Friendly Prompt",
        "scenario": "When building repeated workflows",
        "prompt": "Design a prompt structure that maximizes KV-cache reuse. Identify dynamic elements that invalidate cache. Propose stable template with placeholders for dynamic content."
      },
      {
        "title": "Partition Complex Task",
        "scenario": "When task exceeds context",
        "prompt": "Decompose this complex task into subtasks suitable for sub-agent partitioning. Define isolation boundaries. Specify how results will be aggregated without carrying accumulated context."
      }
    ],
    "output_examples": [
      {
        "input": "Analyze context usage for my current conversation and suggest optimizations",
        "output": [
          "Context Utilization: 73% of 100K token limit",
          "Largest consumers: Tool outputs (45%), Message history (30%)",
          "Recommended actions:",
          "  â€¢ Mask tool outputs from turns 5+ (est. 35% reduction)",
          "  â€¢ Compact message history (est. 20% reduction)",
          "  â€¢ Total potential: 55% token reduction with quality preserved"
        ]
      }
    ],
    "best_practices": [
      "Measure baseline context usage before optimizing to identify dominant consumers",
      "Apply compaction before masking when possible to preserve access to full content",
      "Test optimization strategies at increasing aggressiveness levels to find optimal balance"
    ],
    "anti_patterns": [
      "Masking observations still needed for current task or active reasoning",
      "Compacting system prompt or critical task state information",
      "Optimizing prematurely when context limits are not actually constraining"
    ],
    "faq": [
      {
        "question": "Does this increase Claude's context window?",
        "answer": "No. This skill optimizes how existing context is used. Actual context limits are set by the model."
      },
      {
        "question": "What token reduction can I expect?",
        "answer": "Compaction typically achieves 50-70% reduction. Masking achieves 60-80% on masked observations. Results vary by content type."
      },
      {
        "question": "How do I integrate with my agent framework?",
        "answer": "Import compaction.py utilities and call them when context approaches thresholds. The skill provides example code patterns."
      },
      {
        "question": "Is my data sent anywhere?",
        "answer": "No. All optimization runs locally in memory. No network calls are made by the skill code."
      },
      {
        "question": "Why does quality degrade with aggressive optimization?",
        "answer": "Over-aggressive compaction removes useful context. The skill provides guidelines for safe thresholds and what to preserve."
      },
      {
        "question": "How does this compare to larger context models?",
        "answer": "This skill reduces costs and latency without model upgrade. Larger contexts still help but optimization extends value of any limit."
      }
    ]
  },
  "file_structure": [
    {
      "name": "references",
      "type": "dir",
      "path": "references",
      "children": [
        {
          "name": "optimization_techniques.md",
          "type": "file",
          "path": "references/optimization_techniques.md"
        }
      ]
    },
    {
      "name": "scripts",
      "type": "dir",
      "path": "scripts",
      "children": [
        {
          "name": "compaction.py",
          "type": "file",
          "path": "scripts/compaction.py"
        },
        {
          "name": "verify.py",
          "type": "file",
          "path": "scripts/verify.py"
        }
      ]
    },
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md"
    }
  ]
}
