{
  "name": "asmayaseen-streaming-llm-responses",
  "source": "./plugins/asmayaseen/streaming-llm-responses",
  "description": "Implement real-time streaming UI patterns for AI chat applications. Use when adding response\nlifecycle handlers, progress indicators, client effects, or thread state synchronization.\nCovers onResponseStart/End, onEffect, ProgressUpdateEvent, and client tools.\nNOT when building basic chat without real-time feedback.\n",
  "version": "1.0.0",
  "author": {
    "name": "Asmayaseen"
  },
  "repository": "https://github.com/Asmayaseen/hackathon-2/tree/main/.claude/skills/streaming-llm-responses",
  "license": "UNLICENSED",
  "keywords": [
    "streaming",
    "chat-ui",
    "real-time",
    "react",
    "typescript"
  ],
  "category": "coding",
  "tags": [
    "streaming",
    "chat-ui",
    "real-time",
    "react",
    "typescript"
  ]
}
