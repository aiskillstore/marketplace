{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-02-08T08:41:22.106Z",
    "slug": "inferencesh-agent-tools",
    "source_url": "https://github.com/inferencesh/skills/tree/main/skills/agent-tools/",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "3.0.0",
    "source_type": "community",
    "content_hash": "62d4894f1911c4149ca0261a67cca2f8e5db1a77f48dc83e7116068012d4c383",
    "tree_hash": "1931602a0403408b913d45a0596d9c4d34dec74a1fb19f5e2687a4b0719cef05"
  },
  "skill": {
    "name": "agent-tools",
    "description": "Run 150+ AI apps via inference.sh CLI - image generation, video creation, LLMs, search, 3D, Twitter automation.\nModels: FLUX, Veo, Gemini, Grok, Claude, Seedance, OmniHuman, Tavily, Exa, OpenRouter, and many more.\nUse when running AI apps, generating images/videos, calling LLMs, web search, or automating Twitter.\nTriggers: inference.sh, infsh, ai model, run ai, serverless ai, ai api, flux, veo, claude api,\nimage generation, video generation, openrouter, tavily, exa search, twitter api, grok\n",
    "summary": "Access 150+ cloud AI apps through the inference.sh CLI - image generation, video creation, LLMs, web search, and Twitter automation.",
    "icon": "üõ†Ô∏è",
    "version": "1.0.0",
    "author": "inferencesh",
    "license": "MIT",
    "tags": [
      "AI",
      "CLI",
      "image-generation",
      "video-generation",
      "LLM"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": [
      "network",
      "external_commands"
    ]
  },
  "security_audit": {
    "risk_level": "low",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "Documentation-only skill containing markdown reference files. Static findings are false positives - patterns detected are CLI command examples in documentation, not executable code. All curl pipe patterns use security-enhancing flags (-fsSL). No malicious intent, credential exfiltration, or actual code execution risks detected.",
    "risk_factor_evidence": [
      {
        "factor": "network",
        "evidence": [
          {
            "file": "SKILL.md",
            "line_start": 12,
            "line_end": 12
          },
          {
            "file": "SKILL.md",
            "line_start": 111,
            "line_end": 117
          }
        ]
      },
      {
        "factor": "external_commands",
        "evidence": [
          {
            "file": "SKILL.md",
            "line_start": 21,
            "line_end": 21
          },
          {
            "file": "SKILL.md",
            "line_start": 27,
            "line_end": 44
          }
        ]
      }
    ],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 5,
    "total_lines": 545,
    "audit_model": "claude",
    "audited_at": "2026-02-08T08:41:22.106Z",
    "risk_factors": [
      "network",
      "external_commands"
    ]
  },
  "content": {
    "user_title": "Access 150+ Cloud AI Apps via CLI",
    "value_statement": "Running AI models locally requires expensive GPU hardware. The inference.sh CLI enables access to 150+ cloud AI applications for image generation, video creation, LLM calls, and web search without any local setup.",
    "seo_keywords": [
      "Claude",
      "Codex",
      "Claude Code",
      "inference.sh",
      "AI CLI",
      "image generation CLI",
      "video generation",
      "LLM API",
      "cloud AI",
      "serverless AI"
    ],
    "actual_capabilities": [
      "Generate images using FLUX, Gemini, Grok, and Stable Diffusion models",
      "Create videos with Veo, Seedance, Wan, and OmniHuman",
      "Call LLMs including Claude, Gemini, and OpenRouter models",
      "Perform web search with Tavily and Exa",
      "Automate Twitter/X posting and interactions",
      "Generate 3D models and access media utilities"
    ],
    "limitations": [
      "Requires inference.sh account and API authentication",
      "Usage costs credits based on AI model chosen",
      "Offline execution not supported - all AI tasks run in cloud",
      "CLI must be installed before use"
    ],
    "use_cases": [
      {
        "title": "Generate marketing images with FLUX",
        "description": "Create professional product images and marketing visuals using FLUX models through simple CLI commands without local GPU requirements.",
        "target_user": " marketers, designers, content creators"
      },
      {
        "title": "Build video workflows with Veo 3",
        "description": "Generate short video clips and animations using Google Veo models for social media, presentations, or prototypes.",
        "target_user": " video producers, social media managers"
      },
      {
        "title": "Research with web search and LLM chaining",
        "description": "Combine Tavily web search with Claude or other LLMs to research topics and generate summaries automatically.",
        "target_user": " researchers, analysts, developers"
      }
    ],
    "prompt_templates": [
      {
        "title": "Basic image generation",
        "prompt": "Use the inference.sh CLI to generate an image with FLUX. First list available image apps, then run falai/flux-dev-lora with a prompt of \"${1:a cozy coffee shop interior}\".",
        "scenario": "Generating a single image with FLUX"
      },
      {
        "title": "Video generation workflow",
        "prompt": "Create a drone-shot style video using Veo 3. Generate a sample input file first, then run google/veo-3-1-fast with the prompt \"${1:aerial view of ocean waves at sunset}\".",
        "scenario": "Creating a video with Google Veo"
      },
      {
        "title": "Research with web search",
        "prompt": "Use Tavily search to find information about \"${1:latest developments in quantum computing}\", then summarize the results using Claude Sonnet via OpenRouter.",
        "scenario": "Researching a topic with web search and LLM"
      },
      {
        "title": "Automated Twitter posting",
        "prompt": "Post a promotional tweet using the x/post-tweet app. The tweet text should be: \"${1:Check out our new AI-powered tool!}\"",
        "scenario": "Automating social media posts"
      }
    ],
    "output_examples": [
      {
        "input": "infsh app run falai/flux-dev-lora --input '{\"prompt\": \"a red bicycle in a parisian street\"}'",
        "output": "Task ID: abc123xyz\nImage URL: https://cloud.inference.sh/images/def456.png\n\nThe generated image is ready for download."
      },
      {
        "input": "infsh app run tavily/search-assistant --input '{\"query\": \"Claude Code AI features\"}'",
        "output": "Results:\n1. Claude Code - Anthropic's CLI for AI-assisted development\n2. Features include: code generation, refactoring, debugging\n3. Available via npm: npx @anthropic/claude-code"
      },
      {
        "input": "infsh task get abc123xyz --json",
        "output": "{\n  \"status\": \"completed\",\n  \"output\": {\n    \"url\": \"https://cloud.inference.sh/video.mp4\"\n  }\n}"
      }
    ],
    "best_practices": [
      "Generate sample inputs first with 'infsh app sample' to understand required parameters before running apps",
      "Use version pinning (@version) for production scripts to ensure reproducible results",
      "Store task IDs when running with --no-wait to retrieve results later"
    ],
    "anti_patterns": [
      "Hardcoding API keys directly in command lines - use environment variables instead",
      "Running multiple apps sequentially without checking task status between runs",
      "Forgetting to check available apps before assuming a model is available"
    ],
    "faq": [
      {
        "question": "Do I need a GPU to use this skill?",
        "answer": "No, all AI processing happens in the cloud. You only need the CLI installed locally to submit requests and receive results."
      },
      {
        "question": "How much does inference.sh cost?",
        "answer": "Pricing varies by AI model. Some models offer free credits for testing. Check inference.sh pricing page for current rates."
      },
      {
        "question": "Can I run my own models with this CLI?",
        "answer": "Yes, once you deploy apps to inference.sh, you can run them using the CLI with your own namespace/app-name format."
      },
      {
        "question": "What authentication do I need?",
        "answer": "Run 'infsh login' to authenticate via browser, or set INFSH_API_KEY environment variable for CI/CD use."
      },
      {
        "question": "How long do tasks take?",
        "answer": "Task duration depends on the AI model. Image generation is typically seconds. Video and complex LLM tasks may take minutes."
      },
      {
        "question": "Can I use this with Claude Code?",
        "answer": "Yes, this skill is compatible with Claude Code and other Anthropic tools. Use the Bash tool to run infsh commands."
      }
    ]
  },
  "file_structure": [
    {
      "name": "references",
      "type": "dir",
      "path": "references",
      "children": [
        {
          "name": "app-discovery.md",
          "type": "file",
          "path": "references/app-discovery.md",
          "lines": 113
        },
        {
          "name": "authentication.md",
          "type": "file",
          "path": "references/authentication.md",
          "lines": 60
        },
        {
          "name": "cli-reference.md",
          "type": "file",
          "path": "references/cli-reference.md",
          "lines": 105
        },
        {
          "name": "running-apps.md",
          "type": "file",
          "path": "references/running-apps.md",
          "lines": 149
        }
      ]
    },
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md",
      "lines": 118
    }
  ]
}
