{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-06T07:44:13.729Z",
    "slug": "muratcankoylan-context-fundamentals",
    "source_url": "https://github.com/muratcankoylan/Agent-Skills-for-Context-Engineering/tree/main/skills/context-fundamentals",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "2.0.0",
    "source_type": "community",
    "content_hash": "1a0e0453cd73928f87ee72c37dbda44f284c3ad786bb538c070f6e0dcef16d47",
    "tree_hash": "a8e5a7857660370ad8684b74d769fa2c7c9056a529139ac17cf282f640ceaff0"
  },
  "skill": {
    "name": "context-fundamentals",
    "description": "This skill should be used when the user asks to \"understand context\", \"explain context windows\", \"design agent architecture\", \"debug context issues\", \"optimize context usage\", or discusses context components, attention mechanics, progressive disclosure, or context budgeting. Provides foundational understanding of context engineering for AI agent systems.",
    "summary": "This skill should be used when the user asks to \"understand context\", \"explain context windows\", \"de...",
    "icon": "ðŸ§ ",
    "version": "1.0.0",
    "author": "muratcankoylan",
    "license": "MIT",
    "category": "data",
    "tags": [
      "context-engineering",
      "agent-architecture",
      "token-optimization",
      "context-windows"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": [
      "filesystem"
    ]
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "This is a prompt-based educational skill with supporting utility code for context management. The code provides token estimation, context building, and validation functions. No network calls, no external commands, no credential access, no file writes outside local content loading, and no obfuscation. Behavior matches stated purpose.",
    "risk_factor_evidence": [
      {
        "factor": "filesystem",
        "evidence": [
          {
            "file": "scripts/context_manager.py",
            "line_start": 289,
            "line_end": 313
          }
        ]
      }
    ],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 3,
    "total_lines": 841,
    "audit_model": "claude",
    "audited_at": "2026-01-06T07:44:13.729Z"
  },
  "content": {
    "user_title": "Master Context Engineering Fundamentals",
    "value_statement": "Context is the foundation of effective AI agent performance. This skill teaches you how to understand, design, and optimize context in agent systems. Learn the principles of progressive disclosure, attention mechanics, and context budgeting to build more capable AI agents.",
    "seo_keywords": [
      "context engineering",
      "context windows",
      "Claude Code",
      "agent architecture",
      "token optimization",
      "progressive disclosure",
      "attention mechanisms",
      "context budgeting",
      "AI agent design",
      "prompt engineering"
    ],
    "actual_capabilities": [
      "Explain context components including system prompts, tool definitions, and message history",
      "Describe attention mechanics and position encoding constraints",
      "Apply progressive disclosure principles to manage context efficiently",
      "Design context budgets and implement compaction strategies",
      "Validate context structure and identify optimization opportunities"
    ],
    "limitations": [
      "Does not provide live context monitoring or real-time token counting",
      "Does not integrate with specific model APIs for actual tokenization",
      "Requires implementation of described patterns in your own codebase"
    ],
    "use_cases": [
      {
        "target_user": "AI Engineers",
        "title": "Design Agent Architectures",
        "description": "Build agent systems with effective context management strategies including progressive disclosure and context budgeting."
      },
      {
        "target_user": "Development Teams",
        "title": "Debug Context Issues",
        "description": "Identify and resolve context-related problems that cause unexpected agent behavior or poor performance."
      },
      {
        "target_user": "Technical Leads",
        "title": "Optimize Context Usage",
        "description": "Reduce token costs and improve model performance by applying context engineering principles."
      }
    ],
    "prompt_templates": [
      {
        "title": "Explain Context Basics",
        "scenario": "Understanding context for new team members",
        "prompt": "Explain the core components of context in AI agent systems. Include system prompts, tool definitions, message history, retrieved documents, and tool outputs with examples of each."
      },
      {
        "title": "Context Optimization",
        "scenario": "Reducing token costs in production",
        "prompt": "How should I optimize context usage for a long-running agent? Include strategies for progressive disclosure, context compaction, and when to use summarization versus truncation."
      },
      {
        "title": "Design System Prompts",
        "scenario": "Creating effective agent instructions",
        "prompt": "What are best practices for organizing system prompts? Include guidance on altitude calibration, section structure, and how to write tool descriptions that guide agent behavior effectively."
      },
      {
        "title": "Attention Mechanics",
        "scenario": "Understanding model limitations",
        "prompt": "Explain how attention mechanisms create constraints in long contexts. Include the attention budget concept, position encoding effects, and practical implications for context design."
      }
    ],
    "output_examples": [
      {
        "input": "How should I design the context structure for a coding assistant agent?",
        "output": [
          "Structure your context with clear priority levels: system prompt (highest), task description, retrieved documents (variable), and conversation history",
          "Place critical information at attention-favored positions - the beginning and end of context receive more attention than the middle",
          "Use progressive disclosure: load skill names and descriptions at startup, full content only when skills are activated",
          "Implement context budgeting with 70-80% utilization thresholds for compaction triggers",
          "Separate tool definitions from tool outputs to enable selective inclusion based on current task"
        ]
      }
    ],
    "best_practices": [
      "Design for context degradation rather than hoping to avoid it - assume attention will degrade as context grows",
      "Use the consolidation principle: if you cannot definitively say which tool should be used, the agent cannot either",
      "Prefer smaller high-signal context over larger low-signal context - informativity over exhaustiveness"
    ],
    "anti_patterns": [
      "Stuffing all available information into context hoping more data improves results",
      "Hardcoding complex brittle logic instead of providing clear heuristics",
      "Using vague high-level guidance that fails to give concrete signals for desired outputs"
    ],
    "faq": [
      {
        "question": "Which AI models are compatible with these techniques?",
        "answer": "These principles apply to all transformer-based language models including Claude, GPT-4, and similar systems with context windows."
      },
      {
        "question": "What are typical context window limits?",
        "answer": "Models vary widely - some support 4K tokens while others handle 200K+. Design systems that work across different limits."
      },
      {
        "question": "How do I integrate this with my existing agent framework?",
        "answer": "Apply the patterns to your context construction pipeline. The skill describes principles, not specific implementations."
      },
      {
        "question": "Is my data safe when using context management functions?",
        "answer": "Yes. The utility code processes data locally and does not transmit any information externally or to third parties."
      },
      {
        "question": "Why is my agent ignoring part of the context?",
        "answer": "This typically indicates attention budget exhaustion. Move important information to attention-favored positions and reduce context size."
      },
      {
        "question": "How does this compare to prompt engineering?",
        "answer": "Context engineering is broader - it addresses the entire information pipeline, not just the system prompt content."
      }
    ]
  },
  "file_structure": [
    {
      "name": "references",
      "type": "dir",
      "path": "references",
      "children": [
        {
          "name": "context-components.md",
          "type": "file",
          "path": "references/context-components.md"
        }
      ]
    },
    {
      "name": "scripts",
      "type": "dir",
      "path": "scripts",
      "children": [
        {
          "name": "context_manager.py",
          "type": "file",
          "path": "scripts/context_manager.py"
        }
      ]
    },
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md"
    }
  ]
}
