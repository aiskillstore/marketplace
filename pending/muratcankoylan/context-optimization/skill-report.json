{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-06T07:45:26.975Z",
    "slug": "muratcankoylan-context-optimization",
    "source_url": "https://github.com/muratcankoylan/Agent-Skills-for-Context-Engineering/tree/main/skills/context-optimization",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "2.0.0",
    "source_type": "community",
    "content_hash": "6a7a947d2c1fe30118ecd69d0e98ea21cce0933ba77429b53c186f892b9f089c",
    "tree_hash": "6d2c9f521bb151c78a661101052a154fc566a3c6fe56ee21c39a7f5e2f6f7651"
  },
  "skill": {
    "name": "context-optimization",
    "description": "This skill should be used when the user asks to \"optimize context\", \"reduce token costs\", \"improve context efficiency\", \"implement KV-cache optimization\", \"partition context\", or mentions context limits, observation masking, context budgeting, or extending effective context capacity.",
    "summary": "This skill should be used when the user asks to \"optimize context\", \"reduce token costs\", \"improve c...",
    "icon": "ðŸ“¦",
    "version": "1.0.0",
    "author": "muratcankoylan",
    "license": "MIT",
    "category": "data",
    "tags": [
      "context-management",
      "token-optimization",
      "performance"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": []
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "This is a prompt-based skill containing only documentation and Python utility functions for in-memory text processing. No file system access, network calls, command execution, or credential access. The code performs only token estimation, content summarization, and budget tracking within the calling process.",
    "risk_factor_evidence": [],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 3,
    "total_lines": 833,
    "audit_model": "claude",
    "audited_at": "2026-01-06T07:45:26.975Z"
  },
  "content": {
    "user_title": "Optimize Context for Longer Conversations",
    "value_statement": "Limited context windows constrain complex tasks and increase API costs. This skill provides proven techniques to double or triple effective context capacity through compaction, observation masking, KV-cache optimization, and context partitioning.",
    "seo_keywords": [
      "context optimization",
      "token reduction",
      "KV-cache optimization",
      "context compaction",
      "Claude",
      "Codex",
      "Claude Code",
      "context window",
      "observation masking",
      "token costs"
    ],
    "actual_capabilities": [
      "Summarize context content when approaching token limits",
      "Mask verbose tool outputs with compact references",
      "Design prompts for maximum KV-cache reuse",
      "Partition work across isolated context windows",
      "Track and manage token budget allocation",
      "Calculate cache hit rates and optimization metrics"
    ],
    "limitations": [
      "Does not increase model context window limits",
      "Token estimation uses approximate heuristics",
      "Does not integrate with inference infrastructure",
      "Requires implementation of callback hooks in your code"
    ],
    "use_cases": [
      {
        "target_user": "AI Developers",
        "title": "Build Long-Running Agents",
        "description": "Create agent systems that handle complex multi-step tasks without context overflow or quality degradation."
      },
      {
        "target_user": "Cost-Conscious Users",
        "title": "Reduce API Costs",
        "description": "Cut token usage by 50-70% through smart compression while preserving output quality."
      },
      {
        "target_user": "Enterprise Teams",
        "title": "Scale Production Systems",
        "description": "Implement context management patterns that work reliably at production scale with predictable performance."
      }
    ],
    "prompt_templates": [
      {
        "title": "Check Context Usage",
        "scenario": "Monitoring token utilization",
        "prompt": "Check the current context utilization. If it exceeds 70%, apply compaction to summarize older messages while preserving key decisions and current task state."
      },
      {
        "title": "Mask Tool Outputs",
        "scenario": "Reducing observation overhead",
        "prompt": "Mask tool outputs from 3 or more turns ago. Replace verbose outputs with compact references containing only key metrics and findings."
      },
      {
        "title": "Design Cache-Friendly Prompts",
        "scenario": "Optimizing cache hit rates",
        "prompt": "Design the system prompt to maximize KV-cache stability. Replace dynamic content like timestamps with stable placeholders."
      },
      {
        "title": "Partition Complex Tasks",
        "scenario": "Handling large documents",
        "prompt": "Partition this complex task across sub-agents with isolated contexts. Each sub-agent handles one subtask, with results aggregated at the coordinator level."
      }
    ],
    "output_examples": [
      {
        "input": "Optimize this conversation context. We've used 85% of our 100K token limit and response quality is degrading.",
        "output": [
          "Triggering compaction: Summarizing 15 oldest conversation turns",
          "Masking 8 tool outputs from previous turns",
          "Preserving: system prompt, current task state, recent decisions",
          "Result: Context reduced from 85K to 32K tokens (62% reduction)",
          "Estimated quality impact: Less than 3% degradation"
        ]
      }
    ],
    "best_practices": [
      "Measure current context usage before optimizing to establish baseline",
      "Apply compaction before masking when both techniques are needed",
      "Design prompts for cache stability with consistent formatting",
      "Monitor optimization effectiveness over time and iterate on strategies"
    ],
    "anti_patterns": [
      "Compacting system prompts or critical task state information",
      "Masking observations that are still needed for active reasoning",
      "Ignoring attention distribution and placing important information in the middle",
      "Premature optimization before context limits actually constrain performance"
    ],
    "faq": [
      {
        "question": "Which AI models are supported?",
        "answer": "Works with any model supporting tool use or function calling including Claude 3/4, GPT-4, and Codex models. The utility functions are model-agnostic."
      },
      {
        "question": "What are the token reduction targets?",
        "answer": "Compaction achieves 50-70% token reduction with under 5% quality loss. Masking achieves 60-80% reduction on masked observations."
      },
      {
        "question": "How do I integrate this with my code?",
        "answer": "Import the compaction utilities and call them in your message handling loop. Monitor token usage and trigger optimization when thresholds are exceeded."
      },
      {
        "question": "Is my data safe?",
        "answer": "Yes. All processing happens in-memory within your application. No data is sent to external services or stored externally."
      },
      {
        "question": "Why did response quality drop after optimization?",
        "answer": "Check if critical information was accidentally compacted. Ensure system prompts, key decisions, and current task state are preserved during optimization."
      },
      {
        "question": "How does this compare to Claude's native context?",
        "answer": "Claude has larger context windows. This skill helps you use any context window more efficiently and reduces costs regardless of window size."
      }
    ]
  },
  "file_structure": [
    {
      "name": "references",
      "type": "dir",
      "path": "references",
      "children": [
        {
          "name": "optimization_techniques.md",
          "type": "file",
          "path": "references/optimization_techniques.md"
        }
      ]
    },
    {
      "name": "scripts",
      "type": "dir",
      "path": "scripts",
      "children": [
        {
          "name": "compaction.py",
          "type": "file",
          "path": "scripts/compaction.py"
        }
      ]
    },
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md"
    }
  ]
}
