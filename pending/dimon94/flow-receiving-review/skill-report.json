{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-10T14:21:38.008Z",
    "slug": "dimon94-flow-receiving-review",
    "source_url": "https://github.com/Dimon94/cc-devflow/tree/main/.claude/skills/flow-receiving-review",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "2.0.0",
    "source_type": "community",
    "content_hash": "6160b2d008af44e39bc3f0405d0307eaee17d6cd9b702f9ce56abd1c2aa3059f",
    "tree_hash": "e9c7dba8fb3160dc1045e143c02fa1ffe1b7a8f6f99c0a99eeb43c09fdeec60e"
  },
  "skill": {
    "name": "flow-receiving-review",
    "description": "Handle code review feedback with technical rigor. Don't blindly agree - verify before implementing.",
    "summary": "Handle code review feedback with technical rigor. Don't blindly agree - verify before implementing.",
    "icon": "üîç",
    "version": "1.0.0",
    "author": "Dimon94",
    "license": "MIT",
    "category": "documentation",
    "tags": [
      "code-review",
      "process",
      "workflow",
      "quality"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": []
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "Pure prompt-based skill containing only documentation and guidelines for code review feedback handling. No executable code, no file access, no network calls, no command execution. This is a low-risk instructional skill.",
    "risk_factor_evidence": [],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 1,
    "total_lines": 154,
    "audit_model": "claude",
    "audited_at": "2026-01-10T14:21:38.008Z"
  },
  "content": {
    "user_title": "Verify code review feedback before implementing",
    "value_statement": "Code review feedback can be incorrect or misguided. This skill provides a systematic 3-step process to verify feedback, ask clarifying questions, and respond appropriately‚Äîensuring technical rigor over blind compliance.",
    "seo_keywords": [
      "Claude Code",
      "code review",
      "feedback verification",
      "code review process",
      "technical rigor",
      "software development",
      "code quality",
      "developer workflow",
      "Codex",
      "Claude"
    ],
    "actual_capabilities": [
      "Guide users through a 3-step process: Understand, Verify, Implement",
      "Provide templates for agreeing, asking clarification, and respectfully disagreeing",
      "Identify red flags that indicate blind compliance with incorrect feedback",
      "Help users push back on feedback with technical reasoning and evidence",
      "Cross-reference with flow-review command for comprehensive review workflow"
    ],
    "limitations": [
      "Does not execute code or run tests automatically",
      "Does not access codebase to verify feedback correctness",
      "Does not communicate with external reviewers or platforms",
      "Requires manual verification steps by the user"
    ],
    "use_cases": [
      {
        "target_user": "Software developers",
        "title": "Professional code review response",
        "description": "Developers can use this skill to maintain technical standards when responding to review comments"
      },
      {
        "target_user": "AI coding assistants",
        "title": "Structured feedback handling",
        "description": "AI agents can use this skill to process review feedback systematically before implementing changes"
      },
      {
        "target_user": "Tech leads and reviewers",
        "title": "Quality review guidelines",
        "description": "Team leads can use this skill to ensure review feedback is technically sound before submission"
      }
    ],
    "prompt_templates": [
      {
        "title": "Agree with feedback",
        "scenario": "Acknowledging a valid code review comment",
        "prompt": "Good catch! You're right that [issue]. I've updated [file] to [fix]. Verified by running [test/command]."
      },
      {
        "title": "Ask for clarification",
        "scenario": "When review feedback is unclear",
        "prompt": "I want to make sure I understand correctly. Are you suggesting [interpretation]? If so, I'm wondering about [concern]. Could you elaborate?"
      },
      {
        "title": "Respectfully disagree",
        "scenario": "When feedback appears incorrect",
        "prompt": "I considered [suggestion], but I went with [current approach] because: 1. [Reason 1] 2. [Reason 2]. The trade-off is [X]. What do you think about [alternative]?"
      },
      {
        "title": "Request evidence",
        "scenario": "When unable to reproduce the issue",
        "prompt": "I'm having trouble reproducing [issue]. Could you share: steps to reproduce, expected vs actual behavior, and environment details?"
      }
    ],
    "output_examples": [
      {
        "input": "Reviewer commented that my function should use a for loop instead of map()",
        "output": [
          "Understand: Read the full comment - is this a style preference or a performance concern?",
          "Verify: Does map() actually have issues here? Check if the suggested for loop improves anything.",
          "Respond: If for loop is better, implement and thank them. If map() is correct, explain why with evidence."
        ]
      }
    ],
    "best_practices": [
      "Always verify feedback correctness before implementing - reviewers can be wrong",
      "Ask clarifying questions when feedback is unclear rather than guessing intent",
      "Provide evidence and reasoning when pushing back on feedback",
      "Track your review responses and verification steps in execution logs"
    ],
    "anti_patterns": [
      "Blindly implementing feedback you do not understand or agree with",
      "Silently disagreeing without raising concerns constructively",
      "Skipping verification steps because it seems faster to just make the change",
      "Treating technical discussion as personal argument or conflict"
    ],
    "faq": [
      {
        "question": "Does this skill integrate with other CC-DevFlow commands?",
        "answer": "Yes, it integrates with /flow-review command and references spec-reviewer and code-quality-reviewer agents."
      },
      {
        "question": "What platforms support this skill?",
        "answer": "This skill supports Claude, Codex, and Claude Code. It works in any environment where these AI tools are available."
      },
      {
        "question": "Can this skill run tests automatically?",
        "answer": "No, this is a prompt-based skill. You must manually verify feedback and run tests yourself."
      },
      {
        "question": "Is my review data stored or shared?",
        "answer": "No, this skill is purely instructional. It does not store, transmit, or share any data."
      },
      {
        "question": "How do I handle aggressive or dismissive reviewers?",
        "answer": "Focus on technical facts. Use the response templates to maintain professionalism while standing your ground on technical merits."
      },
      {
        "question": "How is this different from flow-review skill?",
        "answer": "flow-review handles giving feedback to others. flow-receiving-review handles receiving and responding to feedback from others."
      }
    ]
  },
  "file_structure": [
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md"
    }
  ]
}
