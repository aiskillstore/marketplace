{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-10T12:58:54.670Z",
    "slug": "curiouslearner-data-validator",
    "source_url": "https://github.com/CuriousLearner/devkit/tree/main/skills/data-validator",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "2.0.0",
    "source_type": "community",
    "content_hash": "37648d95c76cb19039b58dbbf636f26e0c2d6d52635a4d2cf95ca8a1286e0807",
    "tree_hash": "2a06439282ca08097a092dec72773f3c62a28a21c2f3805b8807435e79749cc0"
  },
  "skill": {
    "name": "data-validator",
    "description": "Validate data against schemas, business rules, and data quality standards.",
    "summary": "Validate data against schemas, business rules, and data quality standards.",
    "icon": "âœ“",
    "version": "1.0.0",
    "author": "CuriousLearner",
    "license": "MIT",
    "category": "data",
    "tags": [
      "validation",
      "data-quality",
      "schema",
      "business-rules"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": []
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "Pure prompt-based skill with no executable code. Contains only documentation, instructions, and code examples for data validation patterns. No scripts, network calls, file system access, environment variable access, or external command execution capabilities.",
    "risk_factor_evidence": [],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 1,
    "total_lines": 923,
    "audit_model": "claude",
    "audited_at": "2026-01-10T12:58:54.670Z"
  },
  "content": {
    "user_title": "Validate data against schemas and business rules",
    "value_statement": "Poor data quality leads to system failures and bad decisions. This skill validates data against JSON schemas, database schemas, and custom business rules to catch errors early. It also detects duplicates, outliers, and format issues while generating detailed quality reports.",
    "seo_keywords": [
      "data validation",
      "JSON Schema",
      "data quality",
      "business rules",
      "Claude",
      "Codex",
      "Claude Code",
      "schema validation",
      "data integrity",
      "format validation"
    ],
    "actual_capabilities": [
      "Validate JSON data against JSON Schema specifications",
      "Check database DataFrame schemas with type and constraint validation",
      "Apply custom business rules and domain-specific logic",
      "Detect duplicates, outliers, and format issues in datasets",
      "Generate comprehensive data quality reports with scores",
      "Validate email, phone, URL, date, and credit card formats"
    ],
    "limitations": [
      "Does not connect to databases or external data sources",
      "Does not modify or fix data automatically",
      "Does not execute validation on scheduled intervals",
      "Schema validation only; does not perform data transformation"
    ],
    "use_cases": [
      {
        "target_user": "Data Engineers",
        "title": "Validate pipeline data",
        "description": "Ensure incoming data meets schema requirements and quality standards before processing"
      },
      {
        "target_user": "API Developers",
        "title": "Validate API contracts",
        "description": "Check request and response payloads conform to JSON Schema specifications"
      },
      {
        "target_user": "Quality Analysts",
        "title": "Audit data quality",
        "description": "Generate reports on completeness, uniqueness, and validity of datasets"
      }
    ],
    "prompt_templates": [
      {
        "title": "Basic validation",
        "scenario": "Validate a simple dataset",
        "prompt": "Validate this JSON data against the provided schema. Check all required fields, data types, and format patterns. Report any validation errors."
      },
      {
        "title": "Business rules",
        "scenario": "Apply domain rules",
        "prompt": "Check this order data against our business rules: total must match items, discount cannot exceed subtotal, shipping address required for physical items."
      },
      {
        "title": "Quality analysis",
        "scenario": "Analyze dataset quality",
        "prompt": "Analyze this dataset for completeness, duplicates, and format issues. Generate a quality report with scores and list the top issues found."
      },
      {
        "title": "Batch validation",
        "scenario": "Validate multiple records",
        "prompt": "Validate all records in this batch against the schema. Return summary statistics: total records, valid count, invalid count, and details on each failure."
      }
    ],
    "output_examples": [
      {
        "input": "Validate this user data: {\"id\": 1, \"email\": \"invalid-email\", \"age\": 200} against the schema requiring valid email format and age between 0-150.",
        "output": [
          "Validation Results: 2 errors found",
          "- email: Invalid email format (expected format: user@domain.com)",
          "- age: Value 200 exceeds maximum allowed (150)",
          "Data Quality Score: 33/100"
        ]
      }
    ],
    "best_practices": [
      "Define schemas and rules before validation to ensure consistency",
      "Validate at system boundaries to catch errors early",
      "Generate detailed error messages to help users fix issues quickly"
    ],
    "anti_patterns": [
      "Skipping validation for performance reasons",
      "Validating only happy path data",
      "Not logging validation failures for monitoring"
    ],
    "faq": [
      {
        "question": "What validation formats are supported?",
        "answer": "JSON Schema Draft 7, Python DataFrame schemas, and custom Python functions for business rules."
      },
      {
        "question": "What is the maximum data size for validation?",
        "answer": "Validation runs on data provided in context. Large datasets should be processed in batches."
      },
      {
        "question": "Can I integrate with my existing validation tools?",
        "answer": "Yes. The skill provides patterns for jsonschema (Python), AJV (JavaScript), and pandas DataFrames."
      },
      {
        "question": "Is my data stored or shared?",
        "answer": "No. The skill operates on data in context only. No data is stored or transmitted externally."
      },
      {
        "question": "Validation fails on valid data. How to troubleshoot?",
        "answer": "Check schema format, ensure validators like Draft7Validator are used, and verify pattern regex syntax."
      },
      {
        "question": "How does this compare to built-in validation?",
        "answer": "This skill provides comprehensive validation including business rules, quality scoring, and detailed reporting beyond basic type checking."
      }
    ]
  },
  "file_structure": [
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md"
    }
  ]
}
