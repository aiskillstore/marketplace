{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-10T13:27:33.501Z",
    "slug": "dyai2025-receiving-code-review",
    "source_url": "https://github.com/DYAI2025/Stoppclock-page/tree/main/stoppclock_speckit/.claude/commands/skills/receiving-code-review",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "2.0.0",
    "source_type": "community",
    "content_hash": "2f6114025609bed0dcf13a9b4a583f625c9f27b91052c9c90a8833af9a83c804",
    "tree_hash": "8b3973fccad0b86ce7039467b982ef05710074ad0014167f093bd1017a6d4ca2"
  },
  "skill": {
    "name": "receiving-code-review",
    "description": "Use when receiving code review feedback, before implementing suggestions, especially if feedback seems unclear or technically questionable - requires technical rigor and verification, not performative agreement or blind implementation",
    "summary": "Use when receiving code review feedback, before implementing suggestions, especially if feedback see...",
    "icon": "üîç",
    "version": "1.0.0",
    "author": "DYAI2025",
    "license": "MIT",
    "category": "coding",
    "tags": [
      "code-review",
      "development",
      "quality",
      "verification",
      "technical"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": []
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "This is a documentation-only skill with no executable code. It provides guidelines for handling code review feedback with technical rigor rather than performative agreement. No security risks detected.",
    "risk_factor_evidence": [],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 1,
    "total_lines": 210,
    "audit_model": "claude",
    "audited_at": "2026-01-10T13:27:33.501Z"
  },
  "content": {
    "user_title": "Handle code reviews with technical rigor",
    "value_statement": "Many developers blindly implement code review feedback without verification, leading to bugs and technical debt. This skill ensures you evaluate feedback technically before implementation, maintaining code quality and preventing unnecessary changes.",
    "seo_keywords": [
      "code review",
      "Claude",
      "Codex",
      "Claude Code",
      "technical verification",
      "code quality",
      "development process",
      "peer review",
      "software engineering",
      "code review best practices"
    ],
    "actual_capabilities": [
      "Provides structured approach to evaluating code review feedback",
      "Prevents blind implementation of suggestions without verification",
      "Includes specific guidelines for handling unclear feedback",
      "Teaches technical pushback when suggestions are incorrect",
      "Emphasizes testing each fix individually",
      "Promotes YAGNI principle for unnecessary features"
    ],
    "limitations": [
      "Requires technical knowledge to evaluate suggestions",
      "May slow down implementation process initially",
      "Assumes reviewer feedback is available",
      "Works best with existing test coverage"
    ],
    "use_cases": [
      {
        "target_user": "Software developers",
        "title": "Evaluate peer review feedback",
        "description": "Systematically assess code review comments before implementation, ensuring technical soundness and avoiding unnecessary changes."
      },
      {
        "target_user": "Senior engineers",
        "title": "Train junior developers",
        "description": "Establish code review culture that values technical correctness over performative agreement and blind implementation."
      },
      {
        "target_user": "Open source contributors",
        "title": "Handle external reviewer suggestions",
        "description": "Navigate code review from project maintainers with appropriate skepticism and technical verification."
      }
    ],
    "prompt_templates": [
      {
        "title": "Basic review handling",
        "scenario": "Simple code review with minor changes",
        "prompt": "I received code review feedback asking to fix variable naming and add error handling. Help me evaluate these suggestions before implementing."
      },
      {
        "title": "Complex architectural feedback",
        "scenario": "Major refactoring suggestions from senior developer",
        "prompt": "A senior developer suggested refactoring our entire authentication system to use a different pattern. How should I evaluate this feedback?"
      },
      {
        "title": "Unclear review comments",
        "scenario": "Review feedback is vague or incomplete",
        "prompt": "My reviewer said 'Fix the performance issues' but didn't specify which ones. How do I handle this unclear feedback?"
      },
      {
        "title": "Conflicting suggestions",
        "scenario": "Multiple reviewers give contradictory advice",
        "prompt": "Two reviewers gave opposite suggestions about database optimization. One says use indexes, another says denormalize. How do I evaluate?"
      }
    ],
    "output_examples": [
      {
        "input": "Review feedback: 'Remove this legacy code, it's not needed anymore'",
        "output": [
          "Checking codebase for usage of legacy code...",
          "Found 3 references in authentication module",
          "Code handles edge case for IE11 compatibility",
          "Response: 'This code handles IE11 edge cases. Remove it and drop IE11 support, or keep it for compatibility?'"
        ]
      }
    ],
    "best_practices": [
      "Always verify suggestions against actual codebase usage before implementing",
      "Ask clarifying questions when feedback is unclear rather than making assumptions",
      "Test each fix individually rather than batching multiple changes",
      "Push back technically when suggestions would break existing functionality"
    ],
    "anti_patterns": [
      "Blindly implementing suggestions without verification or understanding",
      "Using performative agreement like 'Great point!' or 'You're absolutely right!'",
      "Implementing partial feedback when some items are unclear",
      "Avoiding pushback due to social discomfort rather than technical reasons"
    ],
    "faq": [
      {
        "question": "Is this compatible with all code review tools?",
        "answer": "Yes, the principles apply regardless of review platform - GitHub, GitLab, Bitbucket, or internal tools."
      },
      {
        "question": "What if the reviewer gets upset when I push back?",
        "answer": "Use technical reasoning, not defensiveness. Good reviewers appreciate thorough evaluation of their suggestions."
      },
      {
        "question": "How do I integrate this with existing review processes?",
        "answer": "Apply the verification steps mentally before responding to feedback. No process changes needed."
      },
      {
        "question": "Is my data safe when using this approach?",
        "answer": "Yes, this skill doesn't access or transmit any data. It's purely a methodology guide."
      },
      {
        "question": "What if I can't verify a suggestion without significant investigation?",
        "answer": "State the limitation: 'I can't verify this without [X]. Should I investigate or proceed differently?'"
      },
      {
        "question": "How does this compare to other code review approaches?",
        "answer": "This emphasizes technical verification over social niceties, preventing implementation of incorrect suggestions."
      }
    ]
  },
  "file_structure": [
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md"
    },
    {
      "name": "SKILL.zip",
      "type": "file",
      "path": "SKILL.zip"
    }
  ]
}
