{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-10T10:25:59.786Z",
    "slug": "ariegoldkin-ai-native-development",
    "source_url": "https://github.com/ArieGoldkin/ai-agent-hub/tree/main/skills/ai-native-development",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "2.0.0",
    "source_type": "community",
    "content_hash": "127be8aebd7bf9c6820445c35b1e61a792061d43eb73bfbe112b788c77da4c0d",
    "tree_hash": "86f0b58e31d958f459762be9be415c4ef0aa936919fdb03508ec8448e330ebf4"
  },
  "skill": {
    "name": "ai-native-development",
    "description": "Build AI-first applications with RAG pipelines, embeddings, vector databases, agentic workflows, and LLM integration. Master prompt engineering, function calling, streaming responses, and cost optimization for 2025+ AI development.",
    "summary": "Build AI-first applications with RAG pipelines, embeddings, vector databases, agentic workflows, and...",
    "icon": "ðŸ¤–",
    "version": "1.0.0",
    "author": "AI Agent Hub",
    "license": "MIT",
    "category": "coding",
    "tags": [
      "ai",
      "llm",
      "rag",
      "embeddings",
      "vector-database",
      "agents",
      "langchain",
      2025
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": []
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "This skill is a pure knowledge module containing only documentation and TypeScript code templates for building AI applications. No executable scripts, no network behavior beyond documented API patterns, no filesystem access outside the skill directory, and no suspicious capabilities detected. Safe for marketplace publication.",
    "risk_factor_evidence": [],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [
      {
        "title": "eval() usage in calculator tool example",
        "description": "The agentic-workflows.md reference contains a calculator tool example using eval(expression) at line 88-89. While this is documentation code (not executable), using eval() with unvalidated user input creates code injection risk. Recommended: Use a math expression parser library instead.",
        "locations": [
          {
            "file": "references/agentic-workflows.md",
            "line_start": 87,
            "line_end": 89
          }
        ]
      }
    ],
    "dangerous_patterns": [],
    "files_scanned": 10,
    "total_lines": 5589,
    "audit_model": "claude",
    "audited_at": "2026-01-10T10:25:59.786Z"
  },
  "content": {
    "user_title": "Build AI-First Applications with RAG and Agents",
    "value_statement": "Building AI-native applications requires specialized patterns for RAG pipelines, vector databases, and agentic workflows. This skill provides comprehensive templates, reference implementations, and checklists for integrating LLMs, implementing semantic search, and creating autonomous AI agents.",
    "seo_keywords": [
      "ai-native development",
      "rag pipelines",
      "vector databases",
      "llm integration",
      "anthropic claude",
      "openai gpt",
      "agentic workflows",
      "embeddings",
      "semantic search",
      "claude code"
    ],
    "actual_capabilities": [
      "Implement RAG (Retrieval-Augmented Generation) pipelines with citations",
      "Build agentic workflows using ReAct pattern and tool calling",
      "Set up vector databases (Pinecone, Chroma, Weaviate, Qdrant) for semantic search",
      "Create multi-agent systems with orchestrator patterns",
      "Optimize AI costs through model selection and prompt caching",
      "Add observability with LangSmith and LangFuse tracing"
    ],
    "limitations": [
      "Does not include pre-built API keys or LLM service accounts",
      "Requires external LLM API subscriptions (OpenAI, Anthropic) for runtime",
      "Vector database hosting must be configured separately",
      "Templates are starting points that need customization for production"
    ],
    "use_cases": [
      {
        "target_user": "Full-stack developers",
        "title": "Build RAG Chatbots",
        "description": "Create intelligent chatbots that retrieve context from your documents and answer questions with citations."
      },
      {
        "target_user": "ML Engineers",
        "title": "Deploy Vector Search",
        "description": "Implement semantic search systems using embeddings and vector databases for knowledge retrieval at scale."
      },
      {
        "target_user": "Application Architects",
        "title": "Design AI Agents",
        "description": "Architect autonomous agent systems that reason, plan, and take actions using tools and multi-agent collaboration."
      }
    ],
    "prompt_templates": [
      {
        "title": "Basic RAG Query",
        "scenario": "Retrieve context for a question",
        "prompt": "Using the RAG pipeline pattern, answer this question about our documentation: [INSERT QUESTION]"
      },
      {
        "title": "Agent Tool Use",
        "scenario": "Create an agent with tools",
        "prompt": "Build a ReAct agent that can [TASK] using these tools: [LIST TOOLS]"
      },
      {
        "title": "Hybrid Search",
        "scenario": "Combine semantic and keyword search",
        "prompt": "Implement hybrid search combining vector similarity with keyword matching for [USE CASE]"
      },
      {
        "title": "Multi-Agent System",
        "scenario": "Coordinate specialized agents",
        "prompt": "Design a multi-agent system with [N] specialized agents for [COMPLEX TASK]"
      }
    ],
    "output_examples": [
      {
        "input": "How do I build a RAG pipeline for my documentation?",
        "output": [
          "Key components: document ingestion with chunking, embedding generation using text-embedding-3-small, vector storage in Pinecone/Chroma, retrieval with hybrid search, and LLM generation with citations.",
          "Recommended flow: chunk documents (500-1000 tokens, 10% overlap) â†’ create embeddings â†’ upsert to vector DB â†’ query with user question â†’ generate answer with context â†’ add source citations.",
          "See templates/rag-pipeline-template.ts for complete implementation."
        ]
      }
    ],
    "best_practices": [
      "Keep context windows under 75% of model limits and use compression for long documents",
      "Implement hybrid search (semantic + keyword) for better retrieval recall",
      "Add citation tracking to validate that answers are grounded in retrieved context"
    ],
    "anti_patterns": [
      "Sending entire documents as context without chunking",
      "Using high temperature (above 0.3) for factual question answering",
      "Skipping input validation, enabling prompt injection attacks"
    ],
    "faq": [
      {
        "question": "Which LLM providers are supported?",
        "answer": "OpenAI GPT-4/3.5, Anthropic Claude, and any provider with OpenAI-compatible API format."
      },
      {
        "question": "What is the maximum context window?",
        "answer": "Depends on model: GPT-4 Turbo supports 128K tokens, Claude 3 supports 200K tokens."
      },
      {
        "question": "Can this integrate with my existing codebase?",
        "answer": "Yes. Templates use standard patterns and can be adapted to any TypeScript/Node.js project."
      },
      {
        "question": "Is my data sent to external services?",
        "answer": "Documents are sent to your chosen LLM and vector DB providers only. No data is sent to the skill developers."
      },
      {
        "question": "Why is retrieval returning irrelevant results?",
        "answer": "Try adjusting chunk size, adding overlap, using hybrid search, or implementing re-ranking for better relevance."
      },
      {
        "question": "How does this compare to fine-tuning?",
        "answer": "RAG is cheaper, more flexible, and allows real-time updates. Fine-tuning is better for consistent style/tone."
      }
    ]
  },
  "file_structure": [
    {
      "name": "checklists",
      "type": "dir",
      "path": "checklists",
      "children": [
        {
          "name": "ai-implementation-checklist.md",
          "type": "file",
          "path": "checklists/ai-implementation-checklist.md"
        }
      ]
    },
    {
      "name": "examples",
      "type": "dir",
      "path": "examples",
      "children": [
        {
          "name": "chatbot-with-rag-example.ts",
          "type": "file",
          "path": "examples/chatbot-with-rag-example.ts"
        }
      ]
    },
    {
      "name": "references",
      "type": "dir",
      "path": "references",
      "children": [
        {
          "name": "agentic-workflows.md",
          "type": "file",
          "path": "references/agentic-workflows.md"
        },
        {
          "name": "function-calling.md",
          "type": "file",
          "path": "references/function-calling.md"
        },
        {
          "name": "observability.md",
          "type": "file",
          "path": "references/observability.md"
        },
        {
          "name": "rag-patterns.md",
          "type": "file",
          "path": "references/rag-patterns.md"
        },
        {
          "name": "vector-databases.md",
          "type": "file",
          "path": "references/vector-databases.md"
        }
      ]
    },
    {
      "name": "templates",
      "type": "dir",
      "path": "templates",
      "children": [
        {
          "name": "agent-workflow-template.ts",
          "type": "file",
          "path": "templates/agent-workflow-template.ts"
        },
        {
          "name": "rag-pipeline-template.ts",
          "type": "file",
          "path": "templates/rag-pipeline-template.ts"
        }
      ]
    },
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md"
    }
  ]
}
