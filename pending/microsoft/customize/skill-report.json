{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-02-21T11:05:59.444Z",
    "slug": "microsoft-customize",
    "source_url": "https://github.com/microsoft/github-copilot-for-azure/tree/main/plugin/skills/microsoft-foundry/models/deploy-model/customize",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "3.0.0",
    "source_type": "community",
    "content_hash": "c4a4ef6c3cb448e89cce4480c976b492718d277fc59a65aca08427e470d082af",
    "tree_hash": "8b40fd62a8c7d4b1f773839633e33c12f30e0609570ef86fbac7ed37968622f0"
  },
  "skill": {
    "name": "customize",
    "description": "Interactive guided deployment flow for Azure OpenAI models with full customization control. Step-by-step selection of model version, SKU (GlobalStandard/Standard/ProvisionedManaged), capacity, RAI policy (content filter), and advanced options (dynamic quota, priority processing, spillover). USE FOR: custom deployment, customize model deployment, choose version, select SKU, set capacity, configure content filter, RAI policy, deployment options, detailed deployment, advanced deployment, PTU deployment, provisioned throughput. DO NOT USE FOR: quick deployment to optimal region (use preset).",
    "summary": "Interactive guided deployment workflow for Azure OpenAI models with full customization control over version, SKU, capacity, content filtering, and advanced options.",
    "icon": "ðŸ“¦",
    "version": "1.0.0",
    "author": "microsoft",
    "license": "MIT",
    "tags": [
      "azure",
      "openai",
      "deployment",
      "ai-foundry",
      "model-deployment"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": [],
    "category": "devops"
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "This is an official Microsoft skill for Azure AI Foundry model deployment. The static analyzer flagged 124 potential issues (external_commands, network, filesystem), but all are false positives. The detected patterns are legitimate Azure CLI commands, standard Azure Management API endpoints, and documentation path references. No actual security risks confirmed after semantic evaluation.",
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 4,
    "total_lines": 633,
    "audit_model": "claude",
    "audited_at": "2026-02-21T11:05:59.444Z",
    "risk_factors": []
  },
  "content": {
    "user_title": "Deploy Azure OpenAI Models with Full Customization",
    "value_statement": "This skill provides an interactive guided workflow for deploying Azure OpenAI models with precise control over version, SKU, capacity, content filtering, and advanced deployment options. Ideal when you need specific configuration rather than quick defaults.",
    "seo_keywords": [
      "azure openai deployment",
      "azure ai foundry",
      "claude code",
      "codex",
      "azure openai customize",
      "ptu deployment",
      "provisioned throughput",
      "azure model deployment",
      "azure openai sku",
      "azure content filtering"
    ],
    "actual_capabilities": [
      "Interactive guided deployment with 14 phases covering authentication, project verification, model selection, SKU configuration, capacity setup, RAI policy selection, and advanced options",
      "Cross-region fallback - automatically searches all regions when current region has no capacity",
      "SKU selection with live quota checking - queries Azure API to show only deployable SKUs",
      "Advanced options including dynamic quota (GlobalStandard), priority processing (PTU), and spillover configuration",
      "Capacity validation with min/max/step enforcement and PTU calculator for provisioned deployments",
      "Version upgrade policy configuration with options for auto-upgrade, manual, or expiration-based upgrades"
    ],
    "limitations": [
      "Requires Azure CLI authentication and appropriate Cognitive Services Contributor permissions",
      "Does not create new Azure AI Foundry projects - use separate project creation skill",
      "Quota increases must be requested separately via the quota skill",
      "Does not support real-time deployment monitoring beyond initial provisioning state"
    ],
    "use_cases": [
      {
        "title": "Production Deployment with Specific Requirements",
        "description": "Deploy a model with exact capacity, specific version, and custom RAI policy for production workloads requiring precise control.",
        "target_user": "DevOps engineers and ML platform teams"
      },
      {
        "title": "PTU Deployment for Predictable Workloads",
        "description": "Reserve provisioned throughput units for high-volume applications requiring guaranteed response times and fixed monthly costs.",
        "target_user": "Enterprise applications with consistent high-volume usage"
      },
      {
        "title": "Development Environment Setup",
        "description": "Quickly deploy a minimal capacity deployment for development and testing with cost-effective Standard SKU.",
        "target_user": "Developers and data scientists"
      }
    ],
    "prompt_templates": [
      {
        "title": "Basic Model Deployment",
        "prompt": "Deploy gpt-4o to Azure AI Foundry with default settings (GlobalStandard SKU, 10K TPM capacity, dynamic quota enabled).",
        "scenario": "Quick deployment with sensible defaults"
      },
      {
        "title": "Production Deployment with Custom Capacity",
        "prompt": "Deploy gpt-4o for production use with 50K TPM capacity, GlobalStandard SKU, dynamic quota, and name it 'gpt-4o-production'.",
        "scenario": "Production deployment with specific capacity"
      },
      {
        "title": "PTU Deployment for High Volume",
        "prompt": "Deploy gpt-4o with ProvisionedManaged SKU, 200 PTU capacity, and priority processing enabled for guaranteed throughput.",
        "scenario": "Reserved capacity for predictable workloads"
      },
      {
        "title": "Cross-Region Deployment",
        "prompt": "Deploy gpt-4o-mini with Standard SKU and 5K TPM. If no capacity in current region, find the region with best availability.",
        "scenario": "Finding capacity across regions"
      }
    ],
    "output_examples": [
      {
        "input": "Deploy gpt-4o with GlobalStandard SKU and 10K TPM capacity",
        "output": "Deployment Configuration:\n- Model: gpt-4o\n- Version: latest\n- SKU: GlobalStandard\n- Capacity: 10,000 TPM\n- Region: eastus\n- Dynamic Quota: Enabled\n- RAI Policy: Microsoft.DefaultV2\n- Upgrade Policy: OnceNewDefaultVersionAvailable\n\nDeployment Status: Succeeded\nEndpoint: https://account.openai.azure.com/"
      },
      {
        "input": "Deploy with PTU for high-volume workload",
        "output": "PTU Deployment Configuration:\n- Model: gpt-4o\n- SKU: ProvisionedManaged\n- Capacity: 200 PTU\n- Priority Processing: Enabled\n- Region: eastus\n- RAI Policy: Microsoft.DefaultV2\n\nGuaranteed throughput: ~100K TPM input + ~50K TPM output\nMonthly cost: Fixed based on PTU allocation"
      }
    ],
    "best_practices": [
      "Start with recommended capacity and monitor usage with Azure Monitor before scaling up",
      "Use GlobalStandard with dynamic quota for variable production workloads to maximize cost efficiency",
      "Enable spillover for production deployments to handle unexpected traffic peaks gracefully"
    ],
    "anti_patterns": [
      "Setting capacity to maximum without testing - start conservative and scale based on actual usage",
      "Ignoring cross-region fallback when initial region has no capacity - always check availability",
      "Using Standard SKU for production with variable traffic - GlobalStandard with dynamic quota is more cost-effective"
    ],
    "faq": [
      {
        "question": "What is the difference between GlobalStandard and Standard SKU?",
        "answer": "GlobalStandard offers multi-region high availability and dynamic quota scaling, while Standard is single-region and more cost-effective for development/testing. Use GlobalStandard for production."
      },
      {
        "question": "How do I calculate PTU capacity?",
        "answer": "Use the formula: PTU = (Input TPM x 0.001) + (Output TPM x 0.002) + (Requests/min x 0.1). Add 2x headroom for best performance."
      },
      {
        "question": "What happens if no capacity is available in my region?",
        "answer": "The skill automatically queries all Azure regions and presents available options. You can select a different region or request a quota increase."
      },
      {
        "question": "Can I change capacity after deployment?",
        "answer": "Yes, you can update capacity using 'az cognitiveservices account deployment update' command. SKU changes require creating a new deployment."
      },
      {
        "question": "What is dynamic quota?",
        "answer": "Dynamic quota allows your deployment to scale beyond base capacity when additional capacity is available in the region, at no extra cost. Available for GlobalStandard SKU only."
      },
      {
        "question": "How do I configure content filtering?",
        "answer": "Select RAI policy during deployment. Microsoft.DefaultV2 provides balanced filtering. Microsoft.Prompt-Shield adds protection against prompt injection attacks."
      }
    ]
  },
  "file_structure": [
    {
      "name": "references",
      "type": "dir",
      "path": "references",
      "children": [
        {
          "name": "customize-guides.md",
          "type": "file",
          "path": "references/customize-guides.md",
          "lines": 125
        },
        {
          "name": "customize-workflow.md",
          "type": "file",
          "path": "references/customize-workflow.md",
          "lines": 259
        }
      ]
    },
    {
      "name": "EXAMPLES.md",
      "type": "file",
      "path": "EXAMPLES.md",
      "lines": 84
    },
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md",
      "lines": 165
    }
  ]
}
