{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-01T23:53:10.024Z",
    "slug": "wshobson-airflow-dag-patterns",
    "source_url": "https://github.com/wshobson/agents/tree/main/plugins/data-engineering/skills/airflow-dag-patterns",
    "source_ref": "main",
    "model": "codex",
    "analysis_version": "2.0.0",
    "source_type": "community"
  },
  "skill": {
    "name": "airflow-dag-patterns",
    "description": "Build production Apache Airflow DAGs with best practices for operators, sensors, testing, and deployment. Use when creating data pipelines, orchestrating workflows, or scheduling batch jobs.",
    "summary": "Build production Apache Airflow DAGs with best practices for operators, sensors, testing, and deploy...",
    "icon": "ðŸŒ€",
    "version": "1.0.0",
    "license": "MIT",
    "category": "data",
    "tags": [
      "airflow",
      "dag",
      "orchestration",
      "etl",
      "testing"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": [
      "network"
    ]
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "No indicators of data theft, malicious execution, or obfuscation were found. Content is documentation and example code aligned with the skill purpose.",
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 1,
    "total_lines": 523,
    "audit_model": "codex",
    "audited_at": "2026-01-01T23:53:10.023Z"
  },
  "content": {
    "user_title": "Build production Airflow DAGs with proven patterns",
    "value_statement": "Airflow DAGs can fail when structure and retries are not consistent. This skill provides clear patterns for design, sensors, testing, and alerts.",
    "seo_keywords": [
      "Apache Airflow",
      "DAG patterns",
      "ETL pipelines",
      "workflow orchestration",
      "TaskFlow API",
      "Claude",
      "Codex",
      "Claude Code",
      "data engineering",
      "Airflow testing"
    ],
    "actual_capabilities": [
      "Provide TaskFlow API pattern with extraction, transform, load, and notifications",
      "Show dynamic DAG generation from configuration objects",
      "Demonstrate branching and conditional task routing",
      "Provide sensor patterns for S3, external tasks, and custom APIs",
      "Outline error handling with callbacks and trigger rules",
      "Include unit testing patterns with DagBag assertions"
    ],
    "limitations": [
      "Does not run or validate DAGs in a live Airflow environment",
      "Does not configure cloud credentials or secrets management",
      "Examples use placeholder services and paths that require adaptation",
      "Does not generate deployment infrastructure files"
    ],
    "use_cases": [
      {
        "target_user": "Data engineer",
        "title": "Standardize ETL DAGs",
        "description": "Create consistent DAG structures, retries, and schedules for daily and hourly pipelines."
      },
      {
        "target_user": "Platform engineer",
        "title": "Add operational safeguards",
        "description": "Apply sensors, alerts, and failure callbacks to improve reliability."
      },
      {
        "target_user": "Analytics engineer",
        "title": "Test DAG integrity",
        "description": "Write unit tests to ensure DAGs load, have no cycles, and respect dependencies."
      }
    ],
    "prompt_templates": [
      {
        "title": "Start a simple DAG",
        "scenario": "New ETL pipeline with one extract task",
        "prompt": "Create a daily Airflow DAG with start, extract, and end tasks using PythonOperator and basic default_args."
      },
      {
        "title": "Use TaskFlow API",
        "scenario": "ETL with XCom passing",
        "prompt": "Draft a TaskFlow API DAG with extract, transform, and load tasks that pass data between them safely."
      },
      {
        "title": "Add sensors and waits",
        "scenario": "Upstream dependency management",
        "prompt": "Show a pattern for waiting on S3 data and an upstream DAG before processing."
      },
      {
        "title": "Harden error handling",
        "scenario": "Alerting and cleanup",
        "prompt": "Add failure callbacks, retries, and cleanup tasks that run on failure for a critical DAG."
      }
    ],
    "output_examples": [
      {
        "input": "Give me a safe pattern for a daily ETL DAG with retries, testing, and a failure callback.",
        "output": [
          "Use default_args with retries, retry_delay, and exponential backoff",
          "Define a linear start -> extract -> load -> end structure",
          "Add a task failure callback to report errors",
          "Create DagBag tests for load errors, task count, and dependencies"
        ]
      }
    ],
    "best_practices": [
      "Keep tasks idempotent and avoid heavy logic in DAG files",
      "Use TaskFlow API and sensor reschedule mode for efficiency",
      "Add unit tests for DAG loading, structure, and cycles"
    ],
    "anti_patterns": [
      "Using depends_on_past for most tasks",
      "Hardcoding dates instead of Airflow macros",
      "Storing mutable global state in DAG files"
    ],
    "faq": [
      {
        "question": "Is this compatible with Airflow 2.x",
        "answer": "Yes, the patterns target Airflow 2.x and include TaskFlow API examples."
      },
      {
        "question": "What are the limits of the examples",
        "answer": "Examples are templates and require adapting paths, credentials, and environments."
      },
      {
        "question": "Can it integrate with my existing DAGs",
        "answer": "Yes, you can apply the patterns to existing DAG files and refactor safely."
      },
      {
        "question": "Does it access or store my data",
        "answer": "No, it provides guidance only and does not read or transmit data."
      },
      {
        "question": "What if my DAG fails to import",
        "answer": "Use the DagBag tests to identify import errors and fix missing dependencies."
      },
      {
        "question": "How does it compare to generic coding help",
        "answer": "It focuses on Airflow-specific patterns, sensors, testing, and operational safety."
      }
    ]
  },
  "file_structure": [
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md"
    }
  ]
}