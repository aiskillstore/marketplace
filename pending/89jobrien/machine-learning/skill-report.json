{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-10T09:29:15.005Z",
    "slug": "89jobrien-machine-learning",
    "source_url": "https://github.com/89jobrien/steve/tree/main/steve/skills/machine-learning",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "2.0.0",
    "source_type": "community",
    "content_hash": "0d45a3b3720fbc923d62041401f7ce973b55d89faa31342eb79806b2941eb442",
    "tree_hash": "9cbc01040065191b362ad52c2f1b587d1fdbeb5bbef02f57796689f887eb420d"
  },
  "skill": {
    "name": "machine-learning",
    "description": "Machine learning development patterns, model training, evaluation, and deployment. Use when building ML pipelines, training models, feature engineering, model evaluation, or deploying ML systems to production.",
    "summary": "Machine learning development patterns, model training, evaluation, and deployment. Use when building...",
    "icon": "ðŸ§ ",
    "version": "1.0.1",
    "author": "Joseph OBrien",
    "license": "UNLICENSED",
    "category": "data",
    "tags": [
      "machine-learning",
      "model-training",
      "data-science",
      "mlops"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": []
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "Pure documentation skill with no executable code. Contains only markdown guidance for ML development patterns. No scripts, network calls, file system access beyond its own files, or command execution capabilities.",
    "risk_factor_evidence": [],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 2,
    "total_lines": 374,
    "audit_model": "claude",
    "audited_at": "2026-01-10T09:29:15.005Z"
  },
  "content": {
    "user_title": "Apply ML Development Best Practices",
    "value_statement": "Building machine learning systems requires navigating complex choices from data preprocessing to production deployment. This skill provides battle-tested patterns for the complete ML lifecycle.",
    "seo_keywords": [
      "machine learning",
      "ML development",
      "model training",
      "feature engineering",
      "MLOps",
      "Claude",
      "Codex",
      "Claude Code",
      "data preprocessing",
      "model evaluation"
    ],
    "actual_capabilities": [
      "Guide ML problem definition and metric selection",
      "Provide data preprocessing and feature engineering patterns",
      "Recommend model selection based on data characteristics",
      "Explain hyperparameter tuning strategies",
      "Outline production deployment patterns and monitoring",
      "Share MLOps best practices for experiment tracking"
    ],
    "limitations": [
      "Does not execute code or interact with ML frameworks directly",
      "Does not provide custom model implementations or trained weights",
      "Cannot access external data sources or APIs",
      "Does not replace domain expertise for specific use cases"
    ],
    "use_cases": [
      {
        "target_user": "Data scientists",
        "title": "Structure ML Projects",
        "description": "Follow proven patterns from data prep through model deployment"
      },
      {
        "target_user": "ML Engineers",
        "title": "Deploy Models to Production",
        "description": "Learn serving patterns, monitoring strategies, and maintenance schedules"
      },
      {
        "target_user": "Software Engineers",
        "title": "Add ML to Applications",
        "description": "Integrate ML capabilities using REST APIs and batch inference"
      }
    ],
    "prompt_templates": [
      {
        "title": "Problem Definition",
        "scenario": "Start new ML project",
        "prompt": "Help me define the right ML problem type and success metrics for [use case description]."
      },
      {
        "title": "Data Preprocessing",
        "scenario": "Prepare data for training",
        "prompt": "What are the best practices for preprocessing [data type] with [specific challenges]?"
      },
      {
        "title": "Model Selection",
        "scenario": "Choose algorithms",
        "prompt": "Recommend appropriate models for [data size] records with [problem type]. Explain trade-offs."
      },
      {
        "title": "Production Deployment",
        "scenario": "Deploy trained model",
        "prompt": "What deployment patterns work best for [use case] with requirements: [latency, throughput]?"
      }
    ],
    "output_examples": [
      {
        "input": "Help me build a spam classifier with 10K labeled emails",
        "output": [
          "Problem type: Binary classification",
          "Recommended metrics: AUC-ROC (primary), F1 (secondary)",
          "Good starting models: Logistic Regression, Random Forest, or SVM",
          "For 10K samples, use stratified split to maintain class balance",
          "Consider TF-IDF or transformer embeddings for text features",
          "Apply SMOTE if class imbalance exceeds 10:1 ratio"
        ]
      }
    ],
    "best_practices": [
      "Always use held-out test sets for final evaluation after validating on cross-validation",
      "Fit preprocessing on training data only, then transform test data to prevent leakage",
      "Track experiments with version control for code, data, and model artifacts"
    ],
    "anti_patterns": [
      "Using accuracy alone for imbalanced classification problems",
      "Fitting preprocessing steps on the entire dataset before splitting",
      "Deploying models without monitoring for data drift and performance degradation"
    ],
    "faq": [
      {
        "question": "What ML frameworks does this skill support?",
        "answer": "Framework-agnostic guidance applicable to scikit-learn, TensorFlow, PyTorch, XGBoost, and similar libraries."
      },
      {
        "question": "What data sizes can Claude handle with this skill?",
        "answer": "The skill provides guidance for small (<10K), medium (10K-1M), and large (>1M) datasets with appropriate algorithm recommendations."
      },
      {
        "question": "How does this skill integrate with other skills?",
        "answer": "Works with performance (latency), testing (ML testing), database-optimization (feature stores), and debugging skills."
      },
      {
        "question": "Is my data safe when using this skill?",
        "answer": "Yes. This skill only provides guidance patterns. No data is stored, transmitted, or processed externally."
      },
      {
        "question": "Why is my model performing poorly on new data?",
        "answer": "Common causes: data leakage during preprocessing, overfitting to validation set, distribution shift between training and production data."
      },
      {
        "question": "How does this compare to AutoML tools?",
        "answer": "This skill explains concepts and patterns. AutoML tools automate algorithm selection. Understanding both approaches together is most effective."
      }
    ]
  },
  "file_structure": [
    {
      "name": "references",
      "type": "dir",
      "path": "references",
      "children": [
        {
          "name": "preprocessing.md",
          "type": "file",
          "path": "references/preprocessing.md"
        }
      ]
    },
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md"
    }
  ]
}
