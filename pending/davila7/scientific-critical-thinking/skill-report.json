{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-07T00:44:00.977Z",
    "slug": "davila7-scientific-critical-thinking",
    "source_url": "https://github.com/davila7/claude-code-templates/tree/main/cli-tool/components/skills/scientific/scientific-critical-thinking",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "2.0.0",
    "source_type": "community",
    "content_hash": "64fb79cdba3311e9b91fc2fd80b2046a7275ece2f30375c082a8db7bf0ddd02b",
    "tree_hash": "af92c975b80fe79462d9063e6371bc966578b43c0f93e1d9e90fdbf7132c4dd4"
  },
  "skill": {
    "name": "scientific-critical-thinking",
    "description": "Evaluate research rigor. Assess methodology, experimental design, statistical validity, biases, confounding, evidence quality (GRADE, Cochrane ROB), for critical analysis of scientific claims.",
    "summary": "Evaluate research rigor. Assess methodology, experimental design, statistical validity, biases, conf...",
    "icon": "ðŸ”¬",
    "version": "1.0.0",
    "author": "davila7",
    "license": "MIT",
    "category": "research",
    "tags": [
      "critical thinking",
      "scientific evaluation",
      "research methodology",
      "evidence assessment",
      "bias detection"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": []
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "Pure documentation skill containing educational content about scientific methodology and critical thinking frameworks. No executable code, network calls, filesystem access, or system modifications detected.",
    "risk_factor_evidence": [],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 7,
    "total_lines": 2969,
    "audit_model": "claude",
    "audited_at": "2026-01-07T00:44:00.977Z"
  },
  "content": {
    "user_title": "Evaluate scientific research rigor",
    "value_statement": "Scientific claims often go unquestioned despite containing methodological flaws, biases, and overstated conclusions. This skill provides systematic frameworks to assess research quality using established methodologies like GRADE and Cochrane ROB, enabling accurate evidence evaluation.",
    "seo_keywords": [
      "scientific critical thinking",
      "research evaluation",
      "evidence assessment",
      "GRADE framework",
      "Cochrane ROB",
      "methodology critique",
      "bias detection",
      "statistical analysis",
      "scientific claims",
      "Claude Code skill"
    ],
    "actual_capabilities": [
      "Evaluate research methodology for rigor, validity, and potential flaws",
      "Identify cognitive, selection, measurement, and analysis biases",
      "Assess statistical methods, p-value interpretation, and effect sizes",
      "Apply GRADE and Cochrane risk of bias frameworks",
      "Detect logical fallacies in scientific arguments",
      "Provide guidance for designing rigorous experiments"
    ],
    "limitations": [
      "Cannot access external databases or search literature directly",
      "Does not perform statistical calculations or data analysis",
      "Cannot replace domain expert review for specialized fields",
      "Based on provided text rather than live data sources"
    ],
    "use_cases": [
      {
        "target_user": "Researchers",
        "title": "Review papers critically",
        "description": "Evaluate submitted manuscripts or published studies for methodological soundness and bias"
      },
      {
        "target_user": "Students",
        "title": "Learn evidence evaluation",
        "description": "Develop skills to assess scientific claims and understand research quality"
      },
      {
        "target_user": "Professionals",
        "title": "Inform evidence-based decisions",
        "description": "Evaluate research supporting policy or business decisions"
      }
    ],
    "prompt_templates": [
      {
        "title": "Paper Review",
        "scenario": "Evaluating a research paper",
        "prompt": "Critically evaluate this research methodology for rigor and bias. Assess the study design, statistical methods, confounding control, and whether conclusions are justified by the data."
      },
      {
        "title": "Claim Assessment",
        "scenario": "Evaluating scientific claims",
        "prompt": "Evaluate this scientific claim. What evidence supports it? What biases or logical fallacies might be present? How strong is the evidence?"
      },
      {
        "title": "Design Review",
        "scenario": "Planning a study",
        "prompt": "Review my experimental design. What threats to internal and external validity exist? What biases should I control for? How can I improve the methodology?"
      },
      {
        "title": "Meta-Analysis",
        "scenario": "Synthesizing evidence",
        "prompt": "Compare the evidence quality across these studies using GRADE criteria. Which findings are most reliable and why? What are the main sources of bias?"
      }
    ],
    "output_examples": [
      {
        "input": "Evaluate this study: A randomized trial of 50 patients found p=0.04 for the treatment effect and concludes the drug is effective.",
        "output": [
          "Methodological concerns: Small sample (n=50) may lead to inflated effect sizes and reduced reproducibility",
          "Statistical issues: P=0.04 is just below threshold; check for multiple comparisons or selective reporting",
          "Conclusion overstatement: 'Effective' needs clinical significance assessment, not just statistical significance",
          "Missing information: Power analysis, effect size, confidence intervals, and attrition data not reported",
          "Recommendation: Results are suggestive but require replication in adequately powered trial"
        ]
      }
    ],
    "best_practices": [
      "Distinguish statistical significance from practical importance",
      "Always consider alternative explanations and confounding variables",
      "Weight evidence by study quality, not just design level"
    ],
    "anti_patterns": [
      "Accepting causal claims from correlational data",
      "Ignoring sample size and power when evaluating significance",
      "Treating published research as definitively proven"
    ],
    "faq": [
      {
        "question": "What frameworks does this skill use?",
        "answer": "GRADE for evidence quality, Cochrane ROB for bias, plus established scientific methodology principles."
      },
      {
        "question": "Can it replace expert review?",
        "answer": "No, it provides structured analysis but domain expertise remains essential for specialized fields."
      },
      {
        "question": "Does it access databases?",
        "answer": "No, it evaluates text you provide rather than searching external literature."
      },
      {
        "question": "Is my data safe?",
        "answer": "Yes, this skill contains only documentation and does not transmit or store data externally."
      },
      {
        "question": "What study designs can it evaluate?",
        "answer": "RCTs, cohort studies, case-control, cross-sectional, meta-analyses, and more."
      },
      {
        "question": "How is this different from general analysis?",
        "answer": "Specialized focus on scientific rigor with domain-specific frameworks for methodology and bias assessment."
      }
    ]
  },
  "file_structure": [
    {
      "name": "references",
      "type": "dir",
      "path": "references",
      "children": [
        {
          "name": "common_biases.md",
          "type": "file",
          "path": "references/common_biases.md"
        },
        {
          "name": "evidence_hierarchy.md",
          "type": "file",
          "path": "references/evidence_hierarchy.md"
        },
        {
          "name": "experimental_design.md",
          "type": "file",
          "path": "references/experimental_design.md"
        },
        {
          "name": "logical_fallacies.md",
          "type": "file",
          "path": "references/logical_fallacies.md"
        },
        {
          "name": "scientific_method.md",
          "type": "file",
          "path": "references/scientific_method.md"
        },
        {
          "name": "statistical_pitfalls.md",
          "type": "file",
          "path": "references/statistical_pitfalls.md"
        }
      ]
    },
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md"
    }
  ]
}
