{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-07T01:22:58.987Z",
    "slug": "davila7-mcp-builder",
    "source_url": "https://github.com/davila7/claude-code-templates/tree/main/cli-tool/components/skills/development/mcp-builder",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "2.0.0",
    "source_type": "community",
    "content_hash": "cc36ccd15ba6c19c02fabfcc485493b26c142976ccb99c49f90cb488208d1bfc",
    "tree_hash": "89c8cfa8f0da369d867576dd7ced73b987adb503bea5b7a1e0a3c3b40adc99c0"
  },
  "skill": {
    "name": "mcp-builder",
    "description": "Guide for creating high-quality MCP (Model Context Protocol) servers that enable LLMs to interact with external services through well-designed tools. Use when building MCP servers to integrate external APIs or services, whether in Python (FastMCP) or Node/TypeScript (MCP SDK).",
    "summary": "Guide for creating high-quality MCP (Model Context Protocol) servers that enable LLMs to interact wi...",
    "icon": "ðŸ”§",
    "version": "1.0.0",
    "author": "davila7",
    "license": "Complete terms in LICENSE.txt",
    "category": "development",
    "tags": [
      "mcp",
      "api integration",
      "llm tools",
      "python",
      "typescript"
    ],
    "supported_tools": [
      "claude",
      "claude-code"
    ],
    "risk_factors": []
  },
  "security_audit": {
    "risk_level": "low",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "This is a documentation and guidance skill for building MCP servers. Contains Python testing scripts that launch MCP servers as subprocesses and make API calls to Anthropic for evaluation purposes. All capabilities are appropriate for an MCP development toolkit.",
    "risk_factor_evidence": [],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [
      {
        "title": "Subprocess execution for MCP server testing",
        "description": "The evaluation.py script launches MCP servers as subprocesses via stdio transport (lines 431-436). This is necessary for testing MCP servers but involves executing external code. The subprocess runs with the same privileges as the calling process. Example: `python evaluation.py -t stdio -c python -a my_server.py evaluation.xml`",
        "locations": [
          {
            "file": "scripts/evaluation.py",
            "line_start": 431,
            "line_end": 436
          }
        ]
      },
      {
        "title": "Anthropic API calls for evaluation",
        "description": "The evaluation script makes API calls to Anthropic (lines 96-103, 137-144) to test MCP servers with Claude. This involves sending evaluation questions and receiving responses over the network. The API key should be provided via ANTHROPIC_API_KEY environment variable.",
        "locations": [
          {
            "file": "scripts/evaluation.py",
            "line_start": 96,
            "line_end": 144
          }
        ]
      }
    ],
    "dangerous_patterns": [],
    "files_scanned": 10,
    "total_lines": 4267,
    "audit_model": "claude",
    "audited_at": "2026-01-07T01:22:58.987Z"
  },
  "content": {
    "user_title": "Build MCP servers for LLM tool integration",
    "value_statement": "Creating effective MCP servers requires understanding agent-centric design, proper tool definitions, and evaluation strategies. This skill provides comprehensive guidance for building production-ready MCP servers in Python or TypeScript that enable LLMs to interact with external services through well-designed tools.",
    "seo_keywords": [
      "mcp server",
      "model context protocol",
      "claude mcp",
      "llm tool integration",
      "fastmcp",
      "mcp python sdk",
      "mcp typescript sdk",
      "api integration",
      "mcp development",
      "claude code skills"
    ],
    "actual_capabilities": [
      "Guide MCP server architecture and project structure setup",
      "Create tool definitions with input validation using Pydantic or Zod",
      "Implement multiple transport options (stdio, HTTP, SSE)",
      "Build evaluation frameworks to test MCP server effectiveness",
      "Apply security best practices for API authentication and input validation",
      "Design response formats optimized for LLM context efficiency"
    ],
    "limitations": [
      "Does not provide pre-built MCP servers for specific services",
      "Does not execute MCP servers or make actual API calls to external services",
      "Does not include authentication credentials or access tokens",
      "Does not deploy or host MCP servers on remote infrastructure"
    ],
    "use_cases": [
      {
        "target_user": "Platform developers",
        "title": "Integrate external APIs",
        "description": "Build MCP servers that expose your platform API as tools for LLMs, enabling automated interactions with your service."
      },
      {
        "target_user": "AI engineers",
        "title": "Create custom LLM tools",
        "description": "Design and implement tools that extend LLM capabilities with domain-specific functionality and data access."
      },
      {
        "target_user": "DevOps teams",
        "title": "Test MCP server quality",
        "description": "Create evaluation frameworks to verify that MCP servers enable LLMs to accomplish real-world tasks effectively."
      }
    ],
    "prompt_templates": [
      {
        "title": "Build a GitHub MCP",
        "scenario": "Create MCP server for GitHub",
        "prompt": "Build an MCP server for the GitHub API using Python and FastMCP. Include tools for listing repositories, creating issues, and searching code. Follow the mcp-builder skill guidelines for tool design and response formatting."
      },
      {
        "title": "Add authentication",
        "scenario": "Secure MCP with OAuth",
        "prompt": "Add OAuth 2.1 authentication to an existing MCP server. Use environment variables for API keys. Follow security best practices from the mcp-builder skill for token validation and secure transmission."
      },
      {
        "title": "Create evaluations",
        "scenario": "Test MCP effectiveness",
        "prompt": "Create an evaluation framework for an MCP server using the evaluation.py script. Write 10 complex questions that test whether LLMs can effectively use the tools. Include questions requiring multiple tool calls and deep exploration."
      },
      {
        "title": "Optimize for production",
        "scenario": "Scale MCP server",
        "prompt": "Review an existing MCP server implementation and optimize it for production use. Add pagination support, character limits, error handling improvements, and HTTP transport option. Ensure all tools have proper input validation and documentation."
      }
    ],
    "output_examples": [
      {
        "input": "Build an MCP server for a task management API with tools to list tasks, create tasks, and update task status.",
        "output": [
          "## MCP Server: task_manager_mcp",
          "",
          "### Tools Provided:",
          "- list_tasks: List tasks with pagination and filtering",
          "- create_task: Create a new task with title, description, and priority",
          "- update_task_status: Update task status (pending, in_progress, completed)",
          "- get_task: Retrieve detailed task information",
          "",
          "### Implementation:",
          "- Uses FastMCP Python SDK",
          "- Pydantic models for input validation",
          "- Async HTTP requests with httpx",
          "- Character limit of 25,000 tokens",
          "- JSON and Markdown response formats"
        ]
      }
    ],
    "best_practices": [
      "Design tools for complete workflows, not just individual API endpoints. Consolidate related operations into cohesive tools that enable agents to accomplish tasks efficiently.",
      "Use input validation with Pydantic (Python) or Zod (TypeScript) to ensure data integrity. Include descriptive field constraints and error messages.",
      "Implement pagination and character limits to prevent overwhelming LLM context. Return has_more flags and provide guidance on filtering for large datasets."
    ],
    "anti_patterns": [
      "Avoid simply wrapping existing API endpoints as individual tools. This creates tool sprawl and requires agents to make many calls for simple tasks.",
      "Do not return exhaustive data dumps without truncation. LLMs have limited context windows, so optimize responses for information density.",
      "Avoid generic tool names without service prefixes. Use clear naming like github_create_issue instead of create_issue to prevent conflicts."
    ],
    "faq": [
      {
        "question": "Which programming languages are supported for MCP servers?",
        "answer": "Python using the FastMCP SDK and TypeScript using the MCP TypeScript SDK are both fully supported with comprehensive guides and examples."
      },
      {
        "question": "What transport options are available for MCP servers?",
        "answer": "Three transport types are supported: stdio for local subprocess execution, HTTP for web services, and SSE for real-time updates."
      },
      {
        "question": "How do I authenticate MCP servers with external APIs?",
        "answer": "Store API keys in environment variables. Implement OAuth 2.1 for external services with proper token validation before processing requests."
      },
      {
        "question": "Is data sent to external servers when using MCP servers?",
        "answer": "MCP servers you build will make network calls to the services they integrate. The evaluation scripts make calls to Anthropic API for testing."
      },
      {
        "question": "How do I test if my MCP server works effectively?",
        "answer": "Use the evaluation.py script to run test questions against your server. Create 10 complex questions requiring multiple tool calls to verify LLM effectiveness."
      },
      {
        "question": "How does this compare to building custom tools without MCP?",
        "answer": "MCP provides a standardized protocol for tool discovery, invocation, and data formatting. This enables interoperability across different LLM clients and platforms."
      }
    ]
  },
  "file_structure": [
    {
      "name": "reference",
      "type": "dir",
      "path": "reference",
      "children": [
        {
          "name": "evaluation.md",
          "type": "file",
          "path": "reference/evaluation.md"
        },
        {
          "name": "mcp_best_practices.md",
          "type": "file",
          "path": "reference/mcp_best_practices.md"
        },
        {
          "name": "node_mcp_server.md",
          "type": "file",
          "path": "reference/node_mcp_server.md"
        },
        {
          "name": "python_mcp_server.md",
          "type": "file",
          "path": "reference/python_mcp_server.md"
        }
      ]
    },
    {
      "name": "scripts",
      "type": "dir",
      "path": "scripts",
      "children": [
        {
          "name": "connections.py",
          "type": "file",
          "path": "scripts/connections.py"
        },
        {
          "name": "evaluation.py",
          "type": "file",
          "path": "scripts/evaluation.py"
        },
        {
          "name": "example_evaluation.xml",
          "type": "file",
          "path": "scripts/example_evaluation.xml"
        },
        {
          "name": "requirements.txt",
          "type": "file",
          "path": "scripts/requirements.txt"
        }
      ]
    },
    {
      "name": "LICENSE.txt",
      "type": "file",
      "path": "LICENSE.txt"
    },
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md"
    }
  ]
}
