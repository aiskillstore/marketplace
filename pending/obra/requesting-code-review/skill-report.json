{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-06T07:30:05.843Z",
    "slug": "obra-requesting-code-review",
    "source_url": "https://github.com/obra/superpowers/tree/main/skills/requesting-code-review",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "2.0.0",
    "source_type": "community",
    "content_hash": "01b8bab34c33e16747d6aef97c8b0558a5c9bdd6f78162924a968b2f92c3d708",
    "tree_hash": "f36a7f29d05b7dde007efd0d7f36e2b445f6857aa7a1e39510c639dd41eb7a7f"
  },
  "skill": {
    "name": "requesting-code-review",
    "description": "Use when completing tasks, implementing major features, or before merging to verify work meets requirements",
    "summary": "Use when completing tasks, implementing major features, or before merging to verify work meets requi...",
    "icon": "ðŸ‘€",
    "version": "1.0.0",
    "author": "obra",
    "license": "MIT",
    "category": "coding",
    "tags": [
      "code review",
      "quality assurance",
      "workflow",
      "best practices"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": []
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "Pure prompt-based skill containing only documentation and AI prompt templates. No executable code, no network calls, no filesystem access, no command execution. Completely safe for installation.",
    "risk_factor_evidence": [],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 2,
    "total_lines": 294,
    "audit_model": "claude",
    "audited_at": "2026-01-06T07:30:05.843Z"
  },
  "content": {
    "user_title": "Request code review after tasks",
    "value_statement": "Developers often miss issues until they compound. This skill provides a structured workflow for requesting AI code reviews after each task, catching bugs early before they cascade into larger problems.",
    "seo_keywords": [
      "code review skill",
      "Claude Code code review",
      "AI code review",
      "pull request review",
      "code quality",
      "bug detection",
      "software quality assurance",
      "Codex code review",
      "Claude code review",
      "code review workflow"
    ],
    "actual_capabilities": [
      "Guide git SHA collection for review diffs",
      "Dispatch code-reviewer subagent with structured prompts",
      "Categorize issues by severity (Critical, Important, Minor)",
      "Provide production readiness assessment"
    ],
    "limitations": [
      "Does not execute code or run tests automatically",
      "Requires user to provide git SHAs manually",
      "Does not integrate with CI/CD pipelines directly",
      "Only provides prompts; actual review depends on AI model"
    ],
    "use_cases": [
      {
        "target_user": "Individual developers",
        "title": "Review after each task",
        "description": "Catch bugs early in subagent-driven development by reviewing after every completed task"
      },
      {
        "target_user": "Team leads",
        "title": "Pre-merge quality gate",
        "description": "Ensure code meets standards before merging to main branch with structured checklists"
      },
      {
        "target_user": "AI agent workflows",
        "title": "Automated review workflow",
        "description": "Integrate AI code reviews into automated development pipelines and planning execution"
      }
    ],
    "prompt_templates": [
      {
        "title": "Basic review request",
        "scenario": "After completing a feature",
        "prompt": "Review my implementation. What was implemented: {WHAT_WAS_IMPLEMENTED}. Base SHA: {BASE_SHA}, Head SHA: {HEAD_SHA}. Describe the strengths, issues by severity, and whether it is ready to merge."
      },
      {
        "title": "Requirements verification",
        "scenario": "Checking against spec",
        "prompt": "Verify this implementation against the plan. Requirements: {PLAN_OR_REQUIREMENTS}. What was built: {DESCRIPTION}. Check code quality, architecture, and whether all requirements are met."
      },
      {
        "title": "Architecture review",
        "scenario": "Before refactoring",
        "prompt": "Review this code for architectural concerns. Base: {BASE_SHA}, Head: {HEAD_SHA}. Focus on scalability, performance implications, security concerns, and sound design decisions."
      },
      {
        "title": "Production readiness",
        "scenario": "Before merge",
        "prompt": "Assess production readiness. Implementation: {DESCRIPTION}. Check migration strategy, backward compatibility, documentation, error handling, and test coverage. Give clear verdict: ready, ready with fixes, or not ready."
      }
    ],
    "output_examples": [
      {
        "input": "Review my user authentication module. What was implemented: JWT token generation and validation. Base SHA: abc123, Head SHA: def456. Description: Added token creation with 1-hour expiry and validation middleware.",
        "output": [
          "**Strengths:** Clean separation of concerns, proper error handling with fallbacks",
          "**Issues:** Important - Missing token refresh mechanism, Minor - Hardcoded 1-hour expiry should be configurable",
          "**Assessment:** Ready with fixes - Core implementation solid, but refresh needed before production"
        ]
      }
    ],
    "best_practices": [
      "Review after each task in subagent-driven development to catch issues early",
      "Always collect git SHAs before requesting review for accurate diff analysis",
      "Act on feedback proportionally: fix Critical immediately, Important before proceeding, Minor note for later"
    ],
    "anti_patterns": [
      "Skipping review because code seems simple",
      "Ignoring Critical issues or proceeding with unfixed Important issues",
      "Being vague in feedback without file:line references"
    ],
    "faq": [
      {
        "question": "Which AI tools support this skill?",
        "answer": "This skill works with Claude, Codex, and Claude Code through their Task or subagent dispatch mechanisms."
      },
      {
        "question": "What git commands do I need?",
        "answer": "Run git rev-parse to get BASE_SHA (previous commit) and HEAD_SHA (current commit) for the review range."
      },
      {
        "question": "How do I integrate with CI/CD?",
        "answer": "The skill provides prompts you can call from your workflow. Add a step that collects SHAs and dispatches the review subagent."
      },
      {
        "question": "Is my code sent anywhere?",
        "answer": "No. This is a prompt-only skill. Code is only processed locally by your AI assistant and never transmitted externally."
      },
      {
        "question": "What if the AI misses issues?",
        "answer": "AI reviews complement but do not replace human review. Use findings as a starting point and apply your own judgment."
      },
      {
        "question": "How is this different from GitHub PR reviews?",
        "answer": "This provides AI-powered preliminary review. GitHub offers human collaborator comments. Use both: AI catches patterns, humans judge context."
      }
    ]
  },
  "file_structure": [
    {
      "name": "code-reviewer.md",
      "type": "file",
      "path": "code-reviewer.md"
    },
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md"
    }
  ]
}
