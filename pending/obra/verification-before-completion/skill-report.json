{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-14T00:15:18.212Z",
    "slug": "obra-verification-before-completion",
    "source_url": "https://github.com/obra/superpowers/tree/main/skills/verification-before-completion",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "3.0.0",
    "source_type": "community",
    "content_hash": "963f6b63d58d88e029181126528a1c720f76c4f8cfaec3532ece14795aef5b77",
    "tree_hash": "a47ef4ef5b04c2bc29852a290adc9789c5480fde2db005d4f45b021355653408"
  },
  "skill": {
    "name": "verification-before-completion",
    "description": "Use when about to claim work is complete, fixed, or passing, before committing or creating PRs - requires running verification commands and confirming output before making any success claims; evidence before assertions always",
    "summary": "Use when about to claim work is complete, fixed, or passing, before committing or creating PRs - req...",
    "icon": "âœ…",
    "version": "1.0.0",
    "author": "obra",
    "license": "MIT",
    "category": "coding",
    "tags": [
      "testing",
      "verification",
      "qa",
      "development"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": [
      "external_commands"
    ]
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "This skill provides guidelines for proper verification practices in software development. The static findings are false positives - the 'external_commands' references are examples of verification commands developers should run, not actual code execution. The 'weak cryptographic algorithm' finding appears to be a false positive as no cryptographic code exists. This is a documentation-only skill with no executable code.",
    "risk_factor_evidence": [
      {
        "factor": "external_commands",
        "evidence": [
          {
            "file": "SKILL.md",
            "line_start": 18,
            "line_end": 20
          },
          {
            "file": "SKILL.md",
            "line_start": 20,
            "line_end": 26
          },
          {
            "file": "SKILL.md",
            "line_start": 26,
            "line_end": 38
          },
          {
            "file": "SKILL.md",
            "line_start": 38,
            "line_end": 79
          },
          {
            "file": "SKILL.md",
            "line_start": 79,
            "line_end": 82
          },
          {
            "file": "SKILL.md",
            "line_start": 82,
            "line_end": 85
          },
          {
            "file": "SKILL.md",
            "line_start": 85,
            "line_end": 88
          },
          {
            "file": "SKILL.md",
            "line_start": 88,
            "line_end": 91
          },
          {
            "file": "SKILL.md",
            "line_start": 91,
            "line_end": 94
          },
          {
            "file": "SKILL.md",
            "line_start": 94,
            "line_end": 97
          },
          {
            "file": "SKILL.md",
            "line_start": 97,
            "line_end": 100
          },
          {
            "file": "SKILL.md",
            "line_start": 100,
            "line_end": 103
          },
          {
            "file": "SKILL.md",
            "line_start": 103,
            "line_end": 106
          }
        ]
      }
    ],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 1,
    "total_lines": 140,
    "audit_model": "claude",
    "audited_at": "2026-01-14T00:15:18.212Z"
  },
  "content": {
    "user_title": "Verify Work Before Claiming Completion",
    "value_statement": "Prevents false completion claims that damage trust and waste time. Ensures every success statement is backed by actual verification evidence.",
    "seo_keywords": [
      "verification",
      "testing",
      "quality assurance",
      "Claude",
      "Codex",
      "Claude Code",
      "software development",
      "code review",
      "best practices"
    ],
    "actual_capabilities": [
      "Prevents premature completion claims",
      "Requires verification commands before success statements",
      "Enforces evidence-based reporting",
      "Blocks commits/PRs without verification",
      "Validates test results before marking complete"
    ],
    "limitations": [
      "Cannot run actual verification commands",
      "Relies on user to execute checks",
      "Does not fix failing tests",
      "Only provides guidance framework"
    ],
    "use_cases": [
      {
        "target_user": "Software developers",
        "title": "Prevent false test success claims",
        "description": "Ensure tests actually pass before claiming completion, avoiding broken code in production"
      },
      {
        "target_user": "Code reviewers",
        "title": "Verify fixes before approval",
        "description": "Confirm bug fixes work by running verification commands before approving pull requests"
      },
      {
        "target_user": "Project managers",
        "title": "Maintain development quality standards",
        "description": "Enforce verification practices across team to reduce rework and build trust"
      }
    ],
    "prompt_templates": [
      {
        "title": "Basic verification",
        "scenario": "Before claiming tests pass",
        "prompt": "I need to verify my code works. What command should I run to test this, and how do I confirm it passes?"
      },
      {
        "title": "Build verification",
        "scenario": "Before claiming build succeeds",
        "prompt": "I want to ensure my code builds properly. What build command should I run and what output indicates success?"
      },
      {
        "title": "Requirements check",
        "scenario": "Before claiming requirements met",
        "prompt": "I need to verify all requirements are implemented. How should I check each requirement systematically?"
      },
      {
        "title": "Regression testing",
        "scenario": "Before claiming bug fixed",
        "prompt": "I fixed a bug and need to verify it works. What test should I run to confirm the fix and prevent regression?"
      }
    ],
    "output_examples": [
      {
        "input": "I've fixed the login bug",
        "output": [
          "STOP - Before claiming the bug is fixed:",
          "1. Run the failing test case that reproduced the bug",
          "2. Confirm it now passes (0 failures)",
          "3. Run the full test suite to check for regressions",
          "4. Only then state: 'Login bug fixed - test passes with 0 failures'"
        ]
      },
      {
        "input": "The build should work now",
        "output": [
          "STOP - 'Should work' is not verification",
          "1. Run the full build command",
          "2. Check exit code is 0",
          "3. Verify no compilation errors",
          "4. State: 'Build passes - exit code 0, no errors'"
        ]
      }
    ],
    "best_practices": [
      "Always run verification commands fresh before making claims",
      "Document verification evidence with your completion statements",
      "Use exact command output, not assumptions or memory"
    ],
    "anti_patterns": [
      "Claiming 'should work' without running verification",
      "Trusting previous test runs or agent reports",
      "Using vague language like 'probably' or 'seems to'"
    ],
    "faq": [
      {
        "question": "When should I use this skill?",
        "answer": "Use it whenever you're about to claim work is complete, tests pass, or bugs are fixed"
      },
      {
        "question": "What if I'm confident it will work?",
        "answer": "Confidence is not evidence. Run the verification command regardless of your certainty"
      },
      {
        "question": "Can I skip verification if I'm tired?",
        "answer": "No exceptions. Exhaustion is when mistakes happen most - verification is critical"
      },
      {
        "question": "What counts as verification evidence?",
        "answer": "Fresh command output showing 0 failures, exit code 0, or explicit success indicators"
      },
      {
        "question": "Does this apply to agent work?",
        "answer": "Yes - always verify agent reports independently before trusting completion claims"
      },
      {
        "question": "How detailed should verification be?",
        "answer": "Run the full command, check all output, verify exit codes - partial checks prove nothing"
      }
    ]
  },
  "file_structure": [
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md",
      "lines": 140
    }
  ]
}
